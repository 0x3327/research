<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>3327 Research</title>
<link>https://3327.io/documents/research/index.html</link>
<atom:link href="https://3327.io/documents/research/index.xml" rel="self" type="application/rss+xml"/>
<description></description>
<image>
<url>https://3327.io/logo.png</url>
<title>3327 Research</title>
<link>https://3327.io/documents/research/index.html</link>
<height>38</height>
<width>144</width>
</image>
<generator>quarto-1.1.163</generator>
<lastBuildDate>Sun, 28 Aug 2022 00:00:00 GMT</lastBuildDate>
<item>
  <title>[ERFC - 409] Minty - Massive off-chain minting with verifiable on-chain commitments</title>
  <dc:creator>Aleksandar Veljković</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-409.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p>Utilizing Blockchain comes with big limitations when it comes to storing a larger number of documents on the chain. Another problem arises when a large number of documents must be stored on the chain with minimal delay - real-time. In those cases, the time and financial costs may become overwhelming. This research aims to find the solution for this issue by combining off-chain issuing techniques and on-chain commitments to maximize throughput while minimizing costs from the number of transactions required to store the commitments. The solution is formulated as a hybrid (on-chain/off-chain) protocol called Minty.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>While higher utilization of Blockchain in formerly pure Web 2.0 use-cases is a trend, some obstacles prevent a smooth transition to Web 3.0. Most of those issues are known scalability issues, combined with high transaction costs. Two scalability issues closely related to the costs of using Blockchain in business are the number of transactions that could be processed in a second (TPS) and the size limit of the transaction. The TPS metric can easily trick the user into thinking that 1,000s of transactions per second would mean that he or she can submit 1,000 transactions and expect them to be included in a block after a one-second delay. Unfortunately, that assumption would be wrong, and we can prove that with a simple counter-example. Let us assume that TPS is 10,000 transactions, ten times more than the user needs. Although Blockchain protocols could indeed process 10,000 transactions per second, there could be at least 9,001 other transactions from different users waiting to be accepted. In this case, it is impossible to have 10,001 or more transactions in one block, so at least one transaction will have to wait for the next block - breaking the one-second expectation. The last nail for this assumption is the requirement to have all transaction nonces ordered correctly. If one sends 1,000 correctly ordered transactions to the miners, there are no guarantees that the miners will sort them correctly, leaving transactions out of order for the next block. As the Blockchain becomes more utilized, the issue will become more severe. To make the situation worse, some transactions may offer better gas prices than others, prioritizing them and delaying other transactions even further.</p>
<p>Another issue is submitting 1,000 transactions on an EVM blockchain, which requires at least 21,000 gas per transaction. Those amounts may quickly add up costs and disincentivize further use of Blockchain (at least use of mainnet).</p>
<p>The main question is how realistic it is to have a use case where it is required to execute 1,000s of transactions in a short time. The answer is not clear as the question is not correctly formed. If use cases, for some reason, specifically require 1,000s of separate transactions to be executed, then there is no better solution than waiting for faster blockchains. A better question might be how realistic it is to have a use case where it is required to write 1,000s of data blocks on Blockchain often. The answer might be - not a lot, but the numbers will quickly rise as soon as the more efficient solution for performing the task appears. In that case, it becomes reasonable to investigate the possibilities of having much fewer transactions than the number of data blocks and explore off-chain solutions, such as ZK proofs and signatures, to reduce the costs of writing on Blockchain.</p>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p>This research will focus on a generic example problem, minting 1,000s of generic documents in short intervals, which can be easily specialized for any use case requiring minting high volumes of data in a short time. The following sections will also present a concrete example of a real-world use case.</p>
<p>Before we get into details, we shall first define some basic assumptions. The worst-case scenario is putting the data of each document on Blockchain in separate transactions. The more reasonable scenario is writing documents in batches of <embed src="https://latex.codecogs.com/svg.latex?n" title="n" class="img-fluid"> per transaction. Let us assume that a document consists of <embed src="https://latex.codecogs.com/svg.latex?k" title="k" class="img-fluid"> bytes32 elements. The minimum gas required to run a transaction is 21,000 gas and 2,000 more to store one <code>bytes32</code> element. Another restriction is the upper limit of the gas amount per block, which is 30,000,000 on Ethereum. Assuming a very farfetched case where:</p>
<ul>
<li>TPS is 1,000 (currently much lower)</li>
<li>One user gets to have all transactions in all blocks until the document storing is complete (possible only on private chains)</li>
<li>Every document consists of only five <code>bytes32</code> elements (a reasonable amount of data)</li>
<li>One transaction contains 30 documents (reasonable limitation)</li>
</ul>
<p>The number of transactions in a block would be ~93, which enables storing only 2790 documents per second. On the other hand, having a low gas price of 10 gwei, for 30,000,000 gas, the cost would be 0.3 native coins. On Ethereum, with the price of $1500, the cost would be 0.3 * $1500 = $500. Executing the same transaction on Polygon L2, the price would be only 0.7 * $1 = $0.7. This is the price for having 2790 documents stored on-chain under pretty unreal circumstances. To store all 100,000 documents, the total cost would be ~12 coins ($18000 on Ethereum and $12 on Polygon), which would take around 36 seconds. To summarize, the lowest theoretical boundary for storing 100,000 * 5 <code>bytes32</code> elements, under given circumstances, is 36 seconds and $12. In practice, the time delay would be much higher as executing ~3,333 transactions from one user in 36 seconds would only be possible on a private chain.</p>
<p>What if the requirement is to store data of 100,000 documents in 10 seconds with a high probability? How could it be achieved? The only way to reduce the number of transactions executed on Blockchain is to reduce the amount of data that has to be written. There is, of course, a possibility to increase the number of documents in a batch, but we are already hitting the boundary with that in the previous example. When there is a requirement to store exactly 100,000 documents, there are two options: - Compress the data to have more of the smaller documents in batches; the example would be storing hashes of data. - Store no data but generate signed documents off-chain - Store single commitments for multiple data; the example would be storing a root hash of a Merkle tree built from documents.</p>
<p>In each case, we assume the user will receive proof that the document belongs to a commitment and can materialize (mint) its data on the chain by providing the proof.</p>
<p>The first solution might be tempting for smaller amounts of data. However, it reduces the number of transactions for a constant factor (5 in the previous example), which would not be very helpful when data quantity increases.</p>
<p>The second solution is very similar to OWT and represents an ideal solution from a theoretical perspective. However, the issue arises from the time required to generate a large number of signatures, which is much higher than a Merkle tree construction time. The comparison is provided in the results section.</p>
<p>The third option is more suitable for handling large quantities of data, as it scales much better. On the other hand, the construction of the Merkle tree grows exponentially with the number of documents, so the time required to generate bigger trees adds another limit to the number of documents processed in a given time after a certain threshold. Nevertheless, the Merkle tree solution has better potential, as one can generate multiple Merkle trees in parallel (on multicore processors or multiple servers), which can scale document processing to another level. This fact leads us to an outstanding balance between the number of transactions, the number of processed documents, and the time required to prepare and write the data - the parallel computation of multiple Merkle tree roots and writing multiple roots in one transaction. In this scenario, there are better guarantees that a single storage transaction will be executed in 10 seconds while storing <embed src="https://latex.codecogs.com/svg.latex?k" title="k" class="img-fluid"> Merkle roots of <embed src="https://latex.codecogs.com/svg.latex?n" title="n" class="img-fluid">-document trees. Can we go even further? For a few milliseconds more, another tree could be formed from the roots of the trees generated in parallel - leading to one tree with <embed src="https://latex.codecogs.com/svg.latex?m" title="m" class="img-fluid"> subtrees and <embed src="https://latex.codecogs.com/svg.latex?O%28log_%7B2%7D%29" title="O(log_{2})" class="img-fluid"> extra levels. This upgrade results in storing only one root hash for the entire set with <embed src="https://latex.codecogs.com/svg.latex?m" title="m" class="img-fluid"> subtrees generated in parallel for a few times speedup. There is also one more concern regarding parallelization. It is not the case that having 10,000 parallel processes will always result in 10,000 times speedup. The overhead communication between processes adds a slowdown. The results from the following section show the example of speedup achieved when creating Merkle trees in parallel workers.</p>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<p>The assumption of efficiently generating Merkle roots in a parallel way, as data commitments, was put to the test. A simple but representative use case assumed storing trading cards on Blockchain (similar to NFTs but more straightforward). The card consists of an ID, image number (associated with image URL) and owner address. The goal was to enable storing commitments of 100,000 cards in 10 seconds. The flow consisted of generating <embed src="https://latex.codecogs.com/svg.latex?k" title="k" class="img-fluid"> Merkle trees with <embed src="https://latex.codecogs.com/svg.latex?l" title="l" class="img-fluid"> leaves sequentially until all cards had been committed. The resulting roots were used to generate a “cap” Merkle tree, and inclusion proofs for the cards were generated from the subtrees and extended with respective “cap” proofs. In the end, each card had a root commitment stored on Blockchain and inclusion proof generated for the end user to claim or transfer the card. Multiple tests estimated the speed of generating Merkle trees and all of the proofs under different conditions. The variables were the number of leaves and workers that generated trees. One worker generated one tree. The results showed that parallel tree generation achieved, on average, 3.5x - 4x speedup on a 2.6 GHz 6-Core Intel Core i7 CPU. Leaves of the trees were <code>keccak256</code> hashes of card data: - <code>uint256 id</code> - <code>uint256 imageId</code> - <code>address owner</code></p>
<p>The following charts represent the time and speedup results when using parallel tree generation.</p>
<br>
<center>
<img src="https://3327.io/documents/research/assets/ERFC-409/speedup.png" class="img-fluid"> <br> <i>Speedup in number of processed leaves per second when generating multiple trees in parallel compared to a single tree with the same number of leaves. The results assume not just tree generation but also proof generation for all leaves of all trees</i>
</center>
<center>
<p><br></p>
<p><img src="https://3327.io/documents/research/assets/ERFC-409/time-required.png" class="img-fluid"> <br> <i>Chart of the time required to generate all proofs when using different number of workers in parallel</i></p>
</center>
<p>As expected, the time delays increase exponentially with the number of leaves. The speedup of ~4x correlates with the number of CPU cores left available for the workers minus the overhead from communication costs when moving larger data (proofs) between parallel workers and the parent process. We can notice that even with only 20 parallel processes, the communication overhead is clearly observable. Also, 20 parallel workers could generate <embed src="https://latex.codecogs.com/svg.latex?20%20%5Ccdot%2016384%20%3D%20327680" title="20 \cdot 16384 = 327680" class="img-fluid"> proofs in ~7.5 seconds, much greater than the targeted 100,000 documents per second. However, this computation does not count in the time required for generating document hashes and sending commitment storage transactions on Blockchain.</p>
<p>Nevertheless, the results gave us some insights into the parameter values. Additionally, the time required to generate document signatures in parallel was also evaluated, as the off-chain signature issuing approach was a direct competitor of the Merkle tree approach. The results show that the parallel Merkle tree generation approach wins this comparison up to a large number of documents, as the time complexity for generating multiple signatures grows linearly with the number of documents but with much higher base costs. It is important to note that the signature generation results do not discard the possibility of using the signature approach but show that the Merkle trees are a more efficient approach.</p>
<center>
<p><br></p>
<p><img src="https://3327.io/documents/research/assets/ERFC-409/signature-time.png" class="img-fluid"> <br> <i>Chart of the time required to generate all signatures when using different number of workers in parallel</i></p>
</center>
<p><br></p>
<p>The full test consisted of generating document hashes for 1,000,000 documents, generating commitments for 100,000 documents per batch using up to 20 parallel workers with a maximum of 16,384 leaves. Finally, the resulting commitment was sent to Blockchain (Ganache) asynchronously after each batch. The time required for the entire process to complete and store all 1,000,000 document commitments as root hashes of batches was ~55s, or ~180,000 processed documents per 10s. The costs of storing commitments on L2 chain like Polygon would be around $27 per day (having the gas price of 100 gwei), for storing commitments of 1.44 billion documents.</p>
<p>The parameters can and should, be tuned according to the use case. Suppose the number of documents that should be processed per second is insignificant, and higher delays are allowed. In that case, 1,000,000 or more documents could easily be represented as one commitment stored on Blockchain. This approach allows for semi-real-time document processing with minimal delay.</p>
<section id="document-materialization-on-blockchain" class="level2">
<h2 class="anchored" data-anchor-id="document-materialization-on-blockchain">Document materialization on Blockchain</h2>
<p>The smart contract consists of functions for storing commitments and functions used to mint the cards from commitment proofs. The owner of the commitment proof mints the card by providing card data to the smart contract along with inclusion proof and the ID of the corresponding commitment. The smart contract verifies the proof and mints a new card with the given data. The card owner can only do the minting as the message sender’s address is used for the owner’s address. The owner can also mint the card to a different address, where the same process applies, with the only difference being the card minted with a different owner’s address. The one-time overhead costs for the users to mint and/or transfer their documents on the chain are minimal, especially when L2 solutions, like Polygon, are used.</p>
<p>The entire protocol for generating a massive number of documents using off-chain proofs and commitments was assigned the name <b>Minty</b>.</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>The results show that the approach of using parallel off-chain proof generation and storing commitments on the chain enables semi-real-time minting of a massive number of documents with high saves in costs when compared to direct on-chain minting. The example use-case can be further expanded to cover NFTs or any other types of documents which could be minted on the chain. Future research should cover specific applications of the presented protocol and estimate its value in various use cases.</p>


</section>

 ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-409.hugo.html</guid>
  <pubDate>Sun, 28 Aug 2022 00:00:00 GMT</pubDate>
  <media:content url="https://latex.codecogs.com/svg.latex?n " medium="image"/>
</item>
<item>
  <title>Introduction to Avalanche</title>
  <dc:creator>Uros Kukic</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-336.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p>While Bitcoin and Ethereum represent the most popular networks in the Web3 space, they also face technical limitations for practical mass adoption. New networks were developed to address these limitations with novel technologies and approaches. To better understand these innovations and their advantages, this paper looks into one of these networks, Avalanche.</p>
<p>This paper aims to give an overview of the technical architecture of the Avalanche network, as well as present the reader with the technologies they would encounter when developing on the Avalanche network.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>This document aims to give an introduction to the Avalanche network. By describing the consensus mechanism and the network architecture, we can better understand how to develop solutions on it.</p>
<p>This paper looks at the technologies one would encounter when using the Avalanche network. It briefly describes their function, how they can be used, their limitations, and possible improvements in the future.</p>
<section id="components-of-the-avalanche-network" class="level2">
<h2 class="anchored" data-anchor-id="components-of-the-avalanche-network">Components of the Avalanche network</h2>
<p>The Avalanche network is a modular system, so before we describe how the entire network works, we will define the components that form the Avalanche network. Afterward, we can explore how those components interconnect and how each component function works in detail.</p>
<section id="blockchains" class="level3">
<h3 class="anchored" data-anchor-id="blockchains">Blockchains</h3>
<p>When we refer to Blockchains on the Avalanche network, we refer to virtual machines. Every node on a particular network runs that network’s virtual machine (or machines). They dictate valid states, as well as the rules for transitioning between those states.</p>
<p>These virtual machines can be customized to better suit the needs of the product that will use them. In general, one can change the initial state of the blockchain or the state transition rules. For example, one can change how transaction fees are calculated and distributed, or how the funds are distributed initially.</p>
<p>In a later section, we will explore the technical details and different available virtual machines on the Avalanche network.</p>
</section>
<section id="validators" class="level3">
<h3 class="anchored" data-anchor-id="validators">Validators</h3>
<p>Different nodes communicate with each other on the Avalanche network to form the decentralized system. Nodes that run a virtual machine and receive and validate new transactions are considered validators. The validator nodes stake some amount of AVAX and receive rewards for their work.</p>
</section>
<section id="subnets" class="level3">
<h3 class="anchored" data-anchor-id="subnets">Subnets</h3>
<p>A Subnet is a sovereign network that defines its own rules regarding membership and token economics. It is composed of a dynamic subset of Avalanche validators working together to achieve consensus on the state of one or more blockchains. Each blockchain is validated by exactly one Subnet, and a Subnet can have many blockchains. A validator may be a member of many Subnets.</p>
<center>
<p><img src="https://3327.io/documents/research/assets/ERFC-336/Subnets.png" class="img-fluid"></p>
<p>Figure 1: Avalanche subnets overview</p>
<p><em>Source: docs.avax.network</em></p>
</center>
<p>Subnets are independent; they specify their own execution logic, determine their own fee regime, maintain their own state, facilitate their own networking, and provide their own security. They do not share the execution thread, storage, or networking with other Subnets.<sup>1</sup></p>
<p>With all components of the Avalanche network shown, we can demonstrate how they combine together using the Avalanche Primary network as an example.</p>
<p><strong>The primary network</strong></p>
<p>Every validator is a member of Avalanche’s built-in public Subnet, called the Primary network. Validators can be members of as many Subnets as they choose, but they must be members of the Primary network along with them.</p>
<p>The Primary network is comprised of three blockchains:</p>
<ol type="1">
<li><p>The Platform Chain (P-chain) is the metadata blockchain on Avalanche and coordinates validators, keeps track of active Subnets, and enables the creation of new Subnets.<sup>2</sup></p></li>
<li><p>The Contract Chain (C-chain) is a blockchain compatible with the Ethereum Virtual Machine. It enables creating and using smart contracts similarly to how they function on the Ethereum network.</p></li>
<li><p>The Exchange Chain (X-chain) is a blockchain for creating and trading digital assets.<sup>3</sup></p></li>
</ol>
<center>
<p><img src="https://3327.io/documents/research/assets/ERFC-336/Chains.png" class="img-fluid"></p>
<p>Figure 2: The Avalanche primary network chains</p>
<p><em>Source: docs.avax.network</em></p>
</center>
</section>
</section>
<section id="avalanche-consensus-protocol" class="level2">
<h2 class="anchored" data-anchor-id="avalanche-consensus-protocol">Avalanche Consensus Protocol</h2>
<p>For the network to function, the validators need to agree on the state of the blockchain they contain. The process through which they reach this agreement is called a consensus protocol. By ensuring that only valid transactions will be included in the final state of the network, consensus protocols provide security on the network.</p>
<p>The Avalanche Network uses a novel consensus protocol called Avalanche protocol, which functions by randomly subsampling the network multiple times.</p>
<center>
<p><img src="https://3327.io/documents/research/assets/ERFC-336/Mechanism.png" class="img-fluid"></p>
<p>Figure 3: Avalanche consensus mechanism</p>
<p><em>Source: docs.avax.network</em></p>
</center>
<p>When a validator receives a transaction, it checks that the transaction metadata is valid (e.g., the transaction signature is valid, the sender has enough funds to execute the transaction, and such). After confirming the transaction validity locally, the validator selects <em>n</em> nodes randomly if they also consider the transaction valid. If <em>α</em> of those <em>n</em> nodes consider the transaction valid, the round is considered successful. This concludes one successful round, and the process is repeated, starting from the selection of n nodes. If <em>β</em> consecutive rounds are successful, the transaction is accepted, and the state of the blockchain is updated.</p>
<p>In order to increase the throughput of the blockchain, the Avalanche protocol creates a Directed Acyclic Graph (DAG) that represents state changes of the blockchain. A set of transactions is considered a vertex in the DAG. How this data structure functions will be explored further in subsequent research, as it is not the focal point of this document.</p>
<p><strong>Snowman Consensus Protocol</strong></p>
<p>Snowman is a modification of the Avalanche Consensus Protocol, which creates a linear chain of vertices instead of a DAG. This modification is similar to how most decentralized blockchains work, with each vertex representing a block of transactions.</p>
<p>While the X-Chain uses the Avalanche Consensus Protocol, it is noteworthy that the C-chain and X-chain utilize the Snowman protocol for simplicity.</p>
</section>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p>In this section, we will present the experience of a developer starting to develop solutions on the Avalanche network. First we’ll cover the experience of developing a subnet and afterwards the experience of developing a decentralized application (dApp) on the Avalanche network.</p>
<section id="subnet-development" class="level2">
<h2 class="anchored" data-anchor-id="subnet-development">Subnet development</h2>
<p>The official Avalanche documentation<sup>4</sup> offers plenty of subnet creation and deployment guides of increasing complexity to introduce the reader to various aspects of the network.</p>
<p>The Create an EVM Subnet on a Local Network<sup>5</sup> guide enables one to run a subnet locally without worrying about too many dependencies or steps during the setup. The guide explains how to locally create a subnet with five validators and an EVM-compatible blockchain called Subnet-EVM. The guide also gives additional steps on how to stop and start the Subnet or redeploy it.</p>
<p>The following guide<sup>6</sup> instructs the user how to deploy the Subnet used in the previous guide on the Fuji testnet. With detailed instructions, one can follow the menus in the CLI wizard and have a subnet registered on the testnet. The only significant difference is that validators are not automatically created; they need to be added to the Subnet after the deployment.</p>
<p>The subsequent guides require running an Avalanche node, for which one would likely need to install the AvalancheGo<sup>7</sup> and Subnet-CLI<sup>8</sup> libraries. These dependencies raise the level of complexity when working with Avalanche but are foundational for deploying subnets on the production network and unlock the potential to customize node functionality.</p>
<p>After deploying a subnet on the testnet, we worked on customizing a subnet’s virtual machine<sup>9</sup>. By altering the genesis block, we modified the transaction fee calculation. However, the Avalanche guides also offer instructions on building a virtual machine from scratch that the Subnet will use.</p>
<p>Due to the scope of this research, we did not explore the topic further, but we hope to explore customizing subnets and virtual machines which use them deeper.</p>
</section>
<section id="dapp-development" class="level2">
<h2 class="anchored" data-anchor-id="dapp-development">dApp Development</h2>
<p>As we previously mentioned, smart contracts are used on Avalanche C-Chain; thus, the development of dApps is done through that same type of chain. Luckily, the virtual machines used in subnet guides are primarily using Subnet-EVM. This enables developers to use the same “dummy” subnets for dApp development.</p>
<p>The first step for dApp developers should be connecting to a local Subnet using Remix and Metamask, two well-known tools for smart contract development. Using these tools will introduce communicating with subnets to the developer.</p>
<p>For developing more advanced dApps on Avalanche, we used Hardhat for connecting to the Avalanche C-Chain on the Fuji network. After customizing the Hardhat configuration file with the appropriate RPC endpoints, smart contract deployment was identical to the deployment experience on the Ethereum network.</p>
<p>More research is required to validate more complex functionalities, but we expect that most frameworks and tools available for Ethereum dApp development will also work on Avalanche.</p>
</section>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<p>In this section, we will technologies we’ve encountered in the previous section, with a brief explanation of how and why we’ve utilized them and our experience with using those technologies.</p>
<section id="languages" class="level2">
<h2 class="anchored" data-anchor-id="languages">Languages</h2>
<ol type="1">
<li><p><strong>GoLang</strong></p>
<p>Both the Avalanche node implementation and coreth, the virtual machine the c-chain implements, are written in Go. For anyone looking to start developing on the Avalanche network, especially using custom subnets, Go is a language with which they should get acquainted.</p></li>
<li><p><strong>Solidity</strong></p>
<p>For developers who want to create and deploy their own dApps, Solidity is the most employed language for writing smart contracts, which are essential for almost any dApp.</p>
<p>It was built for creating smart contracts on the Ethereum network. However, the Avalanche network’s compatibility with the Ethereum virtual machine means that this language (and all its tools) is available to developers.</p>
<p>Due to its widespread usage, available resources, and tooling, we recommend this language for any developer looking to create dApps on the Avalanche network’s C-Chain.</p></li>
<li><p><strong>NodeJS</strong></p>
<p>Besides Go libraries for communicating with the Avalanche network, developers can also use AvalancheJS to access the Avalanche network using JavaScript.</p>
<p>Coupled with numerous NodeJS libraries for smart contract development, for any developer wanting to create a dApp, we recommend learning NodeJS.</p></li>
</ol>
</section>
<section id="tools" class="level2">
<h2 class="anchored" data-anchor-id="tools">Tools</h2>
<ol type="1">
<li><p><strong>Avalanche-CLI</strong></p>
<p>The Avalanche-CLI is a tool that enables users to create and deploy subnets. With simple-to-use commands, developers can quickly run a Subnet locally and later deploy them on the Avalanche Fuji testnet.</p>
<p>At the time of writing, it supports the following:</p>
<ul>
<li>Creation of Subnet-EVM configs and Subnet-EVM forks</li>
<li>Local deployment of Subnet-EVM-based Subnets</li>
<li>Fuji deployment of Subnet-EVM-based Subnets</li>
</ul>
<p><strong>Our experience</strong></p>
<p>Avalanche-CLI is a great tool for quickly having something running on one’s machine. It does not require a lot of setup or complicated commands. One can interact with an Avalanche subnet with just five commands using common Ethereum tools like Remix and Metamask.</p>
<p>The downside to that ease of use is its limited functionality. The authors note that Avalanche-CLI is under active development and early in its lifecycle, so expect frequent changes and certain limitations with what one can do with it.</p>
<p>At the time of writing, it seems that only Subnet EVM is supported as the blockchain for the Subnet. One can edit the genesis file, enabling customizations of transaction fees, initial fund allocation, consensus, gossip, and validator communication. While this level of customization is quite a lot for someone just getting into the Avalanche network, we expect it is not enough for teams or products that want to deploy custom virtual machines highly tailored for their use case.</p></li>
<li><p><strong>AvalancheGo</strong></p>
<p>As the node implementation for the Avalanche network, AvalancheGo<sup>10</sup> is a foundational library one needs for Avalanche development. Besides running a node instance (which connects to the Avalanche network), the library also enables a wide berth of RPC endpoints for:</p>
<ul>
<li>Interacting with the P-Chain, C-Chain, and X-Chain</li>
<li>Examining the node’s internal state, health, basic information, and statistics</li>
<li>Manage authorization tokens</li>
<li>Fetch transactions, vertices, or blocks</li>
</ul>
<p><strong>Our Experience</strong></p>
<p>During this research, we used AvalancheGo to run our nodes on the Fuji testnet and were able to customize it to communicate with our custom subnet. We also used it together with Avalanche Network Runner and Subnet-CLI to build a custom virtual machine for our Subnet. As such, it was more used as a dependency for other Avalanche tools, and we only had limited interaction with it.</p>
<p>The library functioned without many issues. However, we do have to warn the reader to pay attention to the location of the installation, as quite a few guides assume the default installation location. Installing the library at a non-default location caused unnecessary difficulty following some guides and using other Avalanche network tools.</p>
<p>Since it is an integral library on the Avalanche network, we hope to dive deeper into this library in subsequent research efforts to learn its capabilities and limitations.</p></li>
<li><p><strong>Subnet-CLI</strong></p>
<p>A tool for managing Subnets on the Avalanche production network, this command line interface enables the user to create a new subnet, define its validators, and create and check the status of the blockchain for the Subnet.</p>
<p>Subnet-CLI is also required to build custom node configurations using the Avalanche Network Runner tool.</p>
<p><strong>Our experience</strong></p>
<p>At the time of research, Subnet-CLI was the only tool available for creating a Subnet on the Fuji testnet, so it is a winner in its category by default. Subsequently, Avalanche-CLI was updated to support this functionality, and we found it more straightforward to use than Subnet-CLI.</p>
<p>For now, Subnet-CLI seems to be the primary way to deploy a subnet on the Avalanche production network. However, Avalanche subnet libraries are still in rapid development. As such, we would recommend comparing the functionalities of Subnet-CLI and Avalanche-CLI to see which one has the capabilities the reader requires.</p></li>
<li><p><strong>Avalanche Network Runner</strong></p>
<p>The Avalanche Network Runner allows a user to define, create and interact with a network of Avalanche nodes. It can be used for development and testing. It aims at being a tool for developers and system integrators alike, offering functionality to run networks of AvalancheGo nodes. It also has support for custom node, Subnet, and network configurations, allowing to locally test code before deploying to the mainnet or public testnets<sup>11</sup>.</p>
<p>Although the tool has more dependencies and slightly more complicated commands than Avalanche-CLI, Avalanche Network Runner enables customized configuration for each node individually and more detailed logging when accessing the Subnet via API.</p>
<p><strong>Our experience</strong></p>
<p>We utilized the Avalanche Network Runner to create a Subnet of 5 nodes locally and to add a new node after subnet deployment. The experience was straightforward; we only encountered difficulty setting up the tool’s dependencies.</p>
<p>The ability to use the Avalanche Network Runner as a library enables the developer to set up scripts and access a subnet programmatically. This key feature enables faster testing and development of subnets, making ANR invaluable for developers.</p>
<p>As Avalanche Network Runner is intended as a tool for development and testing, we hope to utilize it more in subsequent research when we further cover developing subnets. In that research, we hope to give a more comprehensive description of this tool.</p></li>
<li><p><strong>Avalanche wallet</strong></p>
<p>The Avalanche wallet is a web application that allows users to create a new wallet or access their existing one. The app shows the wallet balance for each chain and any assets or collectibles the wallets hold.</p>
<p>Users can access their wallets using a private key, mnemonic phrase, keystore file, or a hardware ledger wallet. Access using Metamask is not available at the time of writing.</p>
<p>Inside the app, users can access their wallet address for each Avalanche network chain, send assets and collectibles (or create new collectibles), or send AVAX from one chain to another. Applying for staking or delegating is also available through the web wallet, as well as a view of previously executed transactions and UTXOs.</p>
<p><strong>Our experience</strong></p>
<p>We have used Avalanche wallet when registering a subnet on the Avalanche Fuji testnet for transferring funds between different Avalanche chains. Its missing feature to connect to Metamask does degrade the user experience, but overall the process was straightforward.</p>
<p>Although this paper primarily focuses on development tools, we wanted to mention the Avalanche wallet as something a developer will come across when deploying a subnet on the Fuji testnet, as the faucet transfers AVAX to the wallet on the X-Chain, and a transfer is necessary.</p></li>
<li><p><strong>Remix, Metamask, and Hardhat</strong></p>
<p>In this section, we wanted to mention some Ethereum tools we have used in Avalanche development and how they operated. For more details on specific tools from this group, check out our Web3 Technology Radar<sup>12</sup></p>
<p><strong>Our experience</strong></p>
<p>We used Remix and Metamask to deploy and interact with smart contracts on a local EVM compatible Subnet, and Hardhat for deploying a sample dApp on the Avalanche Fuji testnet.</p>
<p>Aside from customizing the RPC endpoint these tools use and the chain ID, these tools worked seamlessly with local and public Avalanche networks. As we mentioned, while we want to test more tools made for Ethereum on Avalanche in future research, we do not expect many issues with them functioning the same way on Avalanche as they would on Ethereum.</p></li>
</ol>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>In this research, we have described the three main components of the Avalanche network, how they interact to form subnets of validators with specific chains, and the underlying consensus mechanism for those chains. We have also given an overview of the guides and topics one would encounter when starting to work on Avalanche for the first time. Lastly, we have given a list of the technologies a developer should know when working with Avalanche and our experience with them.</p>
<p>We hope to have provided the reader with the foundational understanding of the Avalanche Network, its components, and introductory projects, which will enable them to decide whether Avalanche is a good choice for their use case and how they can get started if it is.</p>
<p>We hope to explore the Avalanche ecosystem further in subsequent research, specifically creating more customized virtual machines and testing, deploying, and monitoring subnets on the Avalanche production network. This research would also include measuring a subnet’s performance and programmatical use of the development tools to test network behavior before deployment.</p>
<p>The Avalanche network’s X-Chain is another subject we would like to research further. Its directed acyclic graph, the data structure of the chain, and high throughput are interesting subjects we would like to explore more comprehensively.</p>
</section>
<section id="bibliography" class="level1">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Bibliography</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-avalabsAvalancheDocs" class="csl-entry">
Ava Labs, ‘Avalanche Docs’, <em>Avalanche Docs</em> &lt;<a href="https://docs.avax.network/" class="uri">https://docs.avax.network/</a>&gt; [accessed 2 August 2022]
</div>
<div id="ref-avalabsAvalancheNetworkRunner" class="csl-entry">
———, ‘Avalanche Network Runner’, <em>Avalanche Network Runner</em> &lt;<a href="https://docs.avax.network/subnets/network-runner" class="uri">https://docs.avax.network/subnets/network-runner</a>&gt; [accessed 7 August 2022]
</div>
<div id="ref-avalabsAvalanchePlatform" class="csl-entry">
———, ‘Avalanche Platform’, <em>Avalanche Platform</em> &lt;<a href="https://docs.avax.network/overview/getting-started/avalanche-platform" class="uri">https://docs.avax.network/overview/getting-started/avalanche-platform</a>&gt; [accessed 2 August 2022]
</div>
<div id="ref-avalabsAvalancheGo" class="csl-entry">
———, ‘AvalancheGo’, <em>AvalancheGo Github Repository</em> &lt;<a href="https://github.com/ava-labs/avalanchego" class="uri">https://github.com/ava-labs/avalanchego</a>&gt; [accessed 7 August 2022]
</div>
<div id="ref-avalabsAvalancheGoAPIsOverview" class="csl-entry">
———, ‘AvalancheGo APIs Overview’, <em>AvalancheGo APIs Overview</em> &lt;<a href="https://docs.avax.network/subnets/customize-a-subnet" class="uri">https://docs.avax.network/subnets/customize-a-subnet</a>&gt; [accessed 3 August 2022]
</div>
<div id="ref-avalabsCreateEVMSubnet" class="csl-entry">
———, ‘Create an EVM Subnet on a Local Network’, <em>Create an EVM Subnet on a Local Network</em> &lt;<a href="https://docs.avax.network/subnets/create-a-local-subnet" class="uri">https://docs.avax.network/subnets/create-a-local-subnet</a>&gt; [accessed 2 August 2022]
</div>
<div id="ref-avalabsCreateEVMSubneta" class="csl-entry">
———, ‘Create an EVM Subnet on Fuji Testnet’, <em>Create an EVM Subnet on Fuji Testnet</em> &lt;<a href="https://docs.avax.network/subnets/create-a-fuji-subnet" class="uri">https://docs.avax.network/subnets/create-a-fuji-subnet</a>&gt; [accessed 3 August 2022]
</div>
<div id="ref-avalabsCustomizeYourEVMPowered" class="csl-entry">
———, ‘Customize Your EVM-Powered Subnet’, <em>Customize Your EVM-Powered Subnet</em> &lt;<a href="https://docs.avax.network/subnets/customize-a-subnet" class="uri">https://docs.avax.network/subnets/customize-a-subnet</a>&gt; [accessed 3 August 2022]
</div>
<div id="ref-avalabsSubnetCLI" class="csl-entry">
———, ‘Subnet-CLI’, <em>Subnet-CLI | Avalanche Docs</em> &lt;<a href="https://docs.avax.network/subnets/subnet-cli" class="uri">https://docs.avax.network/subnets/subnet-cli</a>&gt; [accessed 7 August 2022]
</div>
<div id="ref-avalabsSubnetsOverview" class="csl-entry">
———, ‘Subnets Overview’, <em>Subnets Overview</em> &lt;<a href="https://docs.avax.network/subnets" class="uri">https://docs.avax.network/subnets</a>&gt; [accessed 2 August 2022]
</div>
<div id="ref-mvpworkshopWeb3TechnologyRadar" class="csl-entry">
MVP Workshop, ‘Web3 Technology Radar’, <em>Web3 Technology Radar</em> &lt;<a href="https://web3radar.3327.io/tech-radar" class="uri">https://web3radar.3327.io/tech-radar</a>&gt; [accessed 7 August 2022]
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Ava Labs, ‘Subnets Overview’, <em>Subnets Overview</em> &lt;&lt;https://docs.avax.network/subnets&gt;&gt; [accessed 2 August 2022].↩︎</p></li>
<li id="fn2"><p>Ava Labs, ‘Avalanche Platform’, <em>Avalanche Platform</em> &lt;&lt;https://docs.avax.network/overview/getting-started/avalanche-platform&gt;&gt; [accessed 2 August 2022].↩︎</p></li>
<li id="fn3"><p>Ava Labs, ‘Avalanche Platform’.↩︎</p></li>
<li id="fn4"><p>Ava Labs, ‘Avalanche Docs’, <em>Avalanche Docs</em> &lt;&lt;https://docs.avax.network/&gt;&gt; [accessed 2 August 2022].↩︎</p></li>
<li id="fn5"><p>Ava Labs, ‘Create an EVM Subnet on a Local Network’, <em>Create an EVM Subnet on a Local Network</em> &lt;&lt;https://docs.avax.network/subnets/create-a-local-subnet&gt;&gt; [accessed 2 August 2022].↩︎</p></li>
<li id="fn6"><p>Ava Labs, ‘Create an EVM Subnet on Fuji Testnet’, <em>Create an EVM Subnet on Fuji Testnet</em> &lt;&lt;https://docs.avax.network/subnets/create-a-fuji-subnet&gt;&gt; [accessed 3 August 2022].↩︎</p></li>
<li id="fn7"><p>Ava Labs, ‘AvalancheGo’, <em>AvalancheGo Github Repository</em> &lt;&lt;https://github.com/ava-labs/avalanchego&gt;&gt; [accessed 7 August 2022].↩︎</p></li>
<li id="fn8"><p>Ava Labs, ‘Subnet-CLI’, <em>Subnet-CLI | Avalanche Docs</em> &lt;&lt;https://docs.avax.network/subnets/subnet-cli&gt;&gt; [accessed 7 August 2022].↩︎</p></li>
<li id="fn9"><p>Ava Labs, ‘Customize Your EVM-Powered Subnet’, <em>Customize Your EVM-Powered Subnet</em> &lt;&lt;https://docs.avax.network/subnets/customize-a-subnet&gt;&gt; [accessed 3 August 2022].↩︎</p></li>
<li id="fn10"><p>Ava Labs, ‘AvalancheGo APIs Overview’, <em>AvalancheGo APIs Overview</em> &lt;&lt;https://docs.avax.network/subnets/customize-a-subnet&gt;&gt; [accessed 3 August 2022].↩︎</p></li>
<li id="fn11"><p>Ava Labs, ‘Avalanche Network Runner’, <em>Avalanche Network Runner</em> &lt;&lt;https://docs.avax.network/subnets/network-runner&gt;&gt; [accessed 7 August 2022].↩︎</p></li>
<li id="fn12"><p>MVP Workshop, ‘Web3 Technology Radar’, <em>Web3 Technology Radar</em> &lt;&lt;https://web3radar.3327.io/tech-radar&gt;&gt; [accessed 7 August 2022].↩︎</p></li>
</ol>
</section></div> ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-336.hugo.html</guid>
  <pubDate>Thu, 28 Jul 2022 00:00:00 GMT</pubDate>
  <media:content url="https://3327.io/documents/research/assets/ERFC-336/Subnets.png" medium="image" type="image/png" height="83" width="144"/>
</item>
<item>
  <title>[ERFC - 278] Meritocratic voting</title>
  <dc:creator>Milan Pavlovic</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-278.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p>We considered a setting where a resource or rights are to be distributed among participants/members of a group. One possibility would be to allocate it equally (we can call this system democratic), another possibility would be to allocate it proportionally to relative efforts made, this system is known as meritocratic (based on credits earned).</p>
<p>We are mainly interested in the voting system (for example for DAOs), but believe that a similar system could be used in many other situations.</p>
<p>Prior to June, some of the existing solutions solves a good way process of weighted voting (MACI), and some (Colony) provide the solution for calculating reputation rating. Both have their missings - the role of coordinator in MACI, lack of ZK in Colony, for example. In the last weeks, Polygon came out with their PoligonID - web3 virtual identity which can store various data and uses ZK. It could be a great solution, after some testing and research, and one of its use cases could be Meritocratic voting. We could do deep dive into PolygonID and find others applications of it too, beside Meritocratic voting. It’s very new solution and we could be one of first adopters.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>We considered setting where a resource or rights are to be distributed among participants/members of group. One possibility would be to allocate it equally (we can call this system democratic), another possibility would be to allocate it proportionaly to relative efforts made, this system is known as meritocratic (based on credits earned).</p>
<p>We are mainly interested in voting system (for example for DAOs), but believe that similar system could be used in many other situations.</p>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p>The steps of this research include:</p>
<ul>
<li><p>Research use of blockchain as infrastructure for governance</p></li>
<li><p>Researching known practices, solutions, and implementations (eg. Aragon, Polkadot, Colony, MACI, PolygonID)</p></li>
<li><p>Research how ZK is used, where it is used, and how it could be used in systems which don’t use it yet</p></li>
<li><p>Research the possibility of making dapp</p></li>
</ul>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<p>The first question that one meets is who would favor one and who another system. A meritocratic system would favor members that have high rating/a lot of contributions. While it is a good thing to encourage members to make contributions it can disincentivize members with modest contributions from participating. Also if an objectively-good proposal can be vetoed by some small portion of the community, say 1%, then it doesn’t do well for the organization. If we are into realizing a project with a technical solution like a dapp, we should find the balance between these two extremes or include the option for user “how much meritocratic system” is wanted. Some further market research could be done in this direction.</p>
<p>The next phase of research shows that there are two groups of existing solutions that partly solves a problem at the root of this research. In one group there are solutions that solve problems of blockchain governance (such as Colony and other systems for the governance of DAOs). Another group is solutions for the voting system, most notable is MACI.</p>
<p>While MACI enables efficient weighted voting by using ZK proofs it has its drawbacks. Besides widely accepted missings such as having a coordinator, MACI does not have an efficiently updatable rating system. For example, if our Meritocratic system is to be used on some forum, the rating of a lot of members is changed daily. With MACI it is hard to register all that changes. If a rating of members in our Meritocratic system is rarely changed (for example we are using it for voting at universities where professors change their status/get a promotion every couple of years), MACI is a good existing solution - members pool does not change too fast and it can be efficiently updated. On the other side, MACI supports weighted voting (which because of ZK proofs is efficient) but relies that before voting we have the complete list of members (and their reputation). In short, MACI does not interfere a lot with members polls, it is mainly concerned with the process of voting alone.</p>
<p>Another group of existing solutions is solutions for the governance of blockchains, and DAOs, such as Colony. Colony supports a reputation system that is updateable and based on contributions but lacks ZK voting. They use simple commitments for voting, downsides are notable: after voting members must ‘unlock’ their vote; zk based voting system would be much better - more privacy, less cost. Also, even though Colony uses a reputation system, it does not do it on a blockchain (because of costs - the calculation is too large to be done on-chain due to technical and economic limitations (i.e.&nbsp;the block gas limit and the cost of gas, respectively), this calculation can easily be performed by a typical user’s computer.) so they also assume the role of coordinator. Also, I could not find that they are proving proof of valid reputation calculation, which could be important to some clients.</p>
<p>For a question of calculating reputation there are some nice solutions from Colony which takes into consideration a couple of parameters such as type of contribution, the quantity of contribution, and also the time of inactivity - which brings negative reputation. Reputation rating can be measured with transferable or nontransferable tokens, depending on the use case.</p>
<p>Polkadot is a PoS, mostly-on-chain governed blockchain platform with a number interesting additions, they have for example an elected council and a technical council. Voters require at least 5 DOT to participate in governance and their voting power is based on stake. At a glance, the voters elect councillors, directly vote on referenda and submit proposals. The councilors then have the power to veto dangerous proposals, elect the technical committee, submit proposal of their own for approval by the voters and also control the treasury. The technical council can submit emergency referenda, that are implemented immediately if approved. Identity on Polkadot can be conected with various web2 platforms such as Twitter or Linkedin. They do not use ZK, so that could be tech improvement. For that improvement we could get inspiration from Polygons PolygonID, or simply focus our research on it.</p>
<p>In middle of this research, Polygon came out with blogs that announce their solution for problems of this kind. At it’s core is their PolygonID - private identity on blockchain that uses power of ZK proofs. Namely, to someone prove their reputation, one can be in temptation to use it’s wallet address. But it comes with cost, it risks revalving whole history, a lot of data from wallet, only because of voting. To address such concerns Polygon came with a new Web3 identity primitive - Polygon ID will serve that purpose, and Polygon DAO will be its testing ground. Polygon only announced this project, saying:</p>
<p>“Over the coming months, the Polygon ID ecosystem will grow to include a set of tools, platform services and examples for developers to learn, test and integrate with their apps or dApps leveraging Polygon ID’s unique on-chain capabilities.”</p>
<p>Weather we are about to make our demo app or try to improve/understand some of existing ( PolygonID stands out), paper [2] from litterature sugests immportant questions to think about, some of which are: * Tradeoffs between Privacy vs.&nbsp;Verifiability and Suffrage * Proofs of Personhood, Identity-based suffrage and tradeoffs with Privacy * Meritocratic suffrage and tradeoffs with privacy * …</p>
<p>If we are about to make ZK solution for weighted voting, or reputation managment, good starting point is paper [3] of J. Groth in which there are numerous different votting system as well pseudo code and proofs of correctnes of main ZK attributes such as soundnes. For us, most interesting application would be ‘Borda Vote’. In Borda voting, voters cast weighted votes. The worst candidate gets 1 vote, the second worst 2 votes, and so forth. A valid vote is therefore on the form <img src="https://latex.codecogs.com/png.latex?%5Cprod_%7Bi=1%7D%5E%7BL%7D%20%5Cpi(i)M%5E%7Bi-1%7D"> for some permutation <img src="https://latex.codecogs.com/png.latex?%5Cpi">. In paper there is sugested protocool and correctnes argument for it.</p>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>Need for Meritocratic voting system is most cercitnly large, question is how big is need for frequent and large updates in mebembers poll (mostly because of changing reputation rating). If that need is also large, then doing deeper technical research on this subject is jutified. Arguably, without effective governance processes, blockchain technology will fail to reach its full potential</p>
<p>Solution for our Meritocratic voting problem should be mix of the two - reputation mainteinnig system and voting system. For voting phase we could use MACI (or some variation) but we should design more cost-friendly system for mainteing reputation score/updating members list. If members trust coordinators for that part, than Colony solution works. One upgrade would be to coordinator provide ZK proof for updating reputations of members - proof that state transition is OK. It is elegant solution because it can be done off blockchain an we can chalange coordinator. On the other side, it adds costs to coordinator. If organization does not want that cost it would use Colony.</p>
<p>Another route to go is to monitor closely on PolygonID, try to get some use-case examples, code, and documentation, and dig deeper into their solution. Based on MVP’s good collaboration with Polygon, and the top-of-the-class reputation of Polygon’s ZK teams, I believe that this is a good route to go. We could find others applications of it too, beside Meritocratic voting; and build dapps on-top-of their solution. It’s very new solution and we could be one of first adopters.</p>
</section>
<section id="appendices" class="level1">
<h1>Appendices</h1>
</section>
<section id="bibliography" class="level1">
<h1>Bibliography</h1>
<p>[1] Gradstein, M.; Voting on meritocracy. European Economic Review, 48(4), 797–803.; 2004</p>
<p>[2] SoK: Blockchain Governance; Aggelos Kiayias, Philip Lazos; 2022</p>
<p>[3] https://link.springer.com/chapter/10.1007/11496137_32</p>
<p>[4] https://colony.io/whitepaper.pdf</p>
<p>[5] https://github.com/privacy-scaling-explorations/maci</p>
<p>[6] https://blog.polygon.technology/state-of-governance-2-identity-reputation/</p>
<p>[7] https://blog.polygon.technology/polygon-id-x-polygon-dao-integration-launches-to-create-new-zk-based-governance-frameworks/</p>


</section>

 ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-278.hugo.html</guid>
  <pubDate>Mon, 25 Jul 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>[ERFC - 342] Intro to the Cosmos Network</title>
  <dc:creator>Milos Bojinovic</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-342.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p>Since its inception, Ethereum[1] has enabled smart contract functionality by introducing Ethereum Virtual Machine (EVM). This enabled the possibility of creating many different decentralized applications (DApps). Ethereum is a public general purpose blockchain where everyone can participate, deploy applications and compete for the chain’s resources.</p>
<p>This idea of a general purpose chain capable of handling multiple applications has certain limitations. The most important is the issue of scalability, where in times of network congestion, transaction fees skyrocket, leading to an awful user experience.</p>
<p>The other significant issue is that DApps suffer from a “two-layer” governance system. Besides honoring its rules, a DApp must honor the rules imposed by the protocol. It would be unfeasible to alter the protocol each time there’s a need to enable some feature for one of the DApps.</p>
<p>Besides Ethereum, there are other Layer 1 chains with different approaches. However, they are in ruthless competition with each other. They cannot effectively communicate, which leads to the segmentation of space and slowness of adoption.</p>
<p>Cosmos[2] proposes and enables a separate sovereign, parallel, and optimized chain for each DApp. These independent chains can be separately altered and upgraded on a protocol level while maintaining communication. This cross-chain communication can, under certain rules, be achieved both for new as well as existing chains.</p>
<p>This different way of thinking should be taken seriously as user experience will most likely be the main factor in the race for mass adoption. With 68.72 billion USD worth of assets present in the Cosmos ecosystem[3], this approach shows great potential and should be investigated further.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p><strong>Blockchain can be viewed as a replicated state machine that follows a predefined deterministic transition process.</strong></p>
<p>From the architecture’s standpoint, any blockchain on Cosmos is formed using three layers:</p>
<ul>
<li><strong>network layer</strong> meant to discover nodes that form a peer-to-peer (P2P) network and propagate transactions as well as consensus messages between those nodes</li>
<li><strong>consensus layer</strong> responsible for reaching an agreement between nodes of this P2P network</li>
<li><strong>application layer</strong> which defines the state and the rules under which a transaction can alter it</li>
</ul>
<p>This non-monolithic approach to building a blockchain is supported by a set of tools where:</p>
<ul>
<li>network and consensus layer (responsible for the replication of state across the nodes) are handled by the Tendermint Core[4], which communicates with the application layer through an Application Blockchain Interface (ABCI)*</li>
<li>application layer and its equivalent state machine is created using the Cosmos SDK[5]</li>
</ul>
<p><em>*Tendermint Core and ABCI together comprise Tendermint BFT</em></p>
<p>Using Inter Blockchain Communication (IBC), each Cosmos blockchain can connect with others. IBC also provides a mechanism for connecting with other non-cosmos chains.</p>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p>This exploratory research into the Cosmos project mainly focuses on understanding the architecture and its capabilities. The paper showcases its features and briefly discusses their potential.</p>
<p>However, the research does not go into the specifics of the Cosmos’ tools nor the projects that have been built. Each tool in the Cosmos’ stack should be a part of separate further research.</p>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<section id="cosmos-blockchain" class="level2">
<h2 class="anchored" data-anchor-id="cosmos-blockchain">Cosmos Blockchain</h2>
<section id="tendermint-core" class="level3">
<h3 class="anchored" data-anchor-id="tendermint-core">Tendermint Core</h3>
<p>Tendermint Core handles peer-discovery, validator selection, staking, upgrades, and consensus. In doing so, it heavily relies on:</p>
<ul>
<li><p><strong>Delegated Proof-of-Stake (DPoS)</strong> where validators and delegators vote on proposals with weights proportional to the amount they’ve staked.</p>
<ul>
<li>Validators accept the block by providing their signature. When the new block’s creator gathers the necessary signatures, it is finalized, and it cannot be overturned.</li>
<li>In a blockchain running on Tendermint, transactions have absolute finality, and hard forks should not happen.</li>
</ul></li>
<li><p><strong>Practical Byzantine Fault Tolerance</strong> guarantees that the blockchain will continue functioning even if up to 1/3rd of machines fail or become malevolent.</p></li>
</ul>
</section>
<section id="abci" class="level3">
<h3 class="anchored" data-anchor-id="abci">ABCI</h3>
<p>The ABCI is an interface between Tendermint Core and the application layer. It consists of three main message types:</p>
<ul>
<li><strong>AppendTx</strong> - each transaction is delivered with this message. The application layer checks the transaction’s validity against the application’s state and protocol. As well as if all of the necessary signatures are present.</li>
<li><strong>CheckTX</strong> - performs lower resolution checks (only checks in the transaction context are performed)</li>
<li><strong>Commit</strong> - computes a commitment of the current state which will be put into the new block’s header</li>
</ul>
</section>
<section id="application-layer" class="level3">
<h3 class="anchored" data-anchor-id="application-layer">Application layer</h3>
<p>It is worth explicitly noting that which was implied in the previous paragraphs: <strong>Tendermint doesn’t concern itself with the interpretation of transactions and is unopinionated about their meaning - this is the function of the application layer.</strong></p>
<p>The main focus for most developers involves making changes to the application layer through a framework written in Golang - <a href="https://docs.cosmos.network/">Cosmos SDK</a>. The application layer can be broken down into “modules,” which are built to have a single purpose, thus achieving separation of concerns. These modules are then combined to enable the intended functionality of the new blockchain.</p>
<p>Overall, the development process consists of:</p>
<ul>
<li>defining “messages” which are the main part of the transactions, and where:
<ul>
<li>each transaction can contain multiple messages</li>
<li>each message has a destination module responsible for processing the message</li>
</ul></li>
<li>defining “handlers” for those messages that are called when the corresponding message is received</li>
<li>defining “queries” that will provide a REST API through which the information about the chain’s state can be retrieved and displayed to the user</li>
</ul>
<p>One additional tool that eases the development, especially in the beginning, is the <a href="https://docs.ignite.com/">Ignite CLI</a>. This tool scaffolds pieces of code in the project and is extremely useful for newcomers.</p>
<p>To connect to the chain and to build, as well as issue, transactions, developers should use <a href="https://tutorials.cosmos.network/academy/5-cosmjs/cosmjs-intro.html">CosmJs</a>, a Javascript/Typescript library with which it’s relatively easy to integrate with <a href="https://www.keplr.app/">Keplr wallet</a>. CosmJs needs to know the types of messages in order to build a transaction; this is a somewhat time-consuming process as it needs to be done manually through a terminal - for more info, visit <a href="https://tutorials.cosmos.network/academy/5-cosmjs/create-custom.html">Create Custom CosmJS Interfaces</a></p>
</section>
</section>
<section id="ibc" class="level2">
<h2 class="anchored" data-anchor-id="ibc">IBC</h2>
<section id="zones-and-hubs" class="level3">
<h3 class="anchored" data-anchor-id="zones-and-hubs">Zones and Hubs</h3>
<p>Each independent Cosmos blockchain is referred to as a “zone”. Zones can be connected to “hubs” - blockchains dedicated to managing the communication of zones and their assets.</p>
<p>The Cosmos whitepaper[2] states:</p>
<blockquote class="blockquote">
<p>From the Hub’s perspective, a zone is a multi-asset dynamic-membership multi-signature account that can send and receive tokens using IBC packets. …</p>
</blockquote>
<blockquote class="blockquote">
<p>Like a cryptocurrency account, a zone cannot transfer more tokens than it has, but can receive tokens from others who have them. A zone may be designated as an “source” of one or more token types, granting it the power to inflate that token supply.</p>
</blockquote>
<p>Any of the zones can themselves be hubs to form an acyclic graph. Currently, only one hub exists - “Cosmos Hub”[6], which is the economic center of the whole ecosystem.</p>
<p>Hubs keep up with the state of each zone by the block commits that each zone posts. Zones, however, do not keep track of each other’s state. Information packets are transferred from one zone to another by posting Merkle-proofs which signal that the packet was sent/received.</p>
</section>
<section id="ibc-layers" class="level3">
<h3 class="anchored" data-anchor-id="ibc-layers">IBC layers</h3>
<p>IBC is comprised of two layers:</p>
<ul>
<li>Transport (sometimes referred to as the “Transport, Authentication and Ordering” (TAO)) layer is responsible for providing the infrastructure to establish communication lines between chains in order to transport the packets between the source (sending) and destination (receiving) chain</li>
<li>Application layer specifies how data from the packets should be structured and interpreted by the sending/receiving chain</li>
</ul>
<section id="transport-layer" class="level4">
<h4 class="anchored" data-anchor-id="transport-layer">Transport layer</h4>
<p>The transport layer’s components include:</p>
<ul>
<li><strong>light clients</strong> - which are a blockchain’s light representation. They are designed to connect to a full node and verify the block headers. Two zones (or zone and a hub) interacting over IBC must contain light clients of the other chain. Interestingly, these two chains do not send messages directly to each other but via “relayers”.</li>
<li><strong>relayers</strong> - permissionless off-chain processes constantly monitoring for the presence of the messages in the chain’s state machine. To do this, they need access to a full node of both chains</li>
<li><strong>connections</strong> - connect light clients of two different chains and can have an arbitrary number of “channels”</li>
<li><strong>channels</strong> - route packets to the intended modules; In order to facilitate two-way communication between chains A and B, a 4-step handshake is required:
<ul>
<li>the first message originates from A and signals the initialization attempt to chain B</li>
<li>the second message is sent from B that corresponds to the attempt to open a channel on chain A</li>
<li>the third message is an acknowledgment message sent from A to B that states that A’s channel is open</li>
<li>the fourth message is the confirmation sent from chain B to chain A that that B’s channel is also open</li>
</ul></li>
</ul>
</section>
<section id="application-layer-1" class="level4">
<h4 class="anchored" data-anchor-id="application-layer-1">Application layer</h4>
<p>The application layer sits on top of the TAO layer and supports, among others, these functionalities :</p>
<ul>
<li><strong>fungible (ICS20[7])</strong> / <strong>non-fungible token (NFT - ICS721[8])</strong> transfers</li>
<li><strong>Interchain Accounts ICS27[9]</strong> enable cross-chain interaction - any action that can be performed on the “host” chain can be initiated from the “controller” chain. From the host chain’s perspective, interchain accounts are just regular accounts controlled via IBC messages instead of having a private key.</li>
<li><strong>Interchain Security</strong> allows for a “provider” chain to be in charge of producing blocks for a “consumer” chain.</li>
<li><strong>Fee middleware</strong> is used to pay the costs and incentivize the operation of relayers</li>
<li>etc.</li>
</ul>
</section>
</section>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>This paper has provided a high-level overview of the Cosmos, which has taken a seriously thought-out approach to building blockchains. Its radical way of making the difficulty of developing an application-specific chain comparable to the development of a DApp on a general purpose chain is worth considering during the initial design stage of any project.</p>
<p>There are three major directions in which further research should be conducted:</p>
<ol type="1">
<li>diving deep into the projects built using Cosmos. One example of an interesting project is Evmos[2], a scalable, high-throughput PoS blockchain fully compatible and interoperable with Ethereum</li>
<li>assessing the capabilities of the Cosmos SDK</li>
<li>exploring the ways IBC can connect zones with Proof-Of-Work (PoW) chains</li>
</ol>
<p>Tendermint Core shouldn’t be a priority as it is a relatively old consensus mechanism and can be replaced by newer ones as long as they are adapted to honor the ABCI.</p>
</section>
<section id="bibliography" class="level1">
<h1>Bibliography</h1>
<p>[1] https://ethereum.org/en/whitepaper/</p>
<p>[2] https://v1.cosmos.network/resources/whitepaper</p>
<p>[3] https://cosmos.network/ecosystem/tokens/ (Accessed on 07/08/22)</p>
<p>[4] https://github.com/tendermint/tendermint</p>
<p>[5] https://v1.cosmos.network/sdk</p>
<p>[6] https://hub.cosmos.network/main/hub-overview/overview.html</p>
<p>[7] https://github.com/cosmos/ibc/blob/main/spec/app/ics-020-fungible-token-transfer/README.md</p>
<p>[8] https://github.com/cosmos/ibc/tree/main/spec/app/ics-721-nft-transfer</p>
<p>[9] https://github.com/cosmos/ibc/blob/main/spec/app/ics-027-interchain-accounts/README.md</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs">

</div></section></div> ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-342.hugo.html</guid>
  <pubDate>Sun, 24 Jul 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>[ERFC - 246] Token Engineering and Design of complex systems</title>
  <dc:creator>Aleksandar Damjanovic</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-246.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p>This is the first research paper in the series of research exploring Token Economics and Token Engineering tools and processes. It provides an introduction to the practice and the Process of Token Engineering. It also covers a portion of systems theory and the three most prevalent tools in the field of Token Engineering. These tools are:</p>
<ol type="1">
<li>Machinations - tool token engineers can use in designing Crypto Economic systems in all stages, from System Mapping to Evaluation and improvements on the running system.</li>
<li>cadCad - the package most often used in designing, testing, and validating complex systems through simulation.</li>
<li>TokenSPICE - an EVM Agent-Based Token Simulator written in Python which simulates tokenized ecosystems via an agent-based approach, with EVM “in the loop”.</li>
</ol>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>We as humans are participating in numerous systems in our everyday life. Our families are a system, schools we participate in, markets we shop at, and countries we are residents of all have rules and incentives to get us to comply with their rules and laws. Some incentives are positive (you get paid for your work), and some are negative (steal, and if you are not lucky, you will get caught). Nevertheless, they serve as a guide to the participant’s behavior.</p>
<p>In Web3, we have tokenized decentralized systems that anyone can participate in. Like any other system, the complex socio-economic system that is Web3 system must have rules and limitations to function correctly and according to its purpose. That is why said systems have their own economies to incentivize system participants towards a specific goal. These economies are called Token Economies, as Token is the medium by which transactions happen, and behavior is incentivized. “Tokens represent a part of the state of any cryptoeconomic systems and can be seen as their atomic unit.” - Shermin Voshmgir and Michael Zargham.</p>
<p>A token can cover various functions of money: medium of exchange, store of value, or unit of account. A token can represent anything in the confines of the Web3 tokenized system. But the question here is: How to actually design these tokenized ecosystems? How to analyze said design and simulate it?</p>
<p>This is where the emerging Token Engineering field comes into play.</p>
<p>Token Engineering as a term was first mentioned in 2018. in the paper “Can Blockchains Go Rogue?” by Trent McConaghy of Ocean Protocol. In the article, he calls blockchains the “incentive machines with the power to get people to do stuff by rewarding with tokens”. Trent McConaghy<sup>1</sup></p>
<p>Token engineering is a cross-disciplinary field that draws from systems, electrical, and robotics engineering practices. It also draws from Behavioural and Ecological Economics, AI, and Optimization. Its goal is to create reliable systems that work under varying circumstances and to create tokenomic systems that are exploit-proof. Shermin Voshmgir and Michael Zargham<sup>2</sup></p>
<p><img src="https://3327.io/documents/research/assets/ERFC-246/Cryptoecon.png" width="600"></p>
<p><em>Figure 1: Crypto Economic systems as a cross-disciplinary field</em></p>
<p>As Crypto Economic systems are complex, Token Engineering process includes:</p>
<ol type="1">
<li>Ideation and design of the system</li>
<li>Modelling</li>
<li>Simulation</li>
<li>Testing</li>
<li>Deployment</li>
<li>Maintenance</li>
</ol>
<p>This research will cover the process of token engineering and the tools used by token engineers to design, model and evaluate Crypto Economic systems. These tools are Machinations, cadCad and tokenSPICE.</p>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p>The goal of this research is to serve as an introduction to the field of the Token Engineering, the process of Token Engineering and its tools. It will explore the process as a whole. On the tool side, we will examine Machinations, cadCad, and TokenSPICE.</p>
<p>The research will be done by reviewing the documentation of said tools, trying them out, and interviewing the people behind them. We will also interview an experienced Token Engineer to understand how the process is assessed in practice.</p>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<section id="steps-in-token-engineering-process" class="level2">
<h2 class="anchored" data-anchor-id="steps-in-token-engineering-process">Steps in Token Engineering process</h2>
<p>Below we will present some general steps in the process of Token Engineering.</p>
<section id="system-mapping" class="level3">
<h3 class="anchored" data-anchor-id="system-mapping">System Mapping</h3>
<p><strong>Identifying what concepts and constructs are relevant to our model and goals for the system</strong></p>
<p>Before starting the process, we need to take systems thinking approach. In this stage of the design, the engineer:</p>
<ul>
<li>Builds stakeholder taxonomies by identifying stakeholder groups, their possible actions, and the form of their incentives</li>
<li>Lays out the system dynamics and agent goals.</li>
</ul>
<p>Some of the tools for system mapping are Cluster Maps and Ecosystem Canvas:</p>
<p><strong>Cluster Maps</strong></p>
<p>The system’s goal is set in the middle of a cluster map while the associated nodes are drawn around it. This is a not-so-rigorous approach and is often used to get an outline of the system engineer is creating.</p>
<p><img src="https://3327.io/documents/research/assets/ERFC-246/Cluster.jpeg" width="600"></p>
<p><em>Figure 2: Cluster map example</em>@acarogluToolsSystemsThinkers2017</p>
<p><strong>Ecosystem canvas</strong></p>
<p>When using this method, the purpose of the system is put at the center while key players are laid out in circles radiating outwards.</p>
<p><img src="https://3327.io/documents/research/assets/ERFC-246/Ecosystem_canvas.png" width="600"></p>
<p><em>Figure 3: Ecosystem canvas</em> Author stephenyo<sup>3</sup></p>
</section>
<section id="formalising-the-design" class="level3">
<h3 class="anchored" data-anchor-id="formalising-the-design">Formalising the design</h3>
<p>After the initial phase is the phase of formalizing the design using causal loop diagrams and stock and flow diagrams, there is another tool called Machinations that Token Engineers could use in this step. We will cover Machinations later in the paper.</p>
<p><strong>Causal Loop Diagrams</strong></p>
<p>“A causal loop diagram is a”snapshot of all relationships that matter.” It visualizes key variables (i.e., factors, issues, processes) and how they are interconnected. These diagrams show variables represented as texts and causal relationships between them as arrows.” ‘What Is a Causal Loop Diagram and What Is It Good For? | Marketlinks’<sup>4</sup></p>
<p><img src="https://3327.io/documents/research/assets/ERFC-246/causal_loop.png" width="600"></p>
<p><em>Figure 4: Causal Loop Diagram</em></p>
<p>In a Causal Loop Diagram positive relationships are labeled with a plus sign while negative relationships are labeled with a minus sign. Above example is often used to explain this type of diagrams. It shows how market saturation and word of mouth impact potential adopters and adoption rate.</p>
<p><strong>Stock and flow diagrams</strong></p>
<p>Stock and flow diagrams are a more complex way of formalizing the design. You can see below a representation of the simple system using this diagram.</p>
<p><img src="https://3327.io/documents/research/assets/ERFC-246/stock_flow.png" width="600"></p>
<p><em>Figure 5: Stock and Flow Diagram</em></p>
</section>
<section id="modularising-the-logic-and-model-building" class="level3">
<h3 class="anchored" data-anchor-id="modularising-the-logic-and-model-building">Modularising the logic and model building</h3>
<p>After formalizing the design, system modeling is done using an open-source python package, cadCad. We will cover cadCad in detail in the next section of the paper.</p>
</section>
<section id="refining-the-model" class="level3">
<h3 class="anchored" data-anchor-id="refining-the-model">Refining the model</h3>
<p>As the name suggests, this is the part in the process where the model is refined using quantitative and qualitative backtesting.</p>
</section>
<section id="evaluation-and-improvements-on-the-running-system" class="level3">
<h3 class="anchored" data-anchor-id="evaluation-and-improvements-on-the-running-system">Evaluation and improvements on the running system</h3>
<p>After the system is up and running cadCad model can be used as a “digital twin,” which allows token engineers to:</p>
<ul>
<li>evaluate proposed changes to the system</li>
<li>test the sensitivity of parameters</li>
<li>explore the success criteria and failure modes</li>
<li>evaluate behaviors and policies</li>
<li>make recommendations to governance bodies stephenyo<sup>5</sup></li>
</ul>
</section>
</section>
<section id="machinations" class="level2">
<h2 class="anchored" data-anchor-id="machinations">Machinations</h2>
<p>Machinations is a browser-based tool to design and balance game systems. This tool has seen use from game designers, consultants, developers, and analysts. Token Engineers can also use this tool in designing Crypto Economic systems in stages from System Mapping to Evaluation and improvements on the running system. Machinations shines in pre-production.</p>
<p>Using Machinations, Token Engineer can:</p>
<ul>
<li>Map systems in an interactive diagram</li>
<li>Set parameters that define resource flow</li>
<li>Plot and analyze the results in real-time using the chart option</li>
<li>Simulate outcomes for one player journey or stochastically using batch plays</li>
<li>Export outcomes in CSV</li>
<li>Export design parameters to Google Sheets</li>
</ul>
<p>Machinations is uses these types of nodes:</p>
<ul>
<li>Pools that collect Resources</li>
<li>Sources that create Resources</li>
<li>Drains that consume/destroy resources</li>
<li>Converters that transmute resources</li>
<li>Gates that redistribute resources</li>
</ul>
<p>And two types of connections:</p>
<ul>
<li>Resource connections that determine how the Resources flow</li>
<li>State connections that modify the state of diagram elements Dana<sup>6</sup></li>
</ul>
<p>Below you will find a basic diagram created in machinations that can be used to see the flow of an AMM system:</p>
<p><img src="https://3327.io/documents/research/assets/ERFC-246/Machinations.png" width="600"></p>
<p><em>Figure 6: Machinations diagram example</em></p>
<p>This design was done in less than 20 minutes and represents a basic flow of the user exchanging tokens for crypto using our AMM. The Key takeaway is that machinations, even though its main focus is on game design can be used for the stages of System Mapping and Formalising the design.</p>
</section>
<section id="cad-cad" class="level2">
<h2 class="anchored" data-anchor-id="cad-cad">cad Cad</h2>
<pre><code>                  ___________    ____
  ________ __ ___/ / ____/   |  / __ \
 / ___/ __` / __  / /   / /| | / / / /
/ /__/ /_/ / /_/ / /___/ ___ |/ /_/ /
\___/\__,_/\__,_/\____/_/  |_/_____/
by cadCAD                  ver. 0.4.28
======================================
       Complex Adaptive Dynamics       
       o       i        e
       m       d        s
       p       e        i
       u       d        g
       t                n
       e
       r</code></pre>
<p>cadCad is the package most often used in designing, testing, and validating complex systems through simulation. It supports Monte Carlo methods, A/B testing, and parameter sweeping. cadCad can model systems from agent-based modeling to system dynamic modeling. It can easily be integrated with other Python modules and data science workflows. But first, let’s briefly explain what these methods are:</p>
<p>“Monte Carlo simulations are used to model the probability of different outcomes in a process that cannot easily be predicted due to the intervention of random variables. It is a technique used to understand the impact of risk and uncertainty in prediction and forecasting models.” ‘What Is a Monte Carlo Simulation?’<sup>7</sup></p>
<p>“A/B Testing is a method to compare two (or more) variations of something and determine which one works better. In this method, users are randomly assigned to one of two variants. A statistical analysis is performed to determine which variation performs better for a defined business goal.”<sup>8</sup></p>
<p>“In modeling, parameter sweeps are an important method for fine-tuning parameter values, exploring parameter space, and calibrating simulations to data. A parameter sweep is an iterative process in which simulations are run repeatedly using different values of the parameter(s) of choice. This process enables the modeler to determine a parameter’s”best” value (or range of values), or even where in parameter space the model produces desirable (or non-desirable) behaviors.” ‘Parameter Sweeps and Model Iteration Idmtools Documentation’<sup>9</sup></p>
<p>Although it can be used to simulate any system that can be described as state variables that evolve over time according to a set of equations, cadCad has seen the most use in the Token Engineering process.</p>
<p>The first step in modeling using cadCad is the Visual System mapping we mentioned earlier.</p>
<p>Afterward, the next step is Mathematical specification using differential equations. For example, we will use the simple system of sheep from the cadCad introduction course:</p>
<p><img src="https://3327.io/documents/research/assets/ERFC-246/sheeps.png" width="600"></p>
<p>Here we set the initial differential equations for our model. It is self explanatory. Population growth depends on food sources.</p>
<p><em>Note: This is a simplified model used to for demonstration, Crypto Economy equations are much more complex</em></p>
<p>Afterwards, the Modelling and simulation process in general works like this:</p>
<p><img src="https://3327.io/documents/research/assets/ERFC-246/cadcad-flow.png" style="width:50.0%;height:50.0%"></p>
<p><em>Figure 7: cadCad processes</em></p>
<p>We will briefly explain the steps without going into code examples as we will cover plenty of code examples in future research papers:</p>
<ol type="1">
<li>First, the engineer defines all the state variables in the system and their initial values (they can be of any Python data type)</li>
<li>Afterwards, the variables that impact the behavior of the model.</li>
<li>Policy functions compute one or more signals to be passed to state update functions. They are used to describe the logic and behavior of a system component.</li>
<li>State update functions are then designed to define how the model changes over time.</li>
<li>Partial state update blocks are used for composing state update functions and policy functions in series or parallel.</li>
</ol>
<p>Simulation process steps:</p>
<ol type="1">
<li>In the configuration stage, engineer ties all the model compenents using “config_sim” and chooses how the simulation should run:
<ol type="1">
<li>The number of times it will run</li>
<li>The number of timesteps the simulation will run for</li>
<li>The parameters of the system</li>
</ol></li>
<li>Execution computes the simulation output</li>
<li>Output preparation is the process in which data is manipulated and analyzed in order to answer questions about the model.</li>
<li>Analysis is self explanatory - engineer evaluates the model performance and if there is a need, improves the model. Usually that is the case as the first model is almost always not the optimal one.</li>
</ol>
<p>As we can see cadCad covers the entire Token Engineering process with help from stock and flow diagrams and system mapping tools. We will cover this library and its functionalities in great detail in future research papers.</p>
</section>
<section id="tokenspice" class="level2">
<h2 class="anchored" data-anchor-id="tokenspice">TokenSPICE</h2>
<p>TokenSPICE is an EVM Agent-Based Token Simulator written in Python, which simulates tokenized ecosystems via an agent-based approach, with EVM “in the loop”.</p>
<p>Ethereum Virtual Machine (EVM) is a computation engine which acts like a decentralized computer that has millions of executable projects. It acts as the virtual machine which is the bedrock of Ethereum’s entire operating structure. ‘Ethereum Virtual Machine (EVM) | CoinMarketCap’<sup>10</sup></p>
<p>TokenSPICE has been mainly used in later stage analysis and for verifying and tuning the system designs.</p>
<p>Agent-based modeling focuses on the individual active components of a system. Agents in tokenSPICE can be DAOs, unique users, and other protocols, making it a versatile tool.</p>
<p>It can be used in Token Engineering flows to design, tune and verify tokenized ecosystems.</p>
<p>If the engineer wants to model on the smart contract code directly and skip the equations set up like in cadCad, then the tokenSPICE is the tool of choice.</p>
<p>It uses Brownie, which treats smart contracts as classes, making it easier to run simulations. It also requires less work upfront in contrast to cadCad. Write the contracts in Solidity, then simulate with tokenSPICE.</p>
<p>When you run the simulator, the run function in SimEngine.py is triggered and starts the run loop in it:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><span class="kw" style="color: #003B4F;">def</span> run(<span class="va" style="color: #111111;">self</span>):</span>
<span id="cb2-2">        <span class="co" style="color: #5E5E5E;">"""</span></span>
<span id="cb2-3"><span class="co" style="color: #5E5E5E;">        @description</span></span>
<span id="cb2-4"><span class="co" style="color: #5E5E5E;">          Runs the simulation!  This is the main work routine.</span></span>
<span id="cb2-5"></span>
<span id="cb2-6"><span class="co" style="color: #5E5E5E;">        @return</span></span>
<span id="cb2-7"><span class="co" style="color: #5E5E5E;">           &lt;&lt;none&gt;&gt; but it continually generates an output csv output_dir</span></span>
<span id="cb2-8"><span class="co" style="color: #5E5E5E;">        """</span></span>
<span id="cb2-9">        log.info(<span class="st" style="color: #20794D;">"Begin."</span>)</span>
<span id="cb2-10">        log.info(<span class="bu" style="color: null;">str</span>(<span class="va" style="color: #111111;">self</span>.state.ss) <span class="op" style="color: #5E5E5E;">+</span> <span class="st" style="color: #20794D;">"</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">"</span>)  <span class="co" style="color: #5E5E5E;"># pylint: disable=logging-not-lazy</span></span>
<span id="cb2-11"></span>
<span id="cb2-12">        <span class="cf" style="color: #003B4F;">while</span> <span class="va" style="color: #111111;">True</span>:  </span>
<span id="cb2-13">            <span class="va" style="color: #111111;">self</span>.takeStep()</span>
<span id="cb2-14">            <span class="cf" style="color: #003B4F;">if</span> <span class="va" style="color: #111111;">self</span>.doStop():</span>
<span id="cb2-15">                <span class="cf" style="color: #003B4F;">break</span></span>
<span id="cb2-16">            <span class="va" style="color: #111111;">self</span>.state.tick <span class="op" style="color: #5E5E5E;">+=</span> <span class="dv" style="color: #AD0000;">1</span> </span>
<span id="cb2-17">            chain.mine(blocks<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>, timedelta<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">self</span>.state.ss.time_step)</span>
<span id="cb2-18">        log.info(<span class="st" style="color: #20794D;">"Done"</span>)</span></code></pre></div>
<p>Every single time it loops, every single agent inside the state takes a step:</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"></span>
<span id="cb3-2"><span class="kw" style="color: #003B4F;">def</span> takeStep(<span class="va" style="color: #111111;">self</span>) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb3-3">        <span class="co" style="color: #5E5E5E;">"""Run one tick, updates self.state"""</span></span>
<span id="cb3-4">        log.debug(<span class="st" style="color: #20794D;">"============================================="</span>)</span>
<span id="cb3-5">        log.debug(<span class="st" style="color: #20794D;">"Tick=</span><span class="sc" style="color: #5E5E5E;">%d</span><span class="st" style="color: #20794D;">: begin"</span>, (<span class="va" style="color: #111111;">self</span>.state.tick))</span>
<span id="cb3-6"></span>
<span id="cb3-7">        <span class="cf" style="color: #003B4F;">if</span> (<span class="va" style="color: #111111;">self</span>.elapsedSeconds() <span class="op" style="color: #5E5E5E;">%</span> <span class="va" style="color: #111111;">self</span>.state.ss.log_interval) <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span>:</span>
<span id="cb3-8">            s, dataheader, datarow <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.createLogData()</span>
<span id="cb3-9">            log.info(<span class="st" style="color: #20794D;">""</span>.join(s))</span>
<span id="cb3-10">            <span class="va" style="color: #111111;">self</span>.logToCsv(dataheader, datarow)</span>
<span id="cb3-11"></span>
<span id="cb3-12">        <span class="co" style="color: #5E5E5E;"># main work</span></span>
<span id="cb3-13">        <span class="va" style="color: #111111;">self</span>.state.takeStep()</span>
<span id="cb3-14"></span>
<span id="cb3-15">        log.debug(<span class="st" style="color: #20794D;">"============================================="</span>)</span>
<span id="cb3-16">        log.debug(<span class="st" style="color: #20794D;">"Tick=</span><span class="sc" style="color: #5E5E5E;">%d</span><span class="st" style="color: #20794D;">: done"</span>, <span class="va" style="color: #111111;">self</span>.state.tick)</span></code></pre></div>
<p>The rest of the file is dedicated to logging the results into CSV format, and we will not examine it further.</p>
<p>Similarly, the simulation engine also takes a step when the Agents take a step in the simulation.</p>
<p>Simulation with tokenSPICE can be done using the following command in the terminal and the results can saved in CSV or a plot created in png:</p>
<pre><code>  tsp plot netlists/scheduler/netlist.py outdir_csv outdir_png</code></pre>
<p><em>Note: Netlists are just agents “wired-up”</em></p>
<p>Here we ran a vesting simulation in the Ocean protocol and this is the resulting plot:</p>
<p><img src="https://3327.io/documents/research/assets/ERFC-246/vesting.png" width="600"></p>
<p><em>Figure 8: Vesting simulation in tokenSPICE</em></p>
<p>You can run all kinds of netlists in order to get a “feel” of it, in the tokenSPICE <a href="https://github.com/tokenspice/tokenspice">official GitHub repo</a>.</p>
<p>In contrast to cadCad, which can be used for any type of system, tokenSPICE is focused on EVM systems and incentives. The main difference is that cadCad is mainly used in the early-stage design of systems.</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>Token Engineering as a field is still young, and the community around it is still tiny. However, the quality of tools available is exceptional. The tools range from general game design tools (Machinations) and general system design tools (cadCad) to specialized tools like tokenSPICE. The only missing piece of the puzzle are the Token Engineers, who will focus on mastering these tools to provide valuable insights into both designing and validating crypto-economic systems.</p>
<p>You can see the list of all possible tools for system modeling with tokens, and their strengths and weaknesses <a href="https://github.com/TokenEngineeringCommunity/summary-of-tools/blob/main/README.md">here</a>.</p>
<p>Considering the complex nature of systems in Web3, we have only discovered the tip of the iceberg and the picks to dig deeper and examine the economies of this vast ecosystem.</p>
</section>
<section id="bibliography" class="level1">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Bibliography</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-danaFrameworkBasicsMachinations" class="csl-entry">
Dana, ‘Framework Basics Machinations.io’, <em>Machinations.io</em> &lt;<a href="https://machinations.io/docs/framework-basics/" class="uri">https://machinations.io/docs/framework-basics/</a>&gt; [accessed 30 June 2022]
</div>
<div id="ref-EthereumVirtualMachine" class="csl-entry">
‘Ethereum Virtual Machine (EVM) | CoinMarketCap’, <em>CoinMarketCap Alexandria</em> &lt;<a href="https://coinmarketcap.com/alexandria/glossary/ethereum-virtual-machine-evm" class="uri">https://coinmarketcap.com/alexandria/glossary/ethereum-virtual-machine-evm</a>&gt; [accessed 17 July 2022]
</div>
<div id="ref-mcconaghyCanBlockchainsGo2020" class="csl-entry">
McConaghy, Trent, ‘Can Blockchains Go Rogue?’, <em>Medium</em>, 2020 &lt;<a href="https://blog.oceanprotocol.com/can-blockchains-go-rogue-5134300ce790" class="uri">https://blog.oceanprotocol.com/can-blockchains-go-rogue-5134300ce790</a>&gt; [accessed 29 June 2022]
</div>
<div id="ref-ParameterSweepsModel" class="csl-entry">
‘Parameter Sweeps and Model Iteration Idmtools Documentation’ &lt;<a href="https://institutefordiseasemodeling.github.io/idmtools/parameter-sweeps.html" class="uri">https://institutefordiseasemodeling.github.io/idmtools/parameter-sweeps.html</a>&gt; [accessed 1 July 2022]
</div>
<div id="ref-stephenyoTokenEngineeringProcess2019" class="csl-entry">
stephenyo, Author, ‘A Token Engineering Process’, <em>Syoung.org</em>, 2019 &lt;<a href="https://syounggallery.wordpress.com/2019/10/18/a-token-engineering-process/" class="uri">https://syounggallery.wordpress.com/2019/10/18/a-token-engineering-process/</a>&gt; [accessed 29 June 2022]
</div>
<div id="ref-voshmgirFoundationsCryptoeconomicSystems" class="csl-entry">
Voshmgir, Shermin, and Michael Zargham, ‘Foundations of Cryptoeconomic Systems’, 1.1, 18
</div>
<div id="ref-WhatCausalLoop" class="csl-entry">
‘What Is a Causal Loop Diagram and What Is It Good For? | Marketlinks’ &lt;<a href="https://www.marketlinks.org/resources/what-causal-loop-diagram-and-what-it-good" class="uri">https://www.marketlinks.org/resources/what-causal-loop-diagram-and-what-it-good</a>&gt; [accessed 30 June 2022]
</div>
<div id="ref-WhatMonteCarlo" class="csl-entry">
‘What Is a Monte Carlo Simulation?’, <em>Investopedia</em> &lt;<a href="https://www.investopedia.com/terms/m/montecarlosimulation.asp" class="uri">https://www.investopedia.com/terms/m/montecarlosimulation.asp</a>&gt; [accessed 1 July 2022]
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>‘Can Blockchains Go Rogue?’, <em>Medium</em>, 2020 &lt;&lt;https://blog.oceanprotocol.com/can-blockchains-go-rogue-5134300ce790&gt;&gt; [accessed 29 June 2022].↩︎</p></li>
<li id="fn2"><p>‘Foundations of Cryptoeconomic Systems’, 1.1, 18.↩︎</p></li>
<li id="fn3"><p>‘A Token Engineering Process’, <em>Syoung.org</em>, 2019 &lt;&lt;https://syounggallery.wordpress.com/2019/10/18/a-token-engineering-process/&gt;&gt; [accessed 29 June 2022].↩︎</p></li>
<li id="fn4"><p>&lt;[Https://www.marketlinks.org/resources/what-causal-loop-diagram-and-what-it-good](https://www.marketlinks.org/resources/what-causal-loop-diagram-and-what-it-good)&gt; [accessed 30 June 2022].↩︎</p></li>
<li id="fn5"></li>
<li id="fn6"><p>‘Framework Basics Machinations.io’, <em>Machinations.io</em> &lt;&lt;https://machinations.io/docs/framework-basics/&gt;&gt; [accessed 30 June 2022].↩︎</p></li>
<li id="fn7"><p><em>Investopedia</em> &lt;&lt;https://www.investopedia.com/terms/m/montecarlosimulation.asp&gt;&gt; [accessed 1 July 2022].↩︎</p></li>
<li id="fn8"><p><strong>devbot5sTesting2017?</strong>↩︎</p></li>
<li id="fn9"><p>&lt;[Https://institutefordiseasemodeling.github.io/idmtools/parameter-sweeps.html](https://institutefordiseasemodeling.github.io/idmtools/parameter-sweeps.html)&gt; [accessed 1 July 2022].↩︎</p></li>
<li id="fn10"><p><em>CoinMarketCap Alexandria</em> &lt;&lt;https://coinmarketcap.com/alexandria/glossary/ethereum-virtual-machine-evm&gt;&gt; [accessed 17 July 2022].↩︎</p></li>
</ol>
</section></div> ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-246.hugo.html</guid>
  <pubDate>Tue, 28 Jun 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>[ERFC - 315] Reaching Towards Realtime in Blockchain</title>
  <dc:creator>Milos Bojinovic</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-315.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p>The concept of <strong>Real-Time</strong> can be best explained as a set of guarantees that are given and that need to be met within a predetermined time period. Usually, though not necessarily, this is a short time period. In the case the guarantees are not met before the deadline has been reached, then the performance of the real-time system either degrades or the system has failed completely.</p>
<p>For a blockchain to achieve real-time operations, it has to have low latency and indirectly a high throughput, hopefully without sacrificing decentralization and security.</p>
<p>This is a problem of scaling a blockchain, and several approaches exist, each with its advantages and limitations. These approaches can be grouped into <strong>on-chain</strong> and <strong>off-chain</strong> scaling solutions, with the main difference being whether there exist a need for changing the blockchain’s protocol in some way.</p>
<p>The main focus of this research is put on the off-chain scaling in the Ethereum Ecosystem and how can a Decentralized Application (DApp) potentially achieve something that resembles real-time operations.</p>
<p>The research proposes a framework consisting of an off-chain and on-chain part where the on-chain part would be used to enforce rules that the off-chain code needs to honor.</p>
<p>The ideas proposed here would need to be expanded upon and thoroughly tested in real-world conditions to completely assess their practical significance.</p>
<p>Further research should also take into consideration on-chain scaling, namely ETH2.0, as well as an exciting concept of creating a network of private sovereign blockchains built specifically for the DApp’s needs.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<section id="ethereums-layer-1" class="level2">
<h2 class="anchored" data-anchor-id="ethereums-layer-1">Ethereum’s Layer 1</h2>
<p>Ethereum blockchain, as defined in,<sup>1</sup> can be viewed as a “transaction-based state machine” that groups transactions into blocks which are then sequentially executed in the order that was set by the block’s creator - miner.</p>
<p>Before being included inside a block, the transactions reside in the pending transaction pool. Miners have complete control over what transactions get included and in what order. Each transaction advances the chain’s state for which the miners are rewarded fees paid by the Externally-Owned-Account(EOA)* that initiated the transaction.</p>
<p>In essence, the more the EOA is willing to pay for the service of including their transaction, the more likely it is will be included in the next block. This creates the problem in the situation of blockchain’s network congestion - as the transactions are being created at a faster rate than they can be processed, fees drastically increase, and it becomes a competition between different EOAs, which leads to a bad user experience.</p>
<p>To ease the load put on the Ethereum Mainnet (Layer 1 - L1) chain and effectively perform scaling, multiple approaches exist: Sidechains and schemes commonly referred to as Layer 2 (L2) solutions. L2 solutions include State Channels, Plasma, and Rollups (Optimistic and Zero-Knowledge based).</p>
<p>* Ethereum account can be defined as a private-public keypair mapped to an address. EOA is a type of an Ethereum account where the private key is known and “externally” controlled, in contrast to smart contract accounts where the private key is not known, and only the address exists.</p>
</section>
<section id="off-chain-scaling-approaches" class="level2">
<h2 class="anchored" data-anchor-id="off-chain-scaling-approaches">Off-chain Scaling Approaches</h2>
<p>When considering approaches to Ethereum’s scaling problem, this paper considers only Ethereum Virtual Machine (EVM) compatible sidechains and optimistic rollups.</p>
<section id="sidechains" class="level3">
<h3 class="anchored" data-anchor-id="sidechains">Sidechains</h3>
<p>Sidechains are completely independent parallel blockchains to the Ethereum’s L1, with which they can communicate over two-way bridges. They introduce their own set of parameters and operate on different rules.</p>
<p>For example, <a href="https://polygon.technology/">Polygon</a>, a popular Ethereum sidechain, uses Proof-of-Stake for its consensus mechanism, with block times being around 2.3 seconds<sup>2</sup> (Ethereum’s average block time is between 12 and 14 seconds)<sup>3</sup></p>
</section>
<section id="optimistic-rollups" class="level3">
<h3 class="anchored" data-anchor-id="optimistic-rollups">Optimistic Rollups</h3>
<p>Unlike Sidechains, Optimistic Rollups have their security rooted in the L1 chain.</p>
<p>As Vitalik Buterin, the founder of Ethereum discusses in<sup>4</sup> :</p>
<blockquote class="blockquote">
<p>“Instead of putting all activity on the blockchain directly, users perform the bulk of their activity off-chain in a”layer 2” protocol. There is a smart contract on-chain, which only has two tasks: processing deposits and withdrawals and verifying proofs that everything happening off-chain is following the rules. There are multiple ways to do these proofs, but they all share the property that verifying the proofs on-chain is much cheaper than doing the original computation off-chain.”</p>
</blockquote>
<p>In Optimistic Rollups, after a state is proposed, there exists a period where it can be disputed, after which it cannot be longer challenged.</p>
<p>While anyone can propose a state, one of the optimistic rollups - <a href="https://developer.offchainlabs.com/docs/inside_arbitrum">Arbitrum One</a> chain has used a concept of a “sequencer”<sup>5</sup>:</p>
<blockquote class="blockquote">
<p>The sequencer is a specially designated full node, which is given limited power to control the ordering of transactions. This allows the sequencer to guarantee the results of user transactions immediately, without needing to wait for anything to happen on Ethereum. So no need to wait five minutes or so for block confirmations–and no need to even wait 15 seconds for Ethereum to make a block.</p>
</blockquote>
<p>The company behind Arbitrum has recently introduced another L2 concept chain - AnyTrust Chains<sup>6</sup>, which is operated by a “committee” of nodes signing the state that will later be put on-chain. If nodes go offline or refuse to cooperate, the chain reverts to a standard protocol.</p>
</section>
</section>
<section id="bridges-and-cross-chain-applications" class="level2">
<h2 class="anchored" data-anchor-id="bridges-and-cross-chain-applications">Bridges and Cross-chain Applications</h2>
<p>To enable cross-chain communication, there exist Bridges with the purpose of transferring assets and passing messages. The benefit of bridges is that users can move to a different chain if their needs require it. For example, when either transaction cost is too high or when there is more of a specific user activity going on the target chain - i.e., Non-Fungible Token (NFT) trading.</p>
<p>Bridges operate between two extremes - trusted (there is a centralized entity that is being <em>trusted</em>) and trustless (there is no need for the centralized entity).<sup>7</sup></p>
<p>The security of bridges, however, remains troublesome. As Buterin has pointed out in,<sup>8</sup> in the case of a 51% attack of the chain from which funds are being moved, attacker can broadcast a transaction that deposits some funds to the target chain and then revert it, as soon the assets are minted on the target chain. He states that:</p>
<blockquote class="blockquote">
<p>“… while I am optimistic about a multi-chain blockchain ecosystem (there really are a few separate communities with different values and it’s better for them to live separately than all fight over influence on the same thing), I am pessimistic about cross-chain applications.”</p>
</blockquote>
<section id="application-specific-blockchains" class="level3">
<h3 class="anchored" data-anchor-id="application-specific-blockchains">Application-specific Blockchains</h3>
<p>Instead of having all applications competing for the same resources, a DApp can run its own blockchain. There can exist inter-communication between those private and public chains through bridges.</p>
<p>Each chain operates with a unique set of rules and validators - making them sovereign but less decentralized.</p>
</section>
</section>
<section id="concept-of-time-in-blockchains" class="level2">
<h2 class="anchored" data-anchor-id="concept-of-time-in-blockchains">Concept of Time in Blockchains</h2>
<p>Blockchains operate in discrete time as the state is advanced only when a block is created and validated. It is worth noting that Ethereum’s Yellow Paper[2] states only that the current block’s timestamp should be strictly greater than its predecessor’s timestamp - not what’s the maximum difference between those two values.</p>
<p>This leads to blocks being produced at non-constant time intervals and the concept of time being distorted. When periods and deadlines are mentioned in this paper, it is meant in terms of block numbers.</p>
</section>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p>This paper tries to give a thought framework and a set of underlying principles that can be used to create a DApp that comes as close to real-time operations as possible.</p>
<p>It considers only EVM compatible chains when doing this and reasons how their properties can enable those operations.</p>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<p>The main ideas presented in this research are the separation of DApp’s functionality into parallel processes of different priorities while providing guarantees that a part of the process will be executed in a predefined period.</p>
<p>It breaks the DApp into its <strong>on-chain code</strong> (a set of smart contracts) and <strong>off-chain code</strong> (operates under rules imposed by the on-chain part).</p>
<section id="on-chain-code" class="level2">
<h2 class="anchored" data-anchor-id="on-chain-code">On-chain code</h2>
<section id="parallezization-of-processes" class="level3">
<h3 class="anchored" data-anchor-id="parallezization-of-processes">Parallezization of Processes</h3>
<p>Rather than separating DApp’s functionality into different contract methods with only one method being called per transaction, it is possible to have one method capable of executing different sequences of method calls and accomplishing more.</p>
<p>In the example shown below, there exist three separate processes(P0, P1, P2) that perform operations on the same set of data. Processes P0 and P1 are independent of each other and have no other dependencies (if EVM allowed concurrency, they could be executed in parallel). P2 is, however dependent on P0 and so before calling P2 we need to call P0.</p>
<pre class="solidity"><code>contract Example_0 {

    ...

    function execute (uint[] operation, uint[] data_0) public onlyAdmin returns (bool) {

        for (uint i = 0; i &lt; operation.length; ++i){

            if (operation[i] == 0){

                //P0 : calculate the sum of numbers in `data_0` and put in the `sum` storage variable

            } else if (operation[i] == 1){

                //P1 : store the entire `data_0` into the storage variable `buffer`

            } else if (operation[i] == 2){

                //P2 : if the `sum` even returns 'true'

            }
        }
        return false;
    }

    ...
}</code></pre>
<p>This setup allows us to create “programmable” sequences of operations and a higher degree of freedom. We can call the <code>execute</code> function with its <code>operation</code> argument set to [0, 2], [1], [0, 2, 1], [1, 0, 2] or [0, 1, 2]. We could also execute a single process multiple times by repeating a number corresponding to the process, though in the example above, that would not make much sense.</p>
</section>
<section id="persistence-across-transactions" class="level3">
<h3 class="anchored" data-anchor-id="persistence-across-transactions">Persistence across Transactions</h3>
<p>In the previous example, everything happens in the context of one single transaction, but it doesn’t have to. There can exist another process - P3 that would read from the <code>buffer</code> variable and perform a different operation on its data. Now the order of operations becomes even more important. Because P3 reads from the <code>buffer</code>, we could first call P1 that stores the <code>data_0</code> into the <code>buffer</code> and then P3 or first call P3 and after P1, which would exhibit a completely different behavior.</p>
</section>
<section id="prioritization-of-processes" class="level3">
<h3 class="anchored" data-anchor-id="prioritization-of-processes">Prioritization of Processes</h3>
<p>It is obvious that there are limitations to this approach - transaction size and the transaction cost. This is where prioritization comes in, as not all processes are created equal - some need to be executed more frequently in a shorter period of time while others are less important and can have higher latency. It is up to the DApp’s off-chain code to monitor, decide and optimize for the right moment when a process should be executed.</p>
</section>
<section id="providing-guarantees-committing-to-promises" class="level3">
<h3 class="anchored" data-anchor-id="providing-guarantees-committing-to-promises">Providing Guarantees: Committing to Promises</h3>
<p>Processes can depend upon each other; that is, they depend on the result(state) produced by previously executed processes. As there is so much that can fit into a single transaction, DApp doesn’t have to execute a process and produce a result right away - it can make a claim about that result and simultaneously commit to the promise that it will justify the claim later.</p>
</section>
<section id="honoring-commitments" class="level3">
<h3 class="anchored" data-anchor-id="honoring-commitments">Honoring Commitments</h3>
<p>Commitments made obviously need to be honored. Otherwise, there is no point. If the deadlines are not met, DApp should be penalized, and the users affected should be compensated.</p>
<p>However, there is no direct reason to halt the execution of the processes - they can operate on claims. The issue now becomes that they effectively act on promises - if it is found later on that the claim has not been honored, the processes and all of their results should be affected as well. An example of this dependency is shown in Figure 1.</p>
<center>
<p><img src="https://3327.io/documents/research/assets/ERFC-315/OperatingOnPromises.png" class="img-fluid"></p>
<p>Figure 1: Operating on Claims</p>
</center>
<p>For simplicity, states (S0, S1, S2, S3, S4) are just <code>uint</code> variables, while P0 and P1 are addition and multiplication operations, respectively. The yellow color indicates that a claim has been made for that variable, while green says that the claim has been honored. We see that claiming S0 affects S2 and S4.</p>
<p>It gets even more complicated when a process operates on and produces an update to the same variable. For instance, in Figure 1, if the S2 is fixed to always be equal to S0. The on-chain code would need to keep track of what is affected if the specific claim will not be honored.</p>
<p>How to effectively implement mechanisms that would take into account all of these concerns should be part of separate research.</p>
</section>
</section>
<section id="off-chain-code" class="level2">
<h2 class="anchored" data-anchor-id="off-chain-code">Off-chain code</h2>
<p>Off-chain code’s responsibility can be summed up to:</p>
<ul>
<li>monitor the state of the contract and all of the commitments that need to be honored</li>
<li>decide what to put inside the transaction by predicting when is the best time to execute a process</li>
</ul>
<section id="monitoring-the-on-chain-activity" class="level3">
<h3 class="anchored" data-anchor-id="monitoring-the-on-chain-activity">Monitoring the on-chain activity</h3>
<p>In the case where only the admin account can alter the contract’s state, off-chain code can maintain a separate record offline that will periodically be checked with the actual state read from the chain. If it is possible for users to interact directly with the contract, then the chain needs to be read more often - one approach would be to parse the blocks as soon as they are validated.</p>
</section>
<section id="optimization-of-action-sequences" class="level3">
<h3 class="anchored" data-anchor-id="optimization-of-action-sequences">Optimization of action sequences</h3>
<p>Deciding on how to structure a transaction is a more complex problem, and its main part resides in the scheduling of processes. When should a specific process be scheduled depends on what claims need to be honored and when, as well as the state of the network. If the demand for the network’s resources is high, the execution cost is high as well, so it is better to issue a transaction that will use a lot of resources when the demand becomes lower. However, there is no formal guarantee when a transaction will be mined; there would need to exist models that would try to predict and speculate how the demand will change over time and how much to incentivize the miners.</p>
<section id="bursts-of-transcatiions" class="level4">
<h4 class="anchored" data-anchor-id="bursts-of-transcatiions">Bursts of transcatiions</h4>
<p>Another important concept is that an EOA can create multiple transactions that can be included in the same block. The miner needs to honor only the order in which they are issued.<sup>9</sup> This can be used to enable “bursts” of transactions in order to catch up with the claims that are pending. If there are multiple accounts interacting with the contract, then the order is not guaranteed so there would need to exist some form of synchronization across transactions.</p>
</section>
</section>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>This research has defined a set of principles on how an individual DApp can be structured in order to more effectively distribute its functionality. The ideas proposed have not been tested in practice, so there exists a cloud of doubt about whether this approach is generalizable and sufficient for a large number of DApps.</p>
<p>The research has operated on the assumption that only the DApp’s admin account can alter the on-chain state of a contract, whether by aggregating** the users’ activity or by issuing commands that are made possible by on-chain code. There exist a problem of what happens if the DApp’s off-chain code goes offline, the users should not suffer for it, and so there needs to exist a mechanism that would enable the users to alter the contract’s state as well, which introduces more complexities in the DApp’s design.</p>
<p>The main proposed direction for further research is taking an existing real-world DApp and restructuring its code to enable “parallelization”. Also, as everything is dependent on the off-chain’s code correct scheduling of actions studies and simulations would need to be conducted based on a specific chain’s properties to see how much a chain can handle in terms of the block size, block time, transaction’s execution cost…</p>
<p>Another direction would be Ethereum’s on-chain scaling solution - ETH 2.0, as well as private chains and non-EVM chains and their approaches.</p>
<p>**By collecting signed messages from users that correspond to the action that the user wants to make. This, however, introduces the potential for censorship as well as manipulation when a message will be included in a transaction (both in terms of block numbers and in terms of ordering of messages).</p>
</section>
<section id="bibliography" class="level1">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Bibliography</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-IncompleteGuideRollups" class="csl-entry">
‘An Incomplete Guide to Rollups’ &lt;<a href="https://vitalik.ca/general/2021/01/05/rollup.html" class="uri">https://vitalik.ca/general/2021/01/05/rollup.html</a>&gt; [accessed 26 June 2022]
</div>
<div id="ref-Blocks" class="csl-entry">
‘Blocks’, <em>Ethereum.org</em> &lt;<a href="https://ethereum.org" class="uri">https://ethereum.org</a>&gt; [accessed 27 June 2022]
</div>
<div id="ref-EthereumMiningEthHub" class="csl-entry">
‘Ethereum Mining - EthHub’ &lt;<a href="https://docs.ethhub.io/using-ethereum/mining/" class="uri">https://docs.ethhub.io/using-ethereum/mining/</a>&gt; [accessed 21 June 2022]
</div>
<div id="ref-EthereumWhitepaper" class="csl-entry">
‘Ethereum Whitepaper’, <em>Ethereum.org</em> &lt;<a href="https://ethereum.org" class="uri">https://ethereum.org</a>&gt; [accessed 27 June 2022]
</div>
<div id="ref-ArbitrumOffchainLabs" class="csl-entry">
‘Inside Arbitrum <img src="https://latex.codecogs.com/png.latex?%5Ccdot"> Offchain Labs Dev Center’ &lt;<a href="https://developer.offchainlabs.com/" class="uri">https://developer.offchainlabs.com/</a>&gt; [accessed 27 June 2022]
</div>
<div id="ref-IntroductionBlockchainBridges" class="csl-entry">
‘Introduction to Blockchain Bridges’, <em>Ethereum.org</em> &lt;<a href="https://ethereum.org" class="uri">https://ethereum.org</a>&gt; [accessed 26 June 2022]
</div>
<div id="ref-labsIntroducingAnyTrustChains2022" class="csl-entry">
Labs, Offchain, ‘Introducing AnyTrust Chains: Cheaper, Faster L2 Chains with Minimal Trust Assumptions’, <em>Offchain Labs</em>, 2022 &lt;<a href="https://medium.com/offchainlabs/introducing-anytrust-chains-cheaper-faster-l2-chains-with-minimal-trust-assumptions-31def59eb8d7" class="uri">https://medium.com/offchainlabs/introducing-anytrust-chains-cheaper-faster-l2-chains-with-minimal-trust-assumptions-31def59eb8d7</a>&gt; [accessed 27 June 2022]
</div>
<div id="ref-polygonscan.comPolygonPoSChain" class="csl-entry">
polygonscan.com, ‘Polygon PoS Chain Average Block Time Chart | PolygonScan’, <em>Polygon (MATIC) Blockchain Explorer</em> &lt;<a href="http://polygonscan.com/chart/blocktime" class="uri">http://polygonscan.com/chart/blocktime</a>&gt; [accessed 27 June 2022]
</div>
<div id="ref-vbuterinFundamentalSecu2022" class="csl-entry">
vbuterin, ‘The Fundamental Secu…’, <em>R/Ethereum</em>, 2022 &lt;<a href="https://www.reddit.com/r/ethereum/comments/rwojtk/ama_we_are_the_efs_research_team_pt_7_07_january/hrngyk8/">www.reddit.com/r/ethereum/comments/rwojtk/ama_we_are_the_efs_research_team_pt_7_07_january/hrngyk8/</a>&gt; [accessed 26 June 2022]
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>‘Ethereum Whitepaper’, <em>Ethereum.org</em> &lt;&lt;https://ethereum.org&gt;&gt; [accessed 27 June 2022].↩︎</p></li>
<li id="fn2"><p>Polygonscan.com, ‘Polygon PoS Chain Average Block Time Chart | PolygonScan’, <em>Polygon (MATIC) Blockchain Explorer</em> &lt;&lt;http://polygonscan.com/chart/blocktime&gt;&gt; [accessed 27 June 2022].↩︎</p></li>
<li id="fn3"><p>‘Blocks’, <em>Ethereum.org</em> &lt;&lt;https://ethereum.org&gt;&gt; [accessed 27 June 2022].↩︎</p></li>
<li id="fn4"><p>‘An Incomplete Guide to Rollups’ &lt;&lt;https://vitalik.ca/general/2021/01/05/rollup.html&gt;&gt; [accessed 26 June 2022].↩︎</p></li>
<li id="fn5"><p>‘Inside Arbitrum <img src="https://latex.codecogs.com/png.latex?%5Ccdot"> Offchain Labs Dev Center’ &lt;&lt;https://developer.offchainlabs.com/&gt;&gt; [accessed 27 June 2022].↩︎</p></li>
<li id="fn6"><p>Offchain Labs, ‘Introducing AnyTrust Chains: Cheaper, Faster L2 Chains with Minimal Trust Assumptions’, <em>Offchain Labs</em>, 2022 &lt;&lt;https://medium.com/offchainlabs/introducing-anytrust-chains-cheaper-faster-l2-chains-with-minimal-trust-assumptions-31def59eb8d7&gt;&gt; [accessed 27 June 2022].↩︎</p></li>
<li id="fn7"><p>‘Introduction to Blockchain Bridges’, <em>Ethereum.org</em> &lt;&lt;https://ethereum.org&gt;&gt; [accessed 26 June 2022].↩︎</p></li>
<li id="fn8"><p>Vbuterin, ‘The Fundamental Secu…’, <em>R/Ethereum</em>, 2022 &lt;[www.reddit.com/r/ethereum/comments/rwojtk/ama_we_are_the_efs_research_team_pt_7_07_january/hrngyk8/](https://www.reddit.com/r/ethereum/comments/rwojtk/ama_we_are_the_efs_research_team_pt_7_07_january/hrngyk8/)&gt; [accessed 26 June 2022].↩︎</p></li>
<li id="fn9"><p>‘Ethereum Mining - EthHub’ &lt;&lt;https://docs.ethhub.io/using-ethereum/mining/&gt;&gt; [accessed 21 June 2022].↩︎</p></li>
</ol>
</section></div> ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-315.hugo.html</guid>
  <pubDate>Sun, 19 Jun 2022 00:00:00 GMT</pubDate>
  <media:content url="https://3327.io/documents/research/assets/ERFC-315/OperatingOnPromises.png" medium="image" type="image/png" height="55" width="144"/>
</item>
<item>
  <title>[ERFC - 248] Crosschain Identity</title>
  <dc:creator>Aleksandar Damjanovic</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-248.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p>When we look at the current Web2 user identity solutions, we can see that they are mostly linked to centralized corporate organizations. Although convenient for the end-user, this type of online identity is not owned by the user, and the issuers (Google, Facebook, Twitter, etc.) have complete control of them. In Web3, the focus is on decentralization; however, the problem of cross-chain interoperability of identities is a big one to overcome.</p>
<p>This paper examines the current state of cross-chain identity solutions and the technology behind them to understand how they operate and tackle the previously mentioned interoperability problem. Those solutions are:</p>
<ol type="1">
<li>Litentry - a decentralized cross-chain identity aggregator which enables linking user identities across multiple networks. Litentry collects, indexes, and distributes DIDs to blockchains in a decentralized way.</li>
<li>ORE - a cross-chain global identity registry where users have control over their own identity.</li>
<li>Accumulate (mainnet launch planned for September 2022) - an identity-based, delegated proof-of-stake blockchain solution.</li>
</ol>
<p>It also shortly covers Decentralized Identifiers (DIDs), Accumulate Digital Identifiers (ADIs), tests and analyzes the project’s solutions and current place in the Web3 market.</p>
<p>This paper does not cover Web3 identity solutions that are not cross-chain, as that is not the main focus of this research.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>In Web2, most users’ online identities are linked to centralized corporate organizations like Facebook, Twitter, or Google. The problem with this type of identity is that these organizations “own” your identity on the platform and the associated data. That means that the ease of use (single click logins, app interoperability, etc.) often comes with the price mentioned above. Corporate organizations can close and ban users’ accounts and sell their data which has been the case before. As they have all the data from the user, they can (technically) also generate credentials and log into any website using the user’s identity. ‘Thousands of Leaked Facebook Documents Show Mark Zuckerberg as “Master of Leverage” in Plan to Trade User Data’<sup>1</sup></p>
<p>Web3 is based on blockchain technology. Aside from use in financial applications, blockchain can be used in creating and managing Self-sovereign digital identities, like SSIs. SSI is a digital identity concept in which an individual or company has complete control over their account and personal data. ‘Self-Sovereign Identities’<sup>2</sup></p>
<p>The identity means nothing without claims from trusted sources (government ID credentials, student ID credentials, library card certificates). If many trusted parties assign claims to identity, thus implicitly confirming it, then the identity is valid. We use our ID number, issued by the government, anywhere, and every organization in the country will accept our identity number as it was issued by the trusted party confirming the identity. The validity of the identity is not in the keys, but the claims and the keys are there to verify that we indeed hold those claims.</p>
<p>Currently, when it comes to creating identity in Web3, we have various “approaches” to it:</p>
<ul>
<li>A user’s public key can be seen as a kind of identity on the blockchain. However, it is not very user-friendly, and it is limited in terms of cross-chain interoperability and in terms of representing a user. Users can own multiple addresses, thus having multiple “identities.”</li>
<li>In terms of creating an identity on the Ethereum blockchain, Ethereum Naming Service is the most used. ENS’s job is to map human-readable names like ‘3327.eth’ to machine-readable identifiers such as Ethereum addresses, other cryptocurrency addresses, content hashes, and metadata. ENS addresses can represent the user’s identity and be a kind of a user’s profile with its subdomains.</li>
<li>Various identity aggregators like Litentry, IDX, Accumulate, ORE network (this is debatable), etc.</li>
<li>SBTs and soul accounts are also proposed as a possible solution for an identity standard. However, they are currently a concept. They could evolve and become the standard someday.</li>
</ul>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p>This research will explore current solutions for creating a cross-chain Web3 identity (aggregators, protocols). After mapping the solutions, this research will propose the next steps in tackling this issue.</p>
<p>This paper will tackle this topic by reviewing various cross-chain solutions’ documentation and whitepapers and exploring their properties, implementation, and differences.</p>
<p>This paper will not be covering Web3 identity solutions that are not cross-chain.</p>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<p>Below we will discuss some of the current solutions that are trying to tackle cross-chain identity.</p>
<section id="litentry---identity-aggregator" class="level2">
<h2 class="anchored" data-anchor-id="litentry---identity-aggregator">Litentry - identity aggregator</h2>
<p>Litentry is a decentralized cross-chain identity aggregator which enables linking user identities across multiple networks. Litentry collects, indexes, and distributes DIDs to blockchains in a decentralized way.</p>
<p>Aggregation is the process of integrating a wide range of digital identities from multiple networks.</p>
<p>“Decentralized identifiers (DIDs) are a new type of identifier that enables verifiable, decentralized digital identity. A DID refers to any subject (e.g., a person, organization, thing, data model, abstract entity, etc.) as determined by the controller of the DID.” DIDs, by design, allow the controller of a DID to prove control over it without requiring permission from any other party. ‘Decentralized Identifiers (DIDs) V1.0’<sup>3</sup></p>
<p>Litentry’s main selling point is its decentralized identity and user activity data aggregation infrastructure. It is built on Substrate network.</p>
<p>Protocols could use identity aggregating service for collateralized lending, DeFi insurance rate, and DAO voting power calculations, preventing bots from getting airdrops and various other uses in dApps.</p>
<p>Main features of Litentry:</p>
<ol type="1">
<li>Identity management - The primary focus of this platform are identities. Litentry provides anonymous and independent identities from applications and services used by the user.</li>
<li>Identity Staking - As well as staking tokens and earning, users can “stake” their identity and get rewards.</li>
<li>Distributed storage of identity data.</li>
<li>Users do not need to create multiple accounts to use different platforms of services. They can use one identity to interact with various services.</li>
</ol>
<p>Using Litentry, blockchain projects can “offer” special services to users based on their identity’s quantified data.</p>
<p>“For example, if a new project knows that an account is a Polkadot validator, and it spends hundreds of DOTs on another Parachain for half a year, then the project could directly gift this specific user some token to start to play with, or send him/her an attractive offer of the new DeFi product, or accredit him to be a validated voter.” Litentry<sup>4</sup></p>
<p>It features an identity matching and identity staking mechanism, which are at the very core of the Litentry model. But what do they represent exactly?</p>
<p>Identity Matching is blind matchmaking where random anonymous identities are picked from the on-chain pool of identities, and the substrate off-chain worker processes candidate identity data. The network sends the matchwinners DID as a matching opportunity back to the matching buyer (for example, dApp that wants to do an airdrop). The buyer only has access to the matchwinner’s DID; thus match buyer pays the LIT token in exchange for a matching opportunity.</p>
<p>When it comes to identity staking, that is the process in which an identity owner sends the snapshot of their identity document and DID to the identities pool of blockchain and authorizes the read permissions to the validator node. The owner gets staking and matching rewards in the following blocks. The document is encrypted and stored on IPFS or on the on-chain key-value store. DID is stored on-chain.</p>
<p>Litentry’s use cases and platforms that cover these use cases:</p>
<ol type="1">
<li>TaskFi &amp; Airdrops Whitelisting - Not yet implemented (Drop3 Platform)</li>
</ol>
<p>Litentry identity verification system enables Web3 projects to identify target users and filter out bots. It also has a mechanism where users need to complete the task and then get rewarded after the task is complete.</p>
<ol start="2" type="1">
<li>Social interaction (My Crypto Profile)</li>
</ol>
<p>Using Litentry’s cross-chain capabilities, this platform enables users to generate proof of ownership of various accounts and create a unique identity graph that connects accounts and addresses from Ethereum, Binance, Polkadot, Kusama, Phala, Twitter, and Github into a <strong>unique</strong> Web3 identity. This identity can grant access to various dApps and Airdrops. ‘My Crypto Profile | 0x4d52f8d989796ffde311da9ad696258d5a7b3cc5’<sup>5</sup></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://3327.io/documents/research/assets/ERFC-248/MCP.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">MCP</figcaption><p></p>
</figure>
</div>
<p><em>Picture 1: My Crypto Profile Identity Graph</em></p>
<ol start="3" type="1">
<li>Identity Data Analytics (Web3Go)</li>
</ol>
<p>Web3 go is a multi-chain platform that uses Litentry’s DID aggregated identity data to analyze and provide insights into the activity of a particular cross-chain identity or identities.</p>
<ol start="4" type="1">
<li>Polkadot Name system</li>
</ol>
<p>Litentry currently acts as the main registrar entry for PNS (Polkadot Name System ). Public data is indexed into the domain name with the private name reserved in Litentry’s TEE side chain. A Trusted Execution Environment (TEE) is an environment for executing code; it guarantees code and data loaded inside to be protected with respect to confidentiality and integrity. ‘Polkadot Name System’<sup>6</sup></p>
<p>Litentry products technical overview:</p>
<ol type="1">
<li>Litentry Graph</li>
</ol>
<p>Litentry Graph serves clients with aggregated identity data from Substrate and EVM-based networks. Data is taken directly from the blockchain using APIs such as Polkadot API or using blockchain indexers.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://3327.io/documents/research/assets/ERFC-248/Graph.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Graph</figcaption><p></p>
</figure>
</div>
<p><em>Picture 2: Litentry Graph overview</em></p>
<p>Litentry Graph - An Express GraphQL server using schema stitching to aggregate a collection of remote schemas and subschemas.</p>
<p>Substrate Indexer - takes the data from the Substrate Archives and transforms it into a schema designed for easy querying. Postgres is used to store the data, and a GraphQL query node is used to serve the data to the Litentry graph as a remote schema. This indexer is hosted by Litentry.</p>
<p>Substrate Archive - Is a Postgres database with a real-time feed of raw events and extrinsic data directly from the blockchain. A GraphQL query node is used to serve the data to the Substrate Indexer.</p>
<p>Ethereum &amp; BSC Indedxers - Litentry uses The Graph.</p>
<p>Substrate Chain - The Substrate Chain component queries data directly from blockchain nodes via web sockets using the Polkadot API.</p>
<ol start="2" type="1">
<li>Drop 3</li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://3327.io/documents/research/assets/ERFC-248/Drop3.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Drop3</figcaption><p></p>
</figure>
</div>
<p><em>Picture 3: Drop3 Overview</em></p>
<p><strong>Pallets, Ethereum Verify Bot and Web3 go Analysis are not yet implemented</strong></p>
<p>Drop3 is still in the works. However, they have implemented some tasks into the product like getting verified as a human, connecting polkadot wallet etc.</p>
<ol start="3" type="1">
<li><p>Governance mobile App - We will not go into details of this product as mobile apps are not the topic of the research.</p></li>
<li><p>My Crypto Profile</p></li>
</ol>
<p>Identity Graph:</p>
<pre><code>{
  "version": "v0.1",
  "did": "did:mcp:0xd8ebc2be207451ff9eafb3ef7fada06d64d05059",
  "main": {
    "address": "0x8ad12345c3bc8598d2f602d63e927f5995dcf5d0",
    "chain": "ethereum"
  },
  "web2List": [
    {
      "cid": "bafybeid5fo6ig6ilobawudqwgsu7so5guaedgvkdwyo6k5hnvlqiqjlhaq",
      "account": "x3",
      "socialType": "github",
      "validator": {
        "name": "Litentry Technologies GmbH",
        "validatedAt": "1645810190",
        "signature": "0x0c4c08460e651c6d6949af21c5b290bed39ffcae6cfdb5ef374760758c9387f3643992be7d5b6f5373fb78540b116750471a9fbcc68e5e5ccb5330250158bfab1c"
      }
    }
  ],
  "web3List": [
    {
      "cid": "bafybeihj43osgpx3u5zo567lod25rzfxoqrbspb27v2akdwrgwugziddf4",
      "proofs": ["bafybeidcihuc74xxgatyag2q6iiv7tjwn6vjgc4dk6jravthcryrazzkru"],
      "address": "5DXZdKSFTEx5rE25dnxamebAoSsA4fqgGT9VPFiiouxP2xM1",
      "chain": "polkadot",
      "validator": {
        "name": "Litentry Technologies GmbH",
        "validatedAt": "1645810190",
        "signature": "0x0c4c08460e651c6d6949af21c5b290bed39ffcae6cfdb5ef374760758c9387f3643992be7d5b6f5373fb78540b116750471a9fbcc68e5e5ccb5330250158bfab1c"
      }
    },
    {
      "cid": "bafybeibic6syxpgnvyp5udyrhhuosm3thbslrfm4ivaauqxtus6vbjghsm",
      "proofs": ["bafybeibbsripq672skohuiy6ruztjr5hwclkwoswj6yilt5rkezgmn4f3u"],
      "address": "5GgmqtSXGuh2d3LxRiYo691bL4iTYQNjLCAYNakj4xfmLjnm",
      "chain": "polkadot",
      "validator": {
        "name": "Litentry Technologies GmbH",
        "validatedAt": "1645810356",
        "signature": "0x0c5eb79402646ab7390355404243d73c01cde9ccabd0c26cb1803599c44de8621f69c05848c0e254bdf5849b3ff69fd43b82f3e346cdac3175d052cedf107c3c1c"
      }
    }
  ],
  "createdAt": "1646836239",
  "updatedAt": "1646836239"
}</code></pre>
<p>“Each ID graph is extracted by ID pairs. An ID pair is made of two decentralized verifiable ownership claims. Each ID pair claims the joint ownership of two accounts, it can be a pairing of two web3 addresses, or a pairing of a web3 address and a web2 account. Everyone can verify and trust the ID pair. Each ID graph is represented in its unique DID. For ID graphs that have a common crypto address, one ID graph will be merged into the other ID graphs and keep only one MCP DID.” - Litentry ‘Identity Graph’<sup>7</sup></p>
<p>Token economy:</p>
<p>Suppose we look at the price of LIT token, which is $0.7227 at the time of writing. Litentry reached an all-time high of $14.79 on Feb 16, 2021. Currently, it’s down -95.11% since its record high.</p>
<p>From the market cap of just $26,979,670 we can see that Litentry hasn’t gained much attention or traction as a solution.</p>
</section>
<section id="ore-id---identity-registry" class="level2">
<h2 class="anchored" data-anchor-id="ore-id---identity-registry">ORE ID - identity registry</h2>
<p>Developed by Aikon, ORE is a cross-chain global identity registry where users have control over their own identity. This registry is stored on the ORE blockchain. Users can use ORE ID as a single sign-on to manage their wallets on multiple public blockchains. Single ORE ID account can be used as a wallet on multiple chains because ORE ID accounts hold public and private keypairs for ED 25519, SR25519, and SECP256K1 and SECP256R1 encryption curves.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://3327.io/documents/research/assets/ERFC-248/ore_acc.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Drop3</figcaption><p></p>
</figure>
</div>
<p><em>Picture 4: ORE ID account creation process</em></p>
<p>“Given how sensitive this data is, we use a Trustless Signing Service that allows a user to decrypt their keys and send a signed transaction to various blockchains using ChainJS library. Both of these modules are open source, so any developer can audit the code.” - <a href="https://ore.network/wp-content/uploads/2021/09/ORE-Whitepaper-2.0.pdf">ORE network’s whitepaper</a></p>
<p>ORE ID allows users to access various dApps with a one-click sign-up experience. Users can use social logins of their choosing. ORE ID creates blockchain accounts for the end-user when they sign up and encrypts and stores the user’s private key with their chosen PIN. ORE ID accounts are currently exportable to Scatter Wallet.</p>
<p>When developing an app that uses ORE ID accounts, developers need to register the app and the app logo in order to get their APP-ID and API-key. Documentation is well written and can be found <a href="https://github.com/TeamAikon/oreid">here</a>.</p>
<p>ORE ID operates differently from Litentry as it creates an account that works on multiple chains - it does not aggregate the existing addresses.</p>
<p>Token economy and future of ORE ID:</p>
<p>This project, although an interesting concept, with its market cap of only $ 319,175 doesn’t look like a solution for cross-chain identities and onboarding new users. The current price is $ 0.007984, while its all-time-high was $ 0.320. After testing the ORE ID, it seems that the project has been neglected.</p>
</section>
<section id="accumulate---mainnet-launch-planned-for-september-2022" class="level2">
<h2 class="anchored" data-anchor-id="accumulate---mainnet-launch-planned-for-september-2022">Accumulate - mainnet launch planned for September 2022</h2>
<p>Accumulate is an identity-based, delegated proof-of-stake blockchain solution. It plans on creating a universal communication and audit layer for individuals, entities, and blockchains to transact with each other using their version of identifiers that adhere to W3C standards: Accumulate Digital Identifiers (ADIs).</p>
<p>ADIs are human-readable addresses that users choose to represent their presence on the blockchain. Using ADIs accumulate can serve as a communication and audit layer between blockchains, enabling the transfer of tokens between different chains, no matter the consensus mechanism.</p>
<p>ADIs are made of a collection of independent sub-chains. They are managed by:</p>
<ol type="1">
<li>Token accounts - Issuing tokens and tracking deposits and withdrawals from a token account.</li>
<li>Data accounts - Tracking and organizing data.</li>
<li>Staking accounts - Staking ACME tokens to participate in consensus.</li>
<li>Scratch accounts - Accruing data that is needed to build consensus.</li>
</ol>
<p>Accumulate Innovations:</p>
<ol type="1">
<li>Identity - Accumulate is centered around ADIs where each ADI defines its own state that is independent of other ADIs. Each ADI has its own state and set of accounts and chains. They can be updated independently. They are distributed over a set of Tendermint networks.</li>
<li>Synthetic Transactions - Because each ADI has its state, transactions that are routed to an ADI must be processed independently of all other ADIs. Accumulate generates another transaction that performs settlements within an ADI. These transactions are called synthetic since the protocol generates them in response to the transactions initiated by the user.<br>
</li>
<li>Scratch Accounts - Accumulate provides scratch accounts, which reduce the cost of using the blockchain for consensus building. “Scratch accounts allow processes to provide cryptographic proof of validation and process without overburdening the blockchain” - Accumulate Whitepaper ‘Whitepaper - Accumulate’<sup>8</sup></li>
</ol>
<p>Integrations:</p>
<p>Accumulate protocol supports various smart contract roll-ups. This allows Accumulate to track the state and validity of contracts on third-party chains. Using Accumulate, organizations can process smart contracts across various layer one protocols (Solana, Ethereum, Tezus).</p>
<p>Accumulate also plans on integrating with Layer-0 protocols, for example, Cosmos and Polkadot. In that case, Accumulate can be utilized to manage the transferred asset under the identity (ADI) of a buyer and to continue tracking the assets across multiple chains.</p>
<p>Technical overview:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://3327.io/documents/research/assets/ERFC-248/Accumulate.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Accumulate overview</figcaption><p></p>
</figure>
</div>
<p><em>Picture 5: Accumulate system overview</em></p>
<p>In contrast to the traditional blockchain, where architecture is centered around blocks, Accumulate is centered around accounts. Each account is treated as an independent chain and managed as a growing Merkle tree, and blocks are treated as a synchronization point for all chains in the networks.</p>
<p>Inside the Directory Network and Block Validator Networks is the interconnected network of chains responsible for collecting signatures, communicating with each other, and anchoring roots to other blockchains.</p>
<p>These chains are:</p>
<ol type="1">
<li>Signature chain, which collects signatures for a period of 2 weeks</li>
<li>Main chain which records transactions in the origin account and accounts that are modified by the transactions</li>
<li>Synthetic Transaction chain, which is used to store cryptographic proof that a synthetic transaction was actually produced by a particular BVN.</li>
<li>Binary Patricia Trie, which collects hashes of the current state and history of accounts in BVN and DN.</li>
<li>Root Anchor Chain - collects an anchor once per block from every account and system chain updated during the block.</li>
<li>Intermediate Anchor Chain: Within the Directory Network, this chain collects anchors from the Root Anchor chain of every Block Validator Network once per block.</li>
</ol>
<p>As our topic is identity we will focus more on the account and identity architecture of Accumulate, which is actually at the very core of this protocol:</p>
<p>Accumulate supports these accounts:</p>
<ol type="1">
<li>Lite Token Account - Traditional address whose URL contains a public key hash and human-readable suffix denoting the token or a data type held by the account. When tokens are sent to this account, the account is created if it doesn’t exist. Users can create a key and have a trusted party send tokens to their URL.</li>
<li>Lite Data Account - It is used for collaboration with Factom protocol. Lite Data Accounts are similar to token accounts, but they are limited to writing data.</li>
<li>Accumulate Digital Identifier (ADI) - Primary unit of organization within Accumulate. ADIs can issue their tokens.</li>
<li>Key book and Key Page - Belongs to an ADI and is used for key management.</li>
<li>ADI Token and Data Accounts are explained at the beginning of the topic</li>
</ol>
<p>Identity architecture:</p>
<p>Users can participate in the network through ADIs and Lite Accounts. ADIs give users access to smart contracts, off-chain consensus building, and dynamic key management. Lite Token and Data Accounts are just a “lite” version of ADIs.</p>
<p>ADIs can only be created through the spending of Credits issued through the Accumulate protocol. Users can also use their ADI to sponsor the creation of other ADIs for themselves or others. These identities can govern token issuance, off-chain consensus building, and multisig signatures.</p>
<p>“ADI Data and Token Account URLs have the general format <code>acc://&lt;ADI&gt;/&lt;directory&gt;/&lt;account&gt;</code> where the prefix acc : // specifies the Accumulate blockchain, ADI specifies the toplevel identity in control of the URL, directory specifies a particular type of account, and account specifies data or tokens.” - Accumulate Whitepaper.</p>
<p>We will not venture deeper into the protocol architecture as it is reasonably complex and goes well beyond this research topic. The main takeaway is that it aims to create cross-chain transaction-compatible accounts using ADIs. The details of a way how this will work in practice are not covered in the whitepaper.</p>
<p>This project is still in development, which means the practical implementations of the concepts presented in the whitepaper are still under the big question mark sign.</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>We can see from the explored “solutions” that tackling cross-chain identity problems in Web3 is not an easy task. Many projects emerged but fell victim to their lousy architecture and the general public’s low interest. Different blockchains use different hash functions, making creating a standardized cross-chain identity hard. SBTs, a newly proposed solution by E. Glen Weyl, Puja Ohlhaver, and Vitalik Buterin aim to solve the problem of Web3 identities by creating a new standard. In their paper Decentralized Society: Finding Web3’s Soul, they propose a new solution: Soul Accounts and Soul Bound Tokens. However, there is no talk about Soul accounts being compatible with multiple chains. For more information, see ERFC-261, which we already covered in that paper. However, the concept of creating custom identity systems like the ones above mentioned is an exciting topic, and we think it should be looked into further, regardless of whether building a cross-chain identity or not.</p>
</section>
<section id="bibliography" class="level1">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Bibliography</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-DecentralizedIdentifiersDIDs" class="csl-entry">
‘Decentralized Identifiers (DIDs) V1.0’ &lt;<a href="https://www.w3.org/TR/did-core/" class="uri">https://www.w3.org/TR/did-core/</a>&gt; [accessed 15 June 2022]
</div>
<div id="ref-IdentityGraph" class="csl-entry">
‘Identity Graph’ &lt;<a href="https://docs.litentry.com/products/my-crypto-profile/product-features/identity-graph" class="uri">https://docs.litentry.com/products/my-crypto-profile/product-features/identity-graph</a>&gt; [accessed 15 June 2022]
</div>
<div id="ref-litentryIntroducingLitentry2020" class="csl-entry">
Litentry, ‘Introducing Litentry’, <em>Medium</em>, 2020 &lt;<a href="https://litentry.medium.com/introducing-litentry-d47b23d54281" class="uri">https://litentry.medium.com/introducing-litentry-d47b23d54281</a>&gt; [accessed 15 June 2022]
</div>
<div id="ref-MyCryptoProfile" class="csl-entry">
‘My Crypto Profile | 0x4d52f8d989796ffde311da9ad696258d5a7b3cc5’ &lt;<a href="https://mycryptoprofile.io/profile/0x4d52f8d989796ffde311da9ad696258d5a7b3cc5" class="uri">https://mycryptoprofile.io/profile/0x4d52f8d989796ffde311da9ad696258d5a7b3cc5</a>&gt; [accessed 15 June 2022]
</div>
<div id="ref-PolkadotNameSystem" class="csl-entry">
‘Polkadot Name System’ &lt;<a href="https://www.pns.link/" class="uri">https://www.pns.link/</a>&gt; [accessed 15 June 2022]
</div>
<div id="ref-SelfsovereignIdentities" class="csl-entry">
‘Self-Sovereign Identities’, <em>Bosch Global</em> &lt;<a href="https://www.bosch.com/stories/self-sovereign-identities/" class="uri">https://www.bosch.com/stories/self-sovereign-identities/</a>&gt; [accessed 14 June 2022]
</div>
<div id="ref-ThousandsLeakedFacebook" class="csl-entry">
‘Thousands of Leaked Facebook Documents Show Mark Zuckerberg as “Master of Leverage” in Plan to Trade User Data’, <em>NBC News</em> &lt;<a href="https://www.nbcnews.com/tech/social-media/mark-zuckerberg-leveraged-facebook-user-data-fight-rivals-help-friends-n994706" class="uri">https://www.nbcnews.com/tech/social-media/mark-zuckerberg-leveraged-facebook-user-data-fight-rivals-help-friends-n994706</a>&gt; [accessed 14 June 2022]
</div>
<div id="ref-WhitepaperAccumulate2022" class="csl-entry">
‘Whitepaper - Accumulate’, 2022 &lt;<a href="https://accumulatenetwork.io/whitepaper/" class="uri">https://accumulatenetwork.io/whitepaper/</a>&gt; [accessed 16 June 2022]
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p><em>NBC News</em> &lt;&lt;https://www.nbcnews.com/tech/social-media/mark-zuckerberg-leveraged-facebook-user-data-fight-rivals-help-friends-n994706&gt;&gt; [accessed 14 June 2022].↩︎</p></li>
<li id="fn2"><p><em>Bosch Global</em> &lt;&lt;https://www.bosch.com/stories/self-sovereign-identities/&gt;&gt; [accessed 14 June 2022].↩︎</p></li>
<li id="fn3"><p>&lt;[Https://www.w3.org/TR/did-core/](https://www.w3.org/TR/did-core/)&gt; [accessed 15 June 2022].↩︎</p></li>
<li id="fn4"><p>‘Introducing Litentry’, <em>Medium</em>, 2020 &lt;&lt;https://litentry.medium.com/introducing-litentry-d47b23d54281&gt;&gt; [accessed 15 June 2022].↩︎</p></li>
<li id="fn5"><p>&lt;[Https://mycryptoprofile.io/profile/0x4d52f8d989796ffde311da9ad696258d5a7b3cc5](https://mycryptoprofile.io/profile/0x4d52f8d989796ffde311da9ad696258d5a7b3cc5)&gt; [accessed 15 June 2022].↩︎</p></li>
<li id="fn6"><p>&lt;[Https://www.pns.link/](https://www.pns.link/)&gt; [accessed 15 June 2022].↩︎</p></li>
<li id="fn7"><p>&lt;[Https://docs.litentry.com/products/my-crypto-profile/product-features/identity-graph](https://docs.litentry.com/products/my-crypto-profile/product-features/identity-graph)&gt; [accessed 15 June 2022].↩︎</p></li>
<li id="fn8"><p>2022 &lt;&lt;https://accumulatenetwork.io/whitepaper/&gt;&gt; [accessed 16 June 2022].↩︎</p></li>
</ol>
</section></div> ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-248.hugo.html</guid>
  <pubDate>Tue, 14 Jun 2022 00:00:00 GMT</pubDate>
  <media:content url="https://3327.io/documents/research/assets/ERFC-248/MCP.png" medium="image" type="image/png" height="96" width="144"/>
</item>
<item>
  <title>[ERFC - 270] ZK NFT Mixer</title>
  <dc:creator>Aleksandar Veljković</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-270.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p>NFTs are growing in popularity, and so are the numbers of transactions for transferring the NFTs on the Blockchain. One of the main features of the Blockchain is privacy, but only in terms of pseudo-anonymity. The pseudo-anonymity implies that the user creating the transaction is hidden, as he is represented using an opaque, pseudo-random address. Still, the transactions between the addresses are transparent. By analyzing the transaction graph and external inputs, such as social network posts putting the address in a specific context, it is possible to deduce the address owner and reveal all his transactions. This research aims to analyze the possibility of creating a solution that can enable NFT transfers in an environment that supports complete anonymity but is still compatible with Ethereum. The proposed infrastructure represents a zero-knowledge mixer supporting shielded transfers of the NFTs on the side chain with the ability to withdraw NFTs back on the main chain.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Many existing solutions utilize zero-knowledge proofs to shield transactions or mix the coins and tokens. Those solutions include Zero cash, Tornado cash, Monero, and many more. The common thread connecting all of them is that they are meant for transferring currency. Although some providers (like Tornadocash [1]) announced, ZK solutions for transferring NFTs are not very popular. Unlike the currency, the NFTs are unique objects, and it is not easy nor practical to hide them in plain sight. It is possible to hide what is transferred, but it is easy to follow the trail if the thing that is transferred is unique.</p>
<p>NFTs are finding their way to the sidechains, as the Ethereum mainnet transactions often become too much overhead for minting or transferring NFTs [2]. ZK rollups like zkSync are also used for transferring and minting the NFTs [3], but the “ZK” part of the rollup doesn’t refer to privacy but compression of the transactions as a scalability solution. Bridges between sidechains and Ethereum allow NFT transfers between the chains [4], enabling cheap transactions on the side chain and final transfer back on the main chain. None of the general-purpose side chains provide shielded NFT transfers. A new solution promising shielded transfers for any assets is Namada [5, 6], Blockchain specifically built for asset privacy. With new updates of Nightfall, Polygon also announces featuring private NFT exchanges [7].</p>
<p>This research investigates the possibilities of using existing, widely adopted, general-purpose side chains to implement shielded NFT transfers. If the projects featuring shielded NFTs are scarce, a good question is if there is a market need for such a solution. The answer to this may not come from the current state of the market but the predictions of future trends. As the NFTs gain even more popularity and move from the hype-regulated market of novelties to more serious use cases, such as access control, certificate issuing, and similar, there is an indication that shielding NFTs of such documents will become a requirement. Such trends are also visible through the projects announcing future updates supporting this domain.</p>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p>The main goal of this research is to investigate the possibilities of implementing a zero-knowledge mixer for NFTs, using a side chain for shielding transfers resulting in a proposal of a software architecture and algorithms that would support such a system.</p>
<p>It is essential first to analyze the building blocks of similar solutions to be able to come up with a new one. A cross-chain movement of tokens is enabled using cross-chain bridges. The focus here would be on two-way decentralized bridges between two EVM chains. The two-way bridges consist of two smart contracts on each side. The role of smart contracts is locking tokens on one side and releasing or minting tokens on the other side. The contracts communicate by firing events on one side, and validator nodes that listen to those events trigger operations on the other.</p>
<p>There are two types of blockchains regarding the representation of the main currency on the chain - wallet-based and UTXO base. The wallet-based chains represent currency as a gross numerical value stored in the memory fields associated with specific accounts. When the amount <img src="https://latex.codecogs.com/png.latex?X"> is transferred from wallet A to wallet B, the values are updated so that wallet A has <img src="https://latex.codecogs.com/png.latex?X"> coins less and wallet B has <img src="https://latex.codecogs.com/png.latex?X"> coins more in the associated memory field. This logic is familiar to Ethereum users, as Ethereum is a wallet-based blockchain.</p>
<p>The chains based on UTXOs have a different philosophy. The UTXO acronym stands for “Unspent transaction (TX) output,” which may give a clue on the main structure used for representing the coins. Let’s use Bitcoin as a representative of a UTXO-based chain. Each transaction on Bitcoin requires an input amount of coins that should be transferred to the other address. The user might not see it, but the coins are not just numbers updated with each transaction, as the transactions on Bitcoin have a more strict input-output definition. There are no wallets as memory locations linked with the account, but the coins are represented as one or many UTXOs. Users own their UTXOs by having them linked with their public key and transfer them by signing the transactions using the private key associated with the UTXOs. When the user has a UTXO of five coins and wants to transfer three of them, the transaction uses a UTXO of five coins as input. The outputs of the transaction are two new UTXOs. The first one represents the transferred amount with the value three labeled with the recipient’s public key. The other is the remainder, or the unspent amount with the value two, tagged with the sender’s key. If the user has two UTXOs with two coins each and wants to transfer three coins, the user would use both UTXOs as transaction inputs. Again, the output would be two new UTXOs, one with the transferred amount for the recipient, and the other, the unspent part for the sender.</p>
<p>Systems that enable shielded transactions utilize UTXO representation for the shielded tokens even on chains that are not natively UTXO-based, as that representation is more suitable for the use case. In such systems, the UTXO values are hidden from the public and only visible to the recipient with a private key to decrypt it. The workload for computing transaction parameters is now on the sender’s side, as no other participant can see the UTXO value. The sender prepares the transaction’s inputs and outputs and generates a zero-knowledge proof that the transaction is generated correctly with proper values. The proof must confirm that the sender knows the non-encrypted UTXO value and the correct values of the resulting UTXOs after the transfer. Monero uses additional decoy values as fake UTXOs to spoof the actual token transfer and blur the overall chain of transfers [8]. Preventing double-spending is mainly done using nullifiers - values representing “coupons” for spending the UTXO. The UTXO is tied to a nullifier value, and transferring the UTXO requires the user to submit the nullifier linked with the UTXO, marking the UTXO as used. One nullifier can be used only once. When the piece of UTXO is spent, the remainder and the sent part are converted to new UTXOs with their respective nullifiers.</p>
<p>NFTs represent unique objects, so the methods used for hiding and splitting the token batches are not directly applicable to NFTs. Conversely, if the methods could be adapted to support NFTs, most well-tested algorithms and flows could be reused. Converting NFT to a UTXO-like object, called commitments, may be straightforward. The commitment may hide the token address and ID information, but the quantity value will always be one. Unfortunately, even if the quantity and token information are hidden, tracking the token in the network is easy. There is a 1-to-1 mapping between the input token and the resulting commitment. A solution to this problem may lay in decoys.</p>
<p><img src="https://3327.io/documents/research/assets/ERFC-270/decoy.jpeg"></p>
<p>One NFT can be converted to one correct commitment followed by <img src="https://latex.codecogs.com/png.latex?N-1"> false commitments constructed as decoys. This schema would fail when only the NFT commitment is transferred to the other user, revealing which of the <img src="https://latex.codecogs.com/png.latex?N"> commitments was the NFT. To mitigate this problem, each transfer transaction of the NFT commitment should also include transferring <img src="https://latex.codecogs.com/png.latex?K"> additional decoys to different addresses. When all participants use decoys with their transfers, the transfer graph is quickly blurred, and finding the actual NFT commitment needle in a haystack of decoys becomes difficult. One downside of this approach is a quicker filling of the commitment Merkle tree, but it can be mitigated using a bigger tree. The other is the cost increase. Under the assumption that the decoying mechanism provides reasonable privacy and anonymity, the protocol can reuse the previous building blocks to complete the system.</p>
<section id="depositing-nfts-from-ethereum-to-the-side-chain" class="level2">
<h2 class="anchored" data-anchor-id="depositing-nfts-from-ethereum-to-the-side-chain">Depositing NFTs from Ethereum to the side chain</h2>
<p>User deposits NFTs on the Ethereum smart contract by sending a transaction allowing the smart contract to take over the NFT. On the side chain, <img src="https://latex.codecogs.com/png.latex?N"> commitments are minted and added to a Merkle tree. The smart contract can’t say which commitment resembles the NFT, so the commitment values need to be constructed in a specific way by the user and submitted to Ethereum smart contract. The NFT commitment should be a hash of NFT ID, NFT address, owner’s ephemeral public key, and some secret value. Other, <img src="https://latex.codecogs.com/png.latex?N-1">, commitments should be hashes of a string value NULL, the owner’s ephemeral public key, and some other secret value. The user must provide ZK proof that exactly one commitment is the NFT commitment while all other <img src="https://latex.codecogs.com/png.latex?N-1"> values are decoys. Each commitment is tied to a nullifier, generated as a hash of the commitment ID, a Merkle path of the commitment inside the Merkle tree, and the same secret value used for the specific commitment. The secrets should be different for each commitment-nullifier pair. By doing this setup, the public still doesn’t know which commitment is the NFT, but anyone can verify that one of the commitments indeed is the NFT, while others are blanks.</p>
</section>
<section id="transfering-nfts-on-the-sidechain" class="level2">
<h2 class="anchored" data-anchor-id="transfering-nfts-on-the-sidechain">Transfering NFTs on the sidechain</h2>
<p>Users on the side chain are identified using their new ephemeral keys, meaning the keys should be changed frequently. The keys are the private key, public key, and encryption key. The public key is a private key hash, while the encryption key is “the real” public key, in the sense of public-key cryptography, derived from the private key. Transferring NFTs is similar to tornado cash logic with the addition of decoys. For each NFT transfer, the user also transfers <img src="https://latex.codecogs.com/png.latex?N-1"> other decoys to <img src="https://latex.codecogs.com/png.latex?N-1"> different addresses. Received decoys from other users can (and should) be used in further transfers of NFTs, thus enabling further obfuscation of the trading paths. Each transfer on the sidechain is a shielded transfer, meaning that it is not performed as a regular token transfer but as a protocol backed by zero-knowledge proofs. Before explaining the protocol, let us first see how the commitment is constructed. The commitment contains two values, the commitment value, defined during deposit, and a secret value used as a salt while generating the first value. Both values are stacked in a byte array and encrypted using the owner’s public key. When the user wants to transfer the commitment, a new commitment and decoys are sent to the sidechain. ZK proof is also sent on the chain, proving that all the computations were correct. The sender proves that the new commitment is derived from the proper input commitments and nullifiers, and the output commitments are generated in the way that only one output commitment contains the NFT. The new commitment is encrypted using the recipient’s public key, so only the recipient can decrypt it and use it later. The recipient listens to the sidechain events to see if any new commitment can be decrypted using his private key and notes down all the commitments that pass the test.</p>
</section>
<section id="withdrawing-nfts-from-the-side-chain-to-ethereum" class="level2">
<h2 class="anchored" data-anchor-id="withdrawing-nfts-from-the-side-chain-to-ethereum">Withdrawing NFTs from the side chain to Ethereum</h2>
<p>The user who initiates withdrawal must prove ownership of the commitment representing the NFT by providing ZK proof. The user proves the knowledge of the secret preimage used for generating the initial commitment. When the proof is verified and valid, the commitment is nullified. The smart contract on the Ethereum transfers the locked NFT to the Ethereum address provided within the withdrawal request.</p>
</section>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<p>The system’s building blocks are presented in the previous chapter, and it is time to put them all together. The system architecture consists of two smart contracts, one on Ethereum and the other on the EVM side chain, and a validator network that can support the bridge between the chains.</p>
<p>The commitment format is a slightly modified UTXO Tornado Cash implementation used for TORN tokens, which benefits the protocol’s safety, as it is not an entirely new, untested concept. The strength of the protocol lies in indistinguishable commitments that are simultaneously transferred to multiple addresses. An external viewer cannot discern which of the commitments hide the NFT, as with each transfer step, new <img src="https://latex.codecogs.com/png.latex?N-1"> commitments are generated or reused and transferred to obfuscate the token trail further. The novelty introduced by the protocol lies in the initial issuing of commitments for NFT as hashes, backed by the zero-knowledge proofs, which guarantee that strictly one copy of the token is cloned on the sidechain while the other copies are decoys. The proposed name for the protocol is “The thimblerig protocol,” as it closely resembles a street con artist who tries to hide a ball by shuffling it many times under multiple, same-looking cups.</p>
<p>The downside of the protocol is the volume of commitments generated for transferring decoys and their respective nullifiers, which are stored locally in wallets. A proof of concept implementation is needed to estimate better the protocol cost, efficiency, and practical usability.</p>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>The presented protocol represents a combination of the existing protocols for shielded transfers and token mixing, adapted for NFT transfers. Generic in nature, it can be used between any two EVM chains. The next steps should include selecting the practical use cases that require the shielded NFT token transfers and evaluating the usability of the presented protocol against the selected use cases. Further research may also require a proof of concept implementation between two designated EVM chains.</p>
</section>
<section id="bibliography" class="level1">
<h1>Bibliography</h1>

<p>[1] https://www.coindesk.com/tech/2021/12/15/ethereum-mixer-tornado-cash-launches-major-upgrade-as-v3-approaches/</p>
<p>[2] https://www.one37pm.com/nft/alt-chain-nfts-palm-sidechain-loom-network-xdai</p>
<p>[3] https://zknft.xyz</p>
<p>[4] https://bridge.mintnft.today/</p>
<p>[5] https://namada.net/</p>
<p>[6] https://medium.com/anomanetwork/introducing-namada-shielded-transfers-with-any-assets-dce2e579384c</p>
<p>[7] https://blog.polygon.technology/introducing-polygon-nightfall-mainnet-decentralized-private-transactions-for-enterprise/</p>
<p>[8] https://www.coindesk.com/layer2/privacyweek/2022/01/25/monero-the-privacy-coin-explained/</p>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs">

</div></section></div> ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-270.hugo.html</guid>
  <pubDate>Sun, 05 Jun 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Approaches to Testing Of Smart Contracts</title>
  <dc:creator>Milos Bojinovic</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-259.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p><strong>Smart Contracts</strong> are applications built on blockchain that, once deployed, cannot be altered or updated. With that in mind, their testing is crucial, even more so than in traditional software development.</p>
<p>Several different techniques exist in the testing of Smart Contracts, and it is up to the developers to choose when a technique should be used with the goal of creating tests that will perform sufficient validation. This is a non-standardized, individualistic approach as there is no established methodology for doing this, and the developers’ skill plays an essential part in it.</p>
<p>This research focuses on testing techniques that are most widely used and showcases them in order to give a sense of what kind of testing is possible and where it makes sense.</p>
<p>In testing, there is always the question of whether the collection of tests (test suite) covers all of the cases - “Who will guard the guards themselves?”*.</p>
<p>To answer this question, to a certain degree, the paper elaborates on evaluation tools that indicate whether or not more tests should be written or if there’s a case that is overlooked.</p>
<p>As the techniques and tools mature and increase in complexity, we may see the introduction of standardized methodologies that provide a thinking framework on how code should be written and/or tested, as well as a separation of roles between developers and testers.</p>
<p>*Quis custodiet ipsos custodes? - a Latin phrase found in the work of the Roman poet Juvenal (Satire VI, lines 347–348)</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Testing involves thinking about how code sections should behave in the wanted (ideal) case, but also what consequences might occur if some unintended actions are performed by unaware or even malevolent actors.</p>
<p>The logical question occurs of “what needs to get tested … and how ?”. This is an extremely hard question, and the answer to it lies in the considerations that the developers consciously/unconsciously make. It is important that they keep up to date with the latest techniques, now more than ever, as the past experiences of others can help in establishing best practices and be used in solving similar or completely new problems.</p>
<p>Sanity checks can be performed by using evaluation tools that help with casting light on areas that were previously overlooked. Still, to add another layer of confidence, a set of completely new, trusted eyes should separately go through the code and try to find bugs and/or exploits in it. This is referred to as a Smart Contract audit and is the last step before the deployment to mainnet.</p>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p>The focus of this research is on the testing and evaluation techniques that are currently being used in the area of Smart Contract development in the Ethereum Virtual Machine (EVM) ecosystem without going down the rabbit hole of what the best practices are.</p>
<p>The methodology consists of describing a technique and then giving an appropriate example that shows when it is adequate to use it. Frameworks are purposefully not mentioned, as it is more important to first understand the key concepts of what is being done rather than the unique and specific details of how something is done.</p>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<p>As to not give too abstract and vague descriptions, an example of a smart contract is given on which the testing can be performed and through which a better understanding can be created.</p>
<section id="contract-example" class="level2">
<h2 class="anchored" data-anchor-id="contract-example">Contract example</h2>
<p>The example contract <code>DummyToken</code> can wrap/unwrap Ether through <code>deposit</code> and <code>withdraw</code> functions and transfer the tokens between two addresses using a function of the same name - <code>transfer</code>. During the execution of those functions, a corresponding event is emitted.</p>
<p>The implementation details are purposefully hidden with the intention of starting the thinking process of how those functions should behave both when called in intended and non-intended ways.</p>
<pre class="solidity"><code>/**
 * @dev Implementation of the Dummy Token.
 */
contract DummyToken {

    /**
     * @dev Emitted when tokens are moved from one account (`from`) to
     * another (`to`) of the `value` amount.
     */
    event Transfer(address indexed from, address indexed to, uint value);

    /**
     * @dev Emitted when a new Deposit is made
     */
    event Deposit(address indexed to, uint value);

    /**
     * @dev Emitted when new Withdrawal is made
     */
    event Withdrawal(address indexed to, uint value);

    ...

    /**
     * @dev Mints `value` tokens to `msg.sender` that corresponds to `msg.value` .
     *
     * Returns a boolean value indicating whether the operation succeeded.
     *
     * Emits a {Deposit} event.
     */
    function deposit () public payable returns (bool) {...}

    /**
     * @dev Burns `value` tokens if the `msg.sender` balance can cover it.
     *
     * Returns a boolean value indicating whether the operation succeeded.
     *
     * Emits a {Withdraw} event.
     */
    function withdraw (uint value) public returns (bool) {...}

    /**
     * @dev Moves `value` tokens from the caller's account to `to`.
     *
     * Returns a boolean value indicating whether the operation succeeded.
     *
     * Emits a {Transfer} event.
     */
    function transfer (address to, uint value) public returns (bool) {...}

    /**
     * @dev Returns the number of tokens owned by `account`.
     */
    function balanceOf(address account) public view returns (uint) {...}

    /**
     * @dev Returns the total amount of tokens in existence.
     */
    function totalSupply() public view returns (uint) {...}

}</code></pre>
<section id="specification-of-the-transfer-function" class="level3">
<h3 class="anchored" data-anchor-id="specification-of-the-transfer-function">Specification of the <code>transfer</code> function</h3>
<p>To understand the forms of testing that can be performed, let us write a specification on what one of the functions needs to accomplish, namely the <code>transfer</code> function.</p>
<section id="high-level-specification-of-the-transfer-function" class="level4">
<h4 class="anchored" data-anchor-id="high-level-specification-of-the-transfer-function">High level specification of the <code>transfer</code> function</h4>
<p>This function transfers the amount of tokens (<code>value</code>) from the <code>msg.sender</code>‘s balance to the <code>to</code> address’ balance.</p>
</section>
<section id="low-level-specification-of-the-transfer-function" class="level4">
<h4 class="anchored" data-anchor-id="low-level-specification-of-the-transfer-function">Low level specification of the <code>transfer</code> function</h4>
<ul>
<li>After successful transfer, the balance of <code>to</code> address is incremented by the <code>value</code> amount and the <code>msg.sender</code>’s balance is decremented by it.</li>
<li>If the <code>msg.sender</code>’s balance is smaller than the <code>value</code>, the transaction should revert with the <code>"Transfer amount exceeds balance"</code> message.</li>
<li>If the transfer is successful, the function returns <code>true</code> - otherwise, it returns <code>false</code></li>
<li>If the transfer is successful, the <code>Transfer</code> event should be emitted with the corresponding fields:
<ul>
<li><code>from</code> : <code>msg.sender</code></li>
<li><code>to</code> : value of the <code>to</code> argument</li>
<li><code>value</code> : value of the <code>value</code> argument</li>
</ul></li>
</ul>
</section>
</section>
</section>
<section id="forms-of-testing" class="level2">
<h2 class="anchored" data-anchor-id="forms-of-testing">Forms of testing</h2>
<section id="unit-testing" class="level3">
<h3 class="anchored" data-anchor-id="unit-testing">Unit Testing</h3>
<p>Unit Testing relies on keeping the tests separate from each other and as simple as possible, with each unit test being responsible for testing a single module(“unit”).</p>
<p>These tests follow a common pattern referred to as <strong>Arrange-Act-Assert(AAA)</strong>. First, the “arrangments” are made to put the system in the desired state, then the “act” is performed (function call most often) that leads the system to the next state, after which that state is “asserted” for correctness.</p>
<p>In an individual unit test, most often, only one assertion is made, which increases the number of tests. This, however, has the benefits of having a clear indication of why a test has failed and increasing the code readability.</p>
<p>When thinking about unit testing the <code>DummyToken</code> contract, we will take only the <code>transfer</code> function as an example. Following is an incomplete list of test scenarios for this functionality that should serve as a starting point.</p>
<section id="test-scenarios" class="level4">
<h4 class="anchored" data-anchor-id="test-scenarios">Test Scenarios:</h4>
<p>To form a part of a test suite, let us divide the test scenarios into two sections (<strong>generalized</strong> and <strong>edge cases</strong>) and write some examples of tests for each of them.</p>
<ul>
<li><p><strong>Generalized:</strong></p>
<ul>
<li>Valid* Transfer <code>amount</code>** of <code>DummyToken</code> from <code>address0</code> to <code>address1</code> where <code>address0</code> != <code>address1</code>
<ul>
<li>Tests:
<ul>
<li><code>address0</code>’s balance is decremented by the <code>amount</code></li>
<li><code>address1</code>’s balance is incremented by the <code>amount</code></li>
<li>balances of other adresses has not changed</li>
<li><code>Transfer</code> event was emitted with the corresponding fields</li>
</ul></li>
</ul></li>
<li>Invalid* Transfer <code>amount</code> of <code>DummyToken</code> from <code>address0</code> to <code>address1</code> where <code>address0</code> != <code>address1</code>
<ul>
<li>Tests:
<ul>
<li>transaction was reverted with the right message (“Transfer amount exceeds balance”)</li>
</ul></li>
</ul></li>
<li>…</li>
</ul></li>
<li><p><strong>Edge Cases:</strong></p>
<ul>
<li>Valid/Invalid Transfer <code>amount</code> of <code>DummyToken</code> from <code>address0</code> to <code>address1</code> where <code>address0</code> == <code>address1</code></li>
<li>Valid Transfer <code>0/1</code> of <code>DummyToken</code> from <code>address0</code> to <code>address1</code> where <code>address0</code> != <code>address1</code></li>
<li>Valid Transfer <code>0/1</code> of <code>DummyToken</code> from <code>address0</code> to <code>address1</code> where <code>address0</code> == <code>address1</code></li>
<li>…</li>
</ul></li>
</ul>
<p>*Term “Valid/Invalid” refers to the fact of whether this transfer should be possible (due to balance amounts).</p>
<p>**<code>amount</code> can be any <code>uint</code> (including the value being greater than the total supply)</p>
<p>We can notice that for the first scenario of the generalized section, four tests need to be written, with each of them being a unit test that checks a specific thing (i.e., the sender’s balance has been decremented by the right amount).</p>
<p>It is important to note that a “Property-based Testing” technique was used in the above list, which is a form of an automated process called “fuzzing” that is used to find bugs by feeding randomized data into the system. This technique focuses on the “properties” of the code that should always hold. The tests are not concerned with the actual values of <code>amount</code>, <code>address0</code>, and <code>address1</code>, which can be anything in the allowed range of possibilities. Rather, they aim to say whether the properties around the balances hold in the test scenario - i.e., if an account transfers some tokens to another account, only those two balances should be affected.</p>
</section>
</section>
<section id="integration-testing" class="level3">
<h3 class="anchored" data-anchor-id="integration-testing">Integration Testing</h3>
<p>In the context of Smart Contract testing, integration tests validate interactions between different components of a single contract or across multiple different contracts and are more complex when compared to unit tests.</p>
<p>One form of integration testing is <strong>Stateful testing</strong>, an advanced method of property-based testing, where a single test is defined by:</p>
<ul>
<li>an <strong>initial state</strong> that can, after deployment, be kept as it is or be created by some fixed sequence of <strong>actions</strong></li>
<li><strong>actions</strong> - transactions that lead to a transition of state</li>
<li><strong>invariants</strong> which are properties that should always hold true</li>
</ul>
<p>Starting from the <strong>initial state</strong>, a randomized sequence of <strong>actions</strong> is carried out, where after each action, all of the <strong>invariants</strong> are tested.</p>
<p>For example, when writing a “stateful” test for the <code>DummyToken</code> contract :</p>
<ul>
<li><strong>initial state</strong> can be created such that each test account calls a <code>deposit</code> function with a random amount of Ether provided</li>
<li><strong>actions</strong> can be kept basic (<code>deposit</code> , <code>transfer</code> and <code>withdraw</code>) or more complex (nested - i.e.&nbsp;one action can be [<code>deposit</code>, <code>withdraw</code>, <code>withdraw</code>,…])</li>
<li>one of the <strong>invariants</strong> can be that sum of account balances of the <code>DummyToken</code> must always be equal to the Ether amount that the contract holds</li>
</ul>
<p>Besides being more complex, integration tests require more resources and execution time.</p>
</section>
<section id="static-code-analysis" class="level3">
<h3 class="anchored" data-anchor-id="static-code-analysis">Static (code) analysis</h3>
<p>Both of the above-mentioned forms of testing are considered a type of “dynamic code analysis” that searches for bugs during the execution of the program, and they are the main topic of this research.</p>
<p>It is worth mentioning its counterpart - <strong>Static code analysis</strong> or just <strong>Static analysis</strong>, which is a debugging method that examines the source code before a program is run. This is done by analyzing the code against a set of detection rules that include: timestamp dependency, integer underflow/overflow, re-entrancy issues, use of tx.origin instead of msg.sender, … It remains up to the developer to implement or reject the recommendations of these rules.</p>
</section>
<section id="general-considerations" class="level3">
<h3 class="anchored" data-anchor-id="general-considerations">General Considerations</h3>
<p>Smart Contracts operate in an extremely hostile environment, and this should always be taken into account. During development and testing, the most valuable guiding principle is that everything that can go wrong will eventually go wrong, especially if someone stands to benefit from it.</p>
<p>A set of principles can be adopted to make the functionality of a contract and its complexity more manageable as to reduce the probability of bugs or exploits happening. Some of those include that:</p>
<ul>
<li>code should be modularized and kept simple (KISS and DRY principles*** should be followed)</li>
<li>clarity should be preferred over performance (if possible)</li>
<li>latest versions of battle-tested tools and frameworks should be used</li>
<li>the blockchain characteristics should be considered</li>
<li>the latest security developments should always be incorporated</li>
<li>deployment and testing should be done on Testnet before moving to Mainnet</li>
</ul>
<p>*** KISS (Keep It Simple, Stupid) and DRY (Don’t Repeat Yourself) are software programming principles where KISS states that the most simple solutions often work the best, while DRY follows the reasoning that same/similar code sections should not be replicated across the code base.</p>
</section>
</section>
<section id="evaluation" class="level2">
<h2 class="anchored" data-anchor-id="evaluation">Evaluation</h2>
<p>The purpose of tests is to verify the correctness of the implementation, which poses the question of whether or not the test suite is sufficient for the implementation requirements. To address this and to have a sanity check for a developer’s thought process, evaluation tools have been created.</p>
<section id="code-coverage" class="level3">
<h3 class="anchored" data-anchor-id="code-coverage">Code Coverage</h3>
<p>The term <strong>code coverage</strong> refers to the set of evaluation metrics that are used to determine how much of the program has been tested by the test suite - how many functions have been called, how many statements have been executed, etc.</p>
<p>For example, in the code below, to reach a 100% coverage for the function <code>fcn</code>, at least one of the tests would need to call with parameters that pass all of the three <code>if</code> statements (i.e.&nbsp;<code>fcn(32, 300, 500)</code>).</p>
<pre class="solidity"><code>function fcn (uint a, uint b, uint c) {

    if(a &lt; 100) {
        if(b &gt; 200) {
            if(c &gt; 300 &amp;&amp; c &lt; 600) {
                ...
            }
        }
    }
}</code></pre>
<p>While a high coverage doesn’t generally equal good tests, low coverage helps in identifying gaps in the test suite that can be filled by adding new, carefully designed tests.</p>
<section id="coverage-guided-fuzzing" class="level4">
<h4 class="anchored" data-anchor-id="coverage-guided-fuzzing">Coverage-guided Fuzzing</h4>
<p>During testing, feeding purely randomized values is often wasteful and time-consuming. In the example above, parameter <code>a</code> is of type <code>uint</code>, which means it can hold any value in the range [0, 2**64-1], but the condition <code>a &lt; 100</code> will hold true only for a small portion of time.</p>
<p>Coverage-guided Fuzzing takes into account code coverage information for each random value it tries, and if that value executes a new code, it is put in the set of promising values. For example, if <code>a = 32</code> has been generated, fuzzer will keep note of it, as it opens the door to new code - it can then keep <code>a</code> fixed and randomize parameters <code>b</code> and <code>c</code>, thus reducing the search space.</p>
</section>
</section>
<section id="mutation-testing-mutation-analysis" class="level3">
<h3 class="anchored" data-anchor-id="mutation-testing-mutation-analysis">Mutation Testing (Mutation analysis)</h3>
<p>Mutation testing is a technique used to evaluate the effectiveness of a test suite by introducing minor modifications, called “mutations”, in the code, thus producing “mutants”.</p>
<p>These modifications are performed using a fixed set of mutation operators like operand replacement, expression modification, statement modification, etc.</p>
<p>Listed below is an example of an <strong>original</strong> code as well as one potential <strong>mutant</strong> that can be generated from it.</p>
<p><strong>Original Code</strong></p>
<pre class="solidity"><code>function fcn (uint a, uint b) returns (bool) {

    if(a &gt; b){

        return true;
    }

    return false;
}</code></pre>
<p><strong>Mutant #1</strong> - produced by using an expression modification operator (replaced <code>&gt;</code> with <code>&lt;</code>)</p>
<pre class="solidity"><code>function fcn (uint a, uint b) returns (bool) {

    if(a &lt; b){

        return true;
    }

    return false;
}</code></pre>
<p>These mutants are then tested, and, ideally, all of them would need to get caught (killed) by at least one of the tests. The percentage of killed mutants is referred to as the <strong>mutation score</strong>.</p>
<p>These techniques can give insight into what are the tests missing and where are the blind spots as well as what tests are rarely killing mutants - both of which is valuable when improving the test suite.</p>
<p>If a mutant cannot be compiled (i.e., mutation produced a syntax error), it is called <strong>stillborn</strong> and is not taken into consideration. Sometimes, mutants can have the same behavior as the original code, in which case, they are referred to as <strong>equivalent mutants</strong>. These mutants will not get killed by the test suite and will lower the mutation score. Detecting and taking them out of consideration is not an easy task and is the biggest obstacle to the widespread application of mutation testing.</p>
</section>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>This research concludes that the space of testing techniques is vast and evolving. As the complexity of challenges that the developers are faced with is rapidly increasing, staying up to date is a task by itself.</p>
<p>With time, we will probably see more and more specialized roles and the separation of responsibilities as it was done in traditional software. For this to happen, some standards should be formed that would enable effective communication between team members, namely clear requirement specification documents.</p>
<p>While posing a risk of the field becoming too rigid, rather than each individual/team having a different approach, we may also see the evolution of techniques and frameworks leading up to complete standardized methodologies.</p>
<p>Some possible roads for future research on this topic should include tools that are used when creating a well-documented functional specification for the project and digging deeper into the evaluation methods, specifically mutation testing, which is an active area of research.</p>


</section>

 ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-259.hugo.html</guid>
  <pubDate>Sat, 04 Jun 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>SBT - Soulbound Tokens</title>
  <dc:creator>Aleksandar Damjanovic</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-261.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p>This paper explores the SBTs (Soulbound Tokens) as a concept, their potential use cases, and the difficulties of implementing this solution. It also covers concepts of social and community recovery and briefly covers designated-verifier proofs and verifiable delay functions as they are potential enablers of this solution.</p>
<p>SBTs as a concept have major potential, although they face major obstacles like legacy systems, privacy and cold start issues. Nevertheless there is a positive sentiment towards this solution.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>The online identity of users plays an essential role in Web2. It allows users to have an online reputation, a unique identifier, and access to products and services that would otherwise not be available to them.</p>
<p>In the Web3 ecosystem, there is a persistent problem of proving the identity and personhood of a user without going through various KYC processes. There have been multiple attempts to aggregate identities in a decentralized way, and solutions like Litentry, Open Rights Exchange and IDX have emerged as solutions to this problem. However, there is no standard for creating unique Web3 user identities. These identities, in theory, could broaden the use-cases and the complexity of the ecosystem.</p>
<p>In 2021 and the beginning of 2022, NFTs (Non-fungible tokens) were the “hot topic”. Some of those NFTs reached a sale price of over $90.000.000.<sup>1</sup> At the core of these tokens is their transferability between addresses (parties), be it transfers or sales. Alas, we will not cover NFTs in great detail as there are more papers and research on that topic.</p>
<p>In this paper, we explore the newly proposed primitive: SBTs (Soulbound Tokens), which trade in transferability to satisfy other potential use cases that could not be satisfied with transferable NFTs. The “soulbound” in the name of SBTs takes inspiration from the famous game World of Warcraft, where some items, once acquired, are bound to the player and cannot be traded or transferred.</p>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p>The goal is to understand the need for this type of tokens, the necessity of using them for various use-cases in Web3, and the utility they could provide.</p>
<p>This will be done by exploring the <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4105763">“Decentralized Society: Finding Web3’s Soul”</a> paper written by E. Glen Weyl, Puja Ohlhaver, and Vitalik Buterin and how non-transferable SBTs could transform the Web3 space(lending, governance, reputation, etc.). Current sentiment towards this new primitive will also be explored (social media, blog posts, papers, etc.).</p>
<p>This research can be used as a short overview of the paper mentioned above and an overview of the current sentiment on SBTs.</p>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<section id="some-of-the-current-problems-in-web3" class="level2">
<h2 class="anchored" data-anchor-id="some-of-the-current-problems-in-web3">Some of the current problems in Web3</h2>
<p>If we look at the Web2 as it is now, the online identities of various users are a major part of various processes. Users can even use their identity on other platforms to easily register to others with a click or two. For example, a Google account In the future, unique identity linked to a user (in this case a “Soul”) could be a solution that would bring onboard more people to Web3, unlock new potential uses-cases, and potentially create a standardized reputation system. Currently Web3 is dependent on various Web2 structures regarding representing social identity. Examples:</p>
<ol type="1">
<li>NFT platforms rely on centralized platforms for a proof of scarcity and initial provenance.</li>
<li>DAOs. If DAOS want to prevent Sybil attacks, they usually rely on social media profiles for proof of personhood.</li>
<li>Web3 participants rely on centralized custodial wallets. Wallets that offer decentralized key management are not user-friendly.</li>
<li>Generally, it’s hard to establish reputation systems and manage blacklisting as anyone can create another address and access your protocol, for example</li>
<li>Lack of native web3 identity. This makes undercollateralized lending virtually impossible.</li>
<li>Governance vulnerability to financial attacks.</li>
</ol>
<p>These problems could, in theory, as the paper mentioned earlier says, be solved by introducing SBTs in Web3.</p>
</section>
<section id="what-are-souls-exactly" class="level2">
<h2 class="anchored" data-anchor-id="what-are-souls-exactly">What are souls exactly?</h2>
<p><strong>Souls are accounts or wallets that hold publicly visible, non-transferable tokens. Those tokens could pottentially also be revocable by the issuer.</strong><sup>2</sup></p>
<p>The tokens that the Soul account or wallet owns should be SBTs. Soul could, in theory, hold various types of tokens, but that possibility isn’t explored in the paper. SBTs could be used to represent affiliations, credentials, memberships, etc. but more on that in the following paragraphs. The true power of these tokens lies if there was a possibility for SBTs to be issued and verified by other Soul accounts that are counterparties in the relationship. These counterparty Souls could be individuals, companies, or institutions.</p>
<p>Another essential property of Soul accounts or wallets is the abundance of a requirement for a soul to be linked to a legal name or a need to ensure that there is one soul account per human. Soul accounts or wallets could also be possibly transferred across humans.</p>
<p>Souls can also be a type of reputation signal of the user to the ecosystem. Depending on the SBTs that the soul account has, the user could have a positive or negative reputation. A positive reputation could give the user various benefits regarding products and services, and a negative one could prevent users from accessing them. This property can also pose a problem protocols could “redline” (discriminate) owners of some SBTs and prevent them from using their product.</p>
</section>
<section id="possible-use-cases-of-sbts" class="level2">
<h2 class="anchored" data-anchor-id="possible-use-cases-of-sbts">Possible use cases of SBTs</h2>
<section id="sbts-and-lending" class="level3">
<h3 class="anchored" data-anchor-id="sbts-and-lending">SBTs and Lending</h3>
<p>In traditional finance, reputation is a significant factor in uncollateralized lending. This system often relies on centralized credit scores of borrowers to gauge creditworthiness. However, this has flaws like not providing lending services if there is insufficient data on the borrower and discrimination.</p>
<p>In Web3, users must overcollateralize in the token of their choice to receive a loan. This is where the SBTs could, in theory, provide a solution.</p>
<p><strong>“Implementation and adoption of SBTs have a potential to unlock a censorship-resistant, bottom-up alternative to top-down commercial and”social” credit systems.”</strong> - E. Glen Weyl, Puja Ohlhaver, Vitalik Buterin</p>
<p>In the case of lending, SBTs could represent education credentials, work history, and rental contracts, which could signal “creditworthiness”.</p>
<p>The loans themselves could be represented by the SBTs, which could be burnable by the institution that has given the loan. After the burning of the token, an institution could send another SBT to the borrower. This time it would be a proof of timely repayment SBT. This token could serve as a “signal” to other lenders that this borrower returns his/hers loans on time, which would impact the borrower’s “credit score” and provide the borrower with better loan conditions. Non-transferability prevents transferring or hiding outstanding loans. A rich ecosystem of SBTs ensures that borrowers who try to escape their loans (creating a new soul) will have insufficient SBTs to stake their reputation.</p>
<section id="community-lending-market" class="level4">
<h4 class="anchored" data-anchor-id="community-lending-market">Community lending market</h4>
<p><strong>“SBTs would offer a substrate for community lending practices similar to those pioneered by Muhammad Yunus and the Grameen Bank, where members of a social network agree to support one another’s liabilities. Because a Soul’s constellation of SBTs represents memberships across social groups, participants could easily discover other Souls who would be valuable co-participants in a group lending project.Whereas commercial lending is a”lend-it-and-forget-it” until repayment model, community lending might take a “lend-it-and-help-it” approach—combining working capital with human capital with greater rates of return.”</strong> - E. Glen Weyl, Puja Ohlhaver, Vitalik Buterin</p>
</section>
<section id="what-are-the-first-steps" class="level4">
<h4 class="anchored" data-anchor-id="what-are-the-first-steps">What are the first steps?</h4>
<p>There are a couple of “requirements” for this type of lending to be true:</p>
<ul>
<li>Soul accounts/wallets would carry SBTs they are comfortable sharing publicly. This could be an excellent first step for the adoption of social/intra-community lending in Web3.</li>
<li>Social relationships and credentials would play a significant role in this type of lending.</li>
</ul>
</section>
</section>
<section id="sbts-and-nfts" class="level3">
<h3 class="anchored" data-anchor-id="sbts-and-nfts">SBTs and NFTs</h3>
<p>In terms of NFTs , Souls could play a major role in terms of artist’s reputation. When issuing NFTs artist could issue them from their Soul.</p>
<p>“The more SBTs the artist’s Soul carries, the easier it would be for buyers to identify the Soul as belonging to that artist, and thereby also confirm the NFT’s legitimacy. Artists could go a step further to issue a linked SBT stored in their Soul that attests to the NFT’s membership to a”collection” and vouches for whatever scarcity limits the artist wishes to set. Souls would thus create a verifable, on-chain way to stake and build reputation on the provenance and scarcity of an object.” - E. Glen Weyl, Puja Ohlhaver, Vitalik Buterin</p>
<p>The application of SBTs in this market extends beyond art. Some examples of potential use cases:</p>
<ul>
<li>various services</li>
<li>rentals/property</li>
<li>authentication</li>
<li>social provenance</li>
<li>retail</li>
<li>gaming</li>
<li>and many more, SBTs unlock the use cases where NFTs cannot be applicable</li>
</ul>
</section>
<section id="soul-accounts-in-airdrops-and-daos" class="level3">
<h3 class="anchored" data-anchor-id="soul-accounts-in-airdrops-and-daos">Soul Accounts in Airdrops and DAOs</h3>
<p>Soulbound Tokens could also enable communities to be convened at the intersection of souls and to form a DAO, for example. Drops of SBTs or “Souldrops” can be given based on SBTs and other tokens within a Soul (soul account/wallet). Some examples:</p>
<ul>
<li>conference attendees</li>
<li>certified programmers</li>
<li>early members</li>
<li>etc</li>
</ul>
<p>“Souldrops could also introduce novel incentives to encourage community engagement. Dropped SBTs could be engineered to be soulbound for a period but eventually”vest” into transferable tokens over time. Or the reverse could be true. Transferable tokens held for some period could unlock the right to SBTs that confer further governance rights over a protocol. SBTs open a rich possibility space to experiment with mechanisms that maximize community engagement and other goals, like decentralization” - E. Glen Weyl, Puja Ohlhaver, Vitalik Buterin</p>
<p>In DAOS, SBTs could be used to mitigate Sybil attacks in various ways:</p>
<ul>
<li>computing over a Soul’s constellation of SBTs to differentiate between unique Souls and probable bots and denying any voting power to a Soul that appears to be a Sybil.</li>
<li>conferring more voting power to Souls with more reputable SBTs — like work or educational credentials, licenses, or certifications.</li>
<li>issuing specialized “proof-of-personhood” SBTs could help other DAOs bootstrap Sybil resistance.</li>
<li>checking for correlations between SBTs held by Souls who support a particular vote and applying a lower vote weight to highly correlated voters.</li>
</ul>
<p>Souls and SBTs could also be used to estimate the decentralization degree in the governance of DAOs and protocols.</p>
</section>
<section id="property" class="level3">
<h3 class="anchored" data-anchor-id="property">Property</h3>
<p>So far, NFTs could not effectively be applied to property rights, considering their ease of transfer. Using SBTs, owners could set different rights and limitations for the same property (vehicles, real estate, events, etc.).</p>
</section>
</section>
<section id="recovery-of-soul-accountswallets" class="level2">
<h2 class="anchored" data-anchor-id="recovery-of-soul-accountswallets">Recovery of Soul Accounts/Wallets</h2>
<p>Soul accounts would probably be recoverable by using Social Recovery.</p>
<section id="social-recovery" class="level3">
<h3 class="anchored" data-anchor-id="social-recovery">Social recovery</h3>
<p>A social recovery system/wallet works as follows:</p>
<ul>
<li>There is a single “signing key” that can be used to approve transactions</li>
<li>There is a set of at least 3 (or a much higher number) of “guardians”, of which a majority can cooperate to change the signing key of the account. The signing key can add or remove guardians, though only after a delay.</li>
</ul>
<p>A social recovery wallet can be used as a regular wallet. In case of losing a key, the user can reach out to their guardians and ask them to sign a particular transaction to change the signing pubkey registered in the wallet contract to a new one.</p>
<p>Guardians can be:</p>
<ul>
<li>other devices</li>
<li>friends and family members</li>
<li>institutions (they can verify your identity by phone number, e-mail, etc.)<sup>3</sup></li>
</ul>
</section>
<section id="sbt-community-recovery" class="level3">
<h3 class="anchored" data-anchor-id="sbt-community-recovery">SBT community recovery</h3>
<p>In this proposed solution, Soul recovery is tied to the Soul’s memberships across communities.</p>
<p>“In a community recovery model, recovering a Soul’s private keys would require a member from a qualified majority of a (random subset of) Soul’s communities to consent.” - E. Glen Weyl, Puja Ohlhaver, Vitalik Buterin.</p>
<p>This recovery implies secure, off-chain communication channels where authentication can occur.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://3327.io/documents/research/assets/ERFC-261/Soc_rec_vs_sbt.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">SBT rec</figcaption><p></p>
</figure>
</div>
<p><em>Picture 1: Social recovery vs SBT community recovery</em></p>
<p><strong>By embedding security in sociality , a Soul can always regenerate their keys through community recovery, which deters Soul theft (or sale): because a Seller would need to prove selling the recovery relationships, any attempt to sell a Soul lacks credibility.</strong> - E. Glen Weyl, Puja Ohlhaver, Vitalik Buterin.</p>
<p>This recovery solution is just a proposition and requires more experimentation.</p>
</section>
</section>
<section id="implementation-and-adoption-challenges" class="level2">
<h2 class="anchored" data-anchor-id="implementation-and-adoption-challenges">Implementation and adoption challenges</h2>
<section id="privacy" class="level3">
<h3 class="anchored" data-anchor-id="privacy">Privacy</h3>
<p>One of the biggest challenges in the adoption of SBTs is privacy. Too many public SBTs that a soul possesses can reveal too much information about a soul.</p>
<p>Blockchain systems are public by default, and every transaction and relationship recorded on-chain is available for everyone in the world to see. One possible solution is to have separate souls for professional and private life. These souls can easily be linked if there are no serious privacy solutions.</p>
<p>Another solution is to have SBTs that could store data off-chain, leaving only the hash of the data on-chain.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://3327.io/documents/research/assets/ERFC-261/off_chain_data.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Privacy with SBTs</figcaption><p></p>
</figure>
</div>
<p><em>Picture 2: A way to keep some of the SBTs private</em></p>
<p>The choice of how to store data is left to the person. Possible solutions are:</p>
<ul>
<li>their own devices</li>
<li>a trusted cloud service</li>
<li>IPFS or other decentralized networks</li>
</ul>
<p>Zero-knowledge proofs are another possible solution that could help kickstart the adoption of SBTs. They also can allow people to prove arbitrary statements without revealing any more information beyond the statement itself. They can be computed over SBTs to prove characteristics about a Soul. Privacy could be extended further by introducing multi-party computation techniques like <a href="https://www.esat.kuleuven.be/cosic/blog/introduction-to-garbled-circuit/">garbled circuits</a>.</p>
<p>Other possible solutions for privacy problems include designated-verifier proofs and verifiable delay functions.</p>
<p>For example: If user A wants to prove some property about its SBTs to user B, they can make a zero-knowledge proof of the statement “I hold SBTs that have the property Z.” User B can then be sure as he didn’t make the proof. But what about passing somebody else’s proof? Users can mitigate this by using <a href="https://eprint.iacr.org/2018/601.pdf">verifiable delay functions</a>. Using verifiable delay functions, user A can make and present a proof that can only be made with required SBTs at the moment, but anyone else will be able to make five minutes from now.</p>
</section>
<section id="bribing-the-owners-of-the-sbts" class="level3">
<h3 class="anchored" data-anchor-id="bribing-the-owners-of-the-sbts">Bribing the owners of the SBTs</h3>
<p>Owners of the SBTs could be bribed by various parties in order to influence their voting or to exploit their other SBTs.</p>
<p>In the research paper, writers mention these ways of exploits mitigations:</p>
<ol type="1">
<li>“The ecosystem of SBTs could bootstrap of”thick” community channels , where SBTs signal authentic off-chain community membership with strong social bonds and repeat interactions. This would make it easier for communities to alter and revoke SBTs of impersonators and bots. Such thick channels—which we often and in churches, workplaces, schools, meet-up groups, and organizations in civil society—would provide a more sybil-resistant social substrate to police gaming (e.g., through bots, bribes, impersonation) in more “thin” social channels.</li>
<li>Nested communities could require SBTs to force context on potential collusion vectors “just below” them . For example, if a state were holding a funding round or vote, the state might require every participating citizen to also hold an SBT of a defined county and municipality.</li>
<li>The openness and cryptographic provability of the SBT ecosystem could itself be used to actively detect collusive patterns and penalize inauthentic behavior —perhaps discounting the voting power of collusive Souls, or obliging Souls to accept SBTs representing negative attestations.</li>
<li>ZK technology (eg. MACI ) could cryptographically prevent some attestations made by a Soul from being provable.</li>
<li>Encouraging of whistleblowers</li>
<li>Mechanisms from peer-prediction theory</li>
<li>Correlation scores that focus on correlations where there is a large incentive to be honest if a group of Souls share a common interest.” - E. Glen Weyl, Puja Ohlhaver, Vitalik Buterin. ‘Decentralized Society: Finding Web3’s Soul by E. Glen Weyl, Puja Ohlhaver, Vitalik Buterin :: SSRN’<sup>4</sup></li>
</ol>
</section>
<section id="legacy-systems" class="level3">
<h3 class="anchored" data-anchor-id="legacy-systems">Legacy systems</h3>
<p>Current identity systems tend to concentrate power on the issuer of identity proofs. If we look at the government IDs, for example, the user doesn’t own their identity. Government can track users’ movement (passports), revoke licenses (driving licenses), and put an “expiration date” on your ID card. In Web3 idendity is often handled by identity protocols like: Litentry, ORE network and IDX. When it comes to identity, SBTs and their DeSoc property could, in theory, replace the existing legacy system. However, changes in ID systems usually take a very long time.</p>
</section>
<section id="cold-start-challenge" class="level3">
<h3 class="anchored" data-anchor-id="cold-start-challenge">Cold start challenge</h3>
<p>The research paper asks a question: <strong>What comes first SBTs or social recovery?</strong></p>
<p>When it comes to SBTs currently revokable tokens could be created and minted to wallets. They are referred to as “Proto SBTs”, allthough they are not as practical as SBTs proposed they could be a step in the right direction.</p>
<p>Community recovery wallets like <a href="https://www.argent.xyz/">Argent</a> and <a href="https://loopring.io/#/">Loopring</a> also show that social recovery wallets can work in practice.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://3327.io/documents/research/assets/ERFC-261/Social_recovery.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">soc rec wallets</figcaption><p></p>
</figure>
</div>
<p><em>Picture 3: Social recovery wallets explained</em></p>
<p>“Norms can also shepherd Souls into existence. As we rethink tokens and wallets, we can also reframe how we think about certain classes of NFTs and tokens that are intended to signal membership. In particular, we can introduce a norm of not transferring NFTs and POAPs issued by reputable institutions that reflect attendance to a conference, work experience, or education credentials. Such transfers of membership tokens—if traded for value—could diminish the reputation of a wallet and perhaps discourage issuers from further issuing membership or POAP tokens to that wallet.” - E. Glen Weyl, Puja Ohlhaver, Vitalik Buterin</p>
</section>
</section>
<section id="sentiment" class="level2">
<h2 class="anchored" data-anchor-id="sentiment">Sentiment</h2>
<p>When the paper came out on May 11th 2022, it didn’t gain mainstream attention initially. Around 20th of May the paper and the ideas in it caught the attention of media outside Web3 space with magazines like <a href="https://fortune.com/2022/05/26/what-are-soulbound-tokens-web3-buterin/">Fortune</a> covering the ideas presented.</p>
<p><a href="https://twitter.com/iamjasonlevin/status/1527316024659353601?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1527316024659353601%7Ctwgr%5E%7Ctwcon%5Es1_&amp;ref_url=https%3A%2F%2Fnftnow.com%2Fguides%2Fsoulbound-tokens-sbts-meet-the-tokens-that-may-change-your-life%2F">In an interview</a> held by Jason Levin with E. Glen Weyl , the author predicted that that SBTs will be available for early uses by the end of 2022 and that the 2024 up cycle will focus on SBTs.</p>
<p>Overall response to the paper was very positive all across the board and many potential use cases are discussed.</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>As presented above, Souls and SBTs and their potential implementation have many obstacles in front of them. Problems like privacy, bribing users, and cold-start challenges are not the small ones to get a grip on. Souls and community recovery system would also require efficient and secure off-chain communication channels.</p>
<p>When it comes to privacy, zero-knowledge proofs are a great possible solution to this problem. Other problems presented will be hard to solve.</p>
<p>Regarding Web3 and its mass adoption and its principles, SBTs (Soulbound tokens) seem like the next logical step. There are various potential use-cases for them, and if the initial hurdles presented in this research and the research paper of the authors are to be overcome, it is more than likely that SBTs will start a “new chapter” in Web3 and onboard new users.</p>
<p>If the potential use-cases are satisfied, SBTs have the potential to change society as we know it. All beginnings are rough, right?</p>
</section>
<section id="bibliography" class="level1">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Bibliography</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-DecentralizedSocietyFinding" class="csl-entry">
‘Decentralized Society: Finding Web3’s Soul by E. Glen Weyl, Puja Ohlhaver, Vitalik Buterin :: SSRN’ &lt;<a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4105763" class="uri">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4105763</a>&gt; [accessed 14 June 2022]
</div>
<div id="ref-WhyWeNeed" class="csl-entry">
‘Why We Need Wide Adoption of Social Recovery Wallets’ &lt;<a href="https://vitalik.ca/general/2021/01/11/recovery.html" class="uri">https://vitalik.ca/general/2021/01/11/recovery.html</a>&gt; [accessed 1 June 2022]
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p><strong>MostExpensiveNFTs?</strong>↩︎</p></li>
<li id="fn2"><p><strong>weylDecentralizedSocietyFinding2022?</strong>↩︎</p></li>
<li id="fn3"><p>‘Why We Need Wide Adoption of Social Recovery Wallets’ &lt;&lt;https://vitalik.ca/general/2021/01/11/recovery.html&gt;&gt; [accessed 1 June 2022].↩︎</p></li>
<li id="fn4"><p>&lt;[Https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4105763](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4105763)&gt; [accessed 14 June 2022].↩︎</p></li>
</ol>
</section></div> ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-261.hugo.html</guid>
  <pubDate>Tue, 31 May 2022 00:00:00 GMT</pubDate>
  <media:content url="https://3327.io/documents/research/assets/ERFC-261/Social_recovery.png" medium="image" type="image/png" height="87" width="144"/>
</item>
<item>
  <title>Royalty Contract Standardization - RCS</title>
  <dc:creator>Aleksandar Damjanovic</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-171.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p>This research examines the possibility of hardcoding the royalty logic for the NFT royalty payments. It also explores how are royalties for NFT creators/artists taken care of by two largest NFT marketplaces OpenSea and LooksRare. It examines the EIP-2981 which aims to solve the royalty implementation problem. Small experiment is conducted with a goal to modify the transfer function from the ERC-721 standard.</p>
<p>After explorative research and a short experiment we have come to these conclusions:</p>
<ol type="1">
<li>The Marketplaces prefer handling the royalties themselves and only for the trades on their platform</li>
<li>ERC-2981 contains the optional royalty implementation logic. It’s on the platforms to decide whether they will utilize this standard.</li>
<li>Hardcoding royalties without making “a mess” of the NFT smart-contract is currently way too complex and would require altering the ERC-721 heavily.</li>
</ol>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Current markketplaces and NFTs have fragmented royalty payment implementations. This leaves the nft artist/creator with the issue of unpredictable royalty payments for his art. Each marketplace has different solutions for this problem. EIP-2981 has basic royalty implementation. Which doesn’t enforce actual payments. Royalty Contract Standardization (RCS) could in theory be done by modifying the transfer functions to enable the transfer of royalties to the creator during trading of the NFT via transaction splitting.</p>
<p><strong>This research is the aftermath of a brainstorming session and has some brave assumptions initially, which is why this short research is conducted to further validate those assumptions.</strong></p>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p>The goal of this research is to explore how royalties are taken care of currently and the way EIP-2981 works and the possibility of further improvement.</p>
<p>This will done by doing an explorative research of current royalty implementations on OpenSea and LooksRare as they are the biggest players.</p>
<p>Another examination will be done, maimly of the EIP-2981 standard to explore the solution it proposes.</p>
<p>Afterwards we will examine the possibility of hardcoding royalty in the NFT contract itself.</p>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<section id="opensea" class="level2">
<h2 class="anchored" data-anchor-id="opensea">OpenSea</h2>
<p>OpenSea offers royalties for Artists and Creator which are usually around 10%. They are also applied to secondary sales and the proceeds after fees go to the seller of the NFT.</p>
<p>Users can check the royalty fees with 3 methods:</p>
<ol type="1">
<li>Attempting to buy an NFT which will then open up a checkout window where the royalty amount is listed under the name of the NFT.</li>
<li>Installing the Flava Chrome extension which shows the royalty next to the NFT without needing to open the checkout menu.</li>
<li>Using the NFT analytics tools - There are numerous NFT analytics tools that include creator royalties in their stats.<sup>1</sup></li>
</ol>
<p>As we can see royalties are very important part of NFT space and they are of great importance for both traders and creators.</p>
<section id="how-do-creators-earn-their-royaties" class="level3">
<h3 class="anchored" data-anchor-id="how-do-creators-earn-their-royaties">How do creators earn their royaties</h3>
<p>On OpenSea proceeds from the primary sales of the NFT are immediately forwarded to the creators address. Royalties are usually held by OpenSea for 2-4 weeks before paid out to the creator, this includes <strong>both primary sales and secondary sales</strong>.</p>
<p>Royalties are not automatically set on OpenSea and the creator of the collection must set the royalty percentage and the payout address on the collection level.</p>
</section>
<section id="opensea-royalty-on-other-marketplaces" class="level3">
<h3 class="anchored" data-anchor-id="opensea-royalty-on-other-marketplaces">OpenSea royalty on other marketplaces</h3>
<p>OpenSea royalties are enforced on many other platforms. This is a result of various legal agreements between platforms.</p>
<p>If we are talking about ERC-721 and ERC-1155 standard tokens there is no royalty support on token or smart contract level. That is why previosly mentioned legal agreements are needed to enforce royalty payments.<sup>2</sup></p>
</section>
</section>
<section id="looksrare" class="level2">
<h2 class="anchored" data-anchor-id="looksrare">LooksRare</h2>
<p>LooksRare is a decentralized NFT marketplace which rewards traders, token stakers, creators and collectors for participating on the platform.</p>
<p>It was launched in January 22 with an aim to dethrone Opensea from it’s spot as a leader in the NFT market.</p>
<p>As a community-first platform all the revenue generated is distributed to the stakers of LOOKS token.</p>
<section id="token" class="level3">
<h3 class="anchored" data-anchor-id="token">Token</h3>
<p>LOOKS is the native token that powers the LooksRare marketplace, its price is $0.5908 at the time of this writing. It is used for staking and various rewards.</p>
</section>
<section id="royalties" class="level3">
<h3 class="anchored" data-anchor-id="royalties">Royalties</h3>
<p>Whenever the NFT is traded on LooksRare there are 2 types of fee the seller is charged:</p>
<ul>
<li>Platform fee (2%)</li>
<li>Creator royalties</li>
</ul>
<p>“Creator royalties are fees that are decided by the collection creator. Collection owners can specify a percentage of royalties they wish to recieve on their collection management page.”</p>
<p>Royalties are on-chain. Whenever a sale is made through the platform the royalties are paid in the same transaction as the sale and the creators instantly recieve their royalty. This is one of the ways LooksRare is different from OpenSea.</p>
<p>LooksRare also supports EIP-2981 royalty standard which takes precedent over any royalties specified directly on LooksRare.</p>
</section>
</section>
<section id="eip-2981" class="level2">
<h2 class="anchored" data-anchor-id="eip-2981">EIP-2981</h2>
<p>This standard provides a way to retrieve royalty payment information for NFTs with a goal to enable universal support for royalty payments across all NFT marketplaces and ecosystem participants.</p>
<p>This standard enables all marketplaces to retrieve royalty payment information for a given NFT. This enables accurate royalty payments regardless of which marketplace the NFT is sold or re-sold at.</p>
<p>This standard only provides a mechanism to fetch the royalty amount and recipients. The actual funds transfer is something the marketplace needs to do.</p>
<p>“Royalty amounts are always a percentage of the sale price. If a marketplace chooses not to implement this EIP, then no funds will be paid for secondary sales.”</p>
<p><strong>That is one of the reasons hardcoding royalties idea was proposed.</strong></p>
<p>EIP-2981 can also be integrated with other contracts to return royalty payment information. <strong>ERC-2981</strong> is a royalty standard for many asset types.</p>
<p>It is recomended to read the full specification of the proposal in order to better understand the issue at hand and the way it is handled in the <a href="https://eips.ethereum.org/EIPS/eip-2981">EIP-2981</a>.</p>
<p>In the proposal the writers have come to these conclusions:</p>
<ul>
<li><p>“It is impossible to know which NFT transfers are the result of sales, and which are merely wallets moving or consolidating their NFTs. Therefore, we cannot force every transfer function, such as transferFrom() in ERC-721, to involve a royalty payment as not every transfer is a sale that would require such payment.”</p></li>
<li><p>“It is impossible to fully know and efficiently implement all possible types of royalty payments logic. With that said, it is on the royalty payment receiver to implement all additional complexity and logic for fee splitting, multiple receivers, taxes, accounting, etc. in their own receiving contract or off-chain processes. Attempting to do this as part of this standard, it would dramatically increase the implementation complexity, increase gas costs, and could not possibly cover every potential use-case.”</p></li>
<li><p>“This EIP mandates a percentage-based royalty fee model. It is likely that the most common case of percentage calculation will be where the royaltyAmount is always calculated from the _salePrice using a fixed percent i.e.&nbsp;if the royalty fee is 10%, then a 10% royalty fee must apply whether _salePrice is 10, 10000 or 1234567890.”</p></li>
<li><p>“This EIP does not specify a currency or token used for sales and royalty payments. The same percentage-based royalty fee must be paid regardless of what currency, or token was used in the sale, paid in the same currency or token. This applies to sales in any location including on-chain sales, over-the-counter (OTC) sales, and off-chain sales using fiat currency such as at auction houses. As royalty payments are voluntary, entities that respect this EIP must pay no matter where the sale occurred - a sale outside of the blockchain is still a sale.”</p></li>
</ul>
<p>They also plan on taking on the mechanism for paying and notifying the recepient in the future EIPs.<sup>3</sup></p>
<section id="our-experiment" class="level3">
<h3 class="anchored" data-anchor-id="our-experiment">Our experiment</h3>
<p>After trying to implement hardcoding the royalties the same issue with the transfer function occured.</p>
<pre class="solidity"><code>
// SPDX-License-Identifier: MIT
pragma solidity ^0.8.13;

import "@openzeppelin/contracts@4.5.0/token/ERC721/ERC721.sol";
import "@openzeppelin/contracts@4.5.0/token/ERC721/extensions/ERC721Enumerable.sol";
import "@openzeppelin/contracts@4.5.0/access/Ownable.sol";
import "@openzeppelin/contracts@4.5.0/utils/Counters.sol";
import "@openzeppelin/contracts@4.5.0/interfaces/IERC2981.sol";

contract InstantRoyaltyToken is ERC721, ERC721Enumerable, Ownable, IERC2981 {
    using Counters for Counters.Counter;

    Counters.Counter private _tokenIdCounter;

    address royaltyAddress;
    uint256 royalty = 10_000;

    constructor(address _royaltyAddress ) ERC721("InstantRoyaltyToken", "IRT") {
            royaltyAddress = _royaltyAddress;
    }

    function safeMint(address to) public onlyOwner {
        uint256 tokenId = _tokenIdCounter.current();
        _tokenIdCounter.increment();
        _safeMint(to, tokenId);
    }

    // The following functions are overrides required by Solidity.

    function _beforeTokenTransfer(address from, address to, uint256 tokenId)
        internal
        override(ERC721, ERC721Enumerable)
    {
        super._beforeTokenTransfer(from, to, tokenId);
    }

    function supportsInterface(bytes4 interfaceId)
        public
        view
        override(ERC721, ERC721Enumerable, IERC165)
        returns (bool)
    {
        return interfaceId == type(IERC2981).interfaceId || super.supportsInterface(interfaceId);
    }

    function royaltyInfo(uint256 tokenId, uint256 salePrice) public view override returns(address receiver, uint256 royaltyAmount) {
        return (royaltyAddress, royalty);
    }
    /* 

        * The function below from ERC721 is the main issue. Making this a
        * payable function would add unecessary complexity to the standard
        * and would make the function payable, thus requiring payment 
        * even when sales are not ocurring.

    */
    function transferFrom(
        address from,
        address to,
        uint256 tokenId
    ) public virtual override(ERC721,IERC721) {
            require(_isApprovedOrOwner(_msgSender(), tokenId), "ERC721: transfer caller is not owner nor approved");
            //royaltyInfo and pay royalty for transfer part would go here
            //implementing this would make the function payable
            _transfer(from, to, tokenId);
    }

}</code></pre>
</section>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>After researching how the royalties are taken care of so far by the leading NFT marketplaces we have come to these conclusions:</p>
<ol type="1">
<li>The Marketplaces prefer handling the royalties themselves and only for the trades on their platform</li>
<li>ERC-2981 contains the optional royalty implementation logic. It’s on the platforms to decide whether they will utilize this standard.</li>
<li>Hardcoding royalties without making a mess of the NFT smart-contract is currently way to complex and would require altering the ERC-721 heavily.</li>
</ol>
<p>The above reasons are the reason for not going further with this initiative, however this gave us a better insight of how the NFT marketplaces operate in terms of royalties and how are the new standards for NFTs proposed, and what are the limitations.</p>
<p><em>Special thanks to Stevan Bogosavljevic for his opinions on this research and expertize in NFT royalties. Thank you for showing the fallacies in the logic of this research proposal</em></p>
</section>
<section id="appendices" class="level1">
<h1>Appendices</h1>
</section>
<section id="bibliography" class="level1">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Bibliography</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-10SettingFees" class="csl-entry">
‘10. Setting Fees on Secondary Sales’, <em>OpenSea Developer Documentation</em> &lt;<a href="https://docs.opensea.io/docs/10-setting-fees-on-secondary-sales" class="uri">https://docs.opensea.io/docs/10-setting-fees-on-secondary-sales</a>&gt; [accessed 18 May 2022]
</div>
<div id="ref-NFTAnalyticsTools2022" class="csl-entry">
‘8 NFT Analytics Tools to Boost Your Profits Tokenized’, 2022 &lt;<a href="https://tokenizedhq.com/nft-analytics/" class="uri">https://tokenizedhq.com/nft-analytics/</a>&gt; [accessed 18 May 2022]
</div>
<div id="ref-EIP2981NFTRoyalty" class="csl-entry">
‘EIP-2981: NFT Royalty Standard’, <em>Ethereum Improvement Proposals</em> &lt;<a href="https://eips.ethereum.org/EIPS/eip-2981" class="uri">https://eips.ethereum.org/EIPS/eip-2981</a>&gt; [accessed 18 May 2022]
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>‘8 NFT Analytics Tools to Boost Your Profits Tokenized’, 2022 &lt;&lt;https://tokenizedhq.com/nft-analytics/&gt;&gt; [accessed 18 May 2022].↩︎</p></li>
<li id="fn2"><p>‘10. Setting Fees on Secondary Sales’, <em>OpenSea Developer Documentation</em> &lt;&lt;https://docs.opensea.io/docs/10-setting-fees-on-secondary-sales&gt;&gt; [accessed 18 May 2022].↩︎</p></li>
<li id="fn3"><p>‘EIP-2981: NFT Royalty Standard’, <em>Ethereum Improvement Proposals</em> &lt;&lt;https://eips.ethereum.org/EIPS/eip-2981&gt;&gt; [accessed 18 May 2022].↩︎</p></li>
</ol>
</section></div> ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-171.hugo.html</guid>
  <pubDate>Thu, 12 May 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Data Analytics in Blockchain</title>
  <dc:creator>Milos Bojinovic</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-146.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p><strong>Data Analytics</strong> is the science of analyzing raw data related to a specific problem and extracting all of the necessary information in order to make conclusions about as well as derive approaches for solving it.</p>
<p>In the context of <strong>Blockchain</strong>, Data Analytics revolves around the process of collecting and parsing of raw transaction data thus transforming it into usable and actionable data. Parsing of those transactions requires knowledge about the chain specifics as well as internal workings of Smart Contract that that are of interest which is an extremely time consuming process - all of the data on the Blockchain, while it may be public and unchangable, is unstructured.</p>
<p>Blockchain data, however, holds all of the chain’s history since its inception, making it possible to see past interactions between addresses and/or Smart Contracts. This data can then be segmented to include only a wanted subset for which the analysis will be performed. With this aggregated information it is then possible to gain insight in the past trends for a set of Non-Fungible-Tokens(NFTs) and Decentralized Finance(DeFi) related applications as well as general Crypto related trends and potentially predict future ones.</p>
<p>Data Analytics platforms in the Blockchain space are gaining users as the whole crypto ecosystem evolves and is becoming harder to navigate. With substantial recent investments in this area,<sup>1</sup><sup>2</sup> it is clear that the investors are showing interest in what these platforms can do and the potential they have in shaping the future of Blockchain.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>This research focuses on the type of information that can be extracted from the blockchain, elaborates on where that information can be used and signals the utility that lies in it - especially in the NFT and DeFi related applications that dominate the crypto ecosystem.</p>
<p>Out of the scope of the research falls the aquiring/storing/organizing/displaying of the raw data which are extremely hard and complex processes that also open questions about the decentralization of those processes and the integrity of the collected data.</p>
<p>Instead, it casts a light on the current state of the Data Analytics / Blockchain intersection, top platforms that operate in it and the tools that they provide. These platforms/tools are then categorized based on area where they are used and their use cases briefly explained.</p>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p>Data Analytics platforms/tools enable users to make sense of this rapidly changing space and so the importance of this explorative research lies in the fact that they are relatively new with a huge potential and as such must be investigated further.</p>
<p><strong>The goal</strong> of this research is to:</p>
<ul>
<li>explore, explain and categorise Data Analytics platforms and their tools</li>
</ul>
<p><strong>The methodology</strong> of the research includes:</p>
<ul>
<li><p>taking into account only platforms that support Ethereum Virtual Machine (EVM) compatible chains</p></li>
<li><p>discussing where a platform/tool can be used</p></li>
<li><p>categorizing a platform/tool as one of the following:</p>
<ul>
<li><strong>General Purpose</strong> - contains both of the other categories as well as some additional functionality</li>
<li><strong>NFT specific</strong> - focuses on providing information about a collection/NFT or the NFT market in general</li>
<li><strong>DeFi specific</strong> - focuses on the extracting metrics for specific DeFi projects and DeFi market in general</li>
</ul></li>
</ul>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<p>With those three categories explained above, platforms can be investigated and then grouped. Regarding the distribution of categories that will be elaborated on it is evident that most platforms/tools are not general purpose ones. They require a lot of time to develop and so there is an emerging trend of developing specizalised ones that are easier to develop and target a single niche.</p>
<p>In the following text categories are listed in order, with each category being divided into “Tools” and “Platforms” sections. In the “Tools” section, each entry describes a specific functionality and the “Platforms” section focuses on illustrative platforms that have those functionalities (among others) incorporated into them.</p>
<p>Platforms/tools from the same/different categories are not mutually exclusive and can be combined.</p>
<section id="general-purpose" class="level2">
<h2 class="anchored" data-anchor-id="general-purpose">General Purpose</h2>
<section id="tools" class="level3">
<h3 class="anchored" data-anchor-id="tools">Tools</h3>
<p>Tools in this category query information about the complete transaction activity of a specific address (both Externally-Owned-Accounts (EOA) and Smart Contracts) and groups the extracted information into human readable metrics.</p>
<section id="contract-interactions" class="level4">
<h4 class="anchored" data-anchor-id="contract-interactions">Contract interactions</h4>
<p>For any choosen contract it is possible to extract general information about the:</p>
<ul>
<li>transaction count</li>
<li>unique addresses</li>
<li>token inflow/outflow</li>
</ul>
<p>for a specific timeframe. These values can then be organized and monitored over a larger time periods to provide information about the latest trends and changes in the number of users, who these users are, etc.</p>
<p>They can also be used to detect contracts that were recently deployed that are gaining popularity as to investigate the project with which those contracts are associated with.</p>
<p>More valuable information would be tied to how the contract is being used - what methods are being called, their sequence, etc. To extract meaningfull data, as it was discussed above, there would need to exist a parser with a specific domain knowledge.</p>
</section>
<section id="address-profiler" class="level4">
<h4 class="anchored" data-anchor-id="address-profiler">Address Profiler</h4>
<p>For any user address of interest, it is possible to extract the information about the :</p>
<ul>
<li>portfolio (all of the assets that the address holds)</li>
<li>estimated portfolio value (sum of values of NFT* and ERC20 holdings)</li>
<li>recent token trades (both ERC20 and NFTs)</li>
<li>addresses that the user has interacted with</li>
</ul>
<p>All of these values can also be monitored since the beginning of the chain’s history and addresses can be grouped together to provide some form of live feed for those that are most interesting either to the user or to the platform itself.</p>
<p>*Estimated value of an NFT is platform specific (i.e.&nbsp;see<sup>3</sup>)</p>
</section>
<section id="alerts" class="level4">
<h4 class="anchored" data-anchor-id="alerts">Alerts</h4>
<p>Alerts are delivered to the user, via a communication channel of choice (Telegram, Text Message, Discord, …), when a certain customly defined condition is met - some address buys an NFT, collection’s floor price has increased/decreased by some margin, …</p>
</section>
</section>
<section id="platforms" class="level3">
<h3 class="anchored" data-anchor-id="platforms">Platforms</h3>
<p>Two of the top plaftforms in this category are <a href="https://nansen.ai">Nansen</a> and <a href="dune.xyz">Dune Analytics</a> which can be used to gather and analyze similar information but take two drastically different approaches - user oriented and business oriented, respectively.</p>
<section id="nansen.ai" class="level4">
<h4 class="anchored" data-anchor-id="nansen.ai">Nansen.ai</h4>
<p>This paid platform doesn’t require or demand from user to have technical knowledge and it provides detailed non-customizable dashboards for General purpose, NFT and DeFi specific tools. Almost all of the tools (from the three categories) listed in this paper, in one form or another, are supported by Nansen making it the most comprehensive and beginner friendly platform.</p>
<p>An interesting additional feature that Nansen provides is labeling of some addresses as being “Smart Money” (addresses that were early adopters and/or have made smart decisions in the NFT and/or DeFi space)*. There exist specific dashboards/sections where it is shown what the “Smart Money” is doing - what are they minting/buying/selling, with whom they are interacting, etc. This information can be used by the user to decide what they think is a good strategy for them when investing and can be combined with custom alerts when a certain condition is met.</p>
<p>*See<sup>4</sup> for more details on the labeling of these addresses.</p>
</section>
<section id="duneanalytics.com" class="level4">
<h4 class="anchored" data-anchor-id="duneanalytics.com">DuneAnalytics.com</h4>
<p>Dune Analytics translates raw on-chain transaction data into SQL databases such that the information can be requested using SQL queries. Custom vizualizations (charts, graphs, …) and dashboards can be created from those queries which can then be embedded into other websites.</p>
<p>Additional benefit of the platform is that there exists an active community of members who can create dashboards for which both the visualizations and the SQL queries are publicly avaliable. This enables them to build upon on another’s work, making a powerfull snowball effect.</p>
<p>There exist, however, two drawbacks to the platform:</p>
<ol type="1">
<li>only the platfrom itself can perfom the parsing of smart contracts (users can request a contract to be parsed)</li>
<li>doesn’t provide an API (though paid users can export results as a CSV file)</li>
</ol>
</section>
</section>
</section>
<section id="nft-specific" class="level2">
<h2 class="anchored" data-anchor-id="nft-specific">NFT specific</h2>
<section id="tools-1" class="level3">
<h3 class="anchored" data-anchor-id="tools-1">Tools</h3>
<section id="market-overviewtrends" class="level4">
<h4 class="anchored" data-anchor-id="market-overviewtrends">Market Overview/Trends</h4>
<p>Contains information about the whole NFT market and specific marketplaces, such as:</p>
<ul>
<li>number of distinct users (minters/buyers/sellers)</li>
<li>trading volume</li>
<li>average price of all NFTs sold</li>
<li>floor price (taking into account all NFTs listed)</li>
<li>trending collections</li>
</ul>
<p>These values are then used to analyze the percentage share of a marketplace compared to the whole market which is useful to determine the top marketplaces and capture the moment when there is a drastic shift in the leaderboard.</p>
<p>The tool also helps in discovering new trending NFT collections and on which marketplace is the most of the trading activity for that collection happening thus answering the question where to go to when considering to invest in it.</p>
</section>
<section id="collection-breakdown" class="level4">
<h4 class="anchored" data-anchor-id="collection-breakdown">Collection Breakdown</h4>
<p>Contains information tied to a specific collection and involves:</p>
<ul>
<li>basic information (number of distinct holders, average price, volume, price range, number of trades…)</li>
<li>balance changes (how many NFTs were bought/sold/minted by an address)</li>
<li>rarity stats - what traits are the rarest and thus more valuable</li>
<li>recent mints/trades</li>
<li>similar collections</li>
</ul>
<p>This data can be used to determine whether the majority of NFTs from the collection are held by few addresses which is a bad position for other holders as those addresses can quickly unload the NFTs, selling them at lower prices and so driving the floor price for the entire collection down.</p>
<p>It can also be used to assess the confidence of NFT holders in the collection by seeing if long term holders are suddenly started selling or if the collection is gaining momentum (for example, a lot of trades by different addresses in a short period of time).</p>
<p>All of this can be used by the users to develop unique NFT trading strategies, making this tool extremely informative.</p>
</section>
<section id="nft-breakdown" class="level4">
<h4 class="anchored" data-anchor-id="nft-breakdown">NFT Breakdown</h4>
<p>This tool focuses on a specific NFT from a collection and displays</p>
<ul>
<li>history of trades - changes in ownership and price</li>
<li>similar NFTs (based on traits)</li>
</ul>
<p>One of the obvious use case is tracking the price movement of that NFT but another one is tracking at the same time the price movement of similar NFTs and buying those that seem undervalued (ofter reffered as “sniping”).</p>
</section>
</section>
<section id="platforms-1" class="level3">
<h3 class="anchored" data-anchor-id="platforms-1">Platforms</h3>
<p>All of the previously listed tools are supported by Nansen but there are specialized alternatives that perform limited subset of those functionalities in a same/slightly different way. Some of the popular ones are <a href="https://icy.tools">icy.tools</a>, <a href="https://moby.gg">moby.gg</a> and <a href="https://nftnerds.ai">NFTNerds.ai</a>.</p>
</section>
</section>
<section id="defi-specific" class="level2">
<h2 class="anchored" data-anchor-id="defi-specific">DeFi specific</h2>
<section id="tools-2" class="level3">
<h3 class="anchored" data-anchor-id="tools-2">Tools</h3>
<section id="total-value-locked-tvl-tracker" class="level4">
<h4 class="anchored" data-anchor-id="total-value-locked-tvl-tracker">Total Value Locked (TVL) Tracker</h4>
<p>TVL s the overall value of crypto assets deposited in a specific DeFi protocol – or in DeFi protocols generally. It is often analyzed to determine the oportunities across chains and protocols. When analyzed over longer periods of time it can help in discovering new project trends.</p>
</section>
<section id="recent-activity-tracker" class="level4">
<h4 class="anchored" data-anchor-id="recent-activity-tracker">Recent Activity Tracker</h4>
<p>This tool gathers in real time the latest transactions that happened on Decentralized Exchanges (DEXs), Lending/borrowing and Derivatives platforms. Using it, it is possible to detect and take into account large funds movement by an address that is of interest.</p>
</section>
<section id="stakinglendingliquidity-metrics" class="level4">
<h4 class="anchored" data-anchor-id="stakinglendingliquidity-metrics">Staking/Lending/Liquidity Metrics</h4>
<p>These metrics revolve around the number of lenders/borrowers/stakers of a DeFi platform, their current and past balances (including deposits/withdrawals/liquidations) as well as the distribution of token holders.</p>
</section>
</section>
<section id="platforms-2" class="level3">
<h3 class="anchored" data-anchor-id="platforms-2">Platforms</h3>
<p>Dune Analytics is very useful in this area as the most useful information is DeFi platform specific and needs to be analyzed in a different way. For general, comparable information there are <a href="https://www.defipulse.com/">DeFi Pulse</a> and <a href="https://defillama.com/">DeFi Llama</a>.</p>
</section>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>Using Data Analytics platforms, it is possible to track and analyze the performance of a portfolio for any address and to learn from their past experiences. They are also useful in determining the differences between the most sucessfull and least successful addresses as well as what they have in common. These groups of addresses can then be monitored for future transactions and can alert an user when they happen. Users can then assess the new information and act accordingly.</p>
<p>The bottleneck of this process lies in the human factor that does information assessing manually and so a lot of time is spent on it. Improvements can be made by automating the decision process that leads to the action. Since it would be dealing with real funds, a machine could suggest a potential sequence of actions and the user would still need to aprove it by signing the corresponding transactions.</p>
<p>For example, in NFT trading, a bot could monitor all trades in realtime and detect an increase/decrease in the popularity of a collection which would signal it to buy/sell an NFT or a set of NFTs and suggest the price of it - at what price to list an NFT or what offer to make.</p>
<p>This, and other use cases from specific niches would need to be studied further, as part of a separate research. There exists a question on the utility of those tools, however, their functionalities are in a large measure dependant on the Data Analytics and so their whole processing pipeline would need to be carefully designed.</p>
</section>
<section id="bibliography" class="level1">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Bibliography</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-finsmesDuneAnalyticsRaises2022" class="csl-entry">
FinSMEs, ‘Dune Analytics Raises $69.42M in Series B Funding’, <em>FinSMEs</em>, 2022 &lt;<a href="https://www.finsmes.com/2022/02/dune-analytics-raises-69-42m-in-series-b-funding.html" class="uri">https://www.finsmes.com/2022/02/dune-analytics-raises-69-42m-in-series-b-funding.html</a>&gt; [accessed 8 May 2022]
</div>
<div id="ref-NansenWalletLabels" class="csl-entry">
‘Nansen Wallet Labels &amp; Emojis: What Do They Mean?’ &lt;<a href="https://www.nansen.ai/guides/wallet-labels-emojis-what-do-they-mean" class="uri">https://www.nansen.ai/guides/wallet-labels-emojis-what-do-they-mean</a>&gt; [accessed 9 May 2022]
</div>
<div id="ref-UtilizingNansenInvesting" class="csl-entry">
‘Utilizing Nansen: Investing in NFTs’ &lt;<a href="https://www.nansen.ai/research/utilizing-nansen-investing-in-nfts" class="uri">https://www.nansen.ai/research/utilizing-nansen-investing-in-nfts</a>&gt; [accessed 9 May 2022]
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p><strong>NansenRaises7?</strong>↩︎</p></li>
<li id="fn2"><p>FinSMEs, ‘Dune Analytics Raises $69.42M in Series B Funding’, <em>FinSMEs</em>, 2022 &lt;&lt;https://www.finsmes.com/2022/02/dune-analytics-raises-69-42m-in-series-b-funding.html&gt;&gt; [accessed 8 May 2022].↩︎</p></li>
<li id="fn3"><p>‘Utilizing Nansen: Investing in NFTs’ &lt;&lt;https://www.nansen.ai/research/utilizing-nansen-investing-in-nfts&gt;&gt; [accessed 9 May 2022].↩︎</p></li>
<li id="fn4"><p>‘Nansen Wallet Labels &amp; Emojis: What Do They Mean?’ &lt;&lt;https://www.nansen.ai/guides/wallet-labels-emojis-what-do-they-mean&gt;&gt; [accessed 9 May 2022].↩︎</p></li>
</ol>
</section></div> ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-146.hugo.html</guid>
  <pubDate>Sat, 07 May 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Developing with Ape</title>
  <dc:creator>Aleksandar Damjanovic</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-172.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p>This research examines Ape The Ethereum Development Framework For Python Developers. It examines its plugin system and ease of use. As a conclusion Web3 Tech Radar location is suggested.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Ape is a new tool for creating and exploring on Ethereum and other blockchains. This framework is written in python with a goal of onboarding more python developers to Web3 thus providing much needed inclusivity in the space.</p>
<p>Their goal is to make development smoother with their modular approach. Ape is centered around their open-source plugins written in python; some of them are:</p>
<ol type="1">
<li>Ape-hardhat - Hardhat network provider for Ape</li>
<li>Ape-infura - Infura provider plugins for Ethereum-based networks</li>
<li>Ape-solidity - Support for Solidity smart contracts</li>
<li>Ape-ledger - Ledger Nano S and X plugin for Ape</li>
<li>Ape-alchemy - Alchemy Provider plugins for Ethereum-based networks</li>
</ol>
<p><em>There are over 20 plugins Ape offers. Considering the open-source nature of the project a lot of new plugins are on the way.</em></p>
<p>Current version of Ape is <strong>v0.2.1</strong> and some of the new interesting features offered are:</p>
<ol type="1">
<li>Polygon, Binance Smart Chain, and Fantom support. Developers can build multi-chain applications with ape’s network switching feature.</li>
<li>Impersonated account. This let’s the developers test their project and interact with the contract on a fork network pretending to be any account. If you want to impersonate Vitalik, Ape makes that possible.</li>
</ol>
<p>They are also working on Ape Project Templates which should increase productivity and enhance developers’ experience when using this framework. Some of the templates Ape is currently developing are:</p>
<ol type="1">
<li>NFT template</li>
<li>Token template</li>
<li>Various other templates for airdrops,minting</li>
<li>Templates for different ERC standards</li>
</ol>
<p>Ape is also set out to be the “first professional-grade smart contract development framework to support multi-chain application development, including non-EVM chains like StarkWare” .[^1]</p>
<p>Another sign that Ape is growing is that a Yearn.Finance repo has <a href="https://github.com/yearn/veYFI/pull/98?utm_campaign=Updates%20from%20ApeWorX&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">officially migrated</a> over from Brownie to Ape.</p>
<p>As previosly mentioned, this is a new framework and we are expecting more adoption and improvements in the coming months, especially as more developers “take it for a spin”.</p>
<p>Another interesting thing is that there is a possibility of developers switching to Ape from Brownie framework, as Brownie updates <a href="https://github.com/eth-brownie/brownie/issues/1515">have slowed down</a>.</p>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p>The goal of this research paper is to explore this new player in the smart contract frameworks market, this is an opportunity to explore a new framework that is python oriented.</p>
<p>This will be done by writing a simple smart contract, deployment script for rinkeby and a couple tests for said contract and examining the documentation and tutorials present. That way we can research the ease of use for both beginners and experienced developers, and see what is the approach to development process this open-source framework is taking.</p>
<p>As a result Web3 Tech Radar location for this framework will be suggested.</p>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<p><strong>Beginner friendly?</strong></p>
<p>After initial testing of this framework and considering the state of the documentation at this stage I would recommend this framework to experienced python developers venturing into Web3. Documentation is well written, still in the works and continuosly updated with contributions from the community around this framework. Apeworx Team and Apeworx community is currently working on workshops to get developers up to speed and tutorials are in the works.</p>
<p>Currently there is little materials for newcomers. Considering this is a new open-source project this is understandable. However, for absolute beginners, going through the Brownie framework first is recomended at this stage of Ape’s development. The reason for that is abundance of tutorials, workshops and well written documentation. After Brownie, switch to Ape and its plugin system is smooth.</p>
<p><strong>Performance:</strong></p>
<p>Ape framework performs well. Smart contract was developed and deployed to Rinkeby test network using a python script without any problems. Verification of the contract on Etherscan via a python script is not yet possible but is in the works in the Etherscan plugin.</p>
<p>Testing works well both locally and when using network forks, which makes exhaustive testing possible. Currently Ape doesn’t include built-in smart contract fuzz-testing tool.</p>
<p>Currently the speed of the framework is satisfactory and more improvements are on the way.</p>
<p><strong>Plugins:</strong></p>
<p>Open-source modular plugins are definitely the highlight of this framework. It allows developers to easily install and remove the functionality they need in their development process and I could see this being a way to onboard new developers from the python world and a way to incentivize developers to develop their own plugins. Some of the interesting Ape plugins are:</p>
<p><strong>ape-tokens</strong> is an interesting plugin which allows developers to get token contracts without putting in the addresses themselves.</p>
<p>Example:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">from</span> ape_tokens <span class="im" style="color: #00769E;">import</span> tokens</span>
<span id="cb1-2"></span>
<span id="cb1-3">link <span class="op" style="color: #5E5E5E;">=</span> tokens[<span class="st" style="color: #20794D;">"LINK"</span>]</span>
<span id="cb1-4"></span>
<span id="cb1-5"><span class="bu" style="color: null;">print</span>(link.address)</span></code></pre></div>
<p>This will print out the eth adress of the LINK token. “link” can now be used in various python scripts, be it testing or development.</p>
<p><strong>ape-ledger</strong> is a plugin for Ape Framework which integrates with Ledger devices to load and create accounts, sign messages, and sign transactions.</p>
<p>Requirements</p>
<ul>
<li>have the Ledger USB device connected</li>
<li>have the Ledger USB device unlocked (by entering the passcode)</li>
<li>have the Ethereum app open.</li>
</ul>
<p>Ledger accounts have the following capabilities in ape:</p>
<ul>
<li>Can sign transactions</li>
<li>Can sign messages using the default EIP-191 specification</li>
<li>Can sign messages using the EIP-712 specification</li>
</ul>
<p><strong>ape-trezor</strong> is a plugin for Ape Framework which integrates Trezorlib ethereum.py to load and create accounts, sign messages, and sign transactions.</p>
<p>You can load the account like any other account in Ape console and then use it to sign transactions like this:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1">ape trezor sign<span class="op" style="color: #5E5E5E;">-</span>message [YOUR TREZOR ALIAS] <span class="st" style="color: #20794D;">"hello world"</span></span>
<span id="cb2-2">ape trezor verify <span class="st" style="color: #20794D;">"hello world</span></span></code></pre></div>
<p>The output of verify should be the same address as the account $account_name.</p>
<p><strong>Ape Polygon Ecosystem Plugin</strong> - Ecosystem Plugin for Polygon support in Ape</p>
<p><strong>Ape Fantom Ecosystem Plugin - Ecosystem Plugin for Fantom support in Ape</strong></p>
<p><strong>ape-addressbook</strong> is plugin that allows tracking addresses and contracts in projects and globally. This is an interesting way to improve developers user experience and is currently in development.</p>
<p><em>…And many more.</em></p>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p><strong>Tech Radar Proposal:</strong></p>
<p>Recommended location is the Assess ring at this stage. The reason for that is the shere novelty of this framework. However the development team is great, community is growing and we are seeing new projects emerging using Ape. This framework is with its simplicity aiming to become the industry standard in Ethereum development for python developers and is on a great way to do so.</p>
</section>
<section id="bibliography" class="level1">




</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Bibliography</h2><div id="refs">

</div></section></div> ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-172.hugo.html</guid>
  <pubDate>Sat, 30 Apr 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>OWT - Omni Web Token</title>
  <dc:creator>Aleksandar Veljković</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-147.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p>JSON Web Tokens, or JWT, are the format of JSON encoded data structures for authorizing clients on the Web. Some JWT payloads have a specific standardized structure, defined by the protocol, such as OAuth(2) tokens. Others, however, are designed specifically for particular apps.</p>
<p>Authorization on the Blockchain is done mainly through explicitly whitelisting addresses that are allowed to perform specific actions. Whitelisting introduces high costs when the number of whitelisted addresses is large. A good example is ICO whitelisting, where hundreds or even thousands of participants need to get whitelisted.</p>
<p>This research aims to find an efficient, more cost-effective solution for authorizing users on the Blockchain using a system of authorization tokens issued and received off-chain, without the Blockchain transaction fees, and which will be valid on-chain and off-chain. In addition, the token structure should be transferrable off-chain as a JWT token, compatible with the OAuth2 standard, and reusable in both Web 2.0 and Web 3.0 worlds.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Ethereum Blockhain gas prices are following the price of Ether, resulting in higher transaction fees. The cost of 1 ETH on January 1st, 2019, was $140.82 [1]. On the same day in 2022, the price for 1 ETH was $3,769.70 [2]. That means that the same transaction from 2019 became just three years later became more than 30 times more expensive.</p>
<p>Executing transactions on Blockchain, in general, doesn’t require any specific authorization. The transactions are signed using the private key and paid using ETH from the signer’s wallet. However, some transactions, such are token purchases during ICOs, require explicit approval by the smart contract owner. The approval on the Blockchain is done by whitelisting wallet addresses that are allowed to perform specific actions, submitting the list of the whitelisted wallets, and storing them on the Blockchain. The price of each transaction for storing whitelisted wallets linearly grows by the number of the wallets.</p>
<p>In a more concrete example, storing one 20 byte address on Blockchain, having ETH at the January 1st, 2022 price, costs approximately 20000 GAS or around $5.6, having an average gas price of 74 Gwei. With those prices, storing a hundred whitelisted addresses would cost about $565, with base transaction cost included. It is challenging for technology to expand with such high prices for such basic requirements.</p>
<p>Before introducing the solution this research is proposing, it is essential first to briefly introduce some basic concepts regarding the existing methods for authorization on the Web.</p>
<section id="oauth-standard" class="level2">
<h2 class="anchored" data-anchor-id="oauth-standard">OAuth standard</h2>
<p>Open Authorization, or OAuth for short, is an authorization standard followed by many APIs worldwide. The standard specifies the protocol between client and authorization server and data transferred in protocol messages. There are two versions of OAuth standard, 1 and 2.</p>
<p>OAuth standard doesn’t specify the transfer method for sending messages, but one widely adopted standard is using JWT tokens as the authorization data container.</p>
</section>
<section id="jwt-tokens" class="level2">
<h2 class="anchored" data-anchor-id="jwt-tokens">JWT Tokens</h2>
<p>In 2015, Michael Jones, John Bradley and Nat Sakimura introduced JSON Web Tokens (JWT) through RFC-7519 as a compact structure for representing claims transferred between two parties [3]. Since then, JWTs have been used for client authentication on the Web. Initially, the authentication was performed between APIs but quickly found use in client authentication following the growth of client-heavy applications.</p>
<p>JWT has a general structure, made of a header, body, and signature segments. The header segment includes the token type and a label of the algorithm used for creating signatures.</p>
<p>Example JWT header</p>
<pre><code>{
    "type": "JWT",
    "alg": "ES256"
}</code></pre>
<p>The body segment is a container segment used for storing protocol-specific information. OAuth 2.0 standard, introduced with RFC-6749 [4], specifies several fields required for authorization that are members of the body of a JWT token. Some of those fields are:</p>
<ul>
<li><code>aud</code> (Audience) - Identifier of the user to whom the client will present the token for executing an action</li>
<li><code>exp</code> (Expiration) - Token expiration timestamp</li>
<li><code>iss</code> (Issuer) - Identifier of the token issuer, authorization service provider</li>
<li><code>scope</code> (Action scope) - List of actions for which the token owner would be authorized to perform</li>
<li><code>sub</code> (Subject) - Identifier of the token owner</li>
<li><code>iat</code> (Issued at) - Isusing timestamp</li>
</ul>
<p>Example JWT Body</p>
<pre><code>{
  "sub": "user1",
  "name": "John Doe",
  "iat": 1516239022,
  "aud": "server1",
  "scope": ["data.fetching"]
}</code></pre>
<p>Field <code>name</code> in the JWT body example represents a custom, application-specific data field.</p>
<p>The signature part of the JWT token contains the hash or signature of the token provided by the token issuer.</p>
<p>The three token parts are put together into one base64 encoded string (without trailint <code>=</code> symbols), having the tree parts separated by the dot <code>.</code> symbol.</p>
<p>Example of a complete JWT string</p>
<pre><code>eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ.SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5c</code></pre>
</section>
<section id="general-authorization-protocol" class="level2">
<h2 class="anchored" data-anchor-id="general-authorization-protocol">General Authorization Protocol</h2>
<p>A general protocol for client authorization on the Web using JWT tokens consists of two steps: - Requesting token from the authorization server for executing some action - Presenting the authorization token received from the authorization server to the server which would perform the requested action</p>
</section>
<section id="existing-approaches" class="level2">
<h2 class="anchored" data-anchor-id="existing-approaches">Existing Approaches</h2>
<p>There are some existing approaches for combining the Blockchain and OAuth tokens. In one such research [5], the authors used NFTs as authorization tokens generated on-chain that would be verifiable using the OAuth 2.0 protocol. That approach is inverse to this research: it doesn’t reduce costs but puts authorization tokens on the chain.</p>
</section>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p>The main goal of this research was to find a way to make authorization on the Web cheaper than the existing whitelisting method with the general idea to build a solution analogous to the current, proven methods for authorization on the Web. The key motivation for using tokens as an authorization method is an authorization protocol that shifts significant transaction fees from one authorization entity to many clients that pay only a small additional fee on top of the price they pay for executing the authorized action.</p>
<p>Reducing the price paid by the authorization entity by 100% can be achieved by issuing authorization tokens off-chain. This protocol specification introduces challenges regarding the design of the token, as the token should include all the information that the authorization entity would provide with the Blockchain transaction in the first place.</p>
<p>Reducing the costs of additional fees that clients would now pay for the authorization requires the overhead authorization data submitted on the Blockchain to be as small as possible. This requirement poses the main challenge for token design. Additionally, the Blockchain should not explicitly store authorization data, except as transaction arguments.</p>
<p>Combining these requirements, a perfect authorization schema represents a two-step protocol where the client first acquires the authorization token from the authorization server, off-chain. Second, the client submits the data required for performing the action to the Blockchain with a minor (ideally none) overhead the smart contract would use to confirm the client’s authorization.</p>
<section id="chain-token-ct-representation" class="level2">
<h2 class="anchored" data-anchor-id="chain-token-ct-representation">Chain token (CT) representation</h2>
<p>The essential requirements for the token that would be used on the chain are: - Efficient verifiability; token should be efficiently verifiable on the chain - Authenticity; the probability of token forgery should be negligible - Succinctness; token should be small in byte size - Non-transferability; token should be used only by the user who received the token</p>
<p>As an example throughout this research, we will use the money checkout allowance problem, where a client needs to be authorized to payout a certain amount of money from the account of the authorizing entity. An existing approach for solving this problem is calling the approval method on the smart contract or whitelisting clients and explicitly approving the total allowed amount for each client. Method signature without a token argument would look like this:</p>
<pre><code>payout(address account, address receiver, uint256 amount)</code></pre>
<p>A naive approach for constructing a token that would follow JWT logic would be providing all the values bound by the token. In our example, the values that are required for money checkout from the account are: - account owner identifier; 20 bytes address value - authorized client identifier; 20 bytes address value - allowed amount; 32 bytes value</p>
<p>Next, the apparent problem is a forgery. Everyone can create a token with listed values and submit it on the Blockchain. The solution for this problem is to provide a signature made by the authorization entity, which confirms the provided values. Ethereum signatures contain three segments, v, r, and s, 65 bytes long. All summed up to 137 bytes of memory. Even if this doesn’t look like a significant sum, the main issue is that the token size asymptotically grows by <img src="https://latex.codecogs.com/png.latex?O(n)">, linearly with the number of arguments n.&nbsp;In other words, it would become costly, or even unusable, for methods with more arguments. It is not very efficient, but it is a start.</p>
<section id="token-size-optimization" class="level3">
<h3 class="anchored" data-anchor-id="token-size-optimization">Token size optimization</h3>
<p>The problem with the naive approach is linear growth with the number of arguments. Solving this problem requires looking closely at the method that is being called. The method <code>payout</code> already contains the token values as a method argument, and it would be redundant to provide them again in the token. The same pattern is visible with different use-cases. This observation suggests that we can avoid providing the values within the token but use only a hash of the approved values and check if the hash of the provided input values matches the token hash. Using the hashing method clears the linear growth of the token as the size of the keccak256 hash is fixed to 32 bytes in length, achieving a constant <img src="https://latex.codecogs.com/png.latex?O(1)"> size of the token. The hash can also cover other values that could be hard-coded into the smart contract without a token size increase, which will become an essential feature in later sections.</p>
</section>
<section id="signature-size-optimization" class="level3">
<h3 class="anchored" data-anchor-id="signature-size-optimization">Signature size optimization</h3>
<p>The Ethereum signature size is fixed to 65 bytes. That means that it passes the size of 2 memory words (32 bytes in size) and requires three blocks of memory. The solution for this problem comes with EIP-2098 [6], which proposes a simple technique for compact signature representation, reducing its size by 1 byte and allowing it to fit into two memory blocks.</p>
<p>The total token size is now fixed to 32 bytes of token hash plus another 64 bytes of signature data totaling 96 bytes or three blocks of memory.</p>
</section>
<section id="mapping-oauth2.0-parameters" class="level3">
<h3 class="anchored" data-anchor-id="mapping-oauth2.0-parameters">Mapping OAuth2.0 parameters</h3>
<p>Now that we have a token structure, we need to figure out how to standardize token parameters to comply with the OAuth2.0 standard.</p>
<p>The audience parameter refers to the smart contract containing the payout method. It doesn’t need to be provided explicitly as a method argument as it is already encoded in the smart contract.</p>
<p>The token issuer can be deduced from the signature and doesn’t need to be explicitly provided.</p>
<p>The subject parameter is provided both as the input argument of the <code>payout</code> method. It doesn’t have to be provided explicitly. It should not be provided even as the argument, as it is already given as the message sender value.</p>
<p>The scope parameter describes the action that should be executed. It should not be explicitly provided as it should be hardcoded in the method.</p>
<p>The token expiration time is a tricky one. It doesn’t naturally belong to method arguments, so it should be provided explicitly. To prevent the token size increase, we can do a simple modification of the token hash. The value of the timestamp can be stored in 8 bytes. A straightforward solution is to provide another method argument with an 8-byte value. A more elegant solution is to transform the keccak256 value into “pseudo-keccak224” (SHA224 [7] value, with unchanged initialization value) by truncating the hash size to its 224 bytes prefix and appending 8 bytes extension with expiration timestamp as the last 8 bytes of the token hash. This transformation returns us to the previously proposed token size without extra arguments.</p>
<p>As we can see, all the crucial parameters of the OAuth2.0 protocol can be successfully mapped to the Blockchain transactions and the chain token.</p>
</section>
</section>
<section id="token-reusability" class="level2">
<h2 class="anchored" data-anchor-id="token-reusability">Token reusability</h2>
<p>Some authorization tokens are reusable many times until the expiration date. However, some use-cases require that the tokens may be used only once. An example of such a use case is exactly the example we have used so far. Once the payout method has been executed, the user should not be able to perform double-payout transactions. This problem can be solved the same way as in Web 2.0 - by introducing a payment identifier. The payment identifier should be included as an extra method argument and included in the token hash. This solution also solves the issue of the lost token, as the token can be reissued with the same payment identifier and used for the same payment only once. Specific use cases may require the existence of only one token. In that case, the token (and method arguments) may include <code>jti</code> parameter or JWT token ID as a token identifier or use the token hash as an identifier. The smart contract should implement mechanisms for preventing double payments and a potential blacklisting of tokens.</p>
</section>
<section id="action-scope-schemas" class="level2">
<h2 class="anchored" data-anchor-id="action-scope-schemas">Action scope schemas</h2>
<p>OAuth2.0 proposes a parameter that includes the action scope or label of the action for which the client can use the token. Action scopes are not specified as they can be represented using any string value. The problem here is the cost of using string data types in smart contracts. This research proposes restriction for action type values to numerical data types of 4 bytes. This restriction allows <img src="https://latex.codecogs.com/png.latex?2%5E32"> possible scope values that could represent many use cases.</p>
<p>A library of token schemas can help developers properly format their tokens based on scope number schemas. Furthermore, enumeration of action types can introduce standardization for tokens where a smart contract may require, for example, “scope 42” tokens for executing a method. We present the first two token scopes that would be used in the following use-cases:</p>
<section id="scope-1-generic-identity" class="level3">
<h3 class="anchored" data-anchor-id="scope-1-generic-identity">Scope 1: Generic Identity</h3>
<p>Generic identity scope should be used for verification of the client’s identity. The verification is based on the client’s wallet address and unique identifier in the issuer’s database. The hash for “scope 1” tokens be made by hashing the following array of values in their respective order: - <code>address iss</code>; token issuer <code>address aud</code>; smart contract address or 0 address for general identification - <code>address sub</code>; client’s wallet address - <code>uint4 scope</code>; action scope with value <code>1</code> for generic identification - <code>bytes32 uuid</code>; unique identifier of the client in the issuer’s - <code>uint8 exp</code>; token expiration timestamp in UNIX timestamp format database ### Scope 2: Allowance Allowance tokens, used for crypto cheques, should have hashes made by hashing the following array of values in their respective order: - <code>address iss</code>; token issuer - <code>address aud</code>; smart contract address - <code>address sub</code>; money receiver - <code>uint4 scope</code>; action scope with value <code>2</code> for allowance - <code>bytes32 paymentId</code>; payment identifier (NOTE: token hash may be used as payment ID but it can introduce new problems) - <code>uint256 amount</code>; amount to transfer - <code>uint8 exp</code>; token expiration timestamp in UNIX timestamp format</p>
<p>The reader may notice that in both cases, there are two logical groups of parameters: - general parameters; <code>iss</code>, <code>aud</code>, sub<code>,</code>scope<code>and</code>exp<code>- application-specific parameters;</code>userId<code>,</code>paymentId<code>,</code>amount`</p>
<p>The general parameters are the same for all tokens, and application-specific parameters are different for each scope.</p>
</section>
</section>
<section id="from-chain-token-ct-to-omni-web-token-owt" class="level2">
<h2 class="anchored" data-anchor-id="from-chain-token-ct-to-omni-web-token-owt">From Chain Token (CT) to Omni Web Token (OWT)</h2>
<p>Now that we have the complete definition of the chain token, we can go one more step and make it usable and transferrable in the Web 2.0 world. We can do this by packing chain token data as part of theJWT token, following the OAuth 2.0 schema.</p>
<section id="owt-body" class="level3">
<h3 class="anchored" data-anchor-id="owt-body">OWT Body</h3>
<p>The token scopes define OAuth 2.0 parameters, so the only remaining thing is appropriately packing the chain token into the JWT body and creating a proper JWT signature. The verifier needs to know the CT hash value and the parameters used in the construction of the token.</p>
<p>The proposed OWT body schema is:</p>
<pre><code>{
    aud: &lt;smart contract address&gt;,
    iss: &lt;issuer's wallet address&gt;,
    scope: &lt;readable name of the scope&gt;,
    exp: &lt;token expiration timestamp&gt;
    chain_token: {
        token_hash: &lt;CT hash with expiration timestamp&gt;,
    r: &lt;signature r value&gt;,
    sv: &lt;compact representation of s and v signature values&gt;
        params: [&lt;
                ordered list of token parameters
                in form of:
                 {
                    param: &lt;parameter name&gt;,
                    value: &lt;parameter value&gt;,
                    type: &lt;parameter data type&gt;,
                 }
            &gt;]
    }
}</code></pre>
</section>
<section id="owt-signature" class="level3">
<h3 class="anchored" data-anchor-id="owt-signature">OWT Signature</h3>
<p>The JWT standard allows using the Ethereum secp256k1 signatures by providing the <code>EC256</code> algorithm type value in the token header. The signature of the OWT token is created using the issuer’s private key. To verify the signature, the verifier needs access to the issuer’s public key, which should be available from the issuer’s <code>/.well-known/jwks.json</code> route of the authorization API.</p>
</section>
</section>
<section id="owt-issuing" class="level2">
<h2 class="anchored" data-anchor-id="owt-issuing">OWT Issuing</h2>
<p>The OAuth 2.0 protocol allows using <code>client id</code> and <code>client secret</code> parameters when requesting the authorization tokens. OWT requests can be made using wallet address as client’s identity and signature of the clients wallet address as the <code>client secret</code> parameter</p>
</section>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<p>To test our hypothesis and estimate the costs of working with OWTs, a simple NodeJS library for generating and verifying OWTs was implemented together with testing REST API for issuing OWTs following the OAuth 2.0 protocol. An example smart contract for testing the usability of the chain token was also implemented.</p>
<p>The smart contract used for testing included four methods: - <code>whitelist(address client, uint256 amount)</code> method for whitelisting the user for a given amount of money - <code>payoutOld(uint256 amount)</code> method for performing payout in the old fashioned way by checking the whitelisted amount - <code>payoutNew(address sender, uint256 amount, bytes32 paymentId, bytes32[3] calldata token)</code> method for performing payout using the chain token following “scope 2” schema - <code>payoutNewShort(address sender, uint256 amount, bytes32[3] calldata token)</code> method for performing payout using the chain token but without payment identifier, having token hash as a payment identifier - <code>verifyIdentity(address issuer, bytes32 userId, bytes32[3] calldata token)</code> method for simple verification of the client’s identity following “scope 1” schema</p>
<section id="allowance-use-case" class="level2">
<h2 class="anchored" data-anchor-id="allowance-use-case">Allowance Use Case</h2>
<p>The allowance use case tested the token issuing protocol for payout allowances, evaluated the costs of performing payouts using the token, and compared the results with the basic whitelisting protocol.</p>
<section id="test-setup" class="level3">
<h3 class="anchored" data-anchor-id="test-setup">Test setup</h3>
<p>Authorization entity submitted allowance amount for the client using the <code>whitelist</code> smart contract method. The cost of the whitelisting transaction was 44,484 gas.</p>
</section>
<section id="test-1-payout-by-whitelisting" class="level3">
<h3 class="anchored" data-anchor-id="test-1-payout-by-whitelisting">Test 1: Payout by Whitelisting</h3>
<p>The client executed the <code>payoutOld</code> method of the smart contract with a propper allowance amount. The cost of the payout transaction was 22,389 + T gas.</p>
</section>
<section id="test-2-payout-with-token" class="level3">
<h3 class="anchored" data-anchor-id="test-2-payout-with-token">Test 2: Payout with Token</h3>
<p>The client requested an OWT from the authorization server using OAuth 2.0 request schema. The authorization server verified the client’s credentials and issued a “scope 2” token to the client with a specified allowance amount. The client verified the OWT data and extracted the chain token and its parameters from the OWT. After the OWT verification step, the client submitted them to the smart contract using the <code>payoutNew</code> method. The payout was successful, and the execution cost was 59,935 + T gas.</p>
</section>
<section id="test-3-payout-with-token-using-token-hash-as-payment-identifier" class="level3">
<h3 class="anchored" data-anchor-id="test-3-payout-with-token-using-token-hash-as-payment-identifier">Test 3: Payout with Token using Token Hash as Payment Identifier</h3>
<p>The protocol for issuing and verifying the OWT was done the same way as in the previous test. The only difference was that the token did not follow the “scope 2” schema but left out the payment identifier. The client performed a payout using the <code>payoutNewShort</code> method. Again, the payout was successful, and the execution cost was 59,189 + T gas.</p>
</section>
<section id="cost-analysis" class="level3">
<h3 class="anchored" data-anchor-id="cost-analysis">Cost Analysis</h3>
The test results show that the cost of the payout protocol using whitelisting was 44,484 gas for the issuer and 22,389 gas for the client, resulting in 66,873 gas for the entire protocol. Test 2 showed that using the token has reduced the issuer’s costs to 0, but the client’s cost was increased to 59,935 gas which is 37,546 gas more than in test 1. Interestingly, the overhead cost for the client is lower than the costs of the issuer’s whitelisting, which indicates that using the token reduces the issuer’s fees, compared to whitelisting, even if the issuer compensates the overhead client’s costs by increasing the allowance amount. Test 3 showed that using token hash as payment identifier reduces the costs for extra 746 gas. However, this introduces problems with token reissuing. The exact token needs to be reissued every time the original one gets lost, requiring the expiration timestamp to be the same as the original one for the hashes to match and thus have the same payment identifier. This situation can cause the issuer to be unable to reissue the token as its timestamp has already expired. The results of the cost analysis are presented in Table 1. <br><br>

<table>
<tbody><tr>
<th>
Method
</th>
<th>
Issuer’s costs (gas)
</th>
<th>
Client’s costs (gas)
</th>
<th>
Total protocol costs (gas)
</th>
</tr>
<tr>
<th>
Whitelisting
</th>
<th>
44,484
</th>
<th>
22,389
</th>
<th>
66,873
</th>
</tr>
<tr>
<th>
OWT allowance
</th>
<th>
0
</th>
<th>
59,935
</th>
<th>
59,935
</th>
</tr>
<tr>
<th>
Short OWT allowance
</th>
<th>
0
</th>
<th>
59,189
</th>
<th>
59,189
</th>
</tr>

</tbody></table>
<center>
Table 1. Cost anlysis of the allowance use case methods
</center>
<p><br><br></p>
</section>
</section>
<section id="generic-identity-use-case" class="level2">
<h2 class="anchored" data-anchor-id="generic-identity-use-case">Generic Identity Use Case</h2>
<p>The generic identity use case tested the issuing and verification of the “scope 1” tokens and assessed the costs of using identification tokens on the chain.</p>
<p>The client acquired OWT from the authorization server and submitted the token with the received user id from the issuer’s database. The client submitted the token to the <code>verifyIdentity</code> method of the smart contract and successfully verified the identity token. The cost of the verification was 36,816 gas, which suggests that the verification proces cost was 15,817 gas, leaving out the base transaction cost.</p>
<section id="use-case-analysis" class="level3">
<h3 class="anchored" data-anchor-id="use-case-analysis">Use case analysis</h3>
<p>The test showed that the costs for verifying the identity tokens are low and open a new path for the identity representations valid on multiple chains. Additional use cases may specify scope schemas for more specific identity tokens and introduce low-cost decentralized identities to a multi-chain environment.</p>
</section>
</section>
<section id="general-purpose-token-verification-service-gptvs" class="level2">
<h2 class="anchored" data-anchor-id="general-purpose-token-verification-service-gptvs">General Purpose Token Verification Service (GPTVS)</h2>
<p>The entire verification protocol can be summed up into a token verification smart contract that can be deployed and used by multiple users to verify the authorization tokens for their smart contracts. Blacklisting can be introduced for tokens or clients. This service should allow listing approved issuers and smart contract addresses from which the requests may come. Also, the service can be monetized by requiring a certain amount of Ethers or ERC-20 tokens to be submitted monthly by the users to the verification smart contract, or the service will become unavailable for the requests coming from the user’s smart contracts.</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>The test results show that the OWTs and the chain tokens can cover a variety of use cases while introducing standardization in token construction, issuing, and verification. Operating with OWTs reduces costs for the services requiring whitelisting while enabling new multi-chain use cases thanks to a succinct yet general token structure and easy verification. The following steps would include defining more token schemas covering miscellaneous use cases and implementing the General Purpose Token Verification Service.</p>
</section>
<section id="appendices" class="level1">
<h1>Appendices</h1>
<section id="appendix-1-chain-token-verification-smart-contract" class="level2">
<h2 class="anchored" data-anchor-id="appendix-1-chain-token-verification-smart-contract">Appendix 1: Chain token verification smart contract</h2>
<pre class="solidity"><code>// SPDX-License-Identifier: GPL-3.0
pragma solidity &gt;=0.7.0 &lt;0.9.0;

contract VerifierContract {
        mapping(address =&gt; uint256) whitelisted;
        mapping(bytes32 =&gt; bool ) usedPaymentIds;
        bytes prefix = "\x19Ethereum Signed Message:\n32";
        uint32 genericIdentityScope = 1;
        uint32 payoutScope = 2;

        function checkSignature(bytes32[3] calldata token, address signer) public returns (bool) {
                // Decode r, s, v values
                bytes32 hash = token[0];
                bytes32 sv = token[2];
                bytes32 r = token[1];
                bytes32 s = sv &amp; bytes32((uint((1 &lt;&lt; 255) - 1)));
                uint8 v = uint8(uint(sv &gt;&gt; 255) + 27);

                // Create signature hash
                bytes32 prefixedProof = keccak256(abi.encodePacked(prefix, hash));

                // Verify signer
                address recovered = ecrecover(prefixedProof, v, r, s);
                return recovered == signer;
        }
        
        function whitelist(address client, uint256 amount) public {
                whitelisted[client] = amount;
        }

        function payoutOld(uint256 amount) public {
                require(amount &lt;= (whitelisted[msg.sender]));
                whitelisted[msg.sender] -= amount;
        }

        function payoutNew(address sender, uint256 amount, bytes32 paymentId, bytes32[3] calldata token) public{
                // Check if token has already been used
                require(usedPaymentIds[paymentId] == false);

                // Check token expiration
                uint32 exp = uint32(uint256(token[0]));
                require(exp &gt; block.timestamp, "Token expired");

                // Check token signature
                require(this.checkSignature(token, sender) == true, "Invalid signature");

                // Check token values
                bytes32 prefixedProof = keccak256(abi.encodePacked(sender, address(this), msg.sender, payoutScope, exp, paymentId, amount));
                require (bytes32((uint256(prefixedProof &gt;&gt; 32 &lt;&lt; 32) | uint256(exp))) == token[0]);

                usedPaymentIds[paymentId] = true;
        }

        function payoutNewShort(address sender, uint256 amount, bytes32[3] calldata token) public{
                // Check if token has already been used
                require(usedPaymentIds[token[0]] == false);

                // Check token expiration
                uint32 exp = uint32(uint256(token[0]));
                require(exp &gt; block.timestamp);

                // Check token signature
                require(this.checkSignature(token, sender) == true);

                // Check token values
                bytes32 prefixedProof = keccak256(abi.encodePacked(sender, address(this), msg.sender, payoutScope, exp, amount));
                require (bytes32((uint256(prefixedProof &gt;&gt; 32 &lt;&lt; 32) | uint256(exp))) == token[0]);

                usedPaymentIds[token[0]] = true;
        }

        function verifyIdentity(address issuer, bytes32 userId, bytes32[3] calldata token) public {
                // Check token expiration
                uint32 exp = uint32(uint256(token[0]));
                require(exp &gt; block.timestamp);

                // Check token signature
                require(this.checkSignature(token, issuer) == true);

                // Check token values
                bytes32 prefixedProof = keccak256(abi.encodePacked(issuer, address(this), msg.sender, genericIdentityScope, exp, userId));
                require (bytes32((uint256(prefixedProof &gt;&gt; 32 &lt;&lt; 32) | uint256(exp))) == token[0]);
        }
}</code></pre>
</section>
</section>
<section id="bibliography" class="level1">
<h1>Bibliography</h1>

<ol type="1">
<li><p>Coinmarketcap, Historical snapshot from 2019/01/01, https://coinmarketcap.com/historical/20190101/</p></li>
<li><p>Coinmarketcap, Historical snapshot from 2022/01/01, https://coinmarketcap.com/historical/20220101/</p></li>
<li><p>M. Jones, J. Bradley, N. Sakimura, RFC-7519: JSON Web Token (JWT), https://datatracker.ietf.org/doc/html/rfc7519</p></li>
<li><p>D. Hardt, Ed., RFC-6749: The OAuth 2.0 Authorization Framework, https://datatracker.ietf.org/doc/html/rfc6749</p></li>
<li><p>N. Fotiou, I. Pittaras, V. A. Siris, S. Voulgaris, G. C. Polyzosar, OAuth 2.0 authorization using blockchain-based tokens, arXiv:2001.10461v1, 28 Jan 2020, https://arxiv.org/pdf/2001.10461.pdf</p></li>
<li><p>R Moore, N Johnson, EIP-2098: Compact Signature Representation, https://eips.ethereum.org/EIPS/eip-2098</p></li>
<li><p>R. Housley, RFC-3874: A 224-bit One-way Hash Function: SHA-224, https://datatracker.ietf.org/doc/html/rfc3874</p></li>
</ol>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs">

</div></section></div> ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-147.hugo.html</guid>
  <pubDate>Wed, 06 Apr 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Blacklisting Platform based on untransferable NFTs</title>
  <dc:creator>Aleksandar Damjanovic</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-154.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p>The main topic of this research is exploring the possibility and the need to create the “Authority” protocol that would handle blacklisting based on community voting and assessment. This protocol would mint the untransferable NFT to the blacklisted address. Creating this solutions (both the platform and the NFT) would not be challenging but the need for these solutions is questionable to the author. This paper explored the current blacklist cases and the possibility of creating the said NFTs. The Tether case is in the main focus since the solutions are similar and simple. The main takeaway is that creating this solution is not necessary per se, but the issue is open for discussion.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>When it comes to Web3, security breaches, hacks and malicious behaviour are a big issue. That is why some protocols resort to blacklisting the addressses they deem malicious. Blacklisting is essentially putting the addresses that have engaged in unethical or unacceptable activities on a list which in turn would limit their usage of said protocols.<sup>1</sup></p>
<p>Initial idea for this research is to explore the possibility of creating a platform that would blacklist addresses and send them an untransferable NFT. This platform would take it upon itself to take care of blacklisting for other protocols and users. The cases would be reported and voted on i.e Nexus Mutual model (for more info on their voting model check ERFC-91). When it comes to problems that this solution would solve the main problem is taking care of blacklisting for other protocols, this in turn makes our solution (even with voting) a point of centralization but more on that in later paragraphs.</p>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p>The goal of this research is to explore how was blacklisting taken care of so far and to explore the possibility and need of creating a protocol that would do this with utilizing untransferable NFTs. Untransferable NFTs have been a topic of interest in the field for a while, otherwise there is no explicit point of including them except for “flagging” the addresses for the world to see.</p>
<p>This will be done by examining the source code of protocols that have done blacklisting in the past. After the examination we will draw some conclusions.</p>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<section id="blacklisting" class="level2">
<h2 class="anchored" data-anchor-id="blacklisting">Blacklisting</h2>
<p>As we pointed above we did a deep-dive into contracts that utilize blacklisting. In the beginning of the research we have searched for contracts that previously used blacklisting and we have come across the Tether case as it is the biggest one. There are various contracts that use the blacklist contracts but it is the exact same approach. When it comes to individual sites and addresses MetaMask already blocks sites that are known to steal funds.<sup>2</sup></p>
<p>Stablecoin issuer Tether froze the ethereum <a href="https://etherscan.io/tx/0x60891b856cdae4fd0878d45d2768e640be2dc2a50876d20138797a09877a7cd6#eventlog">address</a> holding over $715,000 worth of USDT. This address is the address of hackers who stole $3 million on the Multichain bridge. This means that they cannot move the funds.</p>
<ul>
<li>The question here is how did Tether manage to do that?</li>
</ul>
<p>They managed that by importing the Blacklist contract in their main contract. We will try to explain the contract in the code-box comments below:</p>
<pre><code>contract BlackList is Ownable, BasicToken {

    // Getters to allow the same blacklist to be used also by other contracts.(including upgraded Tether) 
    function getBlackListStatus(address _maker) external constant returns (bool) {
        return isBlackListed[_maker];
    }

    // Returns the owner of the contract address.
    function getOwner() external constant returns (address) {
        return owner;
    }

    // Puts the blacklisted addresses in the mapping for checking and later use.
    mapping (address =&gt; bool) public isBlackListed;

    // Self explanatory, adds the address to the isBlacklisted mapping. Only owner of the contract can call the function
    function addBlackList (address _evilUser) public onlyOwner {
        isBlackListed[_evilUser] = true;
        AddedBlackList(_evilUser);
    }

    // Removes the address from the blacklist and "unfreezes the assets". Only owner of the contract can call the function.
    function removeBlackList (address _clearedUser) public onlyOwner {
        isBlackListed[_clearedUser] = false;
        RemovedBlackList(_clearedUser);
    }

    // Destroys the funds of the blacklisted address and reduces the total suply by the same amount. Only owner of the contract can call this function.
    function destroyBlackFunds (address _blackListedUser) public onlyOwner {
        require(isBlackListed[_blackListedUser]);
        uint dirtyFunds = balanceOf(_blackListedUser);
        balances[_blackListedUser] = 0;
        _totalSupply -= dirtyFunds;
        DestroyedBlackFunds(_blackListedUser, dirtyFunds);
    }
    // Simple events for transaction logs.
    event DestroyedBlackFunds(address _blackListedUser, uint _balance);

    event AddedBlackList(address _user);

    event RemovedBlackList(address _user);

}</code></pre>
<p>Then they simply put the require statement in all their main contract functions(except for the ones with the “Only Owner modifier”) for example:</p>
<pre><code>// Require statement above makes sure the blacklisted address can't access the function.
function transferFrom(address _from, address _to, uint _value) public whenNotPaused {
        require(!isBlackListed[_from]);
        if (deprecated) {
            return UpgradedStandardToken(upgradedAddress).transferFromByLegacy(msg.sender, _from, _to, _value);
        } else {
            return super.transferFrom(_from, _to, _value);
        }
    }</code></pre>
<p>This approach to blacklisting gives the Tether the absolute control in what addresses it blacklists and for how long.</p>
<p>As we can see in the getBlacklistStatus the other contracts can use the same Blacklist to limit their usage as Tether thus leaning on their decision making.</p>
<p>In theory a blacklist protocol can be created where the voting what address to blacklist could be done by the community. The said addresses would be stored in the contract and those addresses could be whitelisted by voting again. Then, other contracts could lean on the “list” and block the addresses from using their functions. This would also make our solution the major point of centralization and considering how easy it is to set up blacklisting individually this proposes a question is the such solution needed?</p>
<p>Implementing a separate blacklist functions is not challenging and any contract can include them and have the complete control in what addresses it freezes and for how long.</p>
</section>
<section id="untransferable-nfts" class="level2">
<h2 class="anchored" data-anchor-id="untransferable-nfts">Untransferable NFTs</h2>
<p>Untrasferable NFTs have been a topic of interest for a while in Web3 and there are various use cases that have been explored. Such as:</p>
<ul>
<li>identity</li>
<li>badges</li>
<li>achievements, etc</li>
</ul>
<p>Vitalik Buterin in his blog post showed his interest in “soulbound NFTs”. If we want these NFTs to be truly soulbound (untrasferable) we would need to block transferability thus limiting them to only one address. When it comes to badges and achievements there are already POAPs. POAP has made the decision not to block transferability of POAPs themselves since the owners might want to change addresses and migrate assets for various reasons. There are various cases where they have been sold or even given out for free and after that sold for the highest bidder.<sup>3</sup></p>
<p>When it comes to creating a “soulbound NFT” we think that it is possible and that it can be done by modifying the transfer function from the ERC-721 standard.</p>
<p>The main issue here is utilizing them in the Blacklisting sense, the mint function from the ERC-721 interface can be included in the addBlacklist() function which would mint the said token to the said address. But so far we haven’t come to the use-case except for “flagging” the addresses for the world to see, so it seems unnecessary at the moment.</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>When exploring blacklisting we have come to conclusion that it is already implemented in some contracts and that creating a protocol that marks the “malicious” addresses is possible. The untransferable NFTs are possible to create also. The main question here is are those solutions needed? Creating a protocol that others can lean on can be useful but it would also be a major point of centralization and a lot of effort for a feature that simple. Not to mention including untransferable NFTs in the process which at this stage of the research seem unnecessary. What if the address is removed from the blacklist for various reasons does the NFT stay?</p>
</section>
<section id="bibliography" class="level1">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Bibliography</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Soulbound" class="csl-entry">
‘Soulbound’ &lt;<a href="https://vitalik.ca/general/2022/01/26/soulbound.html" class="uri">https://vitalik.ca/general/2022/01/26/soulbound.html</a>&gt; [accessed 12 April 2022]
</div>
<div id="ref-WhatBlacklist" class="csl-entry">
‘What Is a Blacklist?’, <em>Investopedia</em> &lt;<a href="https://www.investopedia.com/terms/b/blacklist.asp" class="uri">https://www.investopedia.com/terms/b/blacklist.asp</a>&gt; [accessed 12 April 2022]
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>‘What Is a Blacklist?’, <em>Investopedia</em> &lt;&lt;https://www.investopedia.com/terms/b/blacklist.asp&gt;&gt; [accessed 12 April 2022].↩︎</p></li>
<li id="fn2"><p><strong>metamaskmetamaskMetaMaskAutomaticallyBlocks2018?</strong>↩︎</p></li>
<li id="fn3"><p>‘Soulbound’ &lt;&lt;https://vitalik.ca/general/2022/01/26/soulbound.html&gt;&gt; [accessed 12 April 2022].↩︎</p></li>
</ol>
</section></div> ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-154.hugo.html</guid>
  <pubDate>Thu, 31 Mar 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>NFT that is bound by time</title>
  <dc:creator>Marija Mijailovic</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-101.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p>NFTs have a unique ID and belong to a single wallet. Two standards define what an NFT is and should do: ERC721 and ERC1155, aiming to distinguish each token to be unique. The development of NFT is still in the early stage, and this research shows how NFTs can change their properties. We go through some existing solutions where some events fundamentally affect the NFT, changing its state, properties, or value. We give an overview of those solutions with a desire to cover how they work under the hood and notice potential problems. In the end, are presented possible use cases that open a new door into the NFT word.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>NFTs (Non-Fungible Tokens) reached incredible popularity in 2021 Ryan Browne<sup>1</sup>. Most of created NFTs are static. We collect it, and we hope its market value will increase. In the case of <em>static</em> NFT, it’s characteristic that its properties and data are immutable and recorded on the blockchain, so such NFTs can’t be changed. Otherwise, there are <em>dynamic</em> NFT for which it’s characteristic that properties and data are mutable, often through oracles that trigger events off-chain system or by interaction with on-chain components, for example, smart contracts other NFTs.</p>
<blockquote class="blockquote">
<p>“Dynamic NFTs are the logical next step for the NFT space, allowing unique items to evolve, and sometimes decay. This replicates the ephemeral nature of the real world and potentially gives exceptional value to a collected item because of its current state. NFTs transitioning from being ‘only’ static to being dynamic can be thought of as progressing from 2D to 3D, it enables an immense possibility of use cases.” — Adrien Berthou, Head of Crypto-Native Comms at DoinGud</p>
</blockquote>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p>The goals of this research:</p>
<ul>
<li>Introduce with dynamic NFT</li>
<li>Search for project that make evolvable NFTs</li>
<li>Research how they work, find some leak</li>
<li>Suggest improvements</li>
</ul>
<p>Methodology for accomplishing those goals:</p>
<ul>
<li>Getting under the hood of open source solutions</li>
<li>Testing existing approach</li>
<li>Solidity</li>
</ul>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<p>First of all, let’s briefly review some existing projects:</p>
<ul>
<li><a href="https://ether.cards/">EtherCards</a>
<ul>
<li>EtherCards is a dynamic NFT platform that allows anyone to give a base set of traits and requirements and launch their NFT collection so that the EtherCards team can create unique NFTs. Traits can be discounts, special access rights, connections to real-world events, airdrops, upgrades, and other benefits. The ability to have traits allows the creator to maximize the value of their art. Ether Cards is an integrated ecosystem composed of two major parts. Those are the platform and the Ether Cards (an advanced membership NFT card). Anybody can use the EtherCards platform, but the owner of the EtherCards card has certain privileges. Under the hood, EtherCards integrate Chainlink VRF to provide verifiable randomness on-chain. Chainlink allows developers to read data from any external API and blockchain network and perform off-chain computation. That will enable NFTs to be connected to the external world to trigger real-world events, in a word, to be dynamic.</li>
<li>EtherCards have supported and worked with <a href="https://blog.ether.cards/lamelo-ball-nft/">LaMelo Ball</a>, <a href="https://nfttyson.com/">Mike Tyson</a>, <a href="https://blog.ether.cards/steve-aoki-partners-with-ether-cards-to-produce-new-animated-nft-collection-dominion-x/">Steve Aoki</a> and <a href="https://blog.ether.cards/artist-profile-dirty-robot/">DirtyRobot</a>. In the above collections, all NFTs metadata are stored <code>https://client-metadata.ether.cards</code> on the central server. Within that metadata is a link that points to NFTs image on IPFS. So, inside the smart contract, we store points to metadata JSON URIs to all variants of one NFT. Later, inside <code>tokenURI</code> function with the support of Chainlink return dynamically created URI of NFT, only one variant.</li>
</ul></li>
<li><a href="https://www.loopheads.info/">Loopheads</a>
<ul>
<li>Loopheads is a Loopring ‘Loopring - <span class="nocase">zkRollup Layer2</span> for Trading and Payment’<sup>2</sup> <em>Moody Brains</em> NFT collection, minted on Looprings Layer 2. There are 25 variants for one Loophead avatar(5 different backgrounds and 5 different brain sizes), which one will be displayed depending on the LRC token price using Uniswap Oracles.</li>
<li>All NFT metadata are stored on decentralized storage - IPFS, within that metadata, is a link that sends to NFT’s image on IPFS. So, inside the smart contract, we store points to metadata JSON URIs to all of the Loophead’s variations. When a Loophead NFT is accessed because Loopheads use ERC1155 standard, the Loophead NFT runs the <code>uri</code> function, the start point of dynamic calculation, to show the loophead avatar. The calculation is done with the support of Uniswwap V3 Oracles. That changes parts of the metadata link based on LRC price and returns only one variant.</li>
</ul></li>
<li><a href="https://docs.uniswap.org/protocol/reference/periphery/libraries/NFTDescriptor">Uniswap LP NFT</a>
<ul>
<li>On Uniswap V3 liquidity provider(LP) position is represented as NFT. This NFT shows information about liquidity position. Based on the pool and your parameters selected on the liquidity providing interface. The unique NFT will be minted, representing your position in that specific pool. As the owner of this NFT, you can modify or save the position. The best part of this project is that NFT is SVG generated entirely on-chain. Because of that, it is secure as an image not rely on any other service that is not on the blockchain, and it affects the price of that NFT.</li>
<li>All liquidity parameters for NFT are stored on-chain. Interesting is that SVG generation is done inside a pure function, and it returns base64 encoded metadata from the view function.</li>
<li>When a Uniswap V3 LP NFT is accessed because it uses the ERC721 standard, it runs the <code>tokenURI</code> function, which is the start point that generates SVG from liquidity parameters and returns base64 encoded metadata.</li>
</ul></li>
<li><a href="https://www.aavegotchi.com/">Aavegotchi</a>
<ul>
<li>Aavegotchi is a crypto collectible game. It was developed to provide users with a new blockchain-based game powered by dynamic NFTs. Aavegotchi information such as Aavegotchi name, traits, and SVG files themselves are saved as contract calldata because it is less gas cost than store in contract storage. The fundamental element of Aavegotchi’s game is randomness. Because of that, they use Chainlink VRF. The main idea behind the game is that the more you love your Aavegotchi character, the more rewards it will give you.</li>
<li>To store SVG, we pass one or more SVG images as a string, along with the information of SVG category type(aavegotchi, collaterals, eyeShapes, wearables) and size of passed SVG images. So inside <code>tokenURI</code> we have all NFTs prepared to return only one determined based on real-life events.</li>
</ul></li>
</ul>
<p>You can quickly determine where your NFT is by calling the <code>tokenURI</code> or <code>uri</code> function on the contract, which returns a URI that points to metadata that shows where NFT lives. Above project for NFT storage use:</p>
<ul>
<li>Centralized server</li>
<li>Decentralized storage (IPFS, Filecoin, Arweave)</li>
<li>On-chain storage</li>
</ul>
<p>The problem with the central server is that the possibility for manipulation is vast. The server owner can change the JSON scheme of your NFT whenever he wants.</p>
<p>The problem with IPFS is that there is no defined way of data replication. It just happens depending on the relevance of the content. In addition, the IPFS node can become offline. The problem is that if the relevance of our data is minor, the bigger is chance to lose data. To resolve the issue, Filecoin and Arweave come into play. Filecoin is a solution where we pay some price to store data for a set time. The problem is that we are limited by time, so our data are not stored permanently. Arweave is a solution that incentivizes the nodes to hold data permanently by paying only one fee in the Arweave token and keeping data forever. The most significant leak here is that it all comes down to having one storage layer that is separate from the blockchain and from the NFT itself on which it is located.</p>
<p>When it comes to on-chain storage, the SVG is scalable because it does not rely on pixels to display the image. SVG is used for vector graphics where we can describe shapes and lines mathematically. But, if we want to present a more complex image in this format, we get a massive SVG file, which will lead to a considerable gas cost. Additionally, the worth of mention is <a href="https://eips.ethereum.org/EIPS/eip-2569">EIP-2569</a>.</p>
<ul>
<li>EIP-2569 is an Ethereum improvement proposal to allow a smart contract to save and retrieve an SVG image. Based on that, the two methods contract must have: <code>getTokenImageSvg(uint256) view returns (string memory)</code> and <code>setTokenImageSvg(uint256 tokenId, string memory imagesvg) internal</code>. As we can see, the potential flaw of function <code>setTokenImageSvg</code> as input parameter accepts SVG image string, which can lead to a considerable gas cost in case of complex SVG.</li>
</ul>
<p>There is no obstacle to the realization of any project that would require the evolution of NFT. Everything needed is that our contract overrides the <code>tokenURI</code> or <code>uri</code> function from ERC721 or ERC1155. Therefore, the precondition is that we have prepared all parameters variants for the dynamic generation of potential variants. The project specification itself decides which variants to return within it.</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span id="cb1-1">  <span class="kw" style="color: #003B4F;">function</span> <span class="fu" style="color: #4758AB;">tokenURI</span>(uint256 tokenId) <span class="kw" style="color: #003B4F;">public</span> view <span class="fu" style="color: #4758AB;">override</span>(ERC721) <span class="fu" style="color: #4758AB;">returns</span> (string memory) {</span>
<span id="cb1-2">    <span class="pp" style="color: #AD0000;">require</span>(<span class="fu" style="color: #4758AB;">_exists</span>(tokenId))<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb1-3">    <span class="cf" style="color: #003B4F;">return</span> <span class="fu" style="color: #4758AB;">generateDynamicNFT</span>(tokenId)<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb1-4">  }</span></code></pre></div>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span id="cb2-1">  <span class="kw" style="color: #003B4F;">function</span> <span class="fu" style="color: #4758AB;">uri</span>(uint256 tokenId) <span class="kw" style="color: #003B4F;">public</span> view <span class="fu" style="color: #4758AB;">override</span>(ERC1155) <span class="fu" style="color: #4758AB;">returns</span> (string memory) {</span>
<span id="cb2-2">    <span class="pp" style="color: #AD0000;">require</span>(<span class="fu" style="color: #4758AB;">_exists</span>(tokenId))<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb2-3">    <span class="cf" style="color: #003B4F;">return</span> <span class="fu" style="color: #4758AB;">generateDynamicNFT</span>(tokenId)<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb2-4">  }</span></code></pre></div>
<p>Inside <code>generateDynamicNFT</code>, the user defines how and under what conditions NFT to generate, usually using oracles.</p>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>This research has shown that it is possible to change the data and properties of NFTs, and the next evaluation in NFT is moving from static NFTs to dynamic NFTs. With dynamic NTFs, some use cases could be:</p>
<ul>
<li>An NFT ticket that could retain a value after the event is finished can turn as a discount for a related event or, as some bonus, gifts.</li>
<li>Sports NFT cards can evolve, such as updating their player’s stats or having a limited edition of sports event cards if the player got a super score in a match.</li>
<li>Sport NFT cards that receive bonuses or losses based on wins/losses.</li>
<li>Artist NFT cards that change on a daily/monthly based.</li>
<li>NFTs affected by social media/real-life events.</li>
<li>NFTs that affect the real world, where a user can receive a physical item in exchange for NFT.</li>
<li>Kata NFTs were on the users’ progress the Kata NFT will change.</li>
<li>Geometric shape that change as price change</li>
</ul>
<p>The only related problem is about on-chain storage assets. Most NFTs do not store their assets directly on the blockchain because the cost of keeping them on-chain is expensive, as every action and every byte of information we hold on the blockchain has a fee. In addition, the Ethereum blockchain is designed to keep a record of transactions and not to serve as a data warehouse. Second, on-chain geometrical arts can quickly present, but for the more complex SVG files, it is possible to use <em>the bottom-top</em> approach. The idea is to have one zero-based image as a base and then add traits dynamically to the base image. Where will store only characteristics on-chain, and the NFT image is created dynamically. On-chain storage reduces external dependence, increasing reliability, durability, ownership, and decentralization. Keeping assets on-chain has excellent value. Users can rely on the same guarantees of immutability they use to secure property ownership, and the value of such art is more significant. When the asset is being followed on the Ethereum, we also want that asset to be placed on the Ethereum somehow.</p>
</section>
<section id="bibliography" class="level1">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Bibliography</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-browneTradingNFTsSpiked2022" class="csl-entry">
Browne, Ryan, ‘Trading in NFTs Spiked 21,000% to More Than $17 Billion in 2021, Report Says’, <em>CNBC</em>, 2022 &lt;<a href="https://www.cnbc.com/2022/03/10/trading-in-nfts-spiked-21000percent-to-top-17-billion-in-2021-report.html" class="uri">https://www.cnbc.com/2022/03/10/trading-in-nfts-spiked-21000percent-to-top-17-billion-in-2021-report.html</a>&gt; [accessed 24 March 2022]
</div>
<div id="ref-LoopringZkRollupLayer2" class="csl-entry">
‘Loopring - <span class="nocase">zkRollup Layer2</span> for Trading and Payment’, <em>Loopring</em> &lt;<a href="https://loopring.org/#/" class="uri">https://loopring.org/#/</a>&gt; [accessed 24 March 2022]
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>‘Trading in NFTs Spiked 21,000% to More Than $17 Billion in 2021, Report Says’, <em>CNBC</em>, 2022 &lt;&lt;https://www.cnbc.com/2022/03/10/trading-in-nfts-spiked-21000percent-to-top-17-billion-in-2021-report.html&gt;&gt; [accessed 24 March 2022].↩︎</p></li>
<li id="fn2"><p><em>Loopring</em> &lt;&lt;https://loopring.org/#/&gt;&gt; [accessed 24 March 2022].↩︎</p></li>
</ol>
</section></div> ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-101.hugo.html</guid>
  <pubDate>Mon, 14 Mar 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Detect NFT Wash Trading</title>
  <dc:creator>Milos Bojinovic</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-90.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p>With the monthly trading volume of the <strong>Non-Fungible Token (NFT)</strong> marketplace <a href="https://opensea.io">OpenSea</a> reaching 5 billion dollars in January 2022<sup>1</sup> it is clear that NFTs are gaining popularity and with that grows the importance of having a transparent trading activity.</p>
<p><strong>Wash trading</strong> is a form of market manipulation where a single entity or a group of colluding entities buy and sell the same asset with the goal of feeding the marketplace misleading information<sup>2</sup>. There are at least two possible benefits to wash trading, the first being that a single asset can be wash traded multiple times, continually increasing the price, thus making the asset appear more sought after than it actually is. This chain of wash trades is broken when an unsuspecting victim buys the asset. The second potential benefit is that the trading can be incentivized by the platform, with rewards being tied to the volume traded. Trading rewards can, at least for a limited time period, be higher than the fees, which makes this process worthwhile.</p>
<p>In the case of NFTs, wash trading is additionally enabled by the associated user anonymity. One single entity can control a large number of addresses without a way of reliably determining who is behind them. Those addresses, however, need to be somehow funded to make them usable, which leads to a money trail that can be followed to detect connections between them and to flag suspicious NFT trades.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Currently, only <a href="https://nansen.ai">Nansen</a>, a blockchain analytics platform that requires a paid subscription, offers a feature called “Wash Trading Filter” where users can see the metrics (volume, average price, etc.) for an NFT collection with and without the filter but cannot browse through the individual NFTs. Another drawback is that Nansen doesn’t disclose how the filter works, and so the question of why some trades were flagged remains.</p>
<p>Data on the blockchain is public, but it is hard to extract specific pieces of information from it. Detecting if a particular NFT was wash traded would require collecting every single trade that was made on all of the marketplaces and checking if the addresses involved in it are connected in some way. This data would need to be safely stored and effectively parsed to enable answering if any arbitrarily chosen NFT has been wash traded. The detection algorithm should also provide adequate reasoning on why a specific trade has been flagged. Developing and publicly disclosing the inner workings of such an algorithm would add more transparency to NFT trading, but it would inevitably lead to the creation of more intricate patterns that would not get caught if the algorithm is not regularly updated.</p>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p><strong>The goals</strong> of this research are to :</p>
<ul>
<li>define what transaction patterns classify as a wash trade</li>
<li>develop ways of extracting the necessary information needed for the detection:
<ul>
<li>trades on two of the largest NFT marketplaces (OpenSea and <a href="https://looksrare.org/">LooksRare</a>)</li>
<li>Ether transfers for each of the accounts involved in the trade</li>
</ul></li>
<li>serve as a starting point for the creation of detection algorithms</li>
</ul>
<p><strong>Methodology</strong> for accomplishing those goals consists of</p>
<ul>
<li>taking into account only Ethereum’s on-chain transactions when discussing ways a wash trade can be made</li>
<li>using <a href="https://docs.etherscan.io/">Etherscan</a> and <a href="https://docs.alchemy.com/alchemy/">Alchemy</a> APIs to enable the data collection process</li>
<li>using Python programming language for the implementation part</li>
</ul>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<section id="wash-trading-patterns" class="level3">
<h3 class="anchored" data-anchor-id="wash-trading-patterns">Wash Trading Patterns</h3>
<p>The explanation for the diagrams used in this paper is the following:</p>
<ul>
<li>White circles with a letter inside them are addresses that are considered</li>
<li>Address can be connected with multiple lines</li>
<li>The line that has the <strong>NFT</strong> written on it signals that those two addresses were involved in an NFT trade</li>
<li>The line containing a number <strong>n</strong> on it signals that exists an Ether transfer trail between those addresses through <strong>n</strong> intermediaries
<ul>
<li>if <strong>n</strong> = 0 that is a direct transfer</li>
<li>if <strong>n</strong> = 1 there is a transfer trail involving one intermediary address</li>
</ul></li>
<li>Lines with an arrow care about the direction of a transfer and point to the new owner’s address</li>
<li>Lines without an arrow do not care about the direction</li>
</ul>
<p>Shown on <em>Figure 1</em> there are two “meta-patterns” that this paper considers.</p>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://3327.io/documents/research/assets/ERFC-90/images/meta-patterns.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">meta-patterns</figcaption><p></p>
</figure>
</div>
<p><em>Figure 1 - Considered Meta-patterns</em></p>
</center>
<p>Meta-patterns can be expanded into specific patterns that care about the direction of those transfers (<em>Figure 2</em>). While some patterns may be more suspicious than others, all of them can be used for the purpose of wash trading. For example <em>pattern 2.2</em> can mean that after making a wash trade and selling the NFT to someone else, addresses <strong>A</strong> and <strong>B</strong> send all of their funds to address <strong>C</strong>.</p>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://3327.io/documents/research/assets/ERFC-90/images/expanded-patterns.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">expanded-patterns</figcaption><p></p>
</figure>
</div>
<p><em>Figure 2 - Expanded patterns</em></p>
</center>
<p>The reason that all of these patterns do not take the time order of transfers into account is that it doesn’t matter - they need to detect only the connections between addresses.</p>
</section>
<section id="collecting-and-parsing-of-data" class="level2">
<h2 class="anchored" data-anchor-id="collecting-and-parsing-of-data">Collecting and Parsing of Data</h2>
<p>This research takes into account only trades of NFTs that follow the ERC721 standard. The same principles can be applied to the trades involving the ERC1155 standard, with the only difference being the collection and parsing of trades.</p>
<p>When an NFT trade is executed, the ERC721 compliant contracts emit a <strong>Transfer event</strong> that contains three fields: previous owner, new owner, and the token id. Using the combination of Etherscan and Alchemy APIs, it is possible to get all the events that were emitted by the transaction and to extract the needed event based on its topic along with all of its fields.</p>
<p>Not every Transfer event corresponds to a trade, so there needs to be an extra processing step that will eliminate all transfers that were not made through a marketplace. To do this, one needs to go through all of the marketplace’s contract’s transactions and select only those that have the right <strong>methodID</strong>.</p>
<p>After the seller’s (previous owner’s) and buyer’s (new owner’s) addresses are known, the last step is collecting and parsing of all of their transactions searching for Ether transfers and all the addresses they have interacted with - in this paper referred to as “associates”.</p>
</section>
<section id="wash-trading-detectors" class="level2">
<h2 class="anchored" data-anchor-id="wash-trading-detectors">Wash Trading Detectors</h2>
<p>Having a set of all of the buyer’s and seller’s associates enables the creation of <strong>Wash Trading Detectors (WTD)</strong>. This paper proposes and implements two basic algorithms:</p>
<ul>
<li><strong>WTD0</strong> that detects a direct transfer by checking if the seller’s address belongs to the set of buyer’s associates</li>
<li><strong>WTD1*</strong> that detects a set of common associates that are Externally Owned Accounts (EOAs)</li>
</ul>
<p>*WTD1 is incomplete because the detected common associate can be a Centralized Exchange’s (CEX) address which would give a false positive. The only way to make the WTD1 fully functional is to manually keep a list of all the addresses that should be ignored.</p>
</section>
<section id="implementation" class="level2">
<h2 class="anchored" data-anchor-id="implementation">Implementation</h2>
<p>Using the proposed ways of getting the data and reasoning on it, it is possible to extract suspicious wash trading patterns, flag those trades, and perform an analysis of the results. The code shown bellow is capable of getting the count of detected wash trades performed through a marketplace in a given block range :</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> utils</span>
<span id="cb1-2"></span>
<span id="cb1-3"><span class="kw" style="color: #003B4F;">def</span> run(contract, methodIds, start_block, end_block):</span>
<span id="cb1-4">    <span class="co" style="color: #5E5E5E;">'''Detects potential Wash trades for a marketplace's contract'''</span></span>
<span id="cb1-5"></span>
<span id="cb1-6">    transactions <span class="op" style="color: #5E5E5E;">=</span> utils.get_all_transactions(</span>
<span id="cb1-7">        contract,</span>
<span id="cb1-8">        start_block,</span>
<span id="cb1-9">        end_block</span>
<span id="cb1-10">    )</span>
<span id="cb1-11"></span>
<span id="cb1-12">    wtd0_count, wtd1_count, total <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb1-13"></span>
<span id="cb1-14">    <span class="cf" style="color: #003B4F;">for</span>  tx <span class="kw" style="color: #003B4F;">in</span> transactions:</span>
<span id="cb1-15"></span>
<span id="cb1-16">        <span class="cf" style="color: #003B4F;">if</span> tx[<span class="st" style="color: #20794D;">'input'</span>][:<span class="dv" style="color: #AD0000;">10</span>] <span class="kw" style="color: #003B4F;">in</span> methodIds:</span>
<span id="cb1-17"></span>
<span id="cb1-18">            status, logs <span class="op" style="color: #5E5E5E;">=</span> utils.get_logs(tx[<span class="st" style="color: #20794D;">'hash'</span>])</span>
<span id="cb1-19"></span>
<span id="cb1-20">            <span class="cf" style="color: #003B4F;">if</span> status <span class="op" style="color: #5E5E5E;">!=</span> <span class="dv" style="color: #AD0000;">1</span>: <span class="co" style="color: #5E5E5E;"># Reverted transaction</span></span>
<span id="cb1-21">                <span class="cf" style="color: #003B4F;">continue</span></span>
<span id="cb1-22"></span>
<span id="cb1-23">            nft_contract, token_id, A, B <span class="op" style="color: #5E5E5E;">=</span> utils.parse_logs(logs)</span>
<span id="cb1-24"></span>
<span id="cb1-25">            <span class="cf" style="color: #003B4F;">if</span> A <span class="op" style="color: #5E5E5E;">==</span> <span class="va" style="color: #111111;">None</span> <span class="kw" style="color: #003B4F;">or</span> B <span class="op" style="color: #5E5E5E;">==</span> <span class="va" style="color: #111111;">None</span>: <span class="co" style="color: #5E5E5E;"># not a standard ERC721</span></span>
<span id="cb1-26">                <span class="cf" style="color: #003B4F;">continue</span></span>
<span id="cb1-27"></span>
<span id="cb1-28">            associates_A <span class="op" style="color: #5E5E5E;">=</span> utils.get_associates(A)</span>
<span id="cb1-29">            associates_B <span class="op" style="color: #5E5E5E;">=</span> utils.get_associates(B)</span>
<span id="cb1-30"></span>
<span id="cb1-31">            wtd0_count <span class="op" style="color: #5E5E5E;">+=</span> <span class="bu" style="color: null;">int</span>(</span>
<span id="cb1-32">                utils.wtd0(A, B, associates_A, associates_B)</span>
<span id="cb1-33">            )</span>
<span id="cb1-34">            wtd1_count <span class="op" style="color: #5E5E5E;">+=</span> <span class="bu" style="color: null;">int</span>(</span>
<span id="cb1-35">                <span class="bu" style="color: null;">len</span>(utils.wtd1(A, B, associates_A, associates_B)) <span class="op" style="color: #5E5E5E;">&gt;</span> <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb1-36">            )</span>
<span id="cb1-37"></span>
<span id="cb1-38">            total <span class="op" style="color: #5E5E5E;">+=</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb1-39"></span>
<span id="cb1-40">    <span class="cf" style="color: #003B4F;">return</span> (wtd0_count, wtd1_count, total)</span></code></pre></div>
<p>The <code>run</code> function consists of getting all transaction data for a marketplace’s contract starting from the <code>start_block</code> up to the <code>end_block</code> and considering only those that are in the provided list of <code>methodIds</code>. These transactions are then parsed, and values are extracted that will be passed to the <code>utils.wtd0</code> and <code>utils.wtd1</code> functions which will perform detection.</p>
<p>For the full implementation of all of the used helper methods from <code>utils</code> module see Appendix A.</p>
<section id="example" class="level3">
<h3 class="anchored" data-anchor-id="example">Example</h3>
<p>For example, let us take the <a href="https://etherscan.io/address/0x7Be8076f4EA4A4AD08075C2508e481d6C946D12b">OpenSea’s Wyvern V1 contract</a> and pass three different block ranges. The <code>['0xab834bab']</code> argument corresponds to the <code>methodID</code> of the contract’s method that gets called when there is a trade.</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1">WYVERN_V1 <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'0x7Be8076f4EA4A4AD08075C2508e481d6C946D12b'</span></span>
<span id="cb2-2"></span>
<span id="cb2-3">ranges <span class="op" style="color: #5E5E5E;">=</span> [</span>
<span id="cb2-4">    [<span class="dv" style="color: #AD0000;">6652089</span>, <span class="dv" style="color: #AD0000;">6652239</span>],</span>
<span id="cb2-5">    [<span class="dv" style="color: #AD0000;">7486211</span>, <span class="dv" style="color: #AD0000;">7486311</span>],</span>
<span id="cb2-6">    [<span class="dv" style="color: #AD0000;">7704798</span>, <span class="dv" style="color: #AD0000;">7704898</span>],</span>
<span id="cb2-7">]</span>
<span id="cb2-8"></span>
<span id="cb2-9"><span class="cf" style="color: #003B4F;">for</span> start_block, end_block <span class="kw" style="color: #003B4F;">in</span> ranges:</span>
<span id="cb2-10"></span>
<span id="cb2-11">    <span class="bu" style="color: null;">print</span>(run(WYVERN_V1, [<span class="st" style="color: #20794D;">'0xab834bab'</span>], start_block, end_block))</span></code></pre></div>
<p>From the total of <strong>23</strong> trades that were made during the provided ranges :</p>
<ul>
<li>WTD0 flags <strong>8</strong> trades</li>
<li>WTD1 flags <strong>11**</strong> trades</li>
</ul>
<p>**WTD1 returns a list of associate addresses; these lists were manually checked through Etherscan to see if they belong to a CEX. The list of ignored addresses is available in Appendix B.</p>
</section>
<section id="implications" class="level3">
<h3 class="anchored" data-anchor-id="implications">Implications</h3>
<p>The sample size of <strong>23</strong> is too small to discuss how the reported numbers relate to all of the NFT trades since the marketplace’s contract deployment. The code itself can, however, serve as a starting point for the development of a service capable of extracting the data from all of the NFT marketplaces since their creation. In that data lies the key to answering not only what trades are a wash trade but also who performed them, how many times was an address linked to a wash trade, whether one NFT has been wash traded multiple times, etc. Such a service would need to effectively manage its resources such as the collection of data and the computation needed in the detection - in the example above, set of associates is always computed from scratch (there is no storing of the result and checking if those values have already been computed). The full specification for the development of this service is out of the scope of this paper and should be a topic of a separate research.</p>
<section id="complex-patterns" class="level4">
<h4 class="anchored" data-anchor-id="complex-patterns">Complex Patterns</h4>
<p>Due to current non-negligible transaction fees on Ethereum and the fact that not many people are deeply looking into each trade, it is unlikely that there are complex patterns present in NFT wash trading. As the fees get lower and as the adoption grows, it’s almost certain that they will emerge. On the <em>Figure 3</em> is shown one pattern that could be used in the process of wash trading.</p>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://3327.io/documents/research/assets/ERFC-90/images/complex-pattern.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">complex-pattern</figcaption><p></p>
</figure>
</div>
<p><em>Figure 3 - Complex pattern</em></p>
</center>
<p>There are two NFT wash trades present (marked by the black and blue colored arrows). The sequence of transfers is the following:</p>
<ol type="1">
<li><strong>A</strong> finances <strong>B</strong> and <strong>C</strong> through 3 and 2 intermediaries, respectively</li>
<li><strong>B</strong> finances <strong>D</strong> through 3 intermediaries</li>
<li><strong>D</strong> buys an NFT from some non-associated address</li>
<li><strong>D</strong> sells the NFT to <strong>C</strong></li>
<li><strong>D</strong> sends the funds to <strong>B</strong> through the same 3 intermediaries that were used before</li>
<li><strong>B</strong> finances <strong>E</strong> through 2 intermediaries</li>
<li><strong>E</strong> buys the NFT from <strong>C</strong></li>
</ol>
<p>After the last step, <strong>E</strong> can sell the NFT to an unsuspecting victim. It is important to note that addresses used do not have to be discarded after each wash trade - i.e.&nbsp;<strong>B</strong> can be used just for routing of the funds. Furthermore, a malevolent entity can inflate the prices of not just a single NFT but for a complete collection, making it look like the collection is very popular, which attracts victims.</p>
</section>
</section>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>This research shows that it is possible to flag a specific trade as being a wash trade. The proposed algorithms can serve as a starting point in this process. To flag a specific NFT as being wash traded there would need to exist a list of all the trades of that NFT. This could be done via a service that would enable the users to browse the history of trades of any NFT on every marketplace and see all of the connections between the addresses that once owned it. If the service is built and popularized while keeping its inner workings public, the malevolent parties would try to evade detection which would lead to the need to constantly improve the algorithm.</p>
</section>
<section id="appendices" class="level1">
<h1>Appendices</h1>
<section id="appendix-a" class="level2">
<h2 class="anchored" data-anchor-id="appendix-a">Appendix A</h2>
<p>Implementation of the <code>utils</code> module.</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;">import</span> time, json, requests</span>
<span id="cb3-2"><span class="im" style="color: #00769E;">from</span> web3 <span class="im" style="color: #00769E;">import</span> Web3</span>
<span id="cb3-3"></span>
<span id="cb3-4">config <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb3-5">    <span class="st" style="color: #20794D;">"alchemy-url"</span> : <span class="st" style="color: #20794D;">""</span>,</span>
<span id="cb3-6">    <span class="st" style="color: #20794D;">"etherscan-api-key"</span>: <span class="st" style="color: #20794D;">""</span>,</span>
<span id="cb3-7">}</span>
<span id="cb3-8"></span>
<span id="cb3-9">web3 <span class="op" style="color: #5E5E5E;">=</span> Web3(Web3.HTTPProvider(config[<span class="st" style="color: #20794D;">'alchemy-url'</span>]))</span>
<span id="cb3-10"></span>
<span id="cb3-11"><span class="kw" style="color: #003B4F;">def</span> get_all_transactions(address, start_block <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span>, end_block <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">19999999</span>):</span>
<span id="cb3-12">    <span class="co" style="color: #5E5E5E;">'''Gets all transactions using Etherscan API for the provided address'''</span></span>
<span id="cb3-13">    transactions <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb3-14"></span>
<span id="cb3-15">    <span class="cf" style="color: #003B4F;">while</span> <span class="va" style="color: #111111;">True</span>:</span>
<span id="cb3-16">        time.sleep(<span class="dv" style="color: #AD0000;">5</span>)</span>
<span id="cb3-17">        result <span class="op" style="color: #5E5E5E;">=</span> requests.get(</span>
<span id="cb3-18">            <span class="st" style="color: #20794D;">'https://api.etherscan.io/api?module=account&amp;action=txlist'</span> <span class="op" style="color: #5E5E5E;">+</span></span>
<span id="cb3-19">            <span class="ss" style="color: #20794D;">f'&amp;address=</span><span class="sc" style="color: #5E5E5E;">{</span>address<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span> <span class="op" style="color: #5E5E5E;">+</span></span>
<span id="cb3-20">            <span class="ss" style="color: #20794D;">f'&amp;startblock=</span><span class="sc" style="color: #5E5E5E;">{</span>start_block<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span> <span class="op" style="color: #5E5E5E;">+</span></span>
<span id="cb3-21">            <span class="ss" style="color: #20794D;">f'&amp;endblock=</span><span class="sc" style="color: #5E5E5E;">{</span>end_block<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span> <span class="op" style="color: #5E5E5E;">+</span></span>
<span id="cb3-22">            <span class="ss" style="color: #20794D;">f'&amp;offset=</span><span class="sc" style="color: #5E5E5E;">{</span><span class="dv" style="color: #AD0000;">1_000</span><span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span> <span class="op" style="color: #5E5E5E;">+</span></span>
<span id="cb3-23">            <span class="ss" style="color: #20794D;">f'&amp;sort=</span><span class="sc" style="color: #5E5E5E;">{</span><span class="st" style="color: #20794D;">"asc"</span><span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span> <span class="op" style="color: #5E5E5E;">+</span></span>
<span id="cb3-24">            <span class="ss" style="color: #20794D;">f'apikey=</span><span class="sc" style="color: #5E5E5E;">{</span>config[<span class="st" style="color: #20794D;">"etherscan-api-key"</span>]<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span></span>
<span id="cb3-25">        ).json()[<span class="st" style="color: #20794D;">'result'</span>]</span>
<span id="cb3-26"></span>
<span id="cb3-27">        transactions <span class="op" style="color: #5E5E5E;">+=</span> result</span>
<span id="cb3-28"></span>
<span id="cb3-29">        <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">len</span>(result) <span class="op" style="color: #5E5E5E;">&lt;</span> <span class="dv" style="color: #AD0000;">1_000</span>:</span>
<span id="cb3-30">            <span class="cf" style="color: #003B4F;">break</span></span>
<span id="cb3-31"></span>
<span id="cb3-32">        start_block <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">int</span>(result[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>][<span class="st" style="color: #20794D;">"blockNumber"</span>]) <span class="op" style="color: #5E5E5E;">+</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb3-33"></span>
<span id="cb3-34"></span>
<span id="cb3-35">    <span class="cf" style="color: #003B4F;">return</span> transactions</span>
<span id="cb3-36"></span>
<span id="cb3-37"><span class="kw" style="color: #003B4F;">def</span> is_EOA(address):</span>
<span id="cb3-38">    <span class="co" style="color: #5E5E5E;">'''Returns true if the address belongs to an Externally Owned Account'''</span></span>
<span id="cb3-39"></span>
<span id="cb3-40">    <span class="cf" style="color: #003B4F;">try</span>:</span>
<span id="cb3-41">        _address <span class="op" style="color: #5E5E5E;">=</span> Web3.toChecksumAddress(address)</span>
<span id="cb3-42">        <span class="cf" style="color: #003B4F;">return</span> web3.eth.getCode(_address) <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">b""</span></span>
<span id="cb3-43">    <span class="cf" style="color: #003B4F;">except</span>:</span>
<span id="cb3-44">        <span class="cf" style="color: #003B4F;">return</span> <span class="va" style="color: #111111;">False</span></span>
<span id="cb3-45"></span>
<span id="cb3-46"><span class="kw" style="color: #003B4F;">def</span> get_associates(address):</span>
<span id="cb3-47">    <span class="co" style="color: #5E5E5E;">'''Returns a set of all account with which the provided addresses interacted with'''</span></span>
<span id="cb3-48"></span>
<span id="cb3-49">    transactions <span class="op" style="color: #5E5E5E;">=</span> get_all_transactions(address)</span>
<span id="cb3-50"></span>
<span id="cb3-51">    associates <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">set</span>()</span>
<span id="cb3-52">    <span class="cf" style="color: #003B4F;">for</span> tx <span class="kw" style="color: #003B4F;">in</span> transactions:</span>
<span id="cb3-53">        <span class="cf" style="color: #003B4F;">if</span> tx[<span class="st" style="color: #20794D;">'from'</span>] <span class="op" style="color: #5E5E5E;">!=</span> address:</span>
<span id="cb3-54">            associates.update([tx[<span class="st" style="color: #20794D;">'from'</span>]])</span>
<span id="cb3-55">        <span class="cf" style="color: #003B4F;">if</span> tx[<span class="st" style="color: #20794D;">'to'</span>] <span class="op" style="color: #5E5E5E;">!=</span> address:</span>
<span id="cb3-56">            associates.update([tx[<span class="st" style="color: #20794D;">'to'</span>]])</span>
<span id="cb3-57"></span>
<span id="cb3-58">    <span class="cf" style="color: #003B4F;">return</span> associates</span>
<span id="cb3-59"></span>
<span id="cb3-60"><span class="kw" style="color: #003B4F;">def</span> get_logs(tx_hash):</span>
<span id="cb3-61">    <span class="co" style="color: #5E5E5E;">'''Gets the logs from the transaction receipt of the tx_hash'''</span></span>
<span id="cb3-62"></span>
<span id="cb3-63">    tx_receipt <span class="op" style="color: #5E5E5E;">=</span> web3.eth.get_transaction_receipt(tx_hash)</span>
<span id="cb3-64"></span>
<span id="cb3-65">    <span class="cf" style="color: #003B4F;">return</span> tx_receipt[<span class="st" style="color: #20794D;">'status'</span>], tx_receipt[<span class="st" style="color: #20794D;">'logs'</span>]</span>
<span id="cb3-66"></span>
<span id="cb3-67"><span class="kw" style="color: #003B4F;">def</span> parse_logs(logs):</span>
<span id="cb3-68">    <span class="co" style="color: #5E5E5E;">'''Returns the NFT contract's address, token id and addresses involved in the trade'''</span></span>
<span id="cb3-69"></span>
<span id="cb3-70">    TRANSFER_TOPIC <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef"</span></span>
<span id="cb3-71">    WRAPPED_ETH <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"0xC02aaA39b223FE8D0A0e5C4F27eAD9083C756Cc2"</span></span>
<span id="cb3-72"></span>
<span id="cb3-73">    nft_contracts, token_ids, _from, _to <span class="op" style="color: #5E5E5E;">=</span> [], [], <span class="va" style="color: #111111;">None</span>, <span class="va" style="color: #111111;">None</span></span>
<span id="cb3-74"></span>
<span id="cb3-75">    <span class="cf" style="color: #003B4F;">for</span> ev <span class="kw" style="color: #003B4F;">in</span> logs:</span>
<span id="cb3-76"></span>
<span id="cb3-77">        <span class="cf" style="color: #003B4F;">if</span> TRANSFER_TOPIC <span class="op" style="color: #5E5E5E;">==</span> ev[<span class="st" style="color: #20794D;">"topics"</span>][<span class="dv" style="color: #AD0000;">0</span>].<span class="bu" style="color: null;">hex</span>() <span class="kw" style="color: #003B4F;">and</span> ev[<span class="st" style="color: #20794D;">"address"</span>] <span class="op" style="color: #5E5E5E;">!=</span> WRAPPED_ETH:</span>
<span id="cb3-78"></span>
<span id="cb3-79">            nft_contracts.append(ev[<span class="st" style="color: #20794D;">"address"</span>])</span>
<span id="cb3-80"></span>
<span id="cb3-81">            bytecode <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">""</span>.join([x.<span class="bu" style="color: null;">hex</span>() <span class="cf" style="color: #003B4F;">for</span> x <span class="kw" style="color: #003B4F;">in</span> ev[<span class="st" style="color: #20794D;">"topics"</span>]]) <span class="op" style="color: #5E5E5E;">+</span> <span class="st" style="color: #20794D;">""</span>.join(ev[<span class="st" style="color: #20794D;">"data"</span>])</span>
<span id="cb3-82">            _from <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"0x"</span> <span class="op" style="color: #5E5E5E;">+</span> bytecode[<span class="dv" style="color: #AD0000;">66</span> : <span class="dv" style="color: #AD0000;">66</span> <span class="op" style="color: #5E5E5E;">*</span> <span class="dv" style="color: #AD0000;">2</span>][<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">40</span>:]</span>
<span id="cb3-83">            _to <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"0x"</span> <span class="op" style="color: #5E5E5E;">+</span> bytecode[<span class="dv" style="color: #AD0000;">66</span> <span class="op" style="color: #5E5E5E;">*</span> <span class="dv" style="color: #AD0000;">2</span> : <span class="dv" style="color: #AD0000;">66</span> <span class="op" style="color: #5E5E5E;">*</span> <span class="dv" style="color: #AD0000;">3</span>][<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">40</span>:]</span>
<span id="cb3-84">            token_ids.append(<span class="bu" style="color: null;">int</span>(bytecode[<span class="dv" style="color: #AD0000;">66</span> <span class="op" style="color: #5E5E5E;">*</span> <span class="dv" style="color: #AD0000;">3</span> : <span class="dv" style="color: #AD0000;">66</span> <span class="op" style="color: #5E5E5E;">*</span> <span class="dv" style="color: #AD0000;">4</span>][<span class="dv" style="color: #AD0000;">2</span>:<span class="dv" style="color: #AD0000;">66</span>], base<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">16</span>))</span>
<span id="cb3-85"></span>
<span id="cb3-86">    <span class="cf" style="color: #003B4F;">return</span> nft_contracts, token_ids, _from, _to</span>
<span id="cb3-87"></span>
<span id="cb3-88"></span>
<span id="cb3-89"><span class="kw" style="color: #003B4F;">def</span> wtd0(A, B, associates_A, associates_B):</span>
<span id="cb3-90">    <span class="co" style="color: #5E5E5E;">'''WTD0 implementation'''</span></span>
<span id="cb3-91"></span>
<span id="cb3-92">    <span class="cf" style="color: #003B4F;">return</span> (A <span class="kw" style="color: #003B4F;">in</span> associates_B) <span class="kw" style="color: #003B4F;">or</span> (B <span class="kw" style="color: #003B4F;">in</span> associates_A)</span>
<span id="cb3-93"></span>
<span id="cb3-94"><span class="kw" style="color: #003B4F;">def</span> wtd1(A, B, associates_A, associates_B):</span>
<span id="cb3-95">    <span class="co" style="color: #5E5E5E;">'''WTD1 implementation'''</span></span>
<span id="cb3-96"></span>
<span id="cb3-97">    EOA_associates <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb3-98"></span>
<span id="cb3-99">    common_associates <span class="op" style="color: #5E5E5E;">=</span> associates_A.intersection(associates_B)</span>
<span id="cb3-100">    <span class="cf" style="color: #003B4F;">for</span> ca <span class="kw" style="color: #003B4F;">in</span> common_associates:</span>
<span id="cb3-101">        <span class="cf" style="color: #003B4F;">if</span> is_EOA(ca):</span>
<span id="cb3-102">            EOA_associates.append(ca)</span>
<span id="cb3-103"></span>
<span id="cb3-104">    <span class="cf" style="color: #003B4F;">return</span> EOA_associates</span></code></pre></div>
</section>
<section id="appendix-b" class="level2">
<h2 class="anchored" data-anchor-id="appendix-b">Appendix B</h2>
<p>Following is the list of all the addresses that were ignored by WTD1 due to the fact that they belong to CEXs</p>
<center>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Address</th>
<th style="text-align: center;">CEX</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">0x564286362092d8e7936f0549571a803b203aaced</td>
<td style="text-align: center;">Binance3</td>
</tr>
<tr class="even">
<td style="text-align: center;">0x59a5208b32e627891c389ebafc644145224006e8</td>
<td style="text-align: center;">HitBTC2</td>
</tr>
<tr class="odd">
<td style="text-align: center;">0x56eddb7aa87536c09ccc2793473599fd21a8b17f</td>
<td style="text-align: center;">Binance17</td>
</tr>
<tr class="even">
<td style="text-align: center;">0xeb2629a2734e272bcc07bda959863f316f4bd4cf</td>
<td style="text-align: center;">Coinbase6</td>
</tr>
<tr class="odd">
<td style="text-align: center;">0xd551234ae421e3bcba99a0da6d736074f22192ff</td>
<td style="text-align: center;">Binance2</td>
</tr>
<tr class="even">
<td style="text-align: center;">0xb5d85cbf7cb3ee0d56b3bb207d5fc4b82f43f511</td>
<td style="text-align: center;">Coinbase5</td>
</tr>
<tr class="odd">
<td style="text-align: center;">0x0681d8db095565fe8a346fa0277bffde9c0edbbf</td>
<td style="text-align: center;">Binance4</td>
</tr>
<tr class="even">
<td style="text-align: center;">0x3f5ce5fbfe3e9af3971dd833d26ba9b5c936f0be</td>
<td style="text-align: center;">Binance</td>
</tr>
</tbody>
</table>
</center>
</section>
</section>
<section id="bibliography" class="level1">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Bibliography</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-haywardOpenSeaHitsRecord2022" class="csl-entry">
Hayward, Decrypt / Andrew, ‘OpenSea Hits Record $5b in Monthly Sales as Ethereum NFT Market Swells’, <em>Decrypt</em>, 2022 &lt;<a href="https://decrypt.co/91748/opensea-record-5b-ethereum-nft-market-swells" class="uri">https://decrypt.co/91748/opensea-record-5b-ethereum-nft-market-swells</a>&gt; [accessed 13 March 2022]
</div>
<div id="ref-WashTradingDefinition" class="csl-entry">
‘Wash Trading Definition’, <em>Investopedia</em> &lt;<a href="https://www.investopedia.com/terms/w/washtrading.asp" class="uri">https://www.investopedia.com/terms/w/washtrading.asp</a>&gt; [accessed 21 March 2022]
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Decrypt / Andrew Hayward, ‘OpenSea Hits Record $5b in Monthly Sales as Ethereum NFT Market Swells’, <em>Decrypt</em>, 2022 &lt;&lt;https://decrypt.co/91748/opensea-record-5b-ethereum-nft-market-swells&gt;&gt; [accessed 13 March 2022].↩︎</p></li>
<li id="fn2"><p>‘Wash Trading Definition’, <em>Investopedia</em> &lt;&lt;https://www.investopedia.com/terms/w/washtrading.asp&gt;&gt; [accessed 21 March 2022].↩︎</p></li>
</ol>
</section></div> ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-90.hugo.html</guid>
  <pubDate>Sat, 12 Mar 2022 00:00:00 GMT</pubDate>
  <media:content url="https://3327.io/documents/research/assets/ERFC-90/images/meta-patterns.png" medium="image" type="image/png" height="35" width="144"/>
</item>
<item>
  <title>Explorative Research on Crypto Insurance - Current state, problems and possibilities of creating new products</title>
  <dc:creator>Aleksandar Damjanovic</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-91.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p>In this paper we covered 5 of the main players in DeFi insurance market in order to determine the products offered, the problems with these products, the way the claims are handled and the possibilty of creating new insurance protocols. Initially we were not familiar with this field and the effort needed for creating these products, so we conducted this explorative research.</p>
<p>After the research we came to these conclusions:</p>
<ol type="1">
<li>In creating these kind of products there needs to be significant effort both in developing and inital investment. Protocols covered utilize Advisory Boards of insurance experts in order to create their products.</li>
<li>State regulation is a big factor in insurance in order to protect the policyholders from malicious insurance offerers. This can be a problem, depending on the states’ attitude towards cryptocurrency.</li>
<li>Handling claims is often left to the community incentivizing just behavior by staking.</li>
<li>Collecting adequate capital initially is also one of the major problems.</li>
<li>Protocols with less staked pools have higher premiums in most cases which shows us that the risk assessment is usually hard to do with new protocols.</li>
<li>There is a limited cover capacity.</li>
<li>Usually there is no cross-chain coverage which limits the protection capability of DeFi protocols on other chains.</li>
<li>Lack of protection diversity: most products offered are limited when compared to the broad coverage of risk types in the traditional insurance market.</li>
<li>Insuring real world Events is almost non-existent. Etherisc offers 2 products using Oracles but our assumption is that there is still no market need for this kind of products thus there is not much movement in this direction. However utilizing Oracles in traditional products is an interesting thing and we think should be looked more into.</li>
</ol>
<p>However, if You would like to go deeper to understand how these protocols work we recommend reading the entire paper.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>In this paper we will be exploring the current state and problems of the decentralized/crypto insurance field with an emphasis to exploring the types of insurance offered, how are claims assessed, processed and finally paid out to the insured in a decentralized way.</p>
<p>Before we go further in the paper we will be shortly covering some insurance basics with a goal of reader’s better understanding of this paper and insurance’s importance in Decentralized Finance (DeFi). Considering Insurance is one of the oldest ways of dispersing risk over many individual units there could be many potential use cases for using this kind of mechanism in Web3, not just for the insurance of loss. Alas, this paper will be covering the current state and problems of Insurance and we will leave the potential cases for discussion.</p>
<p><strong>If you are already familiar with insurance terms you can continue to the Goals &amp; Methodology paragraph.</strong></p>
<section id="what-is-insurance" class="level2">
<h2 class="anchored" data-anchor-id="what-is-insurance">What is Insurance?</h2>
<p>Insurance has a long history, there are claims that it was created around 2000 BC in Babylon, merchant receiving a loan paid the lender extra money in exchange for exemption of loan payment if the merchant’s shipment were stolen. Hovewer, the importance of insurance field cannot be presented without a mention of London’s Lloyd’s. In the 17th century, a London coffeehouse was a meeting place for people seeking marine cargo protection and people willing to take those risks in exchange for premium. The coffeeshop now is the world famous Lloyds. A sheet of cargo and ship information would be filled and the individuals who accepted that risk would sign with their names under it’s description.<sup>1</sup> That brings us to a first term in insurance <strong>underwriting</strong>.</p>
<ul>
<li><p>Underwriting is risk accessment process to determine whether to accept or reject the risk we will come into contact with this term a lot in the later paragraphs.</p></li>
<li><p>As we previously mentioned the point of insurance is to <strong>transfer and share risks.</strong></p></li>
<li><p>The individuals or companies that would like to transfer risk to other parties by paying a certain fee (<strong>premium</strong>) are called <strong>insured</strong>. The reason why the insured avoid the risk is because the loss is too volatile to bear.</p></li>
<li><p>The party that accepts such risks and and associated fee (<strong>premium</strong>) is the <strong>insurer</strong>. Insurers are not averse to exposing themselves to the same risks as insured because of something called <strong>pooling</strong> and the law of <strong>large numbers</strong>. The essence of pooling risk is to <strong>spread losses of the few over the entire group.</strong> The law of large numbers states that <strong>the greater the number of exposures the more closely will the actual results approach to the expected average value</strong></p></li>
</ul>
</section>
<section id="benefits-of-insurance-and-the-nature-of-insurance" class="level2">
<h2 class="anchored" data-anchor-id="benefits-of-insurance-and-the-nature-of-insurance">Benefits of Insurance and the nature of Insurance</h2>
<p>Insurance allows the insureds to “trade” the risk of loss for the certainty of smaller payments. As a result this ensured the stable cash flow since there are no extreme losses, and if they happen, they are covered by the insurance. As a result of this “stability” provided by insurance there is less need for governments assistance which saves public resources.<sup>2</sup></p>
<table>
<colgroup>
<col style="width: 19%">
<col style="width: 20%">
<col style="width: 25%">
<col style="width: 35%">
</colgroup>
<thead>
<tr class="header">
<th>Application</th>
<th>Underwriting</th>
<th>Policy Issuance</th>
<th>Claim if a loss occurs</th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<p><em>Figure 1: The process of issuing insurance</em></p>
<ul>
<li>The application for insurance often starts with quoting process where the amount to be paid in premiums are estimated according to the risk the client would like to manage. After the application the underwriting process occurs.</li>
<li>Underwriter evaluates the information of the application and then accepts and then “fine-tunes” the policy using the rating tables from the actuaries. Actuaries calculate premiums, in DeFi, this is done in a different way, more words on that in the later paragraphs.</li>
<li>After the underwriter accepts the application the policy is issued.</li>
<li>If a loss occures the claims department examines the claim and asks the insured for the proof of loss before they pay the insured amount. The payment depends on the amount of damage suffered and the decision of the claim department.</li>
</ul>
<p>The big part of insurance also is its regulation. Insurance is one of the most actively regulated fields, especially after the financial crisis in 2008. The regulation aims to ensure solvency of the insurers. One of the ways the state regulates Insurance companies is limiting their investment tacticts and portfolio allocation , in other words they don’t let them invest in risky assets which is de-facto the norm in cryptocurrency investments. This is one of the first issues encountered if we were to cooporate with existing insurance companies or create our own protocol that is regulated.<sup>3</sup></p>
</section>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p>The goal of this research is to explore:</p>
<ol type="1">
<li>The current state of DeFi Insurance and Insurance with cryptocurrency.</li>
<li>The process of applying, policy issuing and insurance claiming in a decentralized way of the main competitors in this market</li>
<li>The problems present with this kind of products.</li>
<li>Possibility of insuring material goods with cryptocurrency.</li>
</ol>
<p>Approach to this research will primarily be reading the whitepapers of covered protocols and documentation, discord discussions with staff and reading the reports of other researchers we find online.</p>
<p>Answers to the questions above will give us an insight into this field of DeFi and will provide us with better of understanding of insurance in general for creating potential products if we decide to go into that direction. Considering the effort needed to create this kind of products this short explorative research is conducted.</p>
<p>Approach to this will be explorative one as previously mentioned. We will start with presenting the main competitors in this field and we will analyze their proccesses. Extra attention will be paid to the biggest competitors. Afterwards the problems of these products with cryptocurrency will be presented.</p>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<section id="the-current-state-of-defi-insurance-and-insurance-with-cryptocurrency-and-insurance-processes" class="level2">
<h2 class="anchored" data-anchor-id="the-current-state-of-defi-insurance-and-insurance-with-cryptocurrency-and-insurance-processes">The current state of DeFi Insurance and Insurance with cryptocurrency and insurance processes</h2>
<p>When it comes to crypto-insurance with traditional insurers the market is non-existent, because of the regulation, lack of awareness and the lack of crypto adoption among general public. That’s why we will be covering DeFi insurance field.</p>
<p>DeFi Insurance refers to buying coverage against losses cause by events in Decentralized Finance. With various hacks and exploits over the years the need for insuring users from the results of these events emerged. Contrary to the layman’s belief DeFi Insurance field is big and growing with different protocols emerging in it. However only 2% of all DeFi value is insured at the moment.<sup>4</sup></p>
<p>Main protections offered is capital protection against protocol hack/exploit risk, smart contract failures or stablecoin crashes. The premium user pays for a cover depends on the type of the cover, insurance provider and the duration of the cover.</p>
<p>The Decentralized part in this type of Insurance is that anybody can act as a coverage provider, which supports the initial writers assumption. They become providers by locking up capital in a capital pool of the insurance protocol thus providing needed liquidity. As coverage providers they choose for which protocols or events they want to provide coverage, for example: If they are certain that a protocol is safe from exploits they will prefer providing liquidity to the pool that covers that event.</p>
<p>Another big part of DeFi Insurance is verifying claims. This is often done by the Insurance protocol’s community. Considering the nature of insurance and pooling of risk and collecting coverage from providers they are often assembled as DAOs (Decentralized Autonomous Organizations). This means that governance token holders participate in verifying claims. There are several ways of doing that and we will be covering it in the next paragraph.</p>
<section id="main-players-in-this-market" class="level3">
<h3 class="anchored" data-anchor-id="main-players-in-this-market">Main players in this market</h3>
<p>The 5 main competitors in DeFi insurance are:</p>
<ol type="1">
<li>Nexus Mutual</li>
<li>Bridge Mutual</li>
<li>InsurAce</li>
<li>Nsure</li>
<li>Etherisc</li>
</ol>
<p><em>Note: There are more insurance protocols but in order to keep this research a short overview we will showcase five</em></p>
<p>We will be covering them in detail to explore how they work and the type of products offered.</p>
</section>
<section id="nexus-mutual" class="level3">
<h3 class="anchored" data-anchor-id="nexus-mutual">Nexus mutual</h3>
<p>Nexus mutual is an Ethereum-based platform that offers insurance products led by community management and financials. Nexus mutual is set up as a DAO. Nexus offers three kinds of products:</p>
<ul>
<li>Protection against failures in any protocol used by users yield bearing token (Ethereum only)</li>
<li>Protection against failures in the individual protocol user has funds in, on any chain, but not in other protocols it uses.</li>
<li>Protection against hacks and halted withdrawals on exchanges or custodial wallets<sup>5</sup></li>
</ul>
<p>Simply put, Nexus cover protects against loss of funds, not loss of value, except in the Yield Token Cover. In the Yield Token Cover Nexus <em>may</em> pay a claim if:</p>
<ul>
<li>During the cover period the face value of the covered token and the market value of the covered token differ in price by more than 10% for a continuous period of four hours or more; and</li>
<li>The Covered Member contributes to the mutual, one unit of face value of the covered token in exchange for 0.90 units of cover amount they wish to claim; and</li>
<li>The Covered Member redeems their claim payment during the cover period or within 14 days of the cover period ending.</li>
</ul>
<p>Nexus does not provide Cover where the covered tokens and the cover amount are not denominated in the same refference currency. Nexus also doesn’t provide cover for any material goods loss.</p>
<p><strong>Claim assessing process:</strong></p>
<ul>
<li>All Covered members for a particular covered token will be assessed together for each claim event; and</li>
<li>The face value of the covered token immediately prior to the claim event shall be set as part of the claims assessment process; and</li>
<li>Following a successful claim vote all Covered Members will be able to contribute their covered tokens and redeem their claim payment on a proportional basis up to the cover amount.<sup>6</sup></li>
</ul>
<p>We will not cover the other 2 products into great detail, as they are pretty straight forward. More info on them can be found here: https://nexusmutual.gitbook.io/docs/welcome/faq/cover-products</p>
<p>All protocols and custodial accounts can be covered by the platform provided that <strong>risk assesesors</strong> staked enough value against them. Risk Assessors (experienced auditors, capital providers) can stake value in the form of NXM token, thereby vouching for the security of the protocol/custodian and dropping the price of the cover. NXM can be unstaked at any time subject to a 30-day withdrawal period. When cover is subsequently sold on a protocol or custodian, Risk Assessors earn proportional rewards in NXM equivalent to 50% of the cover premium. If a claim is accepted and a payout occurs, Risk Assessors staked against the protocol/custodian will have their staked NXM burnt on a proportional basis to facilitate the payout of the cover amount. This may result in a Risk Assessor having some or all of their NXM staked against the protocol/custodian burnt to provide capital for the payout of the claim.</p>
<p>Cover becomes available through one of two ways:</p>
<ol type="1">
<li><p>When Risk Assessors stake NXM against a protocol, custodian or cover product more cover is made available. The mutual places limits on the amount of cover to protect the mutual from being too exposed to any single risk. There are two limits a <strong>Specific Risk Limit</strong> and a <strong>Global Capacity Limit</strong>.</p>
<ol type="1">
<li><p><strong>Specific Risk limit</strong> means capacity on any particular risk is limited by the amount of staking on that risk. If there is no staking the mutual cannot offer any cover. Specific Risk limit is equal to : <strong>capacity factor x net_staked_NXM</strong> .</p></li>
<li><p><strong>Global Capacity Limit</strong> is based on the financial resources of the Mutual and is there to ensure the mutual is not overly exposed to any particular risk, regardless of how much is staked. <strong>Global Capacity Limit = Minimum Capital Requirement In ETH (MCReth) x 20%</strong></p></li>
</ol></li>
<li><p>As cover policies expire cover becomes available. User can check Nexus Tracker for info on cover expiry.<sup>7</sup></p></li>
</ol>
<p><strong>Membership issue regarding privacy</strong></p>
<p>Membership in Nexus requires a one-off membership fee of 0.0020 ETH (~$5.50). However, to become a member users need to verify their identity following their Know Your Customer process. They also cannot accept members from 17 countries, Serbia included, thus limiting the usage of the mutual.</p>
<p><strong>Transparency</strong></p>
<p>All deployed contracts of Nexus Mutual can be found here: https://api.nexusmutual.io/version-data/</p>
<p>All info regarding cover, staking and claims approvals/denies can be found here: https://nexustracker.io/</p>
<p><strong>How are Cover purchases taken care of by Nexus?</strong></p>
<p>Users specify which smart contract address they want cover for. They specify the cover amount , currency (ETH or DAI) and Cover Period. Quote will be generated and they need to make the transaction with Metamask. Users can currently pay with ETH, DAI or NXM (nexus mutual tokens). Cover Holders can submit a claim for material loss that occured within the cover period. They can also submit a claim up to 35 days after expiry. <strong>A loss that ocurs after cover policy is ended won’t be covered</strong></p>
<p><strong>How are claims taken care of?</strong></p>
<p>Claims are filed by submission. Members must provide cryptographic evidence of the loss (proof of loss) and their claim is later assessed by Claim Assessors by voting. Assessors are financially incentivised to take a longer-term view as they are required to lockup a stake. This stake is then burned if there is evidence of fradulent voting, which is addressed by Advisory Board. Advisory board consists of five members of founding team of the Nexus Mutual and insurance industry experts. They are said to have :</p>
<ul>
<li>Technical Expertise on Smart Contract Security and blockchain</li>
<li>Technical Expertise on Insurance and Mutuals</li>
<li>General Expertise</li>
</ul>
<p>Advisory board is there to provide techniqual guidance to the members of the mutual as well as to exercize the emergency functions if they are required.</p>
<p>This proposes a question: How do they keep the Advisory Board “in check” with Nexus’s decentralization principles?</p>
<p>Nexus does that by enabling members to kick-vote the Advisory Board members that they think are working maliciously. Board member can be replaced by another member if the membership base agrees. These proposals cannot be interfered with by the existing Advisory Board.</p>
</section>
<section id="bridge-mutual" class="level3">
<h3 class="anchored" data-anchor-id="bridge-mutual">Bridge Mutual</h3>
<p>Bridge Mutual has a similar business model as Nexus Mutual (DAO model). They provide coverage for smart contracts, stablecoins and other services. Bridge allows users to purchase coverage, provide coverage in exchange for yield, vote on policy claims and their payouts. We will not go into great detail as there are various similarities with Nexus Mutual to avoid repeating ourselves.</p>
<p><strong>The main difference between Bridge and Nexus Mutual is that that Bridge doesn’t check customer’s ID and is available for residents all countries</strong></p>
<p>Any user on the platform can create any pool for any project as because the system is permissionless by design.</p>
<ul>
<li>Initial capital (USDT) must be put into the Project Coverage Pool by the user that is creating the pool.</li>
<li>That project can create incentives for coverage providers to provide coverage to their pool by depositing any number of Token into its designated Shield Mining pool which gets distributed to Coverage Providers alongside the typical yield.</li>
</ul>
<p>Coverage Provider examines the risk of providing Coverage Capital to the Project’s Coverage Pool. When they provide capital they are de-facto telling users that they are sure in the security and stability of the project. They recieve yield from the users purchasing policies and the BMI(Bridge Mutual) token staking. When coverage providers supply capital to the coverage pool they receive a token (bmi(project name)Cover) representing their share in the capital within this capital pool. Coverage providers can then stake those tokens in the bmiCover Staking Contract pool to get additional BMI rewards. They also recieve a BMINFT Bond that represent the amount of for example DAI staked in Cover Staking Contract pool. These NFT Bonds are tradable on any NFT marketplace. The purpose of these NFT bonds is to give the user a way out of their position without removing DAI from the ecosystem. When the Coverage Provider sells his NFT he also transfers the ownership of the staked bmiDAIx.</p>
<p>Policy Holder pays a premium for Coverage to protect against the Coverage Event that could affect the insured Project and cause them to lose funds. The total cost of the Premium is split : 80% to coverage 20% to the Reinsurance Pool. They can buy cover for minimum of 1 week and maximum of 52 weeks. Three factors determine the price of cover (premium):</p>
<ol type="1">
<li>The utilization ratio of the pool (ratio between cover bought and cover provided, pools that have higher utilization ratio are riskier and more expensive)</li>
<li>Duration of the cover</li>
<li>Amount of cover which user wants to buy</li>
</ol>
<p>The Reinsurance pool consists of protocol owned funds that are used to provide liquidity to Coverage Pools. The reinsurance pool is funded through 20% of all premiums paid as mentioned above.</p>
<p>The Capital Pool aggregates USDT from the Coverage Pools and provides additional revenue to the protocol. Capital Pool sends USDT to yield generating platforms they deem to have low risk. We coulnd’t find exactly what those platforms are. This is a similarity with classic insurance companies which are limited in what way they invest their funds.</p>
<p><strong>Proving a loss</strong></p>
<p>Policy holders should submit any or all of the following:</p>
<ol type="1">
<li>Transaction IDs proving that Policy Holder’s wallet deposited assets into the protocol and transaction IDs of the Coverable Event</li>
<li>Posts from Protocol team, or an auditing team confirming that there was an exploit and providing additional information</li>
<li>A description of the Coverable Event</li>
<li>If the address affected was not the same address that purchased coverage, any evidence that proves the Policy Holder is the bonafide owner of the address that suffered a Permanent Loss.</li>
</ol>
<p>They also need to deposit 1% of the claim’s value in BMI to prevent spam claims. If the claim is valid, USDT is issued to the Claimant. If a claim is denied they can try again by depositing 1% again.</p>
<p>A successful claim can only recieve up to the policy’s maximum coverable amount. If the DAO determines that the loss suffered was less then the maximum coverable amount, policy owners may recieve less funds. The DAO is incentivized to pay the claimant the exact amount that was lost.</p>
<p><strong>Voting process</strong></p>
<p>Votes for claim approval are anonymous and any user holding vBMI can vote. Voters can wote on multiple Claims before submitting them in a batch send. This is done to save time and gas. Only users that vote in the majority are rewarded with BMI for voting. Users that vote in the minority can lose “reputation” which decreases voting power. If there is a large diference in voting yes or no (80% to 20%) users that voted no will lose a portion of their stake.</p>
<p><img src="https://3327.io/documents/research/posts/https:/1853607048-files.gitbook.io/~/files/v0/b/gitbook-28427.appspot.com/o/assets%2F-McJ-rdy5DzkSkdXp6VM%2F-MdWXc4-iyw6LOwtZ90R%2F-MdWfiqPXhasXmnJESvb%2Fimage.png?alt=media&amp;token=11a1af05-bbde-4941-be28-3274fac85146" style="height: 400px; width:600px;"></p>
<p><em>Figure 2. High Level Overview of Bridge Mutual’s Mechanism</em></p>
</section>
<section id="insureace.io" class="level3">
<h3 class="anchored" data-anchor-id="insureace.io">InsureAce.io</h3>
<p>InsurAce.io is a multi-chain mutual insurance protocol created in April 2021. It offers products that cover 100+ protocols, 3 CEX and 1 IDO platform. Currently they are depoloyed on Ethereum, Binance Smart Chain, Polygon and Avalanche. InsurAce hasn’t yet adopted the DAO governance mechanism, although they are working on it.</p>
<p>Current state of Insurace.io (Capital pool size, Active cover amount, Capital Ratios etc ) can be found here: https://app.insurace.io/Data/Insurance</p>
<p>This protocols has 4 unique selling propositions :</p>
<ol type="1">
<li>“0” Premium - Which means that the premiums are lower for their products. Their team designed portfolio-centric products to embrace risk diversification, developed models to optimize the cover cost. They did so by using advisors that are experts in the Insurance domain.</li>
<li>Enriched Product Line - InsurAce.io also offers products that covers non-Ethereum DeFi protocols.
<ol type="1">
<li>Types of protocols and smart contract systems covered:
<ol type="1">
<li>Lending Protocols</li>
<li>Decentralized Exchanges</li>
<li>Derivative (e.g.&nbsp;Synthetix, Nexus Mutual)</li>
<li>Asset (e.g.&nbsp;Badger, RenVM)</li>
</ol></li>
</ol></li>
<li>SCR Mining - The participants earn $INSUR tokens by staking into the mining pool. The mutual capitals injected through staking will be managed with rigorous risk control models to adjust the Solvency Capital Requirement (SCR) dynamically and use the secured free capital for investment to control the mining speed accordingly.</li>
<li>InsurAce tries to combat the low investment returns. Nexus mutual offers capital return to their providers from the premiums paid by users which is low compared to the yield on Compound and Aave. This problem makes users prefer putting their funds elsewhere, instead of the Insurance Protocol. Insurace combats this with offering users:
<ol type="1">
<li>Option to invest directly in the investment product depending on their risk aversion</li>
<li>Option to stake in the mutual pool and get the investment carries and $INSUR tokens as rewards</li>
<li>Shares of the premium income</li>
</ol></li>
</ol>
<p>InsurAce is operates similarly like the traditional insurance company using the insurance arm and the investment arm.</p>
<p>“The insurance arm maintains reserve pools which maintain the solvency for claim coverage based on risk exposure. The investment arm maintains investment pools that generate carry to subsidize claims and attracts investors with risk appetite. The free capital in the insurance capital pool can be placed into the investment pool to gain a higher yield, while the insurance arm will protect the investment activities. Meanwhile, the investment arm’s yield will complement the premium on the insurance side and reduce the cover cost for customers.” ‘Whitepaper’<sup>8</sup></p>
<p><strong>Pricing model</strong></p>
<p>When it comes to before mentioned protocols they rely heavily on the value staked on individual protocols: the higher value staked the lower the premium will be priced. InsurAce tries to combat this with adopting the new actuary-based pricing model to mitigate this in order to assess the expected loss of insurance products fairly, reduce costs and enhance capability.</p>
<p>“The model’s main inputs are the number/amount of claims and number/amount of exposures in a given time period, which will be used for selecting and training two separate models - the frequency model and the severity model. Frequency modeling produces a model that calibrates the probability of a given number of losses occurring during a specific period, while severity modeling produces the distribution of loss amounts and sets the level of deductible and limit of the coverage amount.” These models are then combined to solve aggregate loss. After that the decided aggregate loss is incorporated into the risk factors of protocols and the premiums are then calculated. The model’s parameters rely on historical data to devise and validate. They plan on taking this further with new Machine Learning methodologies.</p>
<p><strong>Capital model</strong></p>
<p>InsurAce’s capital model refers to EIOPA’s Solvency II, this regime is used for insurance and reinsurance in the European Union. It sets requirements needed for insurance products in order to protect policyholdes and beneficiaries.</p>
<p>“Solvency II is an economic risk-based approach that should assess the”overall solvency” of insurance and reinsurance undertakings through quantitative and qualitative measures. Under Solvency II, the undertaking’s solvency requirements are determined based on their risk profiles and how such risks are managed, providing the right incentives for sound risk management practices and securing enhanced transparency.”</p>
<p>Solvency II has different tiers of which the SCR (Solvency Capital Requirement) and MCR (Minimum Capital Requirement) are the two most important ones.</p>
<p>“The SCR is the capital required to ensure that the insurance company will be able to meet its obligations over the next 12 months with a probability of at least 99.5%, while MCR represents the threshold to correspond to an 85% probability of adequacy over 12 months and is bound between 25% and 45% of the SCR. For supervisory purposes, the SCR and MCR can be regarded as”soft” and “hard” floors.”</p>
<p>InsurAce uses SCR to calculate the minimum requirement funds set aside to pay all the potential claims considering all quantifiable risks. SCR is calculated with the following inputs:</p>
<ol type="1">
<li>All the active covers</li>
<li>All the outstanding claims</li>
<li>The potential incurred but not reported claims</li>
<li>The market currency shock risk</li>
<li>The non-life premium &amp; reserve, lapse and catastrophe risks</li>
<li>The potential operational risk</li>
</ol>
<p><code>SCR% = Capital Pool Size / SCR</code></p>
<p>A high ratio means the insurance company is financially strong with sufficient available funds to cover potential claims and other risks so the company is less likely to be insolvent . <strong>The lowest acceptable ratio is 100%.</strong></p>
<p>InsurAce also offers information of their Capital Efficiency ratio which shows the company’s current success in deploying capital.</p>
<p><code>CER% = Active Cover Amount / Capital Pool Size</code></p>
<p>A high ratio means the insurance company is increasing the productivity of its assets to generate income. Desired ratio is between 100% and 300%.</p>
<p><strong>Risk Assesment by InsurAce.io</strong></p>
<p>InsuraAce’s Advisory Board performs a preliminary risk assesment on the new protocols at first. InsurAce will also work with auditing firms if there is extra complexity or challenges. After that Advisory Board provides a report and rates the protocol 1 to 5. After they rate it protocol will go through the community risk assesment. Members who participate in the assesment get INSUR tokens as incentive.</p>
<p><strong>Claims Assesment by InsurAce.io</strong></p>
<p><img src="https://3327.io/documents/research/posts/https:/2557507273-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2F-MOAoQ0O7ivP8Rd-tXSY-887967055%2Fuploads%2FLlbDnXivNTRl7Zwnlcxn%2Fclaim_assess_eng_v2.0%20(1).png?alt=media&amp;token=c9eccb8d-1707-47b5-adc6-dc09f7fc439c" style="height: 700px; width:550px;"></p>
<p><em>Figure 3: InsureAce’s Claim Assesment process</em></p>
<p>This diagram shows us the whole system of claims Assesment in a clear way. The main difference is the inclusion of the Advisory board members which consists of various industry experts including the CTO of InsurAce.</p>
<p>“$INSUR token holders can stake the $INSUR tokens to become the community Claim Assessor. Claim Assessor will be entitled to the right to vote in each claim assessment and earn $INSUR tokens as reward if their votes match with the voting result. During each voting session, the more tokens the user stake, the more voting tickets they will get (* capped at 5% of the total votes), and the more rewards they will receive.”</p>
</section>
<section id="nsure" class="level3">
<h3 class="anchored" data-anchor-id="nsure">Nsure</h3>
<p>Nsure was targeted to be a platform for users to trade risks borrowing the operation model of previously mentioned Lloyds London. With Nsure information is transparent and users are allowed not only to be outsorcing risk but also to become risk takers, capital providers, governance actors and auditors of the system.</p>
<p>More data on Nsure performance can be found here: https://app.nsure.network/#/cover/my</p>
<p><strong>Product</strong></p>
<p>Nsure offers Smart contract cover like previously mentioned protocols. The coverage and exclusions are identical so we will not go into great detail. More info can be found at: https://docs.nsure.network/nsure-network/docs/nsure-smart-contract-protect-policy-wording</p>
<p><strong>Capital model</strong></p>
<p>Capital is sourced from capital mining, with return of Nsure tokens for the miners to ensure a continuous capital support to the underwriting. Minimum Capital Requirement (MCR) is calculated based on the volume of each project and the correlation between them. A low MCR% below a pre-determined threshold will result into a lock of assets in capital pool, so as to protect the solvency the business.</p>
<p><strong>Pricing model</strong></p>
<p>Nsure uses a Dynamic Pricing Model to set the price. In this model capital supply and demand from the entire platform determines the price jointly similar to the pricing mechanism in the free market, by having Nsure tokens backing the policies bought. The price is self-adjustable to the movement of supply and demand, subject to the model, moderately stabilising the price change.</p>
<p><strong>Rating System</strong></p>
<p>Nsure uses its N-SCOSS rating system to quantify the code security of projects by assessing:</p>
<ol type="1">
<li>History and Team</li>
<li>Exposure</li>
<li>Audit</li>
<li>Code quality</li>
<li>Developer community</li>
</ol>
<p><strong>Claim process</strong></p>
<p><img src="https://3327.io/documents/research/posts/https:/399601259-files.gitbook.io/~/files/v0/b/gitbook-28427.appspot.com/o/assets%2Fnsure-network%2F-MX6EZjd-IYguhPxsT3i%2F-MX6K9inCZbKlXukrmEm%2F0.png?generation=1617178176984217&amp;alt=media" style="height: 500px; width:700px;"></p>
<p><em>Figure 4: Nsure claim process</em></p>
<p>For each policy sold there is one chance of claim filling for free. If the first claim was rejected a claim assesment fee of 10% is requested before new assesment.</p>
<p>Policy holder must provide evidence of loss on the designated project within the insurance period. Proof of loss must include:</p>
<ol type="1">
<li>Proof of ownership of affected account - After identifying his affected account, policyholder may prove his ownership over the account by signature or making a 0 amount payment to a specified address.</li>
<li>Evidence of loss - Policy holder should provide:
<ol type="1">
<li>the snapshot of the affected address’s balance at blocks before and after attack (to assist claim assessors quickly quantify the amount of lost</li>
<li>transaction of selling the damaged assets (loss is only recognised when it is realised)</li>
<li>description of the attack from project team or security specialist</li>
</ol></li>
</ol>
<p><strong>Claim assesment</strong></p>
<p>Nsure introduced a similar voting mechanism as previously mentioned protocols. Its features are:</p>
<ol type="1">
<li>To be registered as a claim assessor candidate, user must deposit a considerable amount of Nsure token. At launch, the deposit is set at () Nsure token.</li>
<li>Claim assessors are randomly picked from registered candidate. For each claim, there will be 5 claim assessors.</li>
<li>As claim assessors’ reward is proportion to premium, users tend to register for larger size policy. To get each policy equal and fair tender, users do not know the premium of the policy at registration.</li>
<li>The token will be slashed if the claim assessor’s judgment is different from the majority.</li>
</ol>
<p>After claims assessors make a decision, policyholder and other Nsure token holders can challenge this decision. This will lead to a public vote for the final conclusion on the issue.</p>
</section>
<section id="etherisc" class="level3">
<h3 class="anchored" data-anchor-id="etherisc">Etherisc</h3>
<p>So far we have been covering only protocols that offer smart contracts protection. Etherisc tries to include material goods into the story. Etherisc is a protocol to collectively build insurance products. Common infrastructure, product templates and insurance license-as-a-service make a platform that allows anyone to create their own insurance products. The first product Etherisc offered was FlightDelay Insurance. Products currently licensed are: Crop Insurance and FlightDelay Insurance. Products currently in design: Hurricane Protection, Crypto Wallet Insurance, Collateral Protection for Crypto backed Loans, Social Insurance (death, heavy illness). They are also open for product requests. Users have the option to build their own insurance product, but more information about the user needs to be provided.<sup>9</sup></p>
<p>They also launched a Joint Grant Program with Chainlink to accelerate the adoption of data-driven decentralized insurance products, so we think that special attention should be paid towards potential building with Etherisc.<sup>10</sup></p>
<p><strong>Etherisc Token</strong></p>
<p>DIP Tokens act as the native internal currency that is inseparable from the protocol and network of its users. DIP tokens are needed to earn transaction fees (% of insurance premiums or fixed cost), incentivize and reward platform users to bring risk to the network, build and maintain risk transfer products. The total supply of Etherisc Tokens is 1 Billion.</p>
<p>DIP tokens give users access to the Decentralized Insurance Platform. By staking DIP token, participants provide collateral (bond) to guarantee future performance, availability, and service levels. Staking also signals quality and reputation. As a result, participants can earn money monetizing their skills, software (for example risk models or UI/UX), risk capital, insurance licenses, claim processing, or regulatory compliance/reporting services.</p>
<p><strong>FlightDelay Insurance example from the Whitepaper - Launched on January 20 2022</strong></p>
<p>In their whitepaper’s FlightDelay Insurance product they use oraclize to obtain data from their data provider. Oraclize charges Etherisc for calling their contract. Etherisc incentivize Oraclize to provide their service correctly by :</p>
<ol type="1">
<li>In the buyers market (market with many oracles) - Demanding of Oraclize to put some tokens in a staking contract which will then returns tokens if they deliver in time and forward the tokens to Etherisc in case they miss their obligations.</li>
<li>In the sellers market (market with only one or few oracles) - Oraclize will earn an additional profit, again by staking tokens in a “staking contract”, but with reversed roles: Etherisc will stake tokens, and Oraclize will earn these tokens if they deliver, and in case they don’t deliver, the tokens are returned to Etherisc.</li>
<li>Both options can be combined with both parties staking tokens from historical flight delay</li>
</ol>
<p>Their experience with the Flight Delay DApp confirmed that insurance applications need plenty of capital to be able to scale. But that entry barrier can be overcome with cryptographic tokens that enable highly customized economics. Their goal is to allow the tokenization of risks on the platform and to make them available on a global open-access marketplace.</p>
<p>In this kind of insurance the probability is calculated from historical flight data. They used flight delay initially as a POC because of low premiums assosciated with them and under normal circumstances flight dellays are well-aproximated by independent probability events. Etherisk leverages ChainLink data.</p>
<p>On January 20th 2022 Etherisc launched FlightDelay on Gnosis Chain Mainnet. It uses Chainlink Data Feeds to autonomously issue policies and execute payouts for travelers who experience flight delays or cancellations. The result of this is insurance policies that are quicker to settle, cheaper to provision thanks to decreases in human and technical overhead and more transparent given the blockchain backend.</p>
<p>FlightDelay is now available for passenger flights globally. The insurance policies are purchasable with USDC using the Gnosis Chain on Etherisc’s FlightDelay portal. More payment options are in the works.</p>
<p><strong>Participants in the Etherisc Protocol</strong></p>
<p>Participants in the protocol are:</p>
<ol type="1">
<li>Customers - Customers can buy insurance using the token. For convenience, third parties can offer payment gateways and integrations which remove the necessity to own cryptocurrency from the end customer. Furthermore, participants can choose to offer insurance products in any native currency - be it a cryptocurrency, a token or a fiat currency. <strong>Use of token: Universal currency to buy insurance products.</strong></li>
<li>Risk model Providers and Actuaries - “Risk models are fundamental for any insurance product. The correctness of the model is precondition for the economic success of the product.Generally, because of the magnitude of value affected by errors and deviations in the model, a Risk Model Provider won’t take responsibility for the economic outcome of his model, but rather for his adherence to principles and established guidelines in his trade.” <strong>Use of token: Staking/Reward for providing or updating risk models</strong></li>
<li>Data providers and oracles - Currently, data is collected together with the application for an insurance, and the insurance company “owns” the data - even after the insurance contract is no longer valid. In a blockchain decentralized environment, the collection of data could be separated. Customers could get paid for voluntarily offering their data to a data pool, which in turn can sell this to interested parties, leaving the ownership of the data completely with the customer. This is an interesting take on handling events in the real world and the real world application of crypto insurance. <strong>Use of token: Reward for giving data. Reward for giving access to data pools. Staking / Reward for providing reliable oracles.</strong></li>
<li>Sales Agents - Sales agents are responsible for offering insurance products like in the traditional insurance. <strong>Use of token: Reward for distribution of products.</strong></li>
<li>Claim Agents - There are still many cases where automatic detection and processing the claims is not possible. Specialized and sometimes independent claims agents already exist that can be somewhat utilized e.g.&nbsp;in the area of car insurance, where they help insurers to process claims in shorter time. These claims agents can immediately use a decentralized platform, as soon as adequate products are available. <strong>Use of token: Reward for the provided service.</strong></li>
<li>License providers - Insurance in most countries depends on a proper license which can be difficult and costly to obtain. There is also a model where a license provider can act as an intermediary to regulators which is interesting if we are to build a new kind of insurance product. <strong>Use of tokens: Staking tokens to provide capital for a license provider, paying fees for licenses.</strong></li>
<li>Product managers - <strong>Use of token: Reward for service.</strong></li>
</ol>
<p>Etheriscs’ approach to crypto insurance is interesting but majority of their products are still in the works.Their first product FlightDelay Insurance was launched on January 10th 2022.<sup>11</sup></p>
</section>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>Above we covered 5 of the main players of the DeFi insurance market in order to determine the products offered,the way the claims are handled and the possibility of creating new insurance protocols.</p>
<p>Quick recap:</p>
<table class="table">
<colgroup>
<col style="width: 8%">
<col style="width: 18%">
<col style="width: 15%">
<col style="width: 19%">
<col style="width: 16%">
<col style="width: 21%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th style="text-align: center;"><strong>Nexus Mutual</strong></th>
<th style="text-align: center;"><strong>Bridge Mutual</strong></th>
<th style="text-align: center;"><strong>InsurAce</strong></th>
<th style="text-align: center;"><strong>Nsure</strong></th>
<th style="text-align: center;"><strong>Etherisc</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Mechanism</td>
<td style="text-align: center;">Mutual</td>
<td style="text-align: center;">Mutual</td>
<td style="text-align: center;">Mutual</td>
<td style="text-align: center;">Open insurance platform</td>
<td style="text-align: center;">Platform to build insurance products</td>
</tr>
<tr class="even">
<td>Insurance</td>
<td style="text-align: center;">Protocol failure, hacks</td>
<td style="text-align: center;">Smart Contracts, Stablecoins</td>
<td style="text-align: center;">Protocols, 3 CEX, 1 IDO</td>
<td style="text-align: center;">Smart Contracts</td>
<td style="text-align: center;">Material Goods, Other real-world events</td>
</tr>
<tr class="odd">
<td>Governance</td>
<td style="text-align: center;">DAO</td>
<td style="text-align: center;">DAO</td>
<td style="text-align: center;">Working on DAO governance mechanism</td>
<td style="text-align: center;">DAO</td>
<td style="text-align: center;">No data/working on DAO</td>
</tr>
<tr class="even">
<td>Identity Check</td>
<td style="text-align: center;">KYC</td>
<td style="text-align: center;">NO</td>
<td style="text-align: center;">NO</td>
<td style="text-align: center;">NO</td>
<td style="text-align: center;">No</td>
</tr>
<tr class="odd">
<td>Availability</td>
<td style="text-align: center;">17 Countries are prohibited</td>
<td style="text-align: center;">Anyone</td>
<td style="text-align: center;">Anyone</td>
<td style="text-align: center;">Anyone</td>
<td style="text-align: center;">Anyone</td>
</tr>
<tr class="even">
<td>Transparency</td>
<td style="text-align: center;">Fully Transparent</td>
<td style="text-align: center;">Fully Transparent</td>
<td style="text-align: center;">Fully Transparent</td>
<td style="text-align: center;">Fully Transparent</td>
<td style="text-align: center;">Fully Transparent</td>
</tr>
<tr class="odd">
<td>Claim Assesment</td>
<td style="text-align: center;">Claim Assessors and Advisory Board</td>
<td style="text-align: center;">Voting of vBMI holders</td>
<td style="text-align: center;">Community Voting</td>
<td style="text-align: center;">Claim Assessors or Public vote</td>
<td style="text-align: center;">Oracles</td>
</tr>
</tbody>
</table>
<p>We went into detail on those protocols and have come to these conclusions:</p>
<ol type="1">
<li>In creating these kind of products there needs to be significant effort both in developing and inital investment. Protocols covered utilize Advisory Boards of insurance experts in order to create their products.</li>
<li>State regulation is a big factor in insurance in order to protect the policyholders from malicious insurance offerers. This can be a problem, depending on the states’ attitude towards cryptocurrency.</li>
<li>Handling claims is often left to the community incentivizing just behavior by staking.</li>
<li>Collecting adequate capital initially is also one of the major problems.</li>
<li>Protocols with less staked pools have higher premiums in most cases which shows us that the risk assessment is usually hard to do with new protocols.</li>
<li>There is a limited cover capacity.</li>
<li>Usually there is no cross-chain coverage which limits the protection capability of DeFi protocols on other chains.</li>
<li>Lack of protection diversity: most products offered are limited when compared to the broad coverage of risk types in the traditional insurance market.</li>
<li>Insuring real world Events is almost non-existent. Etherisc offers 2 products using Oracles but our assumption is that there is still no market need for this kind of products thus there is not much movement in this direction. However utilizing Oracles in traditional products is an interesting thing and we think should be looked more into.</li>
</ol>
</section>
<section id="bibliography" class="level1">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Bibliography</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-HistoryLloydFounding1928" class="csl-entry">
‘A History of Lloyd’s: From the Founding of Lloyd’s <span class="nocase">Coffee-house</span> to the Present Day’, <em>Nature</em>, 122.3069 (1928), 267–68 &lt;https://doi.org/<a href="https://doi.org/10.1038/122267a0">10.1038/122267a0</a>&gt;
</div>
<div id="ref-CapacityLimits" class="csl-entry">
‘Capacity Limits’ &lt;<a href="https://nexusmutual.gitbook.io/docs/users/understanding-nexus-mutual/capacity-limits" class="uri">https://nexusmutual.gitbook.io/docs/users/understanding-nexus-mutual/capacity-limits</a>&gt; [accessed 22 March 2022]
</div>
<div id="ref-CoverProducts" class="csl-entry">
‘Cover Products’ &lt;<a href="https://nexusmutual.gitbook.io/docs/welcome/faq/cover-products" class="uri">https://nexusmutual.gitbook.io/docs/welcome/faq/cover-products</a>&gt; [accessed 11 March 2022]
</div>
<div id="ref-etheriscEtheriscChainlinkLaunch2022" class="csl-entry">
Etherisc, ‘Etherisc and Chainlink Launch Joing Grant Program’, <em>Medium</em>, 2022 &lt;<a href="https://blog.etherisc.com/supporting-the-development-of-blockchain-based-insurance-solutions-through-the-chainlink-etherisc-c1d34076926b" class="uri">https://blog.etherisc.com/supporting-the-development-of-blockchain-based-insurance-solutions-through-the-chainlink-etherisc-c1d34076926b</a>&gt; [accessed 22 March 2022]
</div>
<div id="ref-EtheriscDecentralizedInsurance" class="csl-entry">
‘Etherisc - Decentralized Insurance’ &lt;<a href="https://etherisc.com/" class="uri">https://etherisc.com/</a>&gt; [accessed 14 March 2022]
</div>
<div id="ref-EtheriscLaunchesFlight" class="csl-entry">
‘Etherisc Launches Flight Delay Insurance Platform That Leverages Chainlink Data’ &lt;<a href="https://finance.yahoo.com/news/etherisc-launches-flight-delay-insurance-140029295.html" class="uri">https://finance.yahoo.com/news/etherisc-launches-flight-delay-insurance-140029295.html</a>&gt; [accessed 14 March 2022]
</div>
<div id="ref-litanRegulatingInsuranceCrisis2009" class="csl-entry">
Litan, Robert E, ‘Regulating Insurance After The Crisis’, 2009, 20
</div>
<div id="ref-NexusMutualBuy" class="csl-entry">
‘Nexus Mutual - Buy Cover’ &lt;<a href="https://app.nexusmutual.io/cover" class="uri">https://app.nexusmutual.io/cover</a>&gt; [accessed 11 March 2022]
</div>
<div id="ref-outrevilleInsuranceConcepts1998" class="csl-entry">
Outreville, J., ‘Insurance Concepts’, 1998, pp.&nbsp;131–46 &lt;https://doi.org/<a href="https://doi.org/10.1007/978-1-4615-6187-3_8">10.1007/978-1-4615-6187-3_8</a>&gt;
</div>
<div id="ref-TopDecentralizedInsurance2021" class="csl-entry">
‘Top Decentralized Insurance for DeFi Investors in 2021 | Bitcoinist.com’, 2021 &lt;<a href="https://bitcoinist.com/top-decentralized-insurance-for-defi-investors-in-2021/" class="uri">https://bitcoinist.com/top-decentralized-insurance-for-defi-investors-in-2021/</a>&gt; [accessed 10 March 2022]
</div>
<div id="ref-Whitepaper" class="csl-entry">
‘Whitepaper’ &lt;<a href="https://docs.insurace.io/landing-page/documentation-1/whitepaper" class="uri">https://docs.insurace.io/landing-page/documentation-1/whitepaper</a>&gt; [accessed 13 March 2022]
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>‘A History of Lloyd’s: From the Founding of Lloyd’s <span class="nocase">Coffee-house</span> to the Present Day’, <em>Nature</em>, 122.3069 (1928), 267–68 &lt;https://doi.org/[10.1038/122267a0](https://doi.org/10.1038/122267a0)&gt;.↩︎</p></li>
<li id="fn2"><p>J. Outreville, ‘Insurance Concepts’, 1998, pp.&nbsp;131–46 &lt;https://doi.org/[10.1007/978-1-4615-6187-3_8](https://doi.org/10.1007/978-1-4615-6187-3_8)&gt;.↩︎</p></li>
<li id="fn3"><p>Robert E Litan, ‘Regulating Insurance After The Crisis’, 2009, 20.↩︎</p></li>
<li id="fn4"><p>‘Top Decentralized Insurance for DeFi Investors in 2021 | Bitcoinist.com’, 2021 &lt;&lt;https://bitcoinist.com/top-decentralized-insurance-for-defi-investors-in-2021/&gt;&gt; [accessed 10 March 2022].↩︎</p></li>
<li id="fn5"><p>‘Nexus Mutual - Buy Cover’ &lt;&lt;https://app.nexusmutual.io/cover&gt;&gt; [accessed 11 March 2022].↩︎</p></li>
<li id="fn6"><p>‘Cover Products’ &lt;&lt;https://nexusmutual.gitbook.io/docs/welcome/faq/cover-products&gt;&gt; [accessed 11 March 2022].↩︎</p></li>
<li id="fn7"><p>‘Capacity Limits’ &lt;&lt;https://nexusmutual.gitbook.io/docs/users/understanding-nexus-mutual/capacity-limits&gt;&gt; [accessed 22 March 2022].↩︎</p></li>
<li id="fn8"><p>&lt;[Https://docs.insurace.io/landing-page/documentation-1/whitepaper](https://docs.insurace.io/landing-page/documentation-1/whitepaper)&gt; [accessed 13 March 2022].↩︎</p></li>
<li id="fn9"><p>‘Etherisc - Decentralized Insurance’ &lt;&lt;https://etherisc.com/&gt;&gt; [accessed 14 March 2022].↩︎</p></li>
<li id="fn10"><p>Etherisc, ‘Etherisc and Chainlink Launch Joing Grant Program’, <em>Medium</em>, 2022 &lt;&lt;https://blog.etherisc.com/supporting-the-development-of-blockchain-based-insurance-solutions-through-the-chainlink-etherisc-c1d34076926b&gt;&gt; [accessed 22 March 2022].↩︎</p></li>
<li id="fn11"><p>‘Etherisc Launches Flight Delay Insurance Platform That Leverages Chainlink Data’ &lt;&lt;https://finance.yahoo.com/news/etherisc-launches-flight-delay-insurance-140029295.html&gt;&gt; [accessed 14 March 2022].↩︎</p></li>
</ol>
</section></div> ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-91.hugo.html</guid>
  <pubDate>Wed, 09 Mar 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Transaction splitting</title>
  <dc:creator>Andrej</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-105.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p>Many companies sell goods with a business model based on donating some percent of their profit to charity. The problem is that some of these companies don’t transparently perform these donations. If, for example, the handmade wristwatch company claims that it donates 90 percent of earnings to the charity, the buyers can’t be sure whether they indeed donated the funds to charity or just bought a very expensive product. They can only believe the company itself. Blockchain technology eliminates the need for trust.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>This paper tends to explain and show how the need for trust can be eliminated when it comes to donations and setting up business models in general. Idea is to have a platform that will allow you to set up a use case in which you want to allow users to buy a product from you where a specific percentage of the purchase will go to a different wallet(s).</p>
<ul>
<li>X% of purchase transparently goes to verified charity wallet</li>
<li>a split transaction between different co-creators or marketplace and author</li>
</ul>
<p>We can develop a fully transparent set of smart contracts and protocols on some general-purpose blockchain and introduce to sellers and customers a brand new way for selling goods and doing business in general.</p>
<p>Additionally, if there are too many different wallet recipients, the splitting can be done through merkle tree claim model.</p>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<section id="goals" class="level3">
<h3 class="anchored" data-anchor-id="goals">Goals</h3>
<ul>
<li>How to make charity donations and spending transparent</li>
<li>Eliminate the need for trusting the brand, and provide customers a way to easily verify their spendings</li>
<li>Split input transaction to several different wallets by desired percentage</li>
</ul>
</section>
<section id="methodology" class="level3">
<h3 class="anchored" data-anchor-id="methodology">Methodology</h3>
<ul>
<li>Write a set of smart contracts in Solidity for this purpose.
<ul>
<li>Pros:
<ul>
<li>Portable to any EVM general purpose blockchain</li>
<li>Native support for cryptocurrencies</li>
<li>Possibility for including ERC-20 tokens, as well</li>
<li>Tooling (Hardhat, OpenZeppelin, etc.)</li>
</ul></li>
<li>Cons:
<ul>
<li>Lack of native percentage operator in Solidity, one need to decide up to which decimal the result is reliable</li>
<li>Transaction costs</li>
</ul></li>
</ul></li>
<li>Integrate it with <a href="https://www.npmjs.com/package/bizzswap">Bizzswap</a>
<ul>
<li>Pros:
<ul>
<li>Out of the box solution for paying/swapping coins and tokens</li>
</ul></li>
<li>Cons:
<ul>
<li>Third-party dependency</li>
</ul></li>
</ul></li>
<li>Testing
<ul>
<li>Unit tests</li>
<li>Integration tests</li>
<li>End to end tests</li>
<li>Static analasys</li>
<li>Code coverage</li>
<li>Gas usage</li>
<li>Fuzz testing (optional)</li>
<li>Formal verification (optional)</li>
<li>Audit</li>
<li>Deployment to testnet</li>
</ul></li>
</ul>
<p>The beauty of the end result is that anyone can port a frontend app to this decentralized protocol and incorporate it in their business models, already existing platforms, etc.</p>
</section>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<p>Transaction can be split among several parties in Solidity like this:</p>
<section id="step-1" class="level3">
<h3 class="anchored" data-anchor-id="step-1">Step 1)</h3>
<p>Smart contract should have the ability to receive native coin or any other token. There is a need for a <code>receive()</code> or <code>fallback()</code> function, depends on the implementation of the smart contract.</p>
<p><code>receive()</code> is called if <code>msg.data</code> is empty, otherwise <code>fallback()</code> is called.</p>
<pre class="solidity"><code>    /**
    Which function is called, fallback() or receive()?

           send Ether
               |
         msg.data is empty?
              / \
            yes  no
            /     \
receive() exists?  fallback()
         /   \
        yes   no
        /      \
    receive()   fallback()
    */

    // Function to receive Ether. msg.data must be empty
    receive() external payable {}

    // Fallback function is called when msg.data is not empty
    fallback() external payable {}</code></pre>
</section>
<section id="step-2" class="level3">
<h3 class="anchored" data-anchor-id="step-2">Step 2)</h3>
<p>Smart contract then needs to split the received amount among other wallets by defined percentage. Sending funds is trivial and we won’t focus on that. The most challenging part is proper ratio calculations in a language with no native support for decimal arithmetics.</p>
<p>In Solidity, one must assume that all numbers have 18 decimal precision. For example:</p>
<ul>
<li>1 is 1000000000000000000,</li>
<li>0.5 is 500000000000000000, and</li>
<li>100 is 100000000000000000000</li>
</ul>
<p>Since there are no native language support for percentage arithmetics in Solidity, devs are using Basis Points as a unit of measurement equal to 1/100th of 1 percent. This metric is commonly used for loans and bonds to signify percentage changes or yield spreads in financial instruments, especially when the difference in material interest rates is less than one percent.</p>
<ul>
<li>0.01% = 1 BPS</li>
<li>0.05% = 5 BPS</li>
<li>0.1% = 10 BPS</li>
<li>0.5% = 50 BPS</li>
<li>1% = 100 BPS</li>
<li>10% = 1 000 BPS</li>
<li>100% = 10 000 BPS</li>
</ul>
<p>Possible implementation:</p>
<pre class="solidity"><code>    function calculateFee(uint256 _amount) public pure returns(uint256) {
        // for example 1.85% is fee

        return _amount * 185 / 10000;
    }</code></pre>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>There are no blockers for implementing this idea in Solidity. The tooling is stable, the math is not complex and can be handled by the language, and the blockchain technology itself is capable for storing this type of applications.</p>
</section>
<section id="bibliography" class="level1">




</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Bibliography</h2><div id="refs">

</div></section></div> ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-105.hugo.html</guid>
  <pubDate>Tue, 08 Mar 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>BLS vs Schnorr vs ECDSA digital signatures</title>
  <dc:creator>Andrej</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-39.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p>Bitcoin and Ethereum both use elliptic-curve cryptography for generating keys and signing transactions. The algorithm they both use is called Elliptic Curve Digital Signature Algorithm (ECDSA), which represents a secure way of signing a message (a transaction for example) using Elliptic Curve Cryptography (ECC). This is a comparative analysis of BLS, Schnorr, and ECDSA signatures. The goal is to understand why are Ethereum and Bitcoin migrating from ECDSA, why BLS and Schnorr are superior to ECDSA and what are the key differences between them, how to use these signatures in the development and which Elliptic curves they are using and why.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>The main goal of this paper is to provide a clear understanding of the differences between them and how to use them in future protocol development; to understand why is Bitcoin migrating from ECDSA to Schnorr and why Ethereum is migrating from ECDSA to BLS.</p>
<section id="quick-recap-ecdsa" class="level2">
<h2 class="anchored" data-anchor-id="quick-recap-ecdsa">Quick recap: ECDSA</h2>
<p>Modern cryptography is founded on the idea that the key that you use to encrypt your data can be made public while the key that is used to to decrypt your data can be kept private. As such, these systems are known as public-key cryptographic systems.</p>
<p>ECDSA stands for Elliptic Curve Digital Signature Algorithm. Elliptic curve cryptography is a form of public key cryptography which is based on the algebraic structure of elliptic curves over finite fields. Used by both Bitcoin and Ethereum.</p>
<p>Elliptic curve: secp256k1</p>
<section id="secp256k1" class="level3">
<h3 class="anchored" data-anchor-id="secp256k1">secp256k1</h3>
<p>The elliptic curve domain parameters over <code>Fp</code> associated with a Koblitz curve secp256k1 are specified by the sextuple <code>T = (p, a, b, G, n, h)</code> where the finite field <code>Fp</code> is defined by:</p>
<ul>
<li>p = <code>0xFFFFFFFF FFFFFFFF FFFFFFFF FFFFFFFF FFFFFFFF FFFFFFFF FFFFFFFE FFFFFC2F</code> = <code>2^256 − 2^32 − 2^9 − 2^8 − 2^7 − 2^6 − 2^4 − 1</code></li>
</ul>
<p>The curve <strong>E</strong>: <code>y^2 = x^3 + ax + b</code> over Fp is defined by:</p>
<ul>
<li>a = <code>0x00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000</code></li>
<li>b = <code>0x00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000007</code></li>
</ul>
<p>The base point <strong>G</strong> in compressed form is:</p>
<ul>
<li><code>0x02 79BE667E F9DCBBAC 55A06295 CE870B07 029BFCDB 2DCE28D9 59F2815B 16F81798</code></li>
</ul>
<p>and in uncompressed form is:</p>
<ul>
<li><code>0x04 79BE667E F9DCBBAC 55A06295 CE870B07 029BFCDB 2DCE28D9 59F2815B 16F81798 483ADA77 26A3C465 5DA4FBFC 0E1108A8 FD17B448 A6855419 9C47D08F FB10D4B8</code></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://3327.io/documents/research/posts/https:/github.com/ethereumbook/ethereumbook/raw/develop/images/simple_elliptic_curve.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">secp256k1 curve</figcaption><p></p>
</figure>
</div>
</section>
<section id="private-and-public-keys" class="level3">
<h3 class="anchored" data-anchor-id="private-and-public-keys">Private and public keys</h3>
<p>Private keys are generated as random 256 bits or 64 random hex characters or 32 random bytes. The public key is derived from the private key using ECDSA. Public key is a point on secp256k1 elliptic curve, generated by formula <code>K = k * G</code> where <code>K</code> is public key, <code>k</code> is private key, <code>G</code> is the constant point on secp256k1 elliptic curve and <code>*</code> is the multiplication operator on secp256k1 elliptic curve. There is no inverse, “<code>/</code>” operator, therefore the relationship between <code>k</code> and <code>K</code> is fixed, but can only be calculated in one direction, from <code>k</code> to <code>K</code>. A private key can be converted into a public key, but a public key cannot be converted back into a private key, because the math only works one way. The multiplication of <code>k * G</code> is equivalent to repeated addition, so <code>G + G + G + …​ + G</code>, repeated <code>k</code> times.</p>
</section>
<section id="signing-and-verification" class="level3">
<h3 class="anchored" data-anchor-id="signing-and-verification">Signing and verification</h3>
<p>To sign and verify ECDSA signature using OpenSSL, do next</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb1-1"><span class="co" style="color: #5E5E5E;"># Generate private key</span></span>
<span id="cb1-2"><span class="ex" style="color: null;">openssl</span> genpkey <span class="at" style="color: #657422;">-algorithm</span> rsa <span class="at" style="color: #657422;">-out</span> privatni.pem</span>
<span id="cb1-3"></span>
<span id="cb1-4"><span class="co" style="color: #5E5E5E;"># Generate public key out of private key</span></span>
<span id="cb1-5"><span class="ex" style="color: null;">openssl</span> rsa <span class="at" style="color: #657422;">-pubout</span> <span class="at" style="color: #657422;">-in</span> privatni.pem <span class="at" style="color: #657422;">-out</span> javni.pem</span>
<span id="cb1-6"></span>
<span id="cb1-7"><span class="co" style="color: #5E5E5E;"># Test message for signing</span></span>
<span id="cb1-8"><span class="bu" style="color: null;">echo</span> <span class="st" style="color: #20794D;">"Test"</span> <span class="op" style="color: #5E5E5E;">&gt;</span> message.txt</span>
<span id="cb1-9"></span>
<span id="cb1-10"><span class="co" style="color: #5E5E5E;"># Sign the message (with Bitcoin's hashing alghorithm)</span></span>
<span id="cb1-11"><span class="ex" style="color: null;">openssl</span> dgst <span class="at" style="color: #657422;">-sha256</span> <span class="at" style="color: #657422;">-sign</span> privatni.pem <span class="at" style="color: #657422;">-out</span> signature.bin message.txt</span>
<span id="cb1-12"></span>
<span id="cb1-13"><span class="co" style="color: #5E5E5E;"># Verification</span></span>
<span id="cb1-14"><span class="ex" style="color: null;">openssl</span> dgst <span class="at" style="color: #657422;">-sha256</span> <span class="at" style="color: #657422;">-verify</span> javni.pem <span class="at" style="color: #657422;">-signature</span> signature.bin message.txt</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://3327.io/documents/research/posts/https:/miro.medium.com/max/1400/1*aWEbhqQIpHXZgvNpRSi54g@2x.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">ecdsa signing</figcaption><p></p>
</figure>
</div>
</section>
<section id="ecdsa-verification-in-solidity" class="level3">
<h3 class="anchored" data-anchor-id="ecdsa-verification-in-solidity">ECDSA verification in Solidity</h3>
<pre class="solidty"><code>import "@openzeppelin/contracts/utils/cryptography/ECDSA.sol";

contract Example {
  address public admin;

  constructor() {
    admin = msg.sender;
  }

  function verify(bytes32 _digest, bytes calldata _signature) public view returns(bool) {
    return admin == ECDSA.recover(_digest, _signature);
  }
}</code></pre>
</section>
<section id="ecdsa-verification-in-javascripttypescript" class="level3">
<h3 class="anchored" data-anchor-id="ecdsa-verification-in-javascripttypescript">ECDSA verification in Javascript/Typescript</h3>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode typescript"><code class="sourceCode typescript"><span id="cb3-1"><span class="im" style="color: #00769E;">import</span> { SignerWithAddress } <span class="im" style="color: #00769E;">from</span> <span class="st" style="color: #20794D;">'@nomiclabs/hardhat-ethers/signers'</span><span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb3-2"><span class="im" style="color: #00769E;">import</span> { utils } <span class="im" style="color: #00769E;">from</span> <span class="st" style="color: #20794D;">'ethers'</span><span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb3-3"><span class="im" style="color: #00769E;">import</span> { expect } <span class="im" style="color: #00769E;">from</span> <span class="st" style="color: #20794D;">'chai'</span><span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb3-4"></span>
<span id="cb3-5">(<span class="kw" style="color: #003B4F;">async</span> () <span class="kw" style="color: #003B4F;">=&gt;</span> {</span>
<span id="cb3-6">    <span class="kw" style="color: #003B4F;">let</span> admin<span class="op" style="color: #5E5E5E;">:</span> SignerWithAddress<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb3-7"></span>
<span id="cb3-8">    [admin] <span class="op" style="color: #5E5E5E;">=</span> <span class="cf" style="color: #003B4F;">await</span> ethers<span class="op" style="color: #5E5E5E;">.</span><span class="fu" style="color: #4758AB;">getSigners</span>()<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb3-9"></span>
<span id="cb3-10">    <span class="kw" style="color: #003B4F;">const</span> message<span class="op" style="color: #5E5E5E;">:</span> <span class="dt" style="color: #AD0000;">string</span> <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'Hello World'</span><span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb3-11">    <span class="kw" style="color: #003B4F;">const</span> msgHash<span class="op" style="color: #5E5E5E;">:</span> <span class="dt" style="color: #AD0000;">string</span> <span class="op" style="color: #5E5E5E;">=</span> utils<span class="op" style="color: #5E5E5E;">.</span><span class="fu" style="color: #4758AB;">hashMessage</span>(message)<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb3-12">    <span class="kw" style="color: #003B4F;">const</span> digest<span class="op" style="color: #5E5E5E;">:</span> <span class="bu" style="color: null;">Uint8Array</span> <span class="op" style="color: #5E5E5E;">=</span> utils<span class="op" style="color: #5E5E5E;">.</span><span class="fu" style="color: #4758AB;">arrayify</span>(msgHash)<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb3-13"></span>
<span id="cb3-14">    <span class="kw" style="color: #003B4F;">const</span> signature<span class="op" style="color: #5E5E5E;">:</span> <span class="dt" style="color: #AD0000;">string</span> <span class="op" style="color: #5E5E5E;">=</span> <span class="cf" style="color: #003B4F;">await</span> admin<span class="op" style="color: #5E5E5E;">.</span><span class="fu" style="color: #4758AB;">signMessage</span>(message)<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb3-15"></span>
<span id="cb3-16">    <span class="kw" style="color: #003B4F;">const</span> address<span class="op" style="color: #5E5E5E;">:</span> <span class="dt" style="color: #AD0000;">string</span> <span class="op" style="color: #5E5E5E;">=</span> utils<span class="op" style="color: #5E5E5E;">.</span><span class="fu" style="color: #4758AB;">recoverAddress</span>(digest<span class="op" style="color: #5E5E5E;">,</span> signature)<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb3-17">    <span class="fu" style="color: #4758AB;">expect</span>(address)<span class="op" style="color: #5E5E5E;">.</span><span class="at" style="color: #657422;">to</span><span class="op" style="color: #5E5E5E;">.</span><span class="fu" style="color: #4758AB;">equal</span>(admin<span class="op" style="color: #5E5E5E;">.</span><span class="at" style="color: #657422;">address</span>)<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb3-18">})()<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
</section>
</section>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<section id="bls" class="level2">
<h2 class="anchored" data-anchor-id="bls">BLS</h2>
<p>BLS stands for Boneh-Lynn-Shacham, it’s a signature scheme that is based on bi-linear pairings. A pairing, defined as <code>e(,)</code>, is a bilinear map of 2 groups <code>G1</code> and <code>G2</code> in some other group, <code>GT</code>. <code>e(,)</code> takes as arguments points in G1 and G2.</p>
<p>Pairings that verifies a signature looks like this:</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb4-1"><span class="ex" style="color: null;">e</span><span class="er" style="color: #AD0000;">(</span><span class="ex" style="color: null;">g1,</span> sig<span class="kw" style="color: #003B4F;">)</span> <span class="ex" style="color: null;">=</span> e<span class="er" style="color: #AD0000;">(</span><span class="ex" style="color: null;">P,</span> H<span class="er" style="color: #AD0000;">(</span><span class="ex" style="color: null;">m</span><span class="kw" style="color: #003B4F;">))</span></span>
<span id="cb4-2"></span>
<span id="cb4-3"><span class="co" style="color: #5E5E5E;"># or in expanded form like this</span></span>
<span id="cb4-4"><span class="ex" style="color: null;">e</span><span class="er" style="color: #AD0000;">(</span><span class="ex" style="color: null;">g1,</span> pk<span class="pp" style="color: #AD0000;">*</span>H<span class="er" style="color: #AD0000;">(</span><span class="ex" style="color: null;">m</span><span class="kw" style="color: #003B4F;">))</span> <span class="ex" style="color: null;">=</span> e<span class="er" style="color: #AD0000;">(</span><span class="ex" style="color: null;">pk*g1,</span> H<span class="er" style="color: #AD0000;">(</span><span class="ex" style="color: null;">m</span><span class="kw" style="color: #003B4F;">))</span> <span class="ex" style="color: null;">=</span> e<span class="er" style="color: #AD0000;">(</span><span class="ex" style="color: null;">g1,</span> pk<span class="pp" style="color: #AD0000;">*</span>H<span class="er" style="color: #AD0000;">(</span><span class="ex" style="color: null;">m</span><span class="kw" style="color: #003B4F;">))</span></span></code></pre></div>
<p><code>H(m)</code> is hashing a message to a point on an elliptic curve.</p>
<p>BLS consists of:</p>
<ul>
<li><p><strong>KeyGen</strong> — choose a random <code>α</code>. Given generator <code>g1</code>, <code>P=α*g1</code></p></li>
<li><p><strong>Sign</strong> — <code>σ = α*H(m) ∈ G2</code> (in the case of ETH 2.0)</p></li>
<li><p><strong>Verify<code>(P,m, σ)</code></strong> — if <code>e(g1, σ) = e(P, H(m))</code> return <code>true</code>.</p></li>
</ul>
<p>Elliptic curve: BLS12-381</p>
<section id="bls12-381" class="level3">
<h3 class="anchored" data-anchor-id="bls12-381">BLS12-381</h3>
<p>BLS12-381 is a pairing-friendly elliptic curve construction that is optimal for zk-SNARKs at the 128-bit security level.</p>
<p>Barreto-Naehrig (BN) curves are a class of pairing-friendly elliptic curve constructions built over a base field <code>Fp</code> of order <code>r</code>, where <code>r≈p</code>. It is possible to construct a new BN curve that targets 128-bit security by selecting a curve closer to <code>p≈2^(384)</code>. However, the larger group order <code>r</code> impairs the performance of multi-exponentiation, fast fourier transforms and other cryptographic operations.</p>
<p>Barreto-Lynn-Scott (BLS) curves are a slightly older class of pairing-friendly curves which now appear to be more useful for targeting this security level. Current research suggests that with <code>p≈2^(384)</code>, and with an embedding degree of 12, these curves target the 128-bit security level.</p>
</section>
<section id="private-and-public-keys-1" class="level3">
<h3 class="anchored" data-anchor-id="private-and-public-keys-1">Private and public keys</h3>
<p>The private/secret key (to be used for signing) is just a randomly chosen number between <code>1</code> and <code>r−1</code> inclusive. We’ll call it <code>pk</code>.</p>
<p>The corresponding public key is <code>P=[pk]g1</code>, where <code>g1</code> is the chosen generator of <code>G1</code>. That is, <code>g1</code> multiplied by <code>pk</code>, which is <code>g1</code> added to itself <code>pk</code> times.</p>
<p>The discrete logarithm problem means that it is unfeasible to recover <code>pk</code> given the public key <code>P</code>.</p>
</section>
<section id="signing" class="level3">
<h3 class="anchored" data-anchor-id="signing">Signing</h3>
<p>One can sign the message by calculating the signature <code>σ=[pk]H(m)</code>. That is, by multiplying the hash point by our secret key. But what is <code>H</code>?</p>
<p>To calculate a digital signature over a message, we first need to transform an arbitrary message (byte string) to a point on the <code>G2</code> curve. The initial implementation in Eth2 was “hash-and-check”:</p>
<ol type="1">
<li>Hash your message to an integer modulo <code>q</code></li>
<li>Check if there is a point on the curve with this <code>x</code>-coordinate. If not, add one and repeat</li>
<li>Once you have a point on the curve multiply it by the <code>G2</code> cofactor to convert it into a point in <code>G2</code>.</li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://3327.io/documents/research/posts/https:/miro.medium.com/max/1400/1*IpmIdJLR36iHnOHq1OqHnw@2x.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">bls signing</figcaption><p></p>
</figure>
</div>
</section>
<section id="verification" class="level3">
<h3 class="anchored" data-anchor-id="verification">Verification</h3>
<p>Given a message <code>m</code>, a signature <code>σ</code>, and a public key <code>P</code>, we want to verify that it was signed with the <code>pk</code> corresponding to <code>P</code>. The signature is valid if, and only if, <code>e(g1,σ)=e(P,H(m))</code>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://3327.io/documents/research/posts/https:/miro.medium.com/max/1400/1*CyqBtsUTnME5R4QTU_ZZCg@2x.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">bls verification</figcaption><p></p>
</figure>
</div>
</section>
<section id="aggregation" class="level3">
<h3 class="anchored" data-anchor-id="aggregation">Aggregation</h3>
<p>A really neat property of BLS signatures is that they can be aggregated, so that we need only two pairings to verify a single message signed by <code>n</code> parties, or <code>n - 1</code> pairings to verify <code>n</code> different messages signed by <code>n</code> parties, rather than <code>2n</code> pairings you might naively expect to need. Pairings are expensive to compute, so this is very attractive.</p>
<p>To aggregate signatures we just have to add up the <code>G2</code> points they correspond to: <code>σagg=σ1+σ2+...+σn</code>. We also aggregate the corresponding <code>G1</code> public key points <code>Pagg=P1+P2+...+Pn</code>.</p>
<p>Now the magic of pairings means that we can just verify that <code>e(g1,σagg)=e(Pagg,H(m))</code> to verify all the signatures together with just two pairings.</p>
</section>
<section id="bls-verification-in-solidity" class="level3">
<h3 class="anchored" data-anchor-id="bls-verification-in-solidity">BLS verification in Solidity</h3>
<p>Below shows an example Solidity function that verifies a single signature. EIP-197 defined a pairing precompile contract at address <code>0x8</code> and requires input to a multiple of <code>192</code>. This assembly code calls the precompile contract at address <code>0x8</code> with inputs.</p>
<pre class="solidity"><code>  // Negated genarator of G2
  uint256 constant nG2x1 = 11559732032986387107991004021392285783925812861821192530917403151452391805634;
  uint256 constant nG2x0 = 10857046999023057135944570762232829481370756359578518086990519993285655852781;
  uint256 constant nG2y1 = 17805874995975841540914202342111839520379459829704422454583296818431106115052;
  uint256 constant nG2y0 = 13392588948715843804641432497768002650278120570034223513918757245338268106653;


function verifySingle(
    uint256[2] memory signature, \\ small signature
    uint256[4] memory pubkey, \\ big public key: 96 bytes
    uint256[2] memory message
) public view returns (bool) {
    uint256[12] memory input = [
        signature[0],
        signature[1],
        nG2x1,
        nG2x0,
        nG2y1,
        nG2y0,
        message[0],
        message[1],
        pubkey[1],
        pubkey[0],
        pubkey[3],
        pubkey[2]
    ];
    uint256[1] memory out;
    bool success;

    assembly {
        success := staticcall(sub(gas(), 2000), 8, input, 384, out, 0x20)
        switch success
            case 0 {
                invalid()
            }
    }

    require(success, "");
    return out[0] != 0;
}</code></pre>
</section>
<section id="bls-verification-in-javascripttypescript" class="level3">
<h3 class="anchored" data-anchor-id="bls-verification-in-javascripttypescript">BLS verification in Javascript/Typescript</h3>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span id="cb6-1"><span class="kw" style="color: #003B4F;">const</span> bls <span class="op" style="color: #5E5E5E;">=</span> <span class="pp" style="color: #AD0000;">require</span>(<span class="st" style="color: #20794D;">'@noble/bls12-381'</span>)<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb6-2"></span>
<span id="cb6-3">(<span class="kw" style="color: #003B4F;">async</span> () <span class="kw" style="color: #003B4F;">=&gt;</span> {</span>
<span id="cb6-4">    <span class="co" style="color: #5E5E5E;">// keys, messages &amp; other inputs can be Uint8Arrays or hex strings</span></span>
<span id="cb6-5">    <span class="kw" style="color: #003B4F;">const</span> privateKey <span class="op" style="color: #5E5E5E;">=</span></span>
<span id="cb6-6">        <span class="st" style="color: #20794D;">'67d53f170b908cabb9eb326c3c337762d59289a8fec79f7bc9254b584b73265c'</span><span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb6-7">    <span class="kw" style="color: #003B4F;">const</span> message <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'64726e3da8'</span><span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb6-8">    <span class="kw" style="color: #003B4F;">const</span> publicKey <span class="op" style="color: #5E5E5E;">=</span> bls<span class="op" style="color: #5E5E5E;">.</span><span class="fu" style="color: #4758AB;">getPublicKey</span>(privateKey)<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb6-9">    <span class="kw" style="color: #003B4F;">const</span> signature <span class="op" style="color: #5E5E5E;">=</span> <span class="cf" style="color: #003B4F;">await</span> bls<span class="op" style="color: #5E5E5E;">.</span><span class="fu" style="color: #4758AB;">sign</span>(message<span class="op" style="color: #5E5E5E;">,</span> privateKey)<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb6-10">    <span class="kw" style="color: #003B4F;">const</span> isValid <span class="op" style="color: #5E5E5E;">=</span> <span class="cf" style="color: #003B4F;">await</span> bls<span class="op" style="color: #5E5E5E;">.</span><span class="fu" style="color: #4758AB;">verify</span>(signature<span class="op" style="color: #5E5E5E;">,</span> message<span class="op" style="color: #5E5E5E;">,</span> publicKey)<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb6-11">    <span class="bu" style="color: null;">console</span><span class="op" style="color: #5E5E5E;">.</span><span class="fu" style="color: #4758AB;">log</span>({ publicKey<span class="op" style="color: #5E5E5E;">,</span> signature<span class="op" style="color: #5E5E5E;">,</span> isValid })<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb6-12"></span>
<span id="cb6-13">    <span class="co" style="color: #5E5E5E;">// Sign 1 msg with 3 keys</span></span>
<span id="cb6-14">    <span class="kw" style="color: #003B4F;">const</span> privateKeys <span class="op" style="color: #5E5E5E;">=</span> [</span>
<span id="cb6-15">        <span class="st" style="color: #20794D;">'18f020b98eb798752a50ed0563b079c125b0db5dd0b1060d1c1b47d4a193e1e4'</span><span class="op" style="color: #5E5E5E;">,</span></span>
<span id="cb6-16">        <span class="st" style="color: #20794D;">'ed69a8c50cf8c9836be3b67c7eeff416612d45ba39a5c099d48fa668bf558c9c'</span><span class="op" style="color: #5E5E5E;">,</span></span>
<span id="cb6-17">        <span class="st" style="color: #20794D;">'16ae669f3be7a2121e17d0c68c05a8f3d6bef21ec0f2315f1d7aec12484e4cf5'</span><span class="op" style="color: #5E5E5E;">,</span></span>
<span id="cb6-18">    ]<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb6-19">    <span class="kw" style="color: #003B4F;">const</span> messages <span class="op" style="color: #5E5E5E;">=</span> [<span class="st" style="color: #20794D;">'d2'</span><span class="op" style="color: #5E5E5E;">,</span> <span class="st" style="color: #20794D;">'0d98'</span><span class="op" style="color: #5E5E5E;">,</span> <span class="st" style="color: #20794D;">'05caf3'</span>]<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb6-20">    <span class="kw" style="color: #003B4F;">const</span> publicKeys <span class="op" style="color: #5E5E5E;">=</span> privateKeys<span class="op" style="color: #5E5E5E;">.</span><span class="fu" style="color: #4758AB;">map</span>(bls<span class="op" style="color: #5E5E5E;">.</span><span class="at" style="color: #657422;">getPublicKey</span>)<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb6-21">    <span class="kw" style="color: #003B4F;">const</span> signatures2 <span class="op" style="color: #5E5E5E;">=</span> <span class="cf" style="color: #003B4F;">await</span> <span class="bu" style="color: null;">Promise</span><span class="op" style="color: #5E5E5E;">.</span><span class="fu" style="color: #4758AB;">all</span>(</span>
<span id="cb6-22">        privateKeys<span class="op" style="color: #5E5E5E;">.</span><span class="fu" style="color: #4758AB;">map</span>((p) <span class="kw" style="color: #003B4F;">=&gt;</span> bls<span class="op" style="color: #5E5E5E;">.</span><span class="fu" style="color: #4758AB;">sign</span>(message<span class="op" style="color: #5E5E5E;">,</span> p))</span>
<span id="cb6-23">    )<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb6-24">    <span class="kw" style="color: #003B4F;">const</span> aggPubKey2 <span class="op" style="color: #5E5E5E;">=</span> bls<span class="op" style="color: #5E5E5E;">.</span><span class="fu" style="color: #4758AB;">aggregatePublicKeys</span>(publicKeys)<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb6-25">    <span class="kw" style="color: #003B4F;">const</span> aggSignature2 <span class="op" style="color: #5E5E5E;">=</span> bls<span class="op" style="color: #5E5E5E;">.</span><span class="fu" style="color: #4758AB;">aggregateSignatures</span>(signatures2)<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb6-26">    <span class="kw" style="color: #003B4F;">const</span> isValid2 <span class="op" style="color: #5E5E5E;">=</span> <span class="cf" style="color: #003B4F;">await</span> bls<span class="op" style="color: #5E5E5E;">.</span><span class="fu" style="color: #4758AB;">verify</span>(aggSignature2<span class="op" style="color: #5E5E5E;">,</span> message<span class="op" style="color: #5E5E5E;">,</span> aggPubKey2)<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb6-27">    <span class="bu" style="color: null;">console</span><span class="op" style="color: #5E5E5E;">.</span><span class="fu" style="color: #4758AB;">log</span>({ signatures2<span class="op" style="color: #5E5E5E;">,</span> aggSignature2<span class="op" style="color: #5E5E5E;">,</span> isValid2 })<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb6-28">})()<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
</section>
</section>
<section id="schnorr" class="level2">
<h2 class="anchored" data-anchor-id="schnorr">Schnorr</h2>
<p>Schnorr signatures are generated slightly differently than ECDSA. Instead of two scalars <code>(r,s)</code> we use a point <code>R</code> and a scalar <code>s</code>. Similar to ECDSA, <code>R</code> is a random point on elliptic curve <code>(R = k×G)</code>. Second part of the signature is calculated slightly differently: <code>s = k + hash(P,R,m) ⋅ pk</code>. Here <code>pk</code> is your private key, <code>P = pk×G</code> is your public key, <code>m</code> is the message. Then one can verify this signature by checking that <code>s×G = R + hash(P,R,m)×P</code>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://3327.io/documents/research/posts/https:/miro.medium.com/max/1400/1*hIjYiOdjwBVqdRpa5lrJOg@2x.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">schnorr signing</figcaption><p></p>
</figure>
</div>
<p>This equation is linear, so equations can be added and subtracted with each other and still stay valid. This brings us to several nice features of Schnorr signatures that we can use.</p>
<section id="batch-validation" class="level3">
<h3 class="anchored" data-anchor-id="batch-validation">Batch validation</h3>
<p>To verify a block in Bitcoin blockchain we need to make sure that all signatures in the block are valid. If one of them is not valid we don’t care which one - we just reject the whole block and that’s it.</p>
<p>With ECDSA every signature has to be verified separately. Meaning that if we have 1000 signatures in the block we will need to compute 1000 inversions and 2000 point multiplications. In total ~3000 heavy operations.</p>
<p>With Schnorr signatures we can add up all the signature verification equations and save some computational power. In total for a block with 1000 transactions we need to verify that</p>
<pre><code>(s1+s2+…+s1000)×G=(R1+…+R1000)+(hash(P1,R1,m1)×P1+ hash(P2,R2,m2)×P2+…+hash(P1000,R1000,m1000)×P1000)</code></pre>
<p>Here we have a bunch of point additions (almost free in sense of computational power) and 1001 point multiplication. This is already a factor of 3 improvement - we need to compute roughly one heavy operation per signature.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://3327.io/documents/research/posts/https:/miro.medium.com/max/1400/1*ZVUPaZBVXs-ORSI_rrh0fw@2x.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">batch validation</figcaption><p></p>
</figure>
</div>
</section>
<section id="key-aggregation" class="level3">
<h3 class="anchored" data-anchor-id="key-aggregation">Key aggregation</h3>
<p>We want to keep our bitcoins safe, so we might want to use at least two different private keys to control bitcoins. One we will use on a laptop or a phone and another one - on a hardware wallet / cold wallet. So when one of them is compromised we still have control over our bitcoins.</p>
<p>Currently it is implemented via 2-of-2 multisig script. This requires two separate signatures to be included in the transaction.</p>
<p>With Schnorr signatures we can use a pair of private keys <code>(pk1,pk2)</code> and generate a shared signature corresponding to a shared public key <code>P=P1+P2=pk1×G+pk2×G</code>. To generate this signature we need to choose a random number on every device <code>(k1,k2)</code>, generate a random point <code>Ri=ki×G</code>, add them up to calculate a common <code>hash(P,R1+R2,m)</code> and then get <code>s1</code> and <code>s2</code> from every device <code>(si = ki + hash(P,R,m) ⋅ pki)</code>. Then we can add up these signatures and use a pair <code>(R, s) = (R1+R2, s1+s2)</code> as our signature for shared public key <code>P</code>. No one else won’t be able to say if it is an aggregated signature or not - it looks exactly the same as a normal Schnorr signature.</p>
</section>
</section>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<p>A major reason to use this new stack is that it admits efficient aggregation of many signatures into one signature which directly contributes to the scalability of ETH2.0’s security. With this transition, ECDSA signatures aren’t enough anymore as the number of signatures to verify was too big and would take too long on the average machine.</p>
<p>ETH 2.0 definies 64 committees for every block and each committee can have as many as 2048 validators, with each epoch consisting of 32 blocks. Under normal ECDSA that means 131,072 (64*2048) signatures for every block (12 sec), and 4,194,304 for every epoch (32 blocks). This means that an epoch’s worth of signatures would be 33.6 megabytes which comes to ~7.6 gigabytes per day. In this case, all of the false claims about the ETH 1.0 state-size reaching 1TB back in 2018 would be true in ETH 2.0’s case in fewer than 133 days (based on signatures alone). If every node in the network will need to verify each signature it becomes infeasible to build a scalable, sharded, blockchain.</p>
<p>As a solution to the above, signature aggregation was considered. Technically it will mean that many signatures could be verified in a batch, significantly shortening the time and resources required. ETH 2.0 makes use of the BLS signatures - a signature scheme defined over several elliptic curves that is friendly to aggregation. On the specific curve chosen, signatures are 96 bytes each. If Alice produces signature A, and Bob’s signature is B on the same data, then both Alice’s and Bob’s signatures can be stored and checked together by only storing C = A + B. By using signature aggregation, only 1 signature needs to be stored and checked for the entire committee. This reduces the storage requirements to less than 2 megabytes per day.</p>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>It will be interesting to see how blockchain clients will implement these new changes and how efficient will they be because we already concluded from the paper that the reason for switching from ECDSA is justified. We should monitor also the Bitcoin timeframe to be able to disscus more about Schnoor signatures implementation.</p>
</section>
<section id="appendices" class="level1">
<h1>Appendices</h1>
</section>
<section id="bibliography" class="level1">




</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Bibliography</h2><div id="refs">

</div></section></div> ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-39.hugo.html</guid>
  <pubDate>Fri, 04 Mar 2022 00:00:00 GMT</pubDate>
  <media:content url="https://github.com/ethereumbook/ethereumbook/raw/develop/images/simple_elliptic_curve.png" medium="image" type="image/png"/>
</item>
</channel>
</rss>
