<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>3327 Research</title>
<link>https://3327.io/documents/research/index.html</link>
<atom:link href="https://3327.io/documents/research/index.xml" rel="self" type="application/rss+xml"/>
<description></description>
<image>
<url>https://3327.io/logo.png</url>
<title>3327 Research</title>
<link>https://3327.io/documents/research/index.html</link>
<height>38</height>
<width>144</width>
</image>
<generator>quarto-1.1.163</generator>
<lastBuildDate>Sun, 12 May 2024 00:00:00 GMT</lastBuildDate>
<item>
  <title>[ERFC - 520] Deep Dive: DeFi Derivatives</title>
  <dc:creator>Andrija Raičević</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-520.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p>This research aims to fully explore and understand the current state of the DeFi derivatives market. We embark on this adventure by taking a closer look at what derivatives are, the types of derivatives in DeFi, and their difference from TradFi. By analyzing some of the most prominent derivatives protocols, and their challenges, we will be able to give a complete market overview while also proposing improvements.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Traditional finance (TradFi) and decentralized finance (DeFi) are two different approaches to financial services and transactions. Traditionally, traditional finance refers to the systems and institutions that have been in place for many years, such as banks, brokerage firms, and other financial intermediaries. Decentralized finance, on the other hand, is a newer approach that uses blockchain technology and smart contracts to enable financial transactions and services without intermediaries.</p>
<p>One key difference between TradFi and DeFi is the level of centralization. In traditional finance, financial institutions are typically highly centralized, with a small number of large banks and other companies controlling much of the industry. In contrast, decentralized finance is based on decentralized networks and protocols controlled by many different participants rather than a single central authority.</p>
<p>Another difference between the two is the level of transparency and accessibility. In traditional finance, financial transactions and information can be opaque, with only certain parties having access to specific data and information. On the other hand, decentralized finance transactions and information are typically recorded on a public blockchain, which is transparent and accessible to anyone with the right tools.</p>
<p>Decentralized Finances have been an emerging market for the past three years. It has been spanning and touching every aspect of the Web3 world, resulting in the boom of the market and the rise of many different protocols. These protocols aim to replace Traditional Finances with new, cutting-edge technologies whose sole purpose is to bring accessibility, decentralization, and custody while incentivizing users and staying competitive.</p>
<p>The DeFi market expansion resulted in many TradFi services being bridged to distributed ledger technology. Making services more transparent than in TradFi and open to everyone. Here are some of the most notable DeFi market categories in terms of Total Value Locked[1]:</p>
<ul>
<li>Exchanges</li>
<li>Applications</li>
<li>Lending &amp; Borrowing</li>
<li>Stablecoins and Stableassets</li>
<li>Insurance</li>
<li>Prediction Markets</li>
<li>Indices</li>
<li>Derivatives</li>
</ul>
<p>The market is growing, and the protocols are creating niches in which they operate. However, these categories remain broad, and the borders between them remain blurred.</p>
<p><img src="https://3327.io/documents/research/posts/https:/lh3.googleusercontent.com/dMN57r8t97l1T1eQUqSA2yH-sGlmiCZ3PD3j_MyGCL0QDoswmPf6wW8ker9Wb1RQopGhfOfbCN_QkxYg6wAl7nuJ4KJRvgu4MyMWBnBd_FkRM3Kd5rruI6SsvbWAlfok-81_fXPUfKx1kSKu8dllfFzvBst21b8tghE7Jl4mqjhJ-QPvUEBrTHEvJkHKVw.png" class="img-fluid"></p>
<p>Source: Cryptorank.io</p>
<p>In this research, we will focus on DeFi derivatives as one of the new and unconquered niches. However, before we do that, let’s start small and explain what derivatives are and how they are used in DeFi, the current state of DeFi derivatives, the challenges they face, and progress to exploring possible improvements and new ideas.</p>
<section id="derivatives-and-defi" class="level2">
<h2 class="anchored" data-anchor-id="derivatives-and-defi">Derivatives and DeFi</h2>
<p>Derivatives [2] are financial instruments whose value depends on the underlying asset’s price. They allow investors to expose themselves to market conditions by choosing desired financial instruments. Derivatives can be used either to take on risk and fish for higher returns or to protect the value of your current position. You can get them over the counter or through exchanges.</p>
<p>How does this translate from TradFi to DeFi? DeFi derivatives are simply derivatives built on blockchain technology and operate within the DeFi ecosystem. They solve the same problem as TradFi derivatives. However, their underlying presumptions and solutions are different. Here are four significant differences:</p>
<p><strong>Intermediation</strong> - In TradFi, financial intermediaries are banks and brokerage firms, which are centralized systems that also use human capital to conduct these services. While in DeFi, Code is Law, and smart contracts are the intermediaries and the ones automating the process. The assets are locked into smart contracts, which execute the wanted action. This action can be borrowing derivatives, staking tokens, swapping them, etc.</p>
<p><strong>Custody</strong> - Centralized platforms act as custodians of your assets, making it hard to manipulate them as you wish, especially when it comes to moving higher amounts. Here is where DeFi comes into play, your assets are stored in your wallet at all times, giving you complete control over them, and allowing you to act as you please. To draw a parallel, withdrawing a significant amount from the bank account could take days or trigger their software to flag your account.</p>
<p><strong>Market efficiency</strong> - New technology gives access to more people, increases choice, and decreases market friction, aka transaction costs. Although DeFi derivatives provide access to broader audiences and don’t discriminate based on credit score and other metrics used to evaluate borrowers’ ability to pay back the loan, it falls behind Traditional Finance in terms of choice and market friction. Simply put, the derivatives market is still developing, and there are fewer possibilities in terms of derivatives. Currently, they revolve around options, perpetual swaps, and synthetic assets but face problems with liquidity. Once more users provide liquidity, there will be fewer transaction fees, meaning that DeFi derivatives will operate on Economies of Scale. We will discuss it later in the research.</p>
<p><strong>Collateralization</strong> - In DeFi, anyone can access a particular service provided he has enough assets to offer as collateral. How this works with derivatives is that when you want to borrow an asset, you must provide collateral of at least 150% of the initial value. This collateral is usually a stablecoin or a protocol’s native token that is exchanged for the financial instrument of your choice. Collateral assets provide liquidity to the pool and earn yield while locked, and if their value falls below 150%, the borrower faces liquidation and has to rebalance their position. This way, everyone can access derivatives without needing good credit scores or having the protocol rely on safety nets (such as banks).</p>
</section>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p>In this research, we will explore if the problems and shortcomings related to forward contracts in TradFi can be solved using blockchain technology and basic DeFi operating principles. We will do so by</p>
<ul>
<li>Explaining the concept of derivatives in DeFi</li>
<li>Looking at the most prominent protocols in the DeFi derivatives niche</li>
<li>Analysing their commonalities and challenges they face</li>
<li>Propose a solution of our own with a description of the technical side as well as user experience</li>
</ul>
<p>Our goal is to show that with a right platform forward contracts can be efficient and fully-utilized while their shortcomings can be fully mitigated using DeFi. We also want to show that they can be used to pay real-world assets in installments.</p>
</section>
<section id="explorative-research" class="level1">
<h1>Explorative Research</h1>
<p>This section will describe five derivative types in TradFi and DeFi. Moreover, we will also discuss their competitive advantages in both worlds. [3]</p>
<section id="forwards" class="level2">
<h2 class="anchored" data-anchor-id="forwards">Forwards</h2>
<p>Forward contracts represent a non-standardized financial instrument (derivative) between two parties that want to buy or sell an asset at a predetermined price in the future. They are fully customizable and are different from futures contracts because they are not traded on exchanges. Two parties generally must agree on the specified price, maturity date, and a specific commodity to be delivered. [4]</p>
<p>They are used for hedging against price changes, which is why big corporations are trading with them. Still, since they are not standardized, there is always a counterparty default risk. There aren’t any web3 protocols providing forward contracts. We will use this as a base and an opportunity for our research. Let’s proceed and get a complete overview of the rest of derivatives.</p>
</section>
<section id="options" class="level2">
<h2 class="anchored" data-anchor-id="options">Options</h2>
<p>Options are the most widely used financial instruments since they offer the buyer the right to buy or sell the underlying asset without the obligation of actually doing so.</p>
<p>There are two types of options Call and Put. The Call gives you the right to buy, while Puts give you the right to sell. All options have maturity dates at which the option expires and after which it cannot be exercised.</p>
<p>Depending on when the option can be exercised, there are two types of options, American and European. American options can be exercised at any date before expiration and usually have stocks as an underlying asset. In contrast, European options can be exercised only on the maturity date and use indices (i.e., SP500 pairs as underlying assets). Let us take a look at the DeFi protocol that offers options trading. [5]</p>
<section id="opyn" class="level3">
<h3 class="anchored" data-anchor-id="opyn">Opyn</h3>
<p>Opyn is a DeFi options trading platform operating on Ethereum, Polygon, and Avalanche with $56.8M in Total Value Locked. It allows users to create, buy and sell options. It is also the first options trading platform in DeFi.</p>
<p>Its primary token is OSQTH (OpynSqueeth) which acts as the index that follows the price of ETH-squared (ETH^2). OSQTH is a mix of options, and perpetual swaps called power perpetual. It follows the squared price of an underlying asset without an expiry date, limiting the downside risk while offering a better return than a 2x leveraged Eth position. [6]</p>
<p><img src="https://3327.io/documents/research/posts/https:/lh6.googleusercontent.com/FzQZ0n7bkPlB0urHghfKRj-rjZTDIvbQyZgR6nt_dQ89OjPHqO3w8Y-VLVlSfTzYeiPUjh8ghTQuw2R5Io0-EVl-XVRBz5A4vp5oEiJ1V3q1OTkCr9hBil-SsdoGud4oLA1PAaxy0C7L3kI1PruRQYMBHhFjk4TaoZpR5tcbQVXky8YbfXAUBaYPasst4w.png" class="img-fluid"></p>
<p><img src="https://3327.io/documents/research/posts/https:/lh5.googleusercontent.com/ClZr6OOyTBvFKoH4PycLuvwqceXACwoXDs8vDu1fqbyycj_KmA4g5HNL7J52aSP4Zx7lMs6liuR3UqjY213ze2pcOctN8ErY84fVjnwl_iKNFRO3H57Ioo4uaSFnb7tUlgwmMEcKt4I1CiHyDPedCfYe8IASzwxB7486sNnJlhFOegsFdCaFyWajYA3-ag.png" class="img-fluid"></p>
<p>Source: Opyn.co</p>
<p>Generally, DeFi platforms require collateral for entering the position. The cool thing about Opyn is that their collateral ratio is 0% for the Long Squeeth position, which means that the investors have downside protection with unlimited upside. However, shorting Squeeth requires a collateral ratio of 150%, which is an average in DeFi.</p>
<p>Aside from Long and Short Squeeth, Opyn offers a ‘Crab’ strategy: A position betting on the ETH price moving inside a proposed interval. This is an excellent way of short-term investing during market stagnation since this is a <a href="https://www.investopedia.com/terms/d/deltaneutral.asp#:~:text=Delta%20neutral%20is%20a%20portfolio,of%20the%20position%20to%20zero.">delta-neutral</a> position. Something between Bull and Bear, as it seems.</p>
<p><img src="https://3327.io/documents/research/posts/https:/lh6.googleusercontent.com/2Yda8WXSCnWrg3KigHubX_A78QHBTK14y0lDev8wr-1QKhHi_ag1eR4sZvCiJ8on6nlpqZAuUQ9tgU1sVEKH-OqAs7h18y4mrV95ZlVX6JTCWYF2mgVna-McEx-LmwrhST4EmB3cz7UilGDT5WTFctFE-u4cdUe1L8uu71Zn_RbWUEFuT_91jAhHoswCuA.png" class="img-fluid"></p>
<p>Source: Opyn.co</p>
<p>Our opinion:</p>
<p>Opyn is the most prominent options trading protocol in DeFi. However, Opyn and the rest of the options trading platforms need more options than they offer their traders. As of now, Opyn offers long and short positions on OSQTH as well as Crab strategy.</p>
<p>To boost the adoption of the DeFi Options niche, protocols need to extend their services to creating and trading options spreads. Options spreads are strategies where investors buy options with the same underlying asset but with different strike prices, expiration dates, or both [7][8]. Spreads allow users to protect their assets from potential market volatility while creating opportunities for capturing higher profit margins. So far, Hegic offers options spreads. [9]</p>
<p>Offering a wider choice of options would give investors more profit opportunities, resulting in more capital inflow and, thus, more liquidity. Emphasis on liquidity as the biggest concern in the market right now.</p>
</section>
</section>
<section id="futures" class="level2">
<h2 class="anchored" data-anchor-id="futures">Futures</h2>
<p>Futures require the person to buy or sell an underlying at the specified date regardless of favorable market conditions. In other words, parties agree on the price of an asset paid which will be delivered in the future. They are used for hedging or speculation, just like options. Also, unlike forwards, they are fully standardized financial instruments traded on exchanges.</p>
<p>Futures carry greater risk for investors than options since they must be exercised at the maturity date, which can result in potential losses from the drop in value of the underlying asset. This risk is almost negligible with options since the investors can opt not to exercise the option and only lose the premium they paid for acquiring it.</p>
</section>
<section id="perpetual-swaps" class="level2">
<h2 class="anchored" data-anchor-id="perpetual-swaps">Perpetual Swaps</h2>
<p>Perpetual Swaps are very similar to futures contracts. However, what distinguishes them is that they do not have an expiration date. This implies that investors can open positions and close them as they please without worrying about the maturity date.</p>
<p>Just like futures, perpetual swaps offer investors trading opportunities without directly owning the underlying asset (typically cryptocurrencies, commodities, or currency pairs) while allowing them to open positions bigger than their trading capital. Let’s look at the two most prominent examples of perpetual trading platforms. [10]</p>
<section id="dydx" class="level3">
<h3 class="anchored" data-anchor-id="dydx">dYdX</h3>
<p>We covered perpetual swaps and are now covering one of the first protocols to offer them. dYdX has $437.16M in Total Value locked, making it the second biggest Derivatives platform.</p>
<p>Aside from perpetuals, dYdX is an Order Book DEX that offers borrowing, lending, and spot trading with 0% fees for trade volume under $100K, making them one of the biggest competitors in the industry. The collateral ratio for borrowing is 125%; however, the deposited collateral earns interest. Perpetuals can be 20x leveraged. [11]</p>
<p>Aside from that, they operate on Ethereum and have their own token, DYDX, which is used for governance. Users holding DYDX have voting rights and can participate in the protocol’s decision-making.</p>
</section>
<section id="gmx" class="level3">
<h3 class="anchored" data-anchor-id="gmx">GMX</h3>
<p>The largest Decentralized Perpetuals platform, operating on Arbitrum and Avalanche with over $466M TVL, is GMX. Unlike dYdX, GMX is an AMM that offers its users 50x leveraged trading.</p>
<p>What also makes this platform competitive is its low fees, pool transparency, and native tokens GMX and GLP. GMX is used for governance, and holders earn 30% of protocol fees. GLP is the liquidity provider token, generating lenders 70% of protocol fees. It is also an index of pooled assets that serve as the protocol’s <a href="https://portfolio.nansen.ai/dashboard/gmx?chain=ARBITRUM">Proof of Reserves</a>. [12]</p>
<p><img src="https://3327.io/documents/research/posts/https:/lh3.googleusercontent.com/-qx5CefkGl3e31dV2p0ko9__rlSrM9svnWzomTVew2k0I7Xfmf5ZgGsypjelbI-1MF-cI001YesuMdgQcGmJsAPl_37O380CVaxJD39ToNi01yoHYXfj683k1VB8KP_8ef0CJP_GdP1byvuOzrvrCynwRFtH_dPYnDsg_eg0AFb9SpYHHPWztIKFX39g4w.png" class="img-fluid"></p>
<p>Our opinion:</p>
<p>Perpetual swaps are the most popular and developed derivatives in DeFi as they are not constrained by the maturity date and offer good terms in the sense of leverage. These protocols have greatly captured the market share by offering low transaction fees, high leverage, and transparency. One thing that gives GMX the edge over dYdX is that GMX is</p>
<p>AMM-based and not Order Book. Liquidity is essential for users that want exposure to assets with low trading volumes. While Order Book is still better when there is liquidity as users match each other’s trades, AMMs are a better way of providing liquidity to otherwise illiquid pairs. [13]</p>
</section>
</section>
<section id="synthetics" class="level2">
<h2 class="anchored" data-anchor-id="synthetics">Synthetics</h2>
<p>These derivatives are new to crypto but not necessarily unique in Traditional Finance. Synthetics are assets that track the value or performance of the underlying asset or combinations of assets. In the DeFi sense, synthetics can also be considered tokenized representations of different types of assets. Users can bet for or against these assets by entering long or short positions.</p>
<section id="synthetix" class="level3">
<h3 class="anchored" data-anchor-id="synthetix">Synthetix</h3>
<p>Synthetix is a decentralized platform where users can mint and trade synthetic assets. These assets are called Synths and can be either Regular Synths (long position - sSynth) or Inverse Synths (short position - iSynth). As previously mentioned, users can tokenize real-world assets such as fiat, crypto, indices, commodities, etc. Each tokenized asset is ERC20. [14]</p>
<p>The protocol has a collateralization ratio of 750%, which is exceptionally high. Stakers get flagged for liquidation when the CR falls below 200% giving them three days to rebalance it. The native token is SNX which is also used for governance purposes. The governance scheme is very <a href="https://synthetix.io/governance">delicate</a>; however, it all comes down to community members staking SNX and choosing the next steps for the protocol, such as target collateral, liquidation ratio, and staking rewards.</p>
<p>Synthetic is available on both Ethereum and Optimism, but users are encouraged to use Optimism since the fees are significantly lower. As of now, the Total Value locked is at $308.93M.</p>
<p>Our opinion:</p>
<p>While Synthetix protocol is the largest synthetic assets platform in Web3, it could be better. The user experience and all the loops that the user has to jump through to borrow the synthetic asset make it unappealing for mass adoption. Also, the protocol only offers a few synthetic assets to choose from while maintaining a very high collateral ratio. Mirror protocol, for example, provided many more assets to choose from with a collateral ratio five times lower than Synthetix’ (150%) but unfortunately blew up with the Terraform Labs incident. [15][16]</p>
<p>So far, there aren’t any tokenized ETFs in the space, so creating a synthetic ETF could bring diversity and increase choice in the DeFi Derivatives market.</p>
</section>
</section>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<p>Every project or protocol tries to distinguish itself on the market and bring something new and liberating. However, while doing this research, we noticed a pattern of common resemblances and challenges:</p>
<p><strong>Governance</strong> - All protocols have native tokens that can be staked for voting rights and/or liquidity, providing rewards. These voting rights are put to use when the community proposes protocol improvements (IP). Those improvements usually target LP rewards, collateralization ratio, availability of different asset pairs, etc. It is a good idea to have the community vote on the future aspects of the protocol’s path.</p>
<p><strong>Overcollateralization</strong> - Speaking of collateral, most borrowing and lending protocols like to keep safe at around 150% CR. Derivatives, in general, are riskier and should be handled by more seasoned investors/traders. Still, DeFi is all about accessibility, so the middle ground is found at high CRs, such as 750% in Synthetix’s case. This is very unappealing for investors looking to enter the DeFi derivatives market, as it shifts most of their attention away from following their portfolio to monitoring the collateral and thinking whether they should rebalance it. TradFi has the edge over DeFi, simply because the banks take a mortgage or fall back on government safety nets in case of runs.</p>
<p><strong>Transparency</strong> - This has been a relatively common topic lately, with many (centralized) crypto exchanges failing and people wanting to know what is happening with their assets. More and more DeFi protocols know this is a differentiating factor. Even though they may not be custodial, they are nevertheless setting up their Proofs of Reserve to provide full transparency to the user. The PoRs are essential (especially to AMM-based protocols) in preventing illiquidity and potential bankruptcy. Moreover, the Proof of Reservers was highly overlooked in the recent year, and many protocols failed to deliver theirs, setting themselves up for a potential run-on. Good examples are Celsius and FTX.</p>
<p><strong>Transaction-related costs</strong> - Slippage and protocol fees are variable costs with every transaction. Part of the protocol fees is paid out to liquidity providers or miners, while the other represents protocol revenue. Protocols aim to achieve Economies of Scale by charging low fees to many users. This way, they attract more users who bring in even more liquidity. Looking at GMX and dYdX, it is working (GMX - 0.1% trading fee, dYdX - 0% fees under $100k trading volume). TradFi has many fees for its services, and almost all transactions include a small fee. DeFi is trying to minimize this. However, there is still a long way to go. For example, Polygon charges low fees but bridging your ERC20 to its mainnet will still cost you money.</p>
<p><strong>Leverage</strong> - Finally, and most importantly, everybody loves a good gamble, and if it is not a gamble for you, you love it even more. Leverage allows an investor to control more capital than they initially invested. This is done by borrowing money from the protocol’s liquidity pool to magnify returns on investment potential. However, this also means that you stand to lose more. By now, it is a standard for the protocol to offer at least 20x leverage. GMX is doing 50x. However, some protocols offer 100x leverage. [17]</p>
<section id="fast-forwards---our-solution" class="level2">
<h2 class="anchored" data-anchor-id="fast-forwards---our-solution">Fast Forwards - Our Solution</h2>
<p>Researching the space, we came across many platforms offering services that mix options, futures, and perpetuals but not forwards. This is why we decided to propose our solution called Fast Forwards.</p>
<p>Fast Forwards is a platform (marketplace) that combines derivatives, NFTs, and yield rewards to provide users with forward contract services. Users can buy or sell their assets at a predetermined price on a specified date without the risk of a counterparty default. How does it work?</p>
<p>Let’s say you are a buyer and want to own an NFT but cannot immediately pay its total amount, or you are an NFT holder that wants to sell their NFT but wants to earn passive income while waiting for the NFT to find a buyer. This is where forwards come into play.</p>
<p>Buyers can choose an NFT from our marketplace for whose price they believe will increase and get a forward contract. This forward contract requires the buyer to deposit only a fraction of the prespecified price to reserve the NFT rights to themself. The deposit is locked into the smart contract that requires periodic installments plus interest until it reaches the prespecified value of the NFT. When it reaches the value on the specified date, the NFT is transferred to the buyer. This directly eliminates the problem all DeFi derivatives protocols face, which is over-collateralization.</p>
<p>On the other hand, the seller of the NFT believes that the price of the NFT will decrease and puts it up for sale, hoping to earn a higher premium. When the NFT finds its buyer, it is staked and earns interest yield while locked into the smart contract. The seller earns the total prespecified value plus the accumulated passive income when the forward contract has matured.</p>
<p>In case of not meeting the refinancing requirements of the forward contract (carried out in stablecoins), the buyer faces liquidation. The interest he paid is kept and split between the protocol and the staker, acting as protocol revenues and the staker’s rewards.</p>
<p>Part of the revenue is stored in a reserve pool, which is used to buy and compensate liquidity providers until their NFTs find a match. This is where the community comes into play. Following the successful models of previous protocols, we would issue our governance tokens so that the users can vote on improvement proposals, fees, staking rewards, etc.</p>
<p>Here is the visual representation of the architecture behind Fast Forwards done in Machinations with the help of our fellow researcher Aleksandar Damjanovic. Moreover, here is the <a href="https://my.machinations.io/d/fast-forwards/96cbeb63804d11eda2330626ff1c9bc8">link</a> to the full simulation.</p>
<p><img src="https://3327.io/documents/research/posts/https:/lh6.googleusercontent.com/7R3hCTYC83y19vv89o8CYpo9aY9zQdCHw-9L01IbrUsj6vCQIXss1UMNpx6DUQgq7UoPdvRBvoeg-pLNUr6gQ75u5rZr7FR_IRhziX2j-3myh1oCwbZtcrg0wszXTEkVbl-Qr3PU-UqyXvQle8IisU-VPzoZ3B8H1LcaKwUvAf7bwbun954jvmz1ic7B4w.png" class="img-fluid"></p>
<p>In the short term, the focus is to allow buyers to acquire NFTs through installed payments while sellers earn yield. The concept is based on the Order Book matching system, and this way, we are solving the counterparty default risk by limiting the default possibilities only to the buyers’ side. If the buyer defaults, the sellers still profit and get their NFTs unstaked, making their expected losses equal to zero. This is how DeFi solves the main problem TradFi forwards face.</p>
<p>Looking long term, we expect NFTs to be adopted globally as proof of ownership. This would open the possibility of our platform providing real-asset trading services, such as buying and selling real estate through installed payments on the blockchain with minimal risk.</p>
<p>This is the way to make DeFi permissionless and trustless, and accessible to everyone without even using the over-collateralization as the rest of DeFi Derivatives protocols.</p>
</section>
<section id="risk-and-challenges" class="level2">
<h2 class="anchored" data-anchor-id="risk-and-challenges">Risk and Challenges</h2>
<p>We covered principles on which most platforms operate. However, users should know the risks and challenges associated with Fast Forwards and DeFi derivatives. These include:</p>
<p><strong>Counterparty risk</strong> - In traditional finance, derivatives contracts are typically executed and settled through a clearinghouse, which acts as a middleman and helps to reduce counterparty risk. In DeFi, derivatives contracts are generally executed and paid directly between the user and the platform, which means that users are at risk of defaulting on their obligations. As previously mentioned, Fast Forwards mitigates the seller’s side default risk. However, buyers of the NFTs should carefully consider if they can pay out the whole NFT before entering the long forward position.</p>
<p><strong>Liquidity risk</strong> - Many DeFi derivatives are traded on decentralized exchanges, which can have lower liquidity than traditional centralized exchanges, especially if they are Order Book based. This can make it more difficult for users to buy or sell their positions, especially in times of high volatility, where you want to move assets quickly. A key characteristic of NFTs is that they are illiquid and Order Book based, which could pose a threat to Fast Forwards in the early stages of our platform/marketplace. This can be solved by finding a chain that offers the lowest transaction fees and minimizing the discrepancy between the interest the buyers are paying, and the stakers are receiving. Taking a revenue cut to attract users from both the supply and the demand side.</p>
<p><strong>Regulatory risk</strong> - The DeFi space needs to be more regulated, meaning users have a lower level of protection than traditional finance. However, forwards are not standardized financial instruments, making our platform even more attractive as we wouldn’t have to jump through regulatory hoops.</p>
<p><strong>Technical risk</strong> - Protocols are exposed to attacks that might compromise their users’ assets. No one is bulletproof, which is why we must have smart contract audits to ensure the safety of the assets. Here is a <a href="https://defillama.com/hacks">tracker</a> for all the hacks that happened recently.</p>
<p><strong>Wash trading risk</strong> - We must also consider that before being listed, NFTs could be overpriced through wash trading. This is why we must guarantee fair prices to the buyers of our platforms. We will further explore whether this should be done through our Wash Trading Tool or by letting the buyers bid for NFTs on our platform. A more logical solution would be to let the market sort itself without any intermediation from us.</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>In this research, we fully explored the DeFi derivatives market, from what derivatives are and what platforms utilize them in DeFi to proposing our solution and exploring its challenges. We believe this vast market has many opportunities to create new niches. We saw the opportunity to bridge the most overlooked derivatives, forwards, from TradFi to DeFi, as this hasn’t been done yet. The next steps would be to discuss the architecture of Fast Forwards and explore the product further by challenging it with discussion. If the idea keeps making sense, the next step would be creating a Proof of Concept. Stay tuned.</p>
</section>
<section id="bibliography" class="level1">
<h1>Bibliography</h1>
<p>How to Defi: Beginner</p>
<p>How to Defi: Advanced</p>
<p>[1] https://cointelegraph.com/explained/what-is-total-value-locked-tvl-in-crypto-and-why-does-it-matter</p>
<p>[2] https://www.cfainstitute.org/en/advocacy/issues/derivatives#sort=%40pubbrowsedate%20descending</p>
<p>[3] https://www.investopedia.com/terms/d/derivative.asp</p>
<p>[4] https://www.investopedia.com/terms/f/forwardcontract.asp</p>
<p>[5] https://www.investopedia.com/terms/e/europeanoption.asp</p>
<p>[6] https://medium.com/opyn/squeeth-primer-a-guide-to-understanding-opyns-implementation-of-squeeth-a0f5e8b95684</p>
<p>[7] https://www.sofi.com/learn/content/options-spread/</p>
<p>[8] https://www.schwab.com/learn/story/reducing-risk-with-credit-spread-options-strategy</p>
<p>[9] https://www.hegic.co/</p>
<p>[10] https://jamesbachini.com/defi-derivatives/</p>
<p>[11] https://dydx.exchange/</p>
<p>[12] https://gmx.io/#/</p>
<p>[13] https://mvpworkshop.co/blog/order-book-vs-amm-which-one-will-win/</p>
<p>[14] https://synthetix.io/synths</p>
<p>[15] <a href="https://savagecorner.medium.com/understanding-mirror-protocol-216550826b08#:~:text=Mirror%20Protocol%20charges%201.50%25%20of,closed%20(borrow%20is%20repaid).">https://mirrorprotocol.app/#/trade</a></p>
<p>[16] https://www.kraken.com/learn/what-is-mirror-protocol-mir</p>
<p>[17] https://coinmarketcap.com/alexandria/article/a-deep-dive-into-leverages-in-defi-borrowing-margin-trading-leveraged-tokens-and-options-finnexus</p>


</section>

 ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-520.hugo.html</guid>
  <pubDate>Sun, 12 May 2024 00:00:00 GMT</pubDate>
  <media:content url="https://lh3.googleusercontent.com/dMN57r8t97l1T1eQUqSA2yH-sGlmiCZ3PD3j_MyGCL0QDoswmPf6wW8ker9Wb1RQopGhfOfbCN_QkxYg6wAl7nuJ4KJRvgu4MyMWBnBd_FkRM3Kd5rruI6SsvbWAlfok-81_fXPUfKx1kSKu8dllfFzvBst21b8tghE7Jl4mqjhJ-QPvUEBrTHEvJkHKVw.png" medium="image" type="image/png"/>
</item>
<item>
  <title>[ERFC - 409] Minty - Massive off-chain minting with verifiable on-chain commitments</title>
  <dc:creator>Aleksandar Veljković</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-409.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p>Utilizing Blockchain comes with big limitations when it comes to storing a larger number of documents on the chain. Another problem arises when a large number of documents must be stored on the chain with minimal delay - real-time. In those cases, the time and financial costs may become overwhelming. This research aims to find the solution for this issue by combining off-chain issuing techniques and on-chain commitments to maximize throughput while minimizing costs from the number of transactions required to store the commitments. The solution is formulated as a hybrid (on-chain/off-chain) protocol called Minty.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>While higher utilization of Blockchain in formerly pure Web 2.0 use-cases is a trend, some obstacles prevent a smooth transition to Web 3.0. Most of those issues are known scalability issues, combined with high transaction costs. Two scalability issues closely related to the costs of using Blockchain in business are the number of transactions that could be processed in a second (TPS) and the size limit of the transaction. The TPS metric can easily trick the user into thinking that 1,000s of transactions per second would mean that he or she can submit 1,000 transactions and expect them to be included in a block after a one-second delay. Unfortunately, that assumption would be wrong, and we can prove that with a simple counter-example. Let us assume that TPS is 10,000 transactions, ten times more than the user needs. Although Blockchain protocols could indeed process 10,000 transactions per second, there could be at least 9,001 other transactions from different users waiting to be accepted. In this case, it is impossible to have 10,001 or more transactions in one block, so at least one transaction will have to wait for the next block - breaking the one-second expectation. The last nail for this assumption is the requirement to have all transaction nonces ordered correctly. If one sends 1,000 correctly ordered transactions to the miners, there are no guarantees that the miners will sort them correctly, leaving transactions out of order for the next block. As the Blockchain becomes more utilized, the issue will become more severe. To make the situation worse, some transactions may offer better gas prices than others, prioritizing them and delaying other transactions even further.</p>
<p>Another issue is submitting 1,000 transactions on an EVM blockchain, which requires at least 21,000 gas per transaction. Those amounts may quickly add up costs and disincentivize further use of Blockchain (at least use of mainnet).</p>
<p>The main question is how realistic it is to have a use case where it is required to execute 1,000s of transactions in a short time. The answer is not clear as the question is not correctly formed. If use cases, for some reason, specifically require 1,000s of separate transactions to be executed, then there is no better solution than waiting for faster blockchains. A better question might be how realistic it is to have a use case where it is required to write 1,000s of data blocks on Blockchain often. The answer might be - not a lot, but the numbers will quickly rise as soon as the more efficient solution for performing the task appears. In that case, it becomes reasonable to investigate the possibilities of having much fewer transactions than the number of data blocks and explore off-chain solutions, such as ZK proofs and signatures, to reduce the costs of writing on Blockchain.</p>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p>This research will focus on a generic example problem, minting 1,000s of generic documents in short intervals, which can be easily specialized for any use case requiring minting high volumes of data in a short time. The following sections will also present a concrete example of a real-world use case.</p>
<p>Before we get into details, we shall first define some basic assumptions. The worst-case scenario is putting the data of each document on Blockchain in separate transactions. The more reasonable scenario is writing documents in batches of <embed src="https://latex.codecogs.com/svg.latex?n" title="n" class="img-fluid"> per transaction. Let us assume that a document consists of <embed src="https://latex.codecogs.com/svg.latex?k" title="k" class="img-fluid"> bytes32 elements. The minimum gas required to run a transaction is 21,000 gas and 2,000 more to store one <code>bytes32</code> element. Another restriction is the upper limit of the gas amount per block, which is 30,000,000 on Ethereum. Assuming a very farfetched case where:</p>
<ul>
<li>TPS is 1,000 (currently much lower)</li>
<li>One user gets to have all transactions in all blocks until the document storing is complete (possible only on private chains)</li>
<li>Every document consists of only five <code>bytes32</code> elements (a reasonable amount of data)</li>
<li>One transaction contains 30 documents (reasonable limitation)</li>
</ul>
<p>The number of transactions in a block would be ~93, which enables storing only 2790 documents per second. On the other hand, having a low gas price of 10 gwei, for 30,000,000 gas, the cost would be 0.3 native coins. On Ethereum, with the price of $1500, the cost would be 0.3 * $1500 = $500. Executing the same transaction on Polygon L2, the price would be only 0.7 * $1 = $0.7. This is the price for having 2790 documents stored on-chain under pretty unreal circumstances. To store all 100,000 documents, the total cost would be ~12 coins ($18000 on Ethereum and $12 on Polygon), which would take around 36 seconds. To summarize, the lowest theoretical boundary for storing 100,000 * 5 <code>bytes32</code> elements, under given circumstances, is 36 seconds and $12. In practice, the time delay would be much higher as executing ~3,333 transactions from one user in 36 seconds would only be possible on a private chain.</p>
<p>What if the requirement is to store data of 100,000 documents in 10 seconds with a high probability? How could it be achieved? The only way to reduce the number of transactions executed on Blockchain is to reduce the amount of data that has to be written. There is, of course, a possibility to increase the number of documents in a batch, but we are already hitting the boundary with that in the previous example. When there is a requirement to store exactly 100,000 documents, there are two options: - Compress the data to have more of the smaller documents in batches; the example would be storing hashes of data. - Store no data but generate signed documents off-chain - Store single commitments for multiple data; the example would be storing a root hash of a Merkle tree built from documents.</p>
<p>In each case, we assume the user will receive proof that the document belongs to a commitment and can materialize (mint) its data on the chain by providing the proof.</p>
<p>The first solution might be tempting for smaller amounts of data. However, it reduces the number of transactions for a constant factor (5 in the previous example), which would not be very helpful when data quantity increases.</p>
<p>The second solution is very similar to OWT and represents an ideal solution from a theoretical perspective. However, the issue arises from the time required to generate a large number of signatures, which is much higher than a Merkle tree construction time. The comparison is provided in the results section.</p>
<p>The third option is more suitable for handling large quantities of data, as it scales much better. On the other hand, the construction of the Merkle tree grows exponentially with the number of documents, so the time required to generate bigger trees adds another limit to the number of documents processed in a given time after a certain threshold. Nevertheless, the Merkle tree solution has better potential, as one can generate multiple Merkle trees in parallel (on multicore processors or multiple servers), which can scale document processing to another level. This fact leads us to an outstanding balance between the number of transactions, the number of processed documents, and the time required to prepare and write the data - the parallel computation of multiple Merkle tree roots and writing multiple roots in one transaction. In this scenario, there are better guarantees that a single storage transaction will be executed in 10 seconds while storing <embed src="https://latex.codecogs.com/svg.latex?k" title="k" class="img-fluid"> Merkle roots of <embed src="https://latex.codecogs.com/svg.latex?n" title="n" class="img-fluid">-document trees. Can we go even further? For a few milliseconds more, another tree could be formed from the roots of the trees generated in parallel - leading to one tree with <embed src="https://latex.codecogs.com/svg.latex?m" title="m" class="img-fluid"> subtrees and <embed src="https://latex.codecogs.com/svg.latex?O%28log_%7B2%7D%29" title="O(log_{2})" class="img-fluid"> extra levels. This upgrade results in storing only one root hash for the entire set with <embed src="https://latex.codecogs.com/svg.latex?m" title="m" class="img-fluid"> subtrees generated in parallel for a few times speedup. There is also one more concern regarding parallelization. It is not the case that having 10,000 parallel processes will always result in 10,000 times speedup. The overhead communication between processes adds a slowdown. The results from the following section show the example of speedup achieved when creating Merkle trees in parallel workers.</p>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<p>The assumption of efficiently generating Merkle roots in a parallel way, as data commitments, was put to the test. A simple but representative use case assumed storing trading cards on Blockchain (similar to NFTs but more straightforward). The card consists of an ID, image number (associated with image URL) and owner address. The goal was to enable storing commitments of 100,000 cards in 10 seconds. The flow consisted of generating <embed src="https://latex.codecogs.com/svg.latex?k" title="k" class="img-fluid"> Merkle trees with <embed src="https://latex.codecogs.com/svg.latex?l" title="l" class="img-fluid"> leaves sequentially until all cards had been committed. The resulting roots were used to generate a “cap” Merkle tree, and inclusion proofs for the cards were generated from the subtrees and extended with respective “cap” proofs. In the end, each card had a root commitment stored on Blockchain and inclusion proof generated for the end user to claim or transfer the card. Multiple tests estimated the speed of generating Merkle trees and all of the proofs under different conditions. The variables were the number of leaves and workers that generated trees. One worker generated one tree. The results showed that parallel tree generation achieved, on average, 3.5x - 4x speedup on a 2.6 GHz 6-Core Intel Core i7 CPU. Leaves of the trees were <code>keccak256</code> hashes of card data: - <code>uint256 id</code> - <code>uint256 imageId</code> - <code>address owner</code></p>
<p>The following charts represent the time and speedup results when using parallel tree generation.</p>
<br>
<center>
<img src="https://3327.io/documents/research/assets/ERFC-409/speedup.png" class="img-fluid"> <br> <i>Speedup in number of processed leaves per second when generating multiple trees in parallel compared to a single tree with the same number of leaves. The results assume not just tree generation but also proof generation for all leaves of all trees</i>
</center>
<center>
<p><br></p>
<p><img src="https://3327.io/documents/research/assets/ERFC-409/time-required.png" class="img-fluid"> <br> <i>Chart of the time required to generate all proofs when using different number of workers in parallel</i></p>
</center>
<p>As expected, the time delays increase exponentially with the number of leaves. The speedup of ~4x correlates with the number of CPU cores left available for the workers minus the overhead from communication costs when moving larger data (proofs) between parallel workers and the parent process. We can notice that even with only 20 parallel processes, the communication overhead is clearly observable. Also, 20 parallel workers could generate <embed src="https://latex.codecogs.com/svg.latex?20%20%5Ccdot%2016384%20%3D%20327680" title="20 \cdot 16384 = 327680" class="img-fluid"> proofs in ~7.5 seconds, much greater than the targeted 100,000 documents per second. However, this computation does not count in the time required for generating document hashes and sending commitment storage transactions on Blockchain.</p>
<p>Nevertheless, the results gave us some insights into the parameter values. Additionally, the time required to generate document signatures in parallel was also evaluated, as the off-chain signature issuing approach was a direct competitor of the Merkle tree approach. The results show that the parallel Merkle tree generation approach wins this comparison up to a large number of documents, as the time complexity for generating multiple signatures grows linearly with the number of documents but with much higher base costs. It is important to note that the signature generation results do not discard the possibility of using the signature approach but show that the Merkle trees are a more efficient approach.</p>
<center>
<p><br></p>
<p><img src="https://3327.io/documents/research/assets/ERFC-409/signature-time.png" class="img-fluid"> <br> <i>Chart of the time required to generate all signatures when using different number of workers in parallel</i></p>
</center>
<p><br></p>
<p>The full test consisted of generating document hashes for 1,000,000 documents, generating commitments for 100,000 documents per batch using up to 20 parallel workers with a maximum of 16,384 leaves. Finally, the resulting commitment was sent to Blockchain (Ganache) asynchronously after each batch. The time required for the entire process to complete and store all 1,000,000 document commitments as root hashes of batches was ~55s, or ~180,000 processed documents per 10s. The costs of storing commitments on L2 chain like Polygon would be around $27 per day (having the gas price of 100 gwei), for storing commitments of 1.44 billion documents.</p>
<p>The parameters can and should, be tuned according to the use case. Suppose the number of documents that should be processed per second is insignificant, and higher delays are allowed. In that case, 1,000,000 or more documents could easily be represented as one commitment stored on Blockchain. This approach allows for semi-real-time document processing with minimal delay.</p>
<section id="document-materialization-on-blockchain" class="level2">
<h2 class="anchored" data-anchor-id="document-materialization-on-blockchain">Document materialization on Blockchain</h2>
<p>The smart contract consists of functions for storing commitments and functions used to mint the cards from commitment proofs. The owner of the commitment proof mints the card by providing card data to the smart contract along with inclusion proof and the ID of the corresponding commitment. The smart contract verifies the proof and mints a new card with the given data. The card owner can only do the minting as the message sender’s address is used for the owner’s address. The owner can also mint the card to a different address, where the same process applies, with the only difference being the card minted with a different owner’s address. The one-time overhead costs for the users to mint and/or transfer their documents on the chain are minimal, especially when L2 solutions, like Polygon, are used.</p>
<p>The entire protocol for generating a massive number of documents using off-chain proofs and commitments was assigned the name <b>Minty</b>.</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>The results show that the approach of using parallel off-chain proof generation and storing commitments on the chain enables semi-real-time minting of a massive number of documents with high saves in costs when compared to direct on-chain minting. The example use-case can be further expanded to cover NFTs or any other types of documents which could be minted on the chain. Future research should cover specific applications of the presented protocol and estimate its value in various use cases.</p>


</section>

 ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-409.hugo.html</guid>
  <pubDate>Sun, 28 Aug 2022 00:00:00 GMT</pubDate>
  <media:content url="https://latex.codecogs.com/svg.latex?n " medium="image"/>
</item>
<item>
  <title>[ERFC - 375] Anonymity in MACI</title>
  <dc:creator>Marija Mikic</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-375.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p>MACI - Minimal Anti-Collusion Infrastructure is a collection of smart contracts, ZK circuits and ts packages that we can use to build programs on top. We have already dealt with this topic, we summarized what has been done in MACI so far. More information about MACI can be found in our previous research (MACI [1]) and blog (Can MACI really destroy the collusion? [2]).</p>
<p>This research is a continuation of the previous one, but with the aim of improving MACI. Namely, the problem that we saw as “burning” in MACI is that the coordinator can see how which voter voted. There is no problem if the coordinator is honest, but what if he is not?!</p>
<p>This research solves exactly that problem, i.e.&nbsp;prevents the coordinator from connecting the vote it processes with the voter itself. In this way, the anonymity of voting is completely preserved.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>In order to remove the “burning” problem and fully ensure the privacy of voting, we need to mention the most important components that currently perform encryption-decryption in MACI, as well as the way in which it is achieved.</p>
<p>Voters vote using MACI smart contracts. Before sending their vote to the blockchain, they first encrypt their vote (actually, they encrypt the signature and the command (which contains a couple of components, one of which is the option they voted for)) using a shared key. They use an Elliptic-curve Diffie–Hellman shared key. Voters send this encrypted message to the MACI smart contract and it will be stored on-chain. Using shared keys, the coordinator decrypts each vote. It should be noted that each voter will have a different shared key, and that only the voter and the coordinator know that key.</p>
<p>As it is always easier to understand the matter if there is a visualization, the image below shows the way encryption-decryption works in MACI.</p>
<p><img src="https://3327.io/documents/research/assets/ERFC-375/MACI_A1.png"></p>
<p>After decryption, the coordinator needs to prove that voting was valid and reveal the results of voting. This should be done in the way that everyone is sure in the voting results, without releasing the vote of every individual. In order that the coordinator fulfill both of the above conditions, he will make ZK proofs. In this way, the anonymity of voting is almost completely preserved, up to the coordinator.</p>
<p>Our recommendations for interesting articles about MACI:</p>
<ul>
<li>MACI research [1];</li>
<li>Can MACI really destroy the collusion? [2];</li>
<li>Release Announcement: MACI 1.0 [3];</li>
<li>A Technical Introduction to MACI 1.0 [4].</li>
</ul>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p>As we already stated in the lines above, the intention of this research is to examine the possibilities and try to find a solution that would nullify the possibility of collusion in MACI. Namely, everything is hidden on-chain at the moment, but we want that coordinator not to know which user took what action.</p>
<p>Our proposal is to use ElGamal encryption and re-randomization. The main motivation for this is the article authored by Kobi Gurkan (MACI anonymization - using rerandomizable encryption [8]).</p>
<p>This potential improvement would have enormous implications for rooting out collusion. It is extremely important for the ecosystem to be able to use a decentralized voting system that is completely resistant to collusion. In the first place, it is important to protect the privacy of a certain voter in every sense (on-chain and off-chain). On the other hand, as MACI can be seen to be in use by the clr.fund, where users can vote which projects will receive funding, and for this reason the importance of this potential improvement can be additionally seen.</p>
<p>Therefore, in the future MACI would represent the most perfect system for voting in a decentralized system - a system completely resistant to collusion.</p>
<p>To be able to present the idea clearly, we need to explain how encryption works. In the following lines, we will first explain how ECDH encryption works, and how ElGamal encryption works.</p>
<section id="asymmetric-encryption" class="level2">
<h2 class="anchored" data-anchor-id="asymmetric-encryption">Asymmetric encryption</h2>
<p>The creators of asymmetric cryptography are Whitefield Diffie and Martin Hellman, who in 1976. described the idea of cryptography based on two keys: private (secret) and public key.</p>
<p>The difference between symmetric and asymmetric algorithms is that symmetric algorithms use the same key for encryption and decryption, while asymmetric algorithms use different keys for encryption and decryption. Information encrypted with a public key can only be decrypted with a private key, that can only the person who owns the private asymmetric key.</p>
<p><img src="https://3327.io/documents/research/assets/ERFC-375/Asymmetric.png"></p>
<section id="ecdh-encryption" class="level3">
<h3 class="anchored" data-anchor-id="ecdh-encryption">ECDH encryption</h3>
<p>ECDH is very similar to the DHKE (Diffie–Hellman Key Exchange) algorithm, but it uses ECC point multiplication (consecutive addition). Our recommendation for literature related to elliptic curves in cryptography is Pairings for beginners [9].</p>
<p>ECDH allows two parties, each having an elliptic curve public–private key pair, to establish a shared key. Let <img src="https://latex.codecogs.com/png.latex?G"> be a generator point on the elliptic curve over a finite field <img src="https://latex.codecogs.com/png.latex?F_p"> (where <img src="https://latex.codecogs.com/png.latex?p"> is a prime number). Let <img src="https://latex.codecogs.com/png.latex?pr_A"> and <img src="https://latex.codecogs.com/png.latex?pr_B"> be the private keys of two different people <img src="https://latex.codecogs.com/png.latex?A"> and <img src="https://latex.codecogs.com/png.latex?B">. Then <img src="https://latex.codecogs.com/png.latex?pub_A%20=%20pr_A%20*%20G"> and <img src="https://latex.codecogs.com/png.latex?pub_B%20=%20pr_B%20*%20G"> are their public keys. ECDH is based on the property of elliptic curve points:</p>
<p><img src="https://latex.codecogs.com/png.latex?(pr_A%20*%20G)%20*%20pr_B%20=%20pub_A%20*%20pr_B%20=%20shared%20key%20=%20pub_B%20*%20pr_A%20=%20(pr_B%20*%20G)%20*%20pr_A">.</p>
<p>In this way, both of them know the shared key, and they get it using their private key and the other person’s public key. In this way, each person’s private key remains secret.</p>
<p>The security of the algorithm lies in the difficulty of calculating the discrete logarithm.</p>
</section>
<section id="encryption-in-maci" class="level3">
<h3 class="anchored" data-anchor-id="encryption-in-maci">Encryption in MACI</h3>
<p>Now, we want to show in practice how ECDH works in MACI. First, we start with encryption. The image below shows an encryption template written in Circom (Circom [10]). In order to generate a shared key, the voter will enter as inputs: his private key and the public key of the coordinator (which is available for everyone). As you can see the output of this template will be a shared key.</p>
<p><img src="https://3327.io/documents/research/assets/ERFC-375/Ec.png"></p>
<p>In order to process all the votes after the voting is over and to prove (to make ZK proof) that voting was regular (and announce the outcome of the voting), the coordinator needs to decrypt each vote. To achieve this, the coordinator uses the Decrypt(N) template which can be seen below. Namely, as inputs he enters a message and a shared key (marked as private_key in the code). As an output, he can read the message, i.e.&nbsp;he can see who voted (because the public key will be visible to him) as well as the option for which the voter with that public key voted.</p>
<p><img src="https://3327.io/documents/research/assets/ERFC-375/De.png"></p>
<p>In order for the coordinator to update the State tree, he must read each vote (in that template). The picture below shows what it looks like. In lines 114-117, the coordinator, using his private key and public key of the voter as inputs (using the Ecdh template), derives the shared key. Then in lines 119-127 coordinator decrypts the message (from the voter) using the Decrypt template. Its input data is the shared key that he obtained in lines 114-117 and the encrypted message. The decrypt_comand_out variable contains the decrypted message that the coordinator can read.</p>
<p><img src="https://3327.io/documents/research/assets/ERFC-375/State.png"></p>
</section>
<section id="ec-elgamal-encryption" class="level3">
<h3 class="anchored" data-anchor-id="ec-elgamal-encryption">EC ElGamal encryption</h3>
<p>In 1985, Taher Elgamal created an asymmetric cryptographic algorithm based on the Diffie-Hellman key exchange. Similar to the ECDH algorithm, the security of ElGamal is based on the difficult or almost impossible computation of the discrete logarithm of a large prime number.</p>
<p>Let <img src="https://latex.codecogs.com/png.latex?G"> be a generator point on the elliptic curve over a finite field <img src="https://latex.codecogs.com/png.latex?F_p"> (where <img src="https://latex.codecogs.com/png.latex?p"> is a prime number). Let <img src="https://latex.codecogs.com/png.latex?pr_A"> and <img src="https://latex.codecogs.com/png.latex?pr_B"> be the private keys of two different people <img src="https://latex.codecogs.com/png.latex?A"> and <img src="https://latex.codecogs.com/png.latex?B">. Then <img src="https://latex.codecogs.com/png.latex?pub_A%20=%20a%20*%20G"> and <img src="https://latex.codecogs.com/png.latex?pub_B%20=%20b%20*%20G"> are their public keys. Let person <img src="https://latex.codecogs.com/png.latex?A"> be the person who will encrypt the data. For this purpose, person <img src="https://latex.codecogs.com/png.latex?A"> should do the following:</p>
<ol type="1">
<li><p>choose an arbitrary <img src="https://latex.codecogs.com/png.latex?x"> from the interval <img src="https://latex.codecogs.com/png.latex?(1,p)">;</p></li>
<li><p>calculate <img src="https://latex.codecogs.com/png.latex?x%20*%20G%20=:%20X">;</p></li>
<li><p>assigns a point on the elliptic curve <img src="https://latex.codecogs.com/png.latex?M(m,y)"> to the message <img src="https://latex.codecogs.com/png.latex?m">, where person <img src="https://latex.codecogs.com/png.latex?A"> choose <img src="https://latex.codecogs.com/png.latex?y"> so that the point <img src="https://latex.codecogs.com/png.latex?M"> is a point on the elliptic curve;</p></li>
<li><p>calculate <img src="https://latex.codecogs.com/png.latex?Me%20:=%20M%20+%20pub_B%20*%20x">;</p></li>
<li><p>send <img src="https://latex.codecogs.com/png.latex?Me"> and <img src="https://latex.codecogs.com/png.latex?X"> to person <img src="https://latex.codecogs.com/png.latex?B">.</p></li>
</ol>
<p>Person <img src="https://latex.codecogs.com/png.latex?B"> needs to decrypt the data. For this purpose, person <img src="https://latex.codecogs.com/png.latex?B"> should do the following:</p>
<ol type="1">
<li><p>calculate <img src="https://latex.codecogs.com/png.latex?pub_B%20*%20x%20==%20pr_B%20*%20G%20*%20x%20==%20pr_B%20*%20X">;</p></li>
<li><p>decrypts the message <img src="https://latex.codecogs.com/png.latex?M(m,y)%20==%20Me%20-%20pub_B%20*%20x">;</p></li>
</ol>
<p>Note that when encrypting a message, person <img src="https://latex.codecogs.com/png.latex?A"> needs to know the public key of person <img src="https://latex.codecogs.com/png.latex?B">, while person <img src="https://latex.codecogs.com/png.latex?B"> can decrypt the message without knowing the public key of person <img src="https://latex.codecogs.com/png.latex?A"> (which is not possible with decryption that relies on a shared key, i.e.&nbsp;ECDH).</p>
</section>
</section>
<section id="re-randomization" class="level2">
<h2 class="anchored" data-anchor-id="re-randomization">Re-randomization</h2>
<p>We usually use re-randomization when we want to convey the same message, but two cipher texts cannot be connected to each other. That function randomizes an existing cipher text such that it’s still decryptable under the original public key it was encrypted for.</p>
<p>Suppose we are working with the same elliptic curve. Assume that the notation we used above holds. We want the input parameters to be <img src="https://latex.codecogs.com/png.latex?X"> and <img src="https://latex.codecogs.com/png.latex?Me"> and the output parameters to be <img src="https://latex.codecogs.com/png.latex?X_1"> and <img src="https://latex.codecogs.com/png.latex?Me_1"> to hide the same message.</p>
<p>For this purpose, person <img src="https://latex.codecogs.com/png.latex?A"> should do the following:</p>
<ol type="1">
<li><p>choose an arbitrary <img src="https://latex.codecogs.com/png.latex?z"> from the interval <img src="https://latex.codecogs.com/png.latex?(1,p)">;</p></li>
<li><p>calculate <img src="https://latex.codecogs.com/png.latex?X1%20:=z%20*%20G%20+%20X">;</p></li>
<li><p>calculate <img src="https://latex.codecogs.com/png.latex?Me_1%20:=%20Me%20+%20pub_B%20*%20z">;</p></li>
<li><p>output <img src="https://latex.codecogs.com/png.latex?Me_1"> and <img src="https://latex.codecogs.com/png.latex?X_1">.</p></li>
</ol>
</section>
<section id="nullifier" class="level2">
<h2 class="anchored" data-anchor-id="nullifier">Nullifier</h2>
<p>In the following, we will use nullifier, so for the convenience of the reader, we will define it.</p>
<p>The nullifier is a unique ID that is in connection with the commitment and the ZKP proves the connection, but nobody knows which nullifier is assigned to which commitment.</p>
</section>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<p>In order to achieve complete voter anonymity, we created required building blocks. Codes for ElGamal encryption, decryption and re-randomization are written in circom language. Below is the code for encryption, but all codes are available on github [12].</p>
<p>Code for encryption:</p>
<p><img src="https://3327.io/documents/research/assets/ERFC-375/ElGamalEncryption.png"></p>
<p>The decryption and rerandomization codes existed in a different form and can be viewed in [11].</p>
<p>In order to take advantage of this, the current MACI protocol needs to be modified. Here we will only give an idea of what needs to be done to achieve the desired goal.</p>
<section id="protocol" class="level2">
<h2 class="anchored" data-anchor-id="protocol">Protocol</h2>
<p>In order to achieve the desired result, it is necessary to change the protocol. The current protocol, as we said before, allows the voter to vote and to change the public key (voter can send two types of message). For example, If the voter is blackmailed, he can create a command with the content of the option he wants to vote for and with a new public key. He can sign it with his previous public key, encrypts it (using ECDH encryption) and submits it to the MACI smart contracts. However, the same voter can then vote for the option the blackmailer wants, without that vote being valid (which the blackmailer will not know). How does it achieve this? The voter creates a command with the content of the option the blackmailer wants and the previous public key. He signs it with his previous public key, encrypts it (using ECDH encryption) and submits it to the MACI smart contracts. When the voting is over, the coordinator decrypts the first message, validates the signature, records this vote (because it is valid) and updates the voter’s public key. Then the coordinator decrypts the second message, sees that the signature does not match the new public key and therefore this message is invalid. But the voter can decrypt this message too, as proof of his vote for option blackmailer wants.</p>
<p>We want to preserve these two nice features: first, that the voter can prove to the blackmailer that he voted for that option for which he was blackmailed (without that vote being valid), and second, that all votes are encrypted and stored on-chain. But we also want to add a feature, so that the coordinator does not know which option the voter voted for. In the current protocol, when a voter’s public key is changed, the coordinator knows that the change has occurred and from there coordinator knows how the voter voted (although the public key change helped the voter to deceive the blackmailer).</p>
<p>As we do not want that coordinator to know who is the “owner” of the new public key, we need to disable the coordinator from seeing the link between the old and new public key of the voter. In order to achieve this, it is necessary for the voter to prove (he needs to make ZK proof) that owns the private key for the old public key and to be able to create a new public key based on that. For this purpose, we will need to create a set that will contain all deactivated public keys and his encrypted states. But here we have to be careful, we have to make sure that based on the previous public key, the voter can create exactly one new public key. For this reason we will need nullifiers and the set where we store them. Conclusion, we will need two new sets that we haven’t had so far. Let’s mark the first of them with <img src="https://latex.codecogs.com/png.latex?D"> and the second with <img src="https://latex.codecogs.com/png.latex?N">. Set <img src="https://latex.codecogs.com/png.latex?D"> is public, while set <img src="https://latex.codecogs.com/png.latex?N"> is private. Also, we must expand the set of states, more precisely, in that set there should be a field that says whether the voter’s public key is active or inactive.</p>
<p>Also, we will need two new message types. The first type of message should be to deactivate the old public key. After deactivation, the coordinator adds the old public key with its encrypted state (using ElGamal encryption) to set <img src="https://latex.codecogs.com/png.latex?D">.</p>
<p>Second type of message is that the voter creates a new public key proving that he is the owner of the old one. To achieve this, the voter needs to make a ZK proof that the element (old public key of voter, (<img src="https://latex.codecogs.com/png.latex?X">, <img src="https://latex.codecogs.com/png.latex?Me">)) belongs to the set <img src="https://latex.codecogs.com/png.latex?D">, where (<img src="https://latex.codecogs.com/png.latex?X">, <img src="https://latex.codecogs.com/png.latex?Me">) is the ElGamal encrypted message, as well he need to prove that he knows the private key for the old public key. Also the output of the circuit should be (<img src="https://latex.codecogs.com/png.latex?X_1">, <img src="https://latex.codecogs.com/png.latex?Me_1">) which are obtained by rerandomization (<img src="https://latex.codecogs.com/png.latex?X">, <img src="https://latex.codecogs.com/png.latex?Me">) and nullifier which is the hash of the private key. The content of the message itself should be: (<img src="https://latex.codecogs.com/png.latex?X1">, <img src="https://latex.codecogs.com/png.latex?Me_1">), nullifier, the ZK proof and the new public key. Of course the message is encrypted. The coordinator decrypts the message, if the proof is valid, the nullifier doesn’t already exist in the set <img src="https://latex.codecogs.com/png.latex?N">, places the nullifier in the set <img src="https://latex.codecogs.com/png.latex?N">, adds a new public key and updates its state. Note that in this way the coordinator does not know the old public key of the voter whose vote he is processing. In this way, complete anonymity of voting was achieved.</p>
<section id="example" class="level3">
<h3 class="anchored" data-anchor-id="example">Example</h3>
<p>We now want to illustrate the entire protocol with an example. We want a person <img src="https://latex.codecogs.com/png.latex?A"> to be a voter. Person <img src="https://latex.codecogs.com/png.latex?A"> wants to prove to the blackmailer that she voted for option 1, even though she will vote for option 2. Also, person <img src="https://latex.codecogs.com/png.latex?A"> wants the coordinator not to know which option she voted for. Person <img src="https://latex.codecogs.com/png.latex?A"> can do it for example like this.</p>
<ol type="1">
<li><p>Person <img src="https://latex.codecogs.com/png.latex?A"> accesses the vote with public key 1. Votes for option 2, changes the public key to public key 2, signs the command with public key 1, and encrypts using ElGamal encryption.</p></li>
<li><p>Person <img src="https://latex.codecogs.com/png.latex?A"> then votes for option 1 and signs the vote with public key 1 and encrypts using ElGamal encryption.</p></li>
<li><p>Person <img src="https://latex.codecogs.com/png.latex?A"> deactivates his public key.</p></li>
<li><p>Person <img src="https://latex.codecogs.com/png.latex?A"> activates a new public key based on the old public key using ZK proof and rerandomization.</p></li>
</ol>
<p>Let’s see what happens when the coordinator processes the messages.</p>
<ol type="1">
<li><p>The first message will be valid and will update the state related to the public key of person 1 (a vote for option 2 will be entered and the new public key of person <img src="https://latex.codecogs.com/png.latex?A"> will become public key 2).</p></li>
<li><p>The second message will not be valid and there will be no state change (because person <img src="https://latex.codecogs.com/png.latex?A">’s public key has become public key 2, not 1, as signed in the message).</p></li>
<li><p>It will change the state of public key 2 of person 1 to inactive. When the key state is inactive, that vote is not counted in the total. Therefore, the vote for option 2 is not counted at this time. Also, the coordinator updates the set <img src="https://latex.codecogs.com/png.latex?D"> and writes to it the public key 2 and the encrypted states (using ElGamal encryption)- vote for option 2.</p></li>
<li><p>New key - public key 3 (of person <img src="https://latex.codecogs.com/png.latex?A">, but the coordinator does not know that it is the public key of person <img src="https://latex.codecogs.com/png.latex?A">) writes to the set of public keys and registers a new state (vote for option 2 is now written and this key is considered active).</p></li>
</ol>
<p>Note that person <img src="https://latex.codecogs.com/png.latex?A"> used all 4 message types in the proposed protocol. In this way, person <img src="https://latex.codecogs.com/png.latex?A"> voted for the desired option 2. Also, by decrypting the second message, person <img src="https://latex.codecogs.com/png.latex?A"> can “prove” to the blackmailer that he voted for option 1. And let’s note that the coordinator does not know how the person <img src="https://latex.codecogs.com/png.latex?A"> voted.</p>
</section>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>The research showed that it is possible to achieve complete anonymity of voting, i.e.&nbsp;it was shown that it is possible to avoid that coordinator knows options that each individual voter voted for. Also, for this purpose, codes were made in circom language for ElGamal encryption, decryption and re-randomization. The next step could be the implementation of the presented solution.</p>
</section>
<section id="bibliography" class="level1">
<h1>Bibliography</h1>

<p>[1] MACI, https://github.com/0x3327/3327-operations/blob/babb99c2eec36b95a84c04bde6bd9bb01851e534/_research/ERFC-291.md</p>
<p>[2] Can MACI really destroy the collusion?, https://3327.io/can-maci-really-destroy-the-collusion/</p>
<p>[3] Release Announcement: MACI 1.0, https://medium.com/privacy-scaling-explorations/release-announcement-maci-1-0-c032bddd2157</p>
<p>[4] A Technical Introduction to MACI 1.0, https://medium.com/privacy-scaling-explorations/a-technical-introduction-to-maci-1-0-db95c3a9439a</p>
<p>[5] ECDH Key Exchange, https://cryptobook.nakov.com/asymmetric-key-ciphers/ecdh-key-exchange</p>
<p>[6] Cryptography, http://poincare.matf.bg.ac.rs/~ezivkovm/nastava/kripto.pdf</p>
<p>[7] Cryptography - Notes, http://poincare.matf.bg.ac.rs/~aleksandar/files/kripto/2020/Skripta.pdf</p>
<p>[8] MACI anonymization - using rerandomizable encryption, https://ethresear.ch/t/maci-anonymization-using-rerandomizable-encryption/7054/1</p>
<p>[9] Pairings for beginners, https://static1.squarespace.com/static/5fdbb09f31d71c1227082339/t/5ff394720493bd28278889c6/1609798774687/PairingsForBeginners.pdf</p>
<p>[10] Circom 2 Documentation, https://docs.circom.io/</p>
<p>[11] ElGamal encryption, decryption, and rerandomization, with circom support, https://ethresear.ch/t/elgamal-encryption-decryption-and-rerandomization-with-circom-support/8074</p>
<p>[12] ElGamal codes for encryption, decryption and re-randomization, https://github.com/MarijaMikic/ElGamal</p>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs">

</div></section></div> ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-375.hugo.html</guid>
  <pubDate>Tue, 23 Aug 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>[ERFC - 358] On-chain Capitalization Table</title>
  <dc:creator>Aleksandar Damjanovic</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-358.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p>This research covers the current solutions based on Capitalization Tables in Web3 to fully understand the idea of creating a Capitalization Table Platform that would store the data and changes on-chain. The proposed solution is building a similar solution to Syndicates but without the governance power of token holders. Is this proposed solution just an inefficient DAO? Probably. It is up to the readers to decide.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>This research paper explores the viability of creating a transparent Capitalization Table solution that would store the equity capitalization for a Web3 native/non Web3 native company and its changes on-chain. The motivation for this idea originated from the hypothesis that there is a general lack of transparency of web3 companies funding rounds, equity ownership, and debt positions. If we look at the CoinMarketCap and similar tracking websites, we can see the price history of the token, the largest token holders, and in some cases, the initial token distribution, etc. However, the precise representation of the entity (Capitalization Table, for example) behind the coin is absent. There are also various questionable solutions that provide cap tables behind a paywall. The above reasons are why this research is conducted.</p>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p>The goal of this research is to explore:</p>
<ul>
<li>the current solutions in Web3 that aim to provide transparency in the space</li>
<li>the current solutions in Web3 that are based around Capitalization Tables (if there are any)</li>
<li>is there a way Capitalization Tables of Web3/Web2 companies can be stored on-chain</li>
<li>is there a possibility/need for building a Capitalization Table platform</li>
</ul>
<p>We will accomplish this by exploring what Capitalization Tables are, how they are utilized in Web2, whether there are any limitations/needs for implementing them in Web3, and the current solutions based on entity transparency and Capitalization Tables in Web3.</p>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<p>We will first explain what the Capitalization Table represents, whether any solutions in Web3 already tackle this, and we will go over the possibility and limitations of creating the Capitalization Table service or a tool.</p>
<section id="what-is-the-capitalization-table" class="level3">
<h3 class="anchored" data-anchor-id="what-is-the-capitalization-table">What is the Capitalization Table?</h3>
<p>In all companies, the Capital Structure de-facto represents the company’s quality and investment quality if the investor were to invest in it. Capital structure is a mix of a company’s capital - its debt and equity:</p>
<ul>
<li>Equity is a company’s common and preferred stock plus retained earnings. To not venture deep into what the common and preferred stocks are right now, we can look at equity as stocks + retained earnings.</li>
<li>Debt, if we simplify it, usually represents short-term borrowing and long-term debt</li>
</ul>
<p>Investors analyze capital structure by using ratios like:</p>
<ul>
<li>debt ratio</li>
<li>debt-to-equity ratio</li>
<li>long-term debt to capitalization ratio ‘Analyzing a Company’s Capital Structure’<sup>1</sup></li>
</ul>
<p>We will not explain these ratios in this paper as it is not the research topic, but we listed them to show what the investors are taking into account when researching which company to invest in. These are the basics of fundamental analysis and provide some context for the following paragraphs.</p>
<p>A Capitalization Table is a table or a spreadsheet that shows the equity capitalization of the company ‘Capitalization Table: A Familiar Document in the Startup World’<sup>2</sup>.</p>
<p>They are mostly used by startups and businesses in early stage however they can be used by already established businesses.</p>
<p>In the Capitalization Table, each type of equity ownership capital, the investors and the share price at which the funds were invested/current price is listed.They can also list various convertible securities, warrants and options. They are usually used privately by companies to provide information on investors and market value. Investors can use them to decide if they should invest in a company.</p>
<p>Capitalization Tables can vary in design and the information provided but all of them are centered around above mentioned factors. Here is the example of the table’s structure:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://3327.io/documents/research/assets/ERFC-358/cap_table_ex.webp" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">SBT rec</figcaption><p></p>
</figure>
</div>
<p><em>Image 1 : Capitalization Table example - They can be of various types and detail</em></p>
<p>When making important financial decisions in the company, Capitalization Table is considered. That means the table has to represent the actual state and be updated continously. They do not need to be public but once the company goes public the list of insiders and institutional stakeholder goes public. This is where the idea of storing and tracking this data on-chain becomes interesting.</p>
<p>In the above table you can see that the investors equity stake is calculated by multiplying the share price by the number of shares owned. We will not go into great detail as this Capitalization Table design is pretty self-explanatory.</p>
<p>So in it’s essence Capitalization Table shows who owns how many shares, the current market value and the proportions of the ownership, have in mind that these are updated constantly.</p>
</section>
<section id="are-there-any-current-solutions-in-web3-that-use-capitalization-tables" class="level3">
<h3 class="anchored" data-anchor-id="are-there-any-current-solutions-in-web3-that-use-capitalization-tables">Are there any current solutions in Web3 that use Capitalization Tables?</h3>
<p>Below we will do a short overview of Web3 solutions that aim to provide a similar service or use some type of Capitalization Table. There are various Web2 Cap Table management solutions that support tracking both traditional equity and tokens like Pulley but we will not explore them as the tables are not stored on-chain.</p>
<section id="syndicate" class="level4">
<h4 class="anchored" data-anchor-id="syndicate">Syndicate</h4>
<p>Syndicate ‘Syndicate’<sup>3</sup> is a decentralized investing protocol. It is used to create Investing DAOs. Its Web3 Investment Clubs product has a similar structure as a Capitalization Table. The user creates a wallet through the Syndicate dApp and chooses the name and the club token ticker. Club’s token represents the asset ownership percentage of the investment club (wallet) and the investor’s “equity” in the club. This token is a non-transferrable ERC-20 token used for both the snapshot and on-chain governance voting. The club’s members can track where the investments of their tokens are going and vote for different investment opportunities. So in its essence, Syndicate is used to create investing DAOs.</p>
<p>However, this Capitalization table can only be used for investment clubs, and there is no “Company Capitalization Table” product in the making. Because of that, we won’t examine Syndicate further.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://3327.io/documents/research/assets/ERFC-358/syndicate.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Syndicate</figcaption><p></p>
</figure>
</div>
<p><em>Image 2: How the ownership is represented via Syndicate dApp</em></p>
</section>
<section id="liquify" class="level4">
<h4 class="anchored" data-anchor-id="liquify">Liquify</h4>
<p>Liquify is a solution that helps users automate their token vesting.@LiquiFiTokenVesting It enables Companies to save time from manually distributing tokens, Investors to track and claim their tokens. However, the user’s address needs to be whitelisted to access its services currently. There is not much information about this solution online, but there are claims that they are building the “Carta of Web3”. Carta is a solution for Capitalization Table management and automation with a $7.4 billion valuation. If that is true, then this solution challenges our idea. ‘LiquiFi Is Building the “Carta of Web3” for Companies Issuing Tokens on the Blockchain’<sup>4</sup></p>
</section>
<section id="blockstate" class="level4">
<h4 class="anchored" data-anchor-id="blockstate">Blockstate</h4>
<p>Blockstate, a Swiss security token platform for non-bankable assets, claimed to have the solution for on-chain Capitalization Table management back in 2019. however, there is not much information on the website, and they deleted all their social media profiles. We won’t venture deep into this solution as it seems that the project has failed.</p>
</section>
<section id="magna---still-in-the-works" class="level4">
<h4 class="anchored" data-anchor-id="magna---still-in-the-works">Magna - still in the works</h4>
<p>Magna is a solution that aims to solve the Capitalization Table management problem and become a leading TokenOps platform. ‘Magna - Token Cap Table Management Platform’<sup>5</sup> It plans to provide:</p>
<ul>
<li>Stakeholder views - the dashboard and notifications for unlocks and token positions</li>
<li>Exchange analytics - insights on selling and transferring of tokens</li>
<li>Wallet intelligence - there is no information on what this represents exactly</li>
<li>Possibility of liquid staking - voting and staking with tokens while they are still unlocking</li>
<li>One-time and recurring payments - for vendors or contractors</li>
<li>Support for complex unlocking schedules</li>
</ul>
<p>This project is still in the works, so there is no more information. They are currently listed on the Y Combinator’s website. There is no information on funds raised. This solution would be a direct competitor to our idea. ‘Magna: Carta for Web3: Token Vesting and DeFi Investment Management.’<sup>6</sup></p>
</section>
<section id="legal-nodes" class="level4">
<h4 class="anchored" data-anchor-id="legal-nodes">Legal nodes</h4>
<p>Legal Nodes seems to offer the service of Capitalization Table management via Legal Structuring service. However, this is not an open solution/platform and instead a part of their legal services. ‘Legal Structuring Support for Startups | Legal Nodes’<sup>7</sup></p>
</section>
<section id="proposal-of-the-possible-solution" class="level4">
<h4 class="anchored" data-anchor-id="proposal-of-the-possible-solution">Proposal of the possible solution</h4>
<section id="web3-native-entity" class="level5">
<h5 class="anchored" data-anchor-id="web3-native-entity">Web3 Native entity</h5>
<p>Suppose we were to create a similar product to Syndicate’s - a wallet/smart contract creation dApp where the creator must provide LLC - Limited Liability Company papers before creation. The smart contract would then be able to mint the company’s utility/security token in exchange for tokens invested in various rounds. The invested tokens would then possibly be locked and unlocked after an agreed time, depending on the owner’s settings. We could then fetch the data as it’s transparent and present the capitalization table based on investments for investors to see. The bonding curve would determine the price, or the company owners would set the price themselves via the smart-contract (ICO).</p>
<p>Another great insight would be comparing the price at which the funds were invested and the current price on the market. That would show the overall growth of the LLC.</p>
<p>The prices would be fetched from Oracles and updated daily, thus providing a fully transparent and intuitive experience for the potential future investors in the company.</p>
<p>The company’s debt positions would also be visible and presented via the dApp, and the invested tokens would go into various costs like payments for workers and other operational costs.</p>
<p>This raises a question: <strong>Aren’t DAOs already functioning similarly or at least in a more efficient way?</strong> Yes and no. DAOs issue their token representing the users voting power in the DAO’s governance. The voting process is often slow. This proposed solution would not give the owners of the token governance rights. The tokens distributed would be utility/security tokens. And the governance token would be distributed how the company that owns the wallet/smart contract sees fit.</p>
<p>If we are talking about security tokens they bring regulation with them. As I am not a Legal expert, I cannot comment on that, and it would require separate research.</p>
</section>
</section>
<section id="web2-companies" class="level4">
<h4 class="anchored" data-anchor-id="web2-companies">Web2 companies</h4>
<p>The proposed solution of putting the Capitalization Tables of “Web2” companies on-chain would best fit for private blockchains or the chains where the data can be hidden. However, the hypothesis is that this would open up a legal “can of worms”. More research on the Capitalization Tables regulation is required.</p>
</section>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>There have been various tries at implementing Capitalization Tables in Web3 or similar products. Currently, there are options where Capitalization Table management is offered as a service for clients like the one Legal Nodes offers. There is a platform in the works (Magna) that aims to solve exactly what our idea is about - a standardized Capitalization Table Platform. This shows that the execution speed is as important as a good idea. However, a growing number of companies are interested in blockchain, so making an alternative to Magna, Liquify, or Syndicate would be in the spirit of decentralization.</p>
</section>
<section id="bibliography" class="level1">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Bibliography</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-AnalyzingCompanyCapital" class="csl-entry">
‘Analyzing a Company’s Capital Structure’, <em>Investopedia</em> &lt;<a href="https://www.investopedia.com/articles/basics/06/capitalstructure.asp" class="uri">https://www.investopedia.com/articles/basics/06/capitalstructure.asp</a>&gt; [accessed 29 July 2022]
</div>
<div id="ref-CapitalizationTableFamiliar" class="csl-entry">
‘Capitalization Table: A Familiar Document in the Startup World’, <em>Investopedia</em> &lt;<a href="https://www.investopedia.com/terms/c/capitalization-table.asp" class="uri">https://www.investopedia.com/terms/c/capitalization-table.asp</a>&gt; [accessed 29 July 2022]
</div>
<div id="ref-LegalStructuringSupport" class="csl-entry">
‘Legal Structuring Support for Startups | Legal Nodes’ &lt;<a href="https://legalnodes.com/product/startup-legal-structuring" class="uri">https://legalnodes.com/product/startup-legal-structuring</a>&gt; [accessed 30 July 2022]
</div>
<div id="ref-LiquiFiBuildingCarta" class="csl-entry">
‘LiquiFi Is Building the “Carta of Web3” for Companies Issuing Tokens on the Blockchain’, <em>TechCrunch</em> &lt;<a href="https://social.techcrunch.com/2022/04/21/liquifi-is-building-carta-web3-for-crypto-companies-tokens-blockchain/" class="uri">https://social.techcrunch.com/2022/04/21/liquifi-is-building-carta-web3-for-crypto-companies-tokens-blockchain/</a>&gt; [accessed 30 July 2022]
</div>
<div id="ref-MagnaTokenCap" class="csl-entry">
‘Magna - Token Cap Table Management Platform’ &lt;<a href="https://www.magna.so/" class="uri">https://www.magna.so/</a>&gt; [accessed 30 July 2022]
</div>
<div id="ref-MagnaCartaWeb3" class="csl-entry">
‘Magna: Carta for Web3: Token Vesting and DeFi Investment Management.’, <em>Y Combinator</em> &lt;<a href="https://www.ycombinator.com/companies/magna" class="uri">https://www.ycombinator.com/companies/magna</a>&gt; [accessed 30 July 2022]
</div>
<div id="ref-Syndicate" class="csl-entry">
‘Syndicate’ &lt;<a href="https://syndicate.io/" class="uri">https://syndicate.io/</a>&gt; [accessed 29 July 2022]
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p><em>Investopedia</em> &lt;&lt;https://www.investopedia.com/articles/basics/06/capitalstructure.asp&gt;&gt; [accessed 29 July 2022].↩︎</p></li>
<li id="fn2"><p><em>Investopedia</em> &lt;&lt;https://www.investopedia.com/terms/c/capitalization-table.asp&gt;&gt; [accessed 29 July 2022].↩︎</p></li>
<li id="fn3"><p>&lt;[Https://syndicate.io/](https://syndicate.io/)&gt; [accessed 29 July 2022].↩︎</p></li>
<li id="fn4"><p><em>TechCrunch</em> &lt;&lt;https://social.techcrunch.com/2022/04/21/liquifi-is-building-carta-web3-for-crypto-companies-tokens-blockchain/&gt;&gt; [accessed 30 July 2022].↩︎</p></li>
<li id="fn5"><p>&lt;[Https://www.magna.so/](https://www.magna.so/)&gt; [accessed 30 July 2022].↩︎</p></li>
<li id="fn6"><p><em>Y Combinator</em> &lt;&lt;https://www.ycombinator.com/companies/magna&gt;&gt; [accessed 30 July 2022].↩︎</p></li>
<li id="fn7"><p>&lt;[Https://legalnodes.com/product/startup-legal-structuring](https://legalnodes.com/product/startup-legal-structuring)&gt; [accessed 30 July 2022].↩︎</p></li>
</ol>
</section></div> ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-358.hugo.html</guid>
  <pubDate>Fri, 29 Jul 2022 00:00:00 GMT</pubDate>
  <media:content url="https://3327.io/documents/research/assets/ERFC-358/cap_table_ex.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>Introduction to Avalanche</title>
  <dc:creator>Uros Kukic</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-336.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p>While Bitcoin and Ethereum represent the most popular networks in the Web3 space, they also face technical limitations for practical mass adoption. New networks were developed to address these limitations with novel technologies and approaches. To better understand these innovations and their advantages, this paper looks into one of these networks, Avalanche.</p>
<p>This paper aims to give an overview of the technical architecture of the Avalanche network, as well as present the reader with the technologies they would encounter when developing on the Avalanche network.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>This document aims to give an introduction to the Avalanche network. By describing the consensus mechanism and the network architecture, we can better understand how to develop solutions on it.</p>
<p>This paper looks at the technologies one would encounter when using the Avalanche network. It briefly describes their function, how they can be used, their limitations, and possible improvements in the future.</p>
<section id="components-of-the-avalanche-network" class="level2">
<h2 class="anchored" data-anchor-id="components-of-the-avalanche-network">Components of the Avalanche network</h2>
<p>The Avalanche network is a modular system, so before we describe how the entire network works, we will define the components that form the Avalanche network. Afterward, we can explore how those components interconnect and how each component function works in detail.</p>
<section id="blockchains" class="level3">
<h3 class="anchored" data-anchor-id="blockchains">Blockchains</h3>
<p>When we refer to Blockchains on the Avalanche network, we refer to virtual machines. Every node on a particular network runs that network’s virtual machine (or machines). They dictate valid states, as well as the rules for transitioning between those states.</p>
<p>These virtual machines can be customized to better suit the needs of the product that will use them. In general, one can change the initial state of the blockchain or the state transition rules. For example, one can change how transaction fees are calculated and distributed, or how the funds are distributed initially.</p>
<p>In a later section, we will explore the technical details and different available virtual machines on the Avalanche network.</p>
</section>
<section id="validators" class="level3">
<h3 class="anchored" data-anchor-id="validators">Validators</h3>
<p>Different nodes communicate with each other on the Avalanche network to form the decentralized system. Nodes that run a virtual machine and receive and validate new transactions are considered validators. The validator nodes stake some amount of AVAX and receive rewards for their work.</p>
</section>
<section id="subnets" class="level3">
<h3 class="anchored" data-anchor-id="subnets">Subnets</h3>
<p>A Subnet is a sovereign network that defines its own rules regarding membership and token economics. It is composed of a dynamic subset of Avalanche validators working together to achieve consensus on the state of one or more blockchains. Each blockchain is validated by exactly one Subnet, and a Subnet can have many blockchains. A validator may be a member of many Subnets.</p>
<center>
<p><img src="https://3327.io/documents/research/assets/ERFC-336/Subnets.png" class="img-fluid"></p>
<p>Figure 1: Avalanche subnets overview</p>
<p><em>Source: docs.avax.network</em></p>
</center>
<p>Subnets are independent; they specify their own execution logic, determine their own fee regime, maintain their own state, facilitate their own networking, and provide their own security. They do not share the execution thread, storage, or networking with other Subnets.<sup>1</sup></p>
<p>With all components of the Avalanche network shown, we can demonstrate how they combine together using the Avalanche Primary network as an example.</p>
<p><strong>The primary network</strong></p>
<p>Every validator is a member of Avalanche’s built-in public Subnet, called the Primary network. Validators can be members of as many Subnets as they choose, but they must be members of the Primary network along with them.</p>
<p>The Primary network is comprised of three blockchains:</p>
<ol type="1">
<li><p>The Platform Chain (P-chain) is the metadata blockchain on Avalanche and coordinates validators, keeps track of active Subnets, and enables the creation of new Subnets.<sup>2</sup></p></li>
<li><p>The Contract Chain (C-chain) is a blockchain compatible with the Ethereum Virtual Machine. It enables creating and using smart contracts similarly to how they function on the Ethereum network.</p></li>
<li><p>The Exchange Chain (X-chain) is a blockchain for creating and trading digital assets.<sup>3</sup></p></li>
</ol>
<center>
<p><img src="https://3327.io/documents/research/assets/ERFC-336/Chains.png" class="img-fluid"></p>
<p>Figure 2: The Avalanche primary network chains</p>
<p><em>Source: docs.avax.network</em></p>
</center>
</section>
</section>
<section id="avalanche-consensus-protocol" class="level2">
<h2 class="anchored" data-anchor-id="avalanche-consensus-protocol">Avalanche Consensus Protocol</h2>
<p>For the network to function, the validators need to agree on the state of the blockchain they contain. The process through which they reach this agreement is called a consensus protocol. By ensuring that only valid transactions will be included in the final state of the network, consensus protocols provide security on the network.</p>
<p>The Avalanche Network uses a novel consensus protocol called Avalanche protocol, which functions by randomly subsampling the network multiple times.</p>
<center>
<p><img src="https://3327.io/documents/research/assets/ERFC-336/Mechanism.png" class="img-fluid"></p>
<p>Figure 3: Avalanche consensus mechanism</p>
<p><em>Source: docs.avax.network</em></p>
</center>
<p>When a validator receives a transaction, it checks that the transaction metadata is valid (e.g., the transaction signature is valid, the sender has enough funds to execute the transaction, and such). After confirming the transaction validity locally, the validator selects <em>n</em> nodes randomly if they also consider the transaction valid. If <em>α</em> of those <em>n</em> nodes consider the transaction valid, the round is considered successful. This concludes one successful round, and the process is repeated, starting from the selection of n nodes. If <em>β</em> consecutive rounds are successful, the transaction is accepted, and the state of the blockchain is updated.</p>
<p>In order to increase the throughput of the blockchain, the Avalanche protocol creates a Directed Acyclic Graph (DAG) that represents state changes of the blockchain. A set of transactions is considered a vertex in the DAG. How this data structure functions will be explored further in subsequent research, as it is not the focal point of this document.</p>
<p><strong>Snowman Consensus Protocol</strong></p>
<p>Snowman is a modification of the Avalanche Consensus Protocol, which creates a linear chain of vertices instead of a DAG. This modification is similar to how most decentralized blockchains work, with each vertex representing a block of transactions.</p>
<p>While the X-Chain uses the Avalanche Consensus Protocol, it is noteworthy that the C-chain and X-chain utilize the Snowman protocol for simplicity.</p>
</section>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p>In this section, we will present the experience of a developer starting to develop solutions on the Avalanche network. First we’ll cover the experience of developing a subnet and afterwards the experience of developing a decentralized application (dApp) on the Avalanche network.</p>
<section id="subnet-development" class="level2">
<h2 class="anchored" data-anchor-id="subnet-development">Subnet development</h2>
<p>The official Avalanche documentation<sup>4</sup> offers plenty of subnet creation and deployment guides of increasing complexity to introduce the reader to various aspects of the network.</p>
<p>The Create an EVM Subnet on a Local Network<sup>5</sup> guide enables one to run a subnet locally without worrying about too many dependencies or steps during the setup. The guide explains how to locally create a subnet with five validators and an EVM-compatible blockchain called Subnet-EVM. The guide also gives additional steps on how to stop and start the Subnet or redeploy it.</p>
<p>The following guide<sup>6</sup> instructs the user how to deploy the Subnet used in the previous guide on the Fuji testnet. With detailed instructions, one can follow the menus in the CLI wizard and have a subnet registered on the testnet. The only significant difference is that validators are not automatically created; they need to be added to the Subnet after the deployment.</p>
<p>The subsequent guides require running an Avalanche node, for which one would likely need to install the AvalancheGo<sup>7</sup> and Subnet-CLI<sup>8</sup> libraries. These dependencies raise the level of complexity when working with Avalanche but are foundational for deploying subnets on the production network and unlock the potential to customize node functionality.</p>
<p>After deploying a subnet on the testnet, we worked on customizing a subnet’s virtual machine<sup>9</sup>. By altering the genesis block, we modified the transaction fee calculation. However, the Avalanche guides also offer instructions on building a virtual machine from scratch that the Subnet will use.</p>
<p>Due to the scope of this research, we did not explore the topic further, but we hope to explore customizing subnets and virtual machines which use them deeper.</p>
</section>
<section id="dapp-development" class="level2">
<h2 class="anchored" data-anchor-id="dapp-development">dApp Development</h2>
<p>As we previously mentioned, smart contracts are used on Avalanche C-Chain; thus, the development of dApps is done through that same type of chain. Luckily, the virtual machines used in subnet guides are primarily using Subnet-EVM. This enables developers to use the same “dummy” subnets for dApp development.</p>
<p>The first step for dApp developers should be connecting to a local Subnet using Remix and Metamask, two well-known tools for smart contract development. Using these tools will introduce communicating with subnets to the developer.</p>
<p>For developing more advanced dApps on Avalanche, we used Hardhat for connecting to the Avalanche C-Chain on the Fuji network. After customizing the Hardhat configuration file with the appropriate RPC endpoints, smart contract deployment was identical to the deployment experience on the Ethereum network.</p>
<p>More research is required to validate more complex functionalities, but we expect that most frameworks and tools available for Ethereum dApp development will also work on Avalanche.</p>
</section>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<p>In this section, we will technologies we’ve encountered in the previous section, with a brief explanation of how and why we’ve utilized them and our experience with using those technologies.</p>
<section id="languages" class="level2">
<h2 class="anchored" data-anchor-id="languages">Languages</h2>
<ol type="1">
<li><p><strong>GoLang</strong></p>
<p>Both the Avalanche node implementation and coreth, the virtual machine the c-chain implements, are written in Go. For anyone looking to start developing on the Avalanche network, especially using custom subnets, Go is a language with which they should get acquainted.</p></li>
<li><p><strong>Solidity</strong></p>
<p>For developers who want to create and deploy their own dApps, Solidity is the most employed language for writing smart contracts, which are essential for almost any dApp.</p>
<p>It was built for creating smart contracts on the Ethereum network. However, the Avalanche network’s compatibility with the Ethereum virtual machine means that this language (and all its tools) is available to developers.</p>
<p>Due to its widespread usage, available resources, and tooling, we recommend this language for any developer looking to create dApps on the Avalanche network’s C-Chain.</p></li>
<li><p><strong>NodeJS</strong></p>
<p>Besides Go libraries for communicating with the Avalanche network, developers can also use AvalancheJS to access the Avalanche network using JavaScript.</p>
<p>Coupled with numerous NodeJS libraries for smart contract development, for any developer wanting to create a dApp, we recommend learning NodeJS.</p></li>
</ol>
</section>
<section id="tools" class="level2">
<h2 class="anchored" data-anchor-id="tools">Tools</h2>
<ol type="1">
<li><p><strong>Avalanche-CLI</strong></p>
<p>The Avalanche-CLI is a tool that enables users to create and deploy subnets. With simple-to-use commands, developers can quickly run a Subnet locally and later deploy them on the Avalanche Fuji testnet.</p>
<p>At the time of writing, it supports the following:</p>
<ul>
<li>Creation of Subnet-EVM configs and Subnet-EVM forks</li>
<li>Local deployment of Subnet-EVM-based Subnets</li>
<li>Fuji deployment of Subnet-EVM-based Subnets</li>
</ul>
<p><strong>Our experience</strong></p>
<p>Avalanche-CLI is a great tool for quickly having something running on one’s machine. It does not require a lot of setup or complicated commands. One can interact with an Avalanche subnet with just five commands using common Ethereum tools like Remix and Metamask.</p>
<p>The downside to that ease of use is its limited functionality. The authors note that Avalanche-CLI is under active development and early in its lifecycle, so expect frequent changes and certain limitations with what one can do with it.</p>
<p>At the time of writing, it seems that only Subnet EVM is supported as the blockchain for the Subnet. One can edit the genesis file, enabling customizations of transaction fees, initial fund allocation, consensus, gossip, and validator communication. While this level of customization is quite a lot for someone just getting into the Avalanche network, we expect it is not enough for teams or products that want to deploy custom virtual machines highly tailored for their use case.</p></li>
<li><p><strong>AvalancheGo</strong></p>
<p>As the node implementation for the Avalanche network, AvalancheGo<sup>10</sup> is a foundational library one needs for Avalanche development. Besides running a node instance (which connects to the Avalanche network), the library also enables a wide berth of RPC endpoints for:</p>
<ul>
<li>Interacting with the P-Chain, C-Chain, and X-Chain</li>
<li>Examining the node’s internal state, health, basic information, and statistics</li>
<li>Manage authorization tokens</li>
<li>Fetch transactions, vertices, or blocks</li>
</ul>
<p><strong>Our Experience</strong></p>
<p>During this research, we used AvalancheGo to run our nodes on the Fuji testnet and were able to customize it to communicate with our custom subnet. We also used it together with Avalanche Network Runner and Subnet-CLI to build a custom virtual machine for our Subnet. As such, it was more used as a dependency for other Avalanche tools, and we only had limited interaction with it.</p>
<p>The library functioned without many issues. However, we do have to warn the reader to pay attention to the location of the installation, as quite a few guides assume the default installation location. Installing the library at a non-default location caused unnecessary difficulty following some guides and using other Avalanche network tools.</p>
<p>Since it is an integral library on the Avalanche network, we hope to dive deeper into this library in subsequent research efforts to learn its capabilities and limitations.</p></li>
<li><p><strong>Subnet-CLI</strong></p>
<p>A tool for managing Subnets on the Avalanche production network, this command line interface enables the user to create a new subnet, define its validators, and create and check the status of the blockchain for the Subnet.</p>
<p>Subnet-CLI is also required to build custom node configurations using the Avalanche Network Runner tool.</p>
<p><strong>Our experience</strong></p>
<p>At the time of research, Subnet-CLI was the only tool available for creating a Subnet on the Fuji testnet, so it is a winner in its category by default. Subsequently, Avalanche-CLI was updated to support this functionality, and we found it more straightforward to use than Subnet-CLI.</p>
<p>For now, Subnet-CLI seems to be the primary way to deploy a subnet on the Avalanche production network. However, Avalanche subnet libraries are still in rapid development. As such, we would recommend comparing the functionalities of Subnet-CLI and Avalanche-CLI to see which one has the capabilities the reader requires.</p></li>
<li><p><strong>Avalanche Network Runner</strong></p>
<p>The Avalanche Network Runner allows a user to define, create and interact with a network of Avalanche nodes. It can be used for development and testing. It aims at being a tool for developers and system integrators alike, offering functionality to run networks of AvalancheGo nodes. It also has support for custom node, Subnet, and network configurations, allowing to locally test code before deploying to the mainnet or public testnets<sup>11</sup>.</p>
<p>Although the tool has more dependencies and slightly more complicated commands than Avalanche-CLI, Avalanche Network Runner enables customized configuration for each node individually and more detailed logging when accessing the Subnet via API.</p>
<p><strong>Our experience</strong></p>
<p>We utilized the Avalanche Network Runner to create a Subnet of 5 nodes locally and to add a new node after subnet deployment. The experience was straightforward; we only encountered difficulty setting up the tool’s dependencies.</p>
<p>The ability to use the Avalanche Network Runner as a library enables the developer to set up scripts and access a subnet programmatically. This key feature enables faster testing and development of subnets, making ANR invaluable for developers.</p>
<p>As Avalanche Network Runner is intended as a tool for development and testing, we hope to utilize it more in subsequent research when we further cover developing subnets. In that research, we hope to give a more comprehensive description of this tool.</p></li>
<li><p><strong>Avalanche wallet</strong></p>
<p>The Avalanche wallet is a web application that allows users to create a new wallet or access their existing one. The app shows the wallet balance for each chain and any assets or collectibles the wallets hold.</p>
<p>Users can access their wallets using a private key, mnemonic phrase, keystore file, or a hardware ledger wallet. Access using Metamask is not available at the time of writing.</p>
<p>Inside the app, users can access their wallet address for each Avalanche network chain, send assets and collectibles (or create new collectibles), or send AVAX from one chain to another. Applying for staking or delegating is also available through the web wallet, as well as a view of previously executed transactions and UTXOs.</p>
<p><strong>Our experience</strong></p>
<p>We have used Avalanche wallet when registering a subnet on the Avalanche Fuji testnet for transferring funds between different Avalanche chains. Its missing feature to connect to Metamask does degrade the user experience, but overall the process was straightforward.</p>
<p>Although this paper primarily focuses on development tools, we wanted to mention the Avalanche wallet as something a developer will come across when deploying a subnet on the Fuji testnet, as the faucet transfers AVAX to the wallet on the X-Chain, and a transfer is necessary.</p></li>
<li><p><strong>Remix, Metamask, and Hardhat</strong></p>
<p>In this section, we wanted to mention some Ethereum tools we have used in Avalanche development and how they operated. For more details on specific tools from this group, check out our Web3 Technology Radar<sup>12</sup></p>
<p><strong>Our experience</strong></p>
<p>We used Remix and Metamask to deploy and interact with smart contracts on a local EVM compatible Subnet, and Hardhat for deploying a sample dApp on the Avalanche Fuji testnet.</p>
<p>Aside from customizing the RPC endpoint these tools use and the chain ID, these tools worked seamlessly with local and public Avalanche networks. As we mentioned, while we want to test more tools made for Ethereum on Avalanche in future research, we do not expect many issues with them functioning the same way on Avalanche as they would on Ethereum.</p></li>
</ol>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>In this research, we have described the three main components of the Avalanche network, how they interact to form subnets of validators with specific chains, and the underlying consensus mechanism for those chains. We have also given an overview of the guides and topics one would encounter when starting to work on Avalanche for the first time. Lastly, we have given a list of the technologies a developer should know when working with Avalanche and our experience with them.</p>
<p>We hope to have provided the reader with the foundational understanding of the Avalanche Network, its components, and introductory projects, which will enable them to decide whether Avalanche is a good choice for their use case and how they can get started if it is.</p>
<p>We hope to explore the Avalanche ecosystem further in subsequent research, specifically creating more customized virtual machines and testing, deploying, and monitoring subnets on the Avalanche production network. This research would also include measuring a subnet’s performance and programmatical use of the development tools to test network behavior before deployment.</p>
<p>The Avalanche network’s X-Chain is another subject we would like to research further. Its directed acyclic graph, the data structure of the chain, and high throughput are interesting subjects we would like to explore more comprehensively.</p>
</section>
<section id="bibliography" class="level1">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Bibliography</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-avalabsAvalancheDocs" class="csl-entry">
Ava Labs, ‘Avalanche Docs’, <em>Avalanche Docs</em> &lt;<a href="https://docs.avax.network/" class="uri">https://docs.avax.network/</a>&gt; [accessed 2 August 2022]
</div>
<div id="ref-avalabsAvalancheNetworkRunner" class="csl-entry">
———, ‘Avalanche Network Runner’, <em>Avalanche Network Runner</em> &lt;<a href="https://docs.avax.network/subnets/network-runner" class="uri">https://docs.avax.network/subnets/network-runner</a>&gt; [accessed 7 August 2022]
</div>
<div id="ref-avalabsAvalanchePlatform" class="csl-entry">
———, ‘Avalanche Platform’, <em>Avalanche Platform</em> &lt;<a href="https://docs.avax.network/overview/getting-started/avalanche-platform" class="uri">https://docs.avax.network/overview/getting-started/avalanche-platform</a>&gt; [accessed 2 August 2022]
</div>
<div id="ref-avalabsAvalancheGo" class="csl-entry">
———, ‘AvalancheGo’, <em>AvalancheGo Github Repository</em> &lt;<a href="https://github.com/ava-labs/avalanchego" class="uri">https://github.com/ava-labs/avalanchego</a>&gt; [accessed 7 August 2022]
</div>
<div id="ref-avalabsAvalancheGoAPIsOverview" class="csl-entry">
———, ‘AvalancheGo APIs Overview’, <em>AvalancheGo APIs Overview</em> &lt;<a href="https://docs.avax.network/subnets/customize-a-subnet" class="uri">https://docs.avax.network/subnets/customize-a-subnet</a>&gt; [accessed 3 August 2022]
</div>
<div id="ref-avalabsCreateEVMSubnet" class="csl-entry">
———, ‘Create an EVM Subnet on a Local Network’, <em>Create an EVM Subnet on a Local Network</em> &lt;<a href="https://docs.avax.network/subnets/create-a-local-subnet" class="uri">https://docs.avax.network/subnets/create-a-local-subnet</a>&gt; [accessed 2 August 2022]
</div>
<div id="ref-avalabsCreateEVMSubneta" class="csl-entry">
———, ‘Create an EVM Subnet on Fuji Testnet’, <em>Create an EVM Subnet on Fuji Testnet</em> &lt;<a href="https://docs.avax.network/subnets/create-a-fuji-subnet" class="uri">https://docs.avax.network/subnets/create-a-fuji-subnet</a>&gt; [accessed 3 August 2022]
</div>
<div id="ref-avalabsCustomizeYourEVMPowered" class="csl-entry">
———, ‘Customize Your EVM-Powered Subnet’, <em>Customize Your EVM-Powered Subnet</em> &lt;<a href="https://docs.avax.network/subnets/customize-a-subnet" class="uri">https://docs.avax.network/subnets/customize-a-subnet</a>&gt; [accessed 3 August 2022]
</div>
<div id="ref-avalabsSubnetCLI" class="csl-entry">
———, ‘Subnet-CLI’, <em>Subnet-CLI | Avalanche Docs</em> &lt;<a href="https://docs.avax.network/subnets/subnet-cli" class="uri">https://docs.avax.network/subnets/subnet-cli</a>&gt; [accessed 7 August 2022]
</div>
<div id="ref-avalabsSubnetsOverview" class="csl-entry">
———, ‘Subnets Overview’, <em>Subnets Overview</em> &lt;<a href="https://docs.avax.network/subnets" class="uri">https://docs.avax.network/subnets</a>&gt; [accessed 2 August 2022]
</div>
<div id="ref-mvpworkshopWeb3TechnologyRadar" class="csl-entry">
MVP Workshop, ‘Web3 Technology Radar’, <em>Web3 Technology Radar</em> &lt;<a href="https://web3radar.3327.io/tech-radar" class="uri">https://web3radar.3327.io/tech-radar</a>&gt; [accessed 7 August 2022]
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Ava Labs, ‘Subnets Overview’, <em>Subnets Overview</em> &lt;&lt;https://docs.avax.network/subnets&gt;&gt; [accessed 2 August 2022].↩︎</p></li>
<li id="fn2"><p>Ava Labs, ‘Avalanche Platform’, <em>Avalanche Platform</em> &lt;&lt;https://docs.avax.network/overview/getting-started/avalanche-platform&gt;&gt; [accessed 2 August 2022].↩︎</p></li>
<li id="fn3"><p>Ava Labs, ‘Avalanche Platform’.↩︎</p></li>
<li id="fn4"><p>Ava Labs, ‘Avalanche Docs’, <em>Avalanche Docs</em> &lt;&lt;https://docs.avax.network/&gt;&gt; [accessed 2 August 2022].↩︎</p></li>
<li id="fn5"><p>Ava Labs, ‘Create an EVM Subnet on a Local Network’, <em>Create an EVM Subnet on a Local Network</em> &lt;&lt;https://docs.avax.network/subnets/create-a-local-subnet&gt;&gt; [accessed 2 August 2022].↩︎</p></li>
<li id="fn6"><p>Ava Labs, ‘Create an EVM Subnet on Fuji Testnet’, <em>Create an EVM Subnet on Fuji Testnet</em> &lt;&lt;https://docs.avax.network/subnets/create-a-fuji-subnet&gt;&gt; [accessed 3 August 2022].↩︎</p></li>
<li id="fn7"><p>Ava Labs, ‘AvalancheGo’, <em>AvalancheGo Github Repository</em> &lt;&lt;https://github.com/ava-labs/avalanchego&gt;&gt; [accessed 7 August 2022].↩︎</p></li>
<li id="fn8"><p>Ava Labs, ‘Subnet-CLI’, <em>Subnet-CLI | Avalanche Docs</em> &lt;&lt;https://docs.avax.network/subnets/subnet-cli&gt;&gt; [accessed 7 August 2022].↩︎</p></li>
<li id="fn9"><p>Ava Labs, ‘Customize Your EVM-Powered Subnet’, <em>Customize Your EVM-Powered Subnet</em> &lt;&lt;https://docs.avax.network/subnets/customize-a-subnet&gt;&gt; [accessed 3 August 2022].↩︎</p></li>
<li id="fn10"><p>Ava Labs, ‘AvalancheGo APIs Overview’, <em>AvalancheGo APIs Overview</em> &lt;&lt;https://docs.avax.network/subnets/customize-a-subnet&gt;&gt; [accessed 3 August 2022].↩︎</p></li>
<li id="fn11"><p>Ava Labs, ‘Avalanche Network Runner’, <em>Avalanche Network Runner</em> &lt;&lt;https://docs.avax.network/subnets/network-runner&gt;&gt; [accessed 7 August 2022].↩︎</p></li>
<li id="fn12"><p>MVP Workshop, ‘Web3 Technology Radar’, <em>Web3 Technology Radar</em> &lt;&lt;https://web3radar.3327.io/tech-radar&gt;&gt; [accessed 7 August 2022].↩︎</p></li>
</ol>
</section></div> ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-336.hugo.html</guid>
  <pubDate>Thu, 28 Jul 2022 00:00:00 GMT</pubDate>
  <media:content url="https://3327.io/documents/research/assets/ERFC-336/Subnets.png" medium="image" type="image/png" height="83" width="144"/>
</item>
<item>
  <title>[ERFC - 278] Meritocratic voting</title>
  <dc:creator>Milan Pavlovic</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-278.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p>We considered a setting where a resource or rights are to be distributed among participants/members of a group. One possibility would be to allocate it equally (we can call this system democratic), another possibility would be to allocate it proportionally to relative efforts made, this system is known as meritocratic (based on credits earned).</p>
<p>We are mainly interested in the voting system (for example for DAOs), but believe that a similar system could be used in many other situations.</p>
<p>Prior to June, some of the existing solutions solves a good way process of weighted voting (MACI), and some (Colony) provide the solution for calculating reputation rating. Both have their missings - the role of coordinator in MACI, lack of ZK in Colony, for example. In the last weeks, Polygon came out with their PoligonID - web3 virtual identity which can store various data and uses ZK. It could be a great solution, after some testing and research, and one of its use cases could be Meritocratic voting. We could do deep dive into PolygonID and find others applications of it too, beside Meritocratic voting. It’s very new solution and we could be one of first adopters.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>We considered setting where a resource or rights are to be distributed among participants/members of group. One possibility would be to allocate it equally (we can call this system democratic), another possibility would be to allocate it proportionaly to relative efforts made, this system is known as meritocratic (based on credits earned).</p>
<p>We are mainly interested in voting system (for example for DAOs), but believe that similar system could be used in many other situations.</p>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p>The steps of this research include:</p>
<ul>
<li><p>Research use of blockchain as infrastructure for governance</p></li>
<li><p>Researching known practices, solutions, and implementations (eg. Aragon, Polkadot, Colony, MACI, PolygonID)</p></li>
<li><p>Research how ZK is used, where it is used, and how it could be used in systems which don’t use it yet</p></li>
<li><p>Research the possibility of making dapp</p></li>
</ul>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<p>The first question that one meets is who would favor one and who another system. A meritocratic system would favor members that have high rating/a lot of contributions. While it is a good thing to encourage members to make contributions it can disincentivize members with modest contributions from participating. Also if an objectively-good proposal can be vetoed by some small portion of the community, say 1%, then it doesn’t do well for the organization. If we are into realizing a project with a technical solution like a dapp, we should find the balance between these two extremes or include the option for user “how much meritocratic system” is wanted. Some further market research could be done in this direction.</p>
<p>The next phase of research shows that there are two groups of existing solutions that partly solves a problem at the root of this research. In one group there are solutions that solve problems of blockchain governance (such as Colony and other systems for the governance of DAOs). Another group is solutions for the voting system, most notable is MACI.</p>
<p>While MACI enables efficient weighted voting by using ZK proofs it has its drawbacks. Besides widely accepted missings such as having a coordinator, MACI does not have an efficiently updatable rating system. For example, if our Meritocratic system is to be used on some forum, the rating of a lot of members is changed daily. With MACI it is hard to register all that changes. If a rating of members in our Meritocratic system is rarely changed (for example we are using it for voting at universities where professors change their status/get a promotion every couple of years), MACI is a good existing solution - members pool does not change too fast and it can be efficiently updated. On the other side, MACI supports weighted voting (which because of ZK proofs is efficient) but relies that before voting we have the complete list of members (and their reputation). In short, MACI does not interfere a lot with members polls, it is mainly concerned with the process of voting alone.</p>
<p>Another group of existing solutions is solutions for the governance of blockchains, and DAOs, such as Colony. Colony supports a reputation system that is updateable and based on contributions but lacks ZK voting. They use simple commitments for voting, downsides are notable: after voting members must ‘unlock’ their vote; zk based voting system would be much better - more privacy, less cost. Also, even though Colony uses a reputation system, it does not do it on a blockchain (because of costs - the calculation is too large to be done on-chain due to technical and economic limitations (i.e.&nbsp;the block gas limit and the cost of gas, respectively), this calculation can easily be performed by a typical user’s computer.) so they also assume the role of coordinator. Also, I could not find that they are proving proof of valid reputation calculation, which could be important to some clients.</p>
<p>For a question of calculating reputation there are some nice solutions from Colony which takes into consideration a couple of parameters such as type of contribution, the quantity of contribution, and also the time of inactivity - which brings negative reputation. Reputation rating can be measured with transferable or nontransferable tokens, depending on the use case.</p>
<p>Polkadot is a PoS, mostly-on-chain governed blockchain platform with a number interesting additions, they have for example an elected council and a technical council. Voters require at least 5 DOT to participate in governance and their voting power is based on stake. At a glance, the voters elect councillors, directly vote on referenda and submit proposals. The councilors then have the power to veto dangerous proposals, elect the technical committee, submit proposal of their own for approval by the voters and also control the treasury. The technical council can submit emergency referenda, that are implemented immediately if approved. Identity on Polkadot can be conected with various web2 platforms such as Twitter or Linkedin. They do not use ZK, so that could be tech improvement. For that improvement we could get inspiration from Polygons PolygonID, or simply focus our research on it.</p>
<p>In middle of this research, Polygon came out with blogs that announce their solution for problems of this kind. At it’s core is their PolygonID - private identity on blockchain that uses power of ZK proofs. Namely, to someone prove their reputation, one can be in temptation to use it’s wallet address. But it comes with cost, it risks revalving whole history, a lot of data from wallet, only because of voting. To address such concerns Polygon came with a new Web3 identity primitive - Polygon ID will serve that purpose, and Polygon DAO will be its testing ground. Polygon only announced this project, saying:</p>
<p>“Over the coming months, the Polygon ID ecosystem will grow to include a set of tools, platform services and examples for developers to learn, test and integrate with their apps or dApps leveraging Polygon ID’s unique on-chain capabilities.”</p>
<p>Weather we are about to make our demo app or try to improve/understand some of existing ( PolygonID stands out), paper [2] from litterature sugests immportant questions to think about, some of which are: * Tradeoffs between Privacy vs.&nbsp;Verifiability and Suffrage * Proofs of Personhood, Identity-based suffrage and tradeoffs with Privacy * Meritocratic suffrage and tradeoffs with privacy * …</p>
<p>If we are about to make ZK solution for weighted voting, or reputation managment, good starting point is paper [3] of J. Groth in which there are numerous different votting system as well pseudo code and proofs of correctnes of main ZK attributes such as soundnes. For us, most interesting application would be ‘Borda Vote’. In Borda voting, voters cast weighted votes. The worst candidate gets 1 vote, the second worst 2 votes, and so forth. A valid vote is therefore on the form <img src="https://latex.codecogs.com/png.latex?%5Cprod_%7Bi=1%7D%5E%7BL%7D%20%5Cpi(i)M%5E%7Bi-1%7D"> for some permutation <img src="https://latex.codecogs.com/png.latex?%5Cpi">. In paper there is sugested protocool and correctnes argument for it.</p>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>Need for Meritocratic voting system is most cercitnly large, question is how big is need for frequent and large updates in mebembers poll (mostly because of changing reputation rating). If that need is also large, then doing deeper technical research on this subject is jutified. Arguably, without effective governance processes, blockchain technology will fail to reach its full potential</p>
<p>Solution for our Meritocratic voting problem should be mix of the two - reputation mainteinnig system and voting system. For voting phase we could use MACI (or some variation) but we should design more cost-friendly system for mainteing reputation score/updating members list. If members trust coordinators for that part, than Colony solution works. One upgrade would be to coordinator provide ZK proof for updating reputations of members - proof that state transition is OK. It is elegant solution because it can be done off blockchain an we can chalange coordinator. On the other side, it adds costs to coordinator. If organization does not want that cost it would use Colony.</p>
<p>Another route to go is to monitor closely on PolygonID, try to get some use-case examples, code, and documentation, and dig deeper into their solution. Based on MVP’s good collaboration with Polygon, and the top-of-the-class reputation of Polygon’s ZK teams, I believe that this is a good route to go. We could find others applications of it too, beside Meritocratic voting; and build dapps on-top-of their solution. It’s very new solution and we could be one of first adopters.</p>
</section>
<section id="appendices" class="level1">
<h1>Appendices</h1>
</section>
<section id="bibliography" class="level1">
<h1>Bibliography</h1>
<p>[1] Gradstein, M.; Voting on meritocracy. European Economic Review, 48(4), 797–803.; 2004</p>
<p>[2] SoK: Blockchain Governance; Aggelos Kiayias, Philip Lazos; 2022</p>
<p>[3] https://link.springer.com/chapter/10.1007/11496137_32</p>
<p>[4] https://colony.io/whitepaper.pdf</p>
<p>[5] https://github.com/privacy-scaling-explorations/maci</p>
<p>[6] https://blog.polygon.technology/state-of-governance-2-identity-reputation/</p>
<p>[7] https://blog.polygon.technology/polygon-id-x-polygon-dao-integration-launches-to-create-new-zk-based-governance-frameworks/</p>


</section>

 ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-278.hugo.html</guid>
  <pubDate>Mon, 25 Jul 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>[ERFC - 342] Intro to the Cosmos Network</title>
  <dc:creator>Milos Bojinovic</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-342.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p>Since its inception, Ethereum[1] has enabled smart contract functionality by introducing Ethereum Virtual Machine (EVM). This enabled the possibility of creating many different decentralized applications (DApps). Ethereum is a public general purpose blockchain where everyone can participate, deploy applications and compete for the chain’s resources.</p>
<p>This idea of a general purpose chain capable of handling multiple applications has certain limitations. The most important is the issue of scalability, where in times of network congestion, transaction fees skyrocket, leading to an awful user experience.</p>
<p>The other significant issue is that DApps suffer from a “two-layer” governance system. Besides honoring its rules, a DApp must honor the rules imposed by the protocol. It would be unfeasible to alter the protocol each time there’s a need to enable some feature for one of the DApps.</p>
<p>Besides Ethereum, there are other Layer 1 chains with different approaches. However, they are in ruthless competition with each other. They cannot effectively communicate, which leads to the segmentation of space and slowness of adoption.</p>
<p>Cosmos[2] proposes and enables a separate sovereign, parallel, and optimized chain for each DApp. These independent chains can be separately altered and upgraded on a protocol level while maintaining communication. This cross-chain communication can, under certain rules, be achieved both for new as well as existing chains.</p>
<p>This different way of thinking should be taken seriously as user experience will most likely be the main factor in the race for mass adoption. With 68.72 billion USD worth of assets present in the Cosmos ecosystem[3], this approach shows great potential and should be investigated further.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p><strong>Blockchain can be viewed as a replicated state machine that follows a predefined deterministic transition process.</strong></p>
<p>From the architecture’s standpoint, any blockchain on Cosmos is formed using three layers:</p>
<ul>
<li><strong>network layer</strong> meant to discover nodes that form a peer-to-peer (P2P) network and propagate transactions as well as consensus messages between those nodes</li>
<li><strong>consensus layer</strong> responsible for reaching an agreement between nodes of this P2P network</li>
<li><strong>application layer</strong> which defines the state and the rules under which a transaction can alter it</li>
</ul>
<p>This non-monolithic approach to building a blockchain is supported by a set of tools where:</p>
<ul>
<li>network and consensus layer (responsible for the replication of state across the nodes) are handled by the Tendermint Core[4], which communicates with the application layer through an Application Blockchain Interface (ABCI)*</li>
<li>application layer and its equivalent state machine is created using the Cosmos SDK[5]</li>
</ul>
<p><em>*Tendermint Core and ABCI together comprise Tendermint BFT</em></p>
<p>Using Inter Blockchain Communication (IBC), each Cosmos blockchain can connect with others. IBC also provides a mechanism for connecting with other non-cosmos chains.</p>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p>This exploratory research into the Cosmos project mainly focuses on understanding the architecture and its capabilities. The paper showcases its features and briefly discusses their potential.</p>
<p>However, the research does not go into the specifics of the Cosmos’ tools nor the projects that have been built. Each tool in the Cosmos’ stack should be a part of separate further research.</p>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<section id="cosmos-blockchain" class="level2">
<h2 class="anchored" data-anchor-id="cosmos-blockchain">Cosmos Blockchain</h2>
<section id="tendermint-core" class="level3">
<h3 class="anchored" data-anchor-id="tendermint-core">Tendermint Core</h3>
<p>Tendermint Core handles peer-discovery, validator selection, staking, upgrades, and consensus. In doing so, it heavily relies on:</p>
<ul>
<li><p><strong>Delegated Proof-of-Stake (DPoS)</strong> where validators and delegators vote on proposals with weights proportional to the amount they’ve staked.</p>
<ul>
<li>Validators accept the block by providing their signature. When the new block’s creator gathers the necessary signatures, it is finalized, and it cannot be overturned.</li>
<li>In a blockchain running on Tendermint, transactions have absolute finality, and hard forks should not happen.</li>
</ul></li>
<li><p><strong>Practical Byzantine Fault Tolerance</strong> guarantees that the blockchain will continue functioning even if up to 1/3rd of machines fail or become malevolent.</p></li>
</ul>
</section>
<section id="abci" class="level3">
<h3 class="anchored" data-anchor-id="abci">ABCI</h3>
<p>The ABCI is an interface between Tendermint Core and the application layer. It consists of three main message types:</p>
<ul>
<li><strong>AppendTx</strong> - each transaction is delivered with this message. The application layer checks the transaction’s validity against the application’s state and protocol. As well as if all of the necessary signatures are present.</li>
<li><strong>CheckTX</strong> - performs lower resolution checks (only checks in the transaction context are performed)</li>
<li><strong>Commit</strong> - computes a commitment of the current state which will be put into the new block’s header</li>
</ul>
</section>
<section id="application-layer" class="level3">
<h3 class="anchored" data-anchor-id="application-layer">Application layer</h3>
<p>It is worth explicitly noting that which was implied in the previous paragraphs: <strong>Tendermint doesn’t concern itself with the interpretation of transactions and is unopinionated about their meaning - this is the function of the application layer.</strong></p>
<p>The main focus for most developers involves making changes to the application layer through a framework written in Golang - <a href="https://docs.cosmos.network/">Cosmos SDK</a>. The application layer can be broken down into “modules,” which are built to have a single purpose, thus achieving separation of concerns. These modules are then combined to enable the intended functionality of the new blockchain.</p>
<p>Overall, the development process consists of:</p>
<ul>
<li>defining “messages” which are the main part of the transactions, and where:
<ul>
<li>each transaction can contain multiple messages</li>
<li>each message has a destination module responsible for processing the message</li>
</ul></li>
<li>defining “handlers” for those messages that are called when the corresponding message is received</li>
<li>defining “queries” that will provide a REST API through which the information about the chain’s state can be retrieved and displayed to the user</li>
</ul>
<p>One additional tool that eases the development, especially in the beginning, is the <a href="https://docs.ignite.com/">Ignite CLI</a>. This tool scaffolds pieces of code in the project and is extremely useful for newcomers.</p>
<p>To connect to the chain and to build, as well as issue, transactions, developers should use <a href="https://tutorials.cosmos.network/academy/5-cosmjs/cosmjs-intro.html">CosmJs</a>, a Javascript/Typescript library with which it’s relatively easy to integrate with <a href="https://www.keplr.app/">Keplr wallet</a>. CosmJs needs to know the types of messages in order to build a transaction; this is a somewhat time-consuming process as it needs to be done manually through a terminal - for more info, visit <a href="https://tutorials.cosmos.network/academy/5-cosmjs/create-custom.html">Create Custom CosmJS Interfaces</a></p>
</section>
</section>
<section id="ibc" class="level2">
<h2 class="anchored" data-anchor-id="ibc">IBC</h2>
<section id="zones-and-hubs" class="level3">
<h3 class="anchored" data-anchor-id="zones-and-hubs">Zones and Hubs</h3>
<p>Each independent Cosmos blockchain is referred to as a “zone”. Zones can be connected to “hubs” - blockchains dedicated to managing the communication of zones and their assets.</p>
<p>The Cosmos whitepaper[2] states:</p>
<blockquote class="blockquote">
<p>From the Hub’s perspective, a zone is a multi-asset dynamic-membership multi-signature account that can send and receive tokens using IBC packets. …</p>
</blockquote>
<blockquote class="blockquote">
<p>Like a cryptocurrency account, a zone cannot transfer more tokens than it has, but can receive tokens from others who have them. A zone may be designated as an “source” of one or more token types, granting it the power to inflate that token supply.</p>
</blockquote>
<p>Any of the zones can themselves be hubs to form an acyclic graph. Currently, only one hub exists - “Cosmos Hub”[6], which is the economic center of the whole ecosystem.</p>
<p>Hubs keep up with the state of each zone by the block commits that each zone posts. Zones, however, do not keep track of each other’s state. Information packets are transferred from one zone to another by posting Merkle-proofs which signal that the packet was sent/received.</p>
</section>
<section id="ibc-layers" class="level3">
<h3 class="anchored" data-anchor-id="ibc-layers">IBC layers</h3>
<p>IBC is comprised of two layers:</p>
<ul>
<li>Transport (sometimes referred to as the “Transport, Authentication and Ordering” (TAO)) layer is responsible for providing the infrastructure to establish communication lines between chains in order to transport the packets between the source (sending) and destination (receiving) chain</li>
<li>Application layer specifies how data from the packets should be structured and interpreted by the sending/receiving chain</li>
</ul>
<section id="transport-layer" class="level4">
<h4 class="anchored" data-anchor-id="transport-layer">Transport layer</h4>
<p>The transport layer’s components include:</p>
<ul>
<li><strong>light clients</strong> - which are a blockchain’s light representation. They are designed to connect to a full node and verify the block headers. Two zones (or zone and a hub) interacting over IBC must contain light clients of the other chain. Interestingly, these two chains do not send messages directly to each other but via “relayers”.</li>
<li><strong>relayers</strong> - permissionless off-chain processes constantly monitoring for the presence of the messages in the chain’s state machine. To do this, they need access to a full node of both chains</li>
<li><strong>connections</strong> - connect light clients of two different chains and can have an arbitrary number of “channels”</li>
<li><strong>channels</strong> - route packets to the intended modules; In order to facilitate two-way communication between chains A and B, a 4-step handshake is required:
<ul>
<li>the first message originates from A and signals the initialization attempt to chain B</li>
<li>the second message is sent from B that corresponds to the attempt to open a channel on chain A</li>
<li>the third message is an acknowledgment message sent from A to B that states that A’s channel is open</li>
<li>the fourth message is the confirmation sent from chain B to chain A that that B’s channel is also open</li>
</ul></li>
</ul>
</section>
<section id="application-layer-1" class="level4">
<h4 class="anchored" data-anchor-id="application-layer-1">Application layer</h4>
<p>The application layer sits on top of the TAO layer and supports, among others, these functionalities :</p>
<ul>
<li><strong>fungible (ICS20[7])</strong> / <strong>non-fungible token (NFT - ICS721[8])</strong> transfers</li>
<li><strong>Interchain Accounts ICS27[9]</strong> enable cross-chain interaction - any action that can be performed on the “host” chain can be initiated from the “controller” chain. From the host chain’s perspective, interchain accounts are just regular accounts controlled via IBC messages instead of having a private key.</li>
<li><strong>Interchain Security</strong> allows for a “provider” chain to be in charge of producing blocks for a “consumer” chain.</li>
<li><strong>Fee middleware</strong> is used to pay the costs and incentivize the operation of relayers</li>
<li>etc.</li>
</ul>
</section>
</section>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>This paper has provided a high-level overview of the Cosmos, which has taken a seriously thought-out approach to building blockchains. Its radical way of making the difficulty of developing an application-specific chain comparable to the development of a DApp on a general purpose chain is worth considering during the initial design stage of any project.</p>
<p>There are three major directions in which further research should be conducted:</p>
<ol type="1">
<li>diving deep into the projects built using Cosmos. One example of an interesting project is Evmos[2], a scalable, high-throughput PoS blockchain fully compatible and interoperable with Ethereum</li>
<li>assessing the capabilities of the Cosmos SDK</li>
<li>exploring the ways IBC can connect zones with Proof-Of-Work (PoW) chains</li>
</ol>
<p>Tendermint Core shouldn’t be a priority as it is a relatively old consensus mechanism and can be replaced by newer ones as long as they are adapted to honor the ABCI.</p>
</section>
<section id="bibliography" class="level1">
<h1>Bibliography</h1>
<p>[1] https://ethereum.org/en/whitepaper/</p>
<p>[2] https://v1.cosmos.network/resources/whitepaper</p>
<p>[3] https://cosmos.network/ecosystem/tokens/ (Accessed on 07/08/22)</p>
<p>[4] https://github.com/tendermint/tendermint</p>
<p>[5] https://v1.cosmos.network/sdk</p>
<p>[6] https://hub.cosmos.network/main/hub-overview/overview.html</p>
<p>[7] https://github.com/cosmos/ibc/blob/main/spec/app/ics-020-fungible-token-transfer/README.md</p>
<p>[8] https://github.com/cosmos/ibc/tree/main/spec/app/ics-721-nft-transfer</p>
<p>[9] https://github.com/cosmos/ibc/blob/main/spec/app/ics-027-interchain-accounts/README.md</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs">

</div></section></div> ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-342.hugo.html</guid>
  <pubDate>Sun, 24 Jul 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>[ERFC - 246] Token Engineering and Design of complex systems</title>
  <dc:creator>Aleksandar Damjanovic</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-246.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p>This is the first research paper in the series of research exploring Token Economics and Token Engineering tools and processes. It provides an introduction to the practice and the Process of Token Engineering. It also covers a portion of systems theory and the three most prevalent tools in the field of Token Engineering. These tools are:</p>
<ol type="1">
<li>Machinations - tool token engineers can use in designing Crypto Economic systems in all stages, from System Mapping to Evaluation and improvements on the running system.</li>
<li>cadCad - the package most often used in designing, testing, and validating complex systems through simulation.</li>
<li>TokenSPICE - an EVM Agent-Based Token Simulator written in Python which simulates tokenized ecosystems via an agent-based approach, with EVM “in the loop”.</li>
</ol>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>We as humans are participating in numerous systems in our everyday life. Our families are a system, schools we participate in, markets we shop at, and countries we are residents of all have rules and incentives to get us to comply with their rules and laws. Some incentives are positive (you get paid for your work), and some are negative (steal, and if you are not lucky, you will get caught). Nevertheless, they serve as a guide to the participant’s behavior.</p>
<p>In Web3, we have tokenized decentralized systems that anyone can participate in. Like any other system, the complex socio-economic system that is Web3 system must have rules and limitations to function correctly and according to its purpose. That is why said systems have their own economies to incentivize system participants towards a specific goal. These economies are called Token Economies, as Token is the medium by which transactions happen, and behavior is incentivized. “Tokens represent a part of the state of any cryptoeconomic systems and can be seen as their atomic unit.” - Shermin Voshmgir and Michael Zargham.</p>
<p>A token can cover various functions of money: medium of exchange, store of value, or unit of account. A token can represent anything in the confines of the Web3 tokenized system. But the question here is: How to actually design these tokenized ecosystems? How to analyze said design and simulate it?</p>
<p>This is where the emerging Token Engineering field comes into play.</p>
<p>Token Engineering as a term was first mentioned in 2018. in the paper “Can Blockchains Go Rogue?” by Trent McConaghy of Ocean Protocol. In the article, he calls blockchains the “incentive machines with the power to get people to do stuff by rewarding with tokens”. Trent McConaghy<sup>1</sup></p>
<p>Token engineering is a cross-disciplinary field that draws from systems, electrical, and robotics engineering practices. It also draws from Behavioural and Ecological Economics, AI, and Optimization. Its goal is to create reliable systems that work under varying circumstances and to create tokenomic systems that are exploit-proof. Shermin Voshmgir and Michael Zargham<sup>2</sup></p>
<p><img src="https://3327.io/documents/research/assets/ERFC-246/Cryptoecon.png" width="600"></p>
<p><em>Figure 1: Crypto Economic systems as a cross-disciplinary field</em></p>
<p>As Crypto Economic systems are complex, Token Engineering process includes:</p>
<ol type="1">
<li>Ideation and design of the system</li>
<li>Modelling</li>
<li>Simulation</li>
<li>Testing</li>
<li>Deployment</li>
<li>Maintenance</li>
</ol>
<p>This research will cover the process of token engineering and the tools used by token engineers to design, model and evaluate Crypto Economic systems. These tools are Machinations, cadCad and tokenSPICE.</p>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p>The goal of this research is to serve as an introduction to the field of the Token Engineering, the process of Token Engineering and its tools. It will explore the process as a whole. On the tool side, we will examine Machinations, cadCad, and TokenSPICE.</p>
<p>The research will be done by reviewing the documentation of said tools, trying them out, and interviewing the people behind them. We will also interview an experienced Token Engineer to understand how the process is assessed in practice.</p>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<section id="steps-in-token-engineering-process" class="level2">
<h2 class="anchored" data-anchor-id="steps-in-token-engineering-process">Steps in Token Engineering process</h2>
<p>Below we will present some general steps in the process of Token Engineering.</p>
<section id="system-mapping" class="level3">
<h3 class="anchored" data-anchor-id="system-mapping">System Mapping</h3>
<p><strong>Identifying what concepts and constructs are relevant to our model and goals for the system</strong></p>
<p>Before starting the process, we need to take systems thinking approach. In this stage of the design, the engineer:</p>
<ul>
<li>Builds stakeholder taxonomies by identifying stakeholder groups, their possible actions, and the form of their incentives</li>
<li>Lays out the system dynamics and agent goals.</li>
</ul>
<p>Some of the tools for system mapping are Cluster Maps and Ecosystem Canvas:</p>
<p><strong>Cluster Maps</strong></p>
<p>The system’s goal is set in the middle of a cluster map while the associated nodes are drawn around it. This is a not-so-rigorous approach and is often used to get an outline of the system engineer is creating.</p>
<p><img src="https://3327.io/documents/research/assets/ERFC-246/Cluster.jpeg" width="600"></p>
<p><em>Figure 2: Cluster map example</em>@acarogluToolsSystemsThinkers2017</p>
<p><strong>Ecosystem canvas</strong></p>
<p>When using this method, the purpose of the system is put at the center while key players are laid out in circles radiating outwards.</p>
<p><img src="https://3327.io/documents/research/assets/ERFC-246/Ecosystem_canvas.png" width="600"></p>
<p><em>Figure 3: Ecosystem canvas</em> Author stephenyo<sup>3</sup></p>
</section>
<section id="formalising-the-design" class="level3">
<h3 class="anchored" data-anchor-id="formalising-the-design">Formalising the design</h3>
<p>After the initial phase is the phase of formalizing the design using causal loop diagrams and stock and flow diagrams, there is another tool called Machinations that Token Engineers could use in this step. We will cover Machinations later in the paper.</p>
<p><strong>Causal Loop Diagrams</strong></p>
<p>“A causal loop diagram is a”snapshot of all relationships that matter.” It visualizes key variables (i.e., factors, issues, processes) and how they are interconnected. These diagrams show variables represented as texts and causal relationships between them as arrows.” ‘What Is a Causal Loop Diagram and What Is It Good For? | Marketlinks’<sup>4</sup></p>
<p><img src="https://3327.io/documents/research/assets/ERFC-246/causal_loop.png" width="600"></p>
<p><em>Figure 4: Causal Loop Diagram</em></p>
<p>In a Causal Loop Diagram positive relationships are labeled with a plus sign while negative relationships are labeled with a minus sign. Above example is often used to explain this type of diagrams. It shows how market saturation and word of mouth impact potential adopters and adoption rate.</p>
<p><strong>Stock and flow diagrams</strong></p>
<p>Stock and flow diagrams are a more complex way of formalizing the design. You can see below a representation of the simple system using this diagram.</p>
<p><img src="https://3327.io/documents/research/assets/ERFC-246/stock_flow.png" width="600"></p>
<p><em>Figure 5: Stock and Flow Diagram</em></p>
</section>
<section id="modularising-the-logic-and-model-building" class="level3">
<h3 class="anchored" data-anchor-id="modularising-the-logic-and-model-building">Modularising the logic and model building</h3>
<p>After formalizing the design, system modeling is done using an open-source python package, cadCad. We will cover cadCad in detail in the next section of the paper.</p>
</section>
<section id="refining-the-model" class="level3">
<h3 class="anchored" data-anchor-id="refining-the-model">Refining the model</h3>
<p>As the name suggests, this is the part in the process where the model is refined using quantitative and qualitative backtesting.</p>
</section>
<section id="evaluation-and-improvements-on-the-running-system" class="level3">
<h3 class="anchored" data-anchor-id="evaluation-and-improvements-on-the-running-system">Evaluation and improvements on the running system</h3>
<p>After the system is up and running cadCad model can be used as a “digital twin,” which allows token engineers to:</p>
<ul>
<li>evaluate proposed changes to the system</li>
<li>test the sensitivity of parameters</li>
<li>explore the success criteria and failure modes</li>
<li>evaluate behaviors and policies</li>
<li>make recommendations to governance bodies stephenyo<sup>5</sup></li>
</ul>
</section>
</section>
<section id="machinations" class="level2">
<h2 class="anchored" data-anchor-id="machinations">Machinations</h2>
<p>Machinations is a browser-based tool to design and balance game systems. This tool has seen use from game designers, consultants, developers, and analysts. Token Engineers can also use this tool in designing Crypto Economic systems in stages from System Mapping to Evaluation and improvements on the running system. Machinations shines in pre-production.</p>
<p>Using Machinations, Token Engineer can:</p>
<ul>
<li>Map systems in an interactive diagram</li>
<li>Set parameters that define resource flow</li>
<li>Plot and analyze the results in real-time using the chart option</li>
<li>Simulate outcomes for one player journey or stochastically using batch plays</li>
<li>Export outcomes in CSV</li>
<li>Export design parameters to Google Sheets</li>
</ul>
<p>Machinations is uses these types of nodes:</p>
<ul>
<li>Pools that collect Resources</li>
<li>Sources that create Resources</li>
<li>Drains that consume/destroy resources</li>
<li>Converters that transmute resources</li>
<li>Gates that redistribute resources</li>
</ul>
<p>And two types of connections:</p>
<ul>
<li>Resource connections that determine how the Resources flow</li>
<li>State connections that modify the state of diagram elements Dana<sup>6</sup></li>
</ul>
<p>Below you will find a basic diagram created in machinations that can be used to see the flow of an AMM system:</p>
<p><img src="https://3327.io/documents/research/assets/ERFC-246/Machinations.png" width="600"></p>
<p><em>Figure 6: Machinations diagram example</em></p>
<p>This design was done in less than 20 minutes and represents a basic flow of the user exchanging tokens for crypto using our AMM. The Key takeaway is that machinations, even though its main focus is on game design can be used for the stages of System Mapping and Formalising the design.</p>
</section>
<section id="cad-cad" class="level2">
<h2 class="anchored" data-anchor-id="cad-cad">cad Cad</h2>
<pre><code>                  ___________    ____
  ________ __ ___/ / ____/   |  / __ \
 / ___/ __` / __  / /   / /| | / / / /
/ /__/ /_/ / /_/ / /___/ ___ |/ /_/ /
\___/\__,_/\__,_/\____/_/  |_/_____/
by cadCAD                  ver. 0.4.28
======================================
       Complex Adaptive Dynamics       
       o       i        e
       m       d        s
       p       e        i
       u       d        g
       t                n
       e
       r</code></pre>
<p>cadCad is the package most often used in designing, testing, and validating complex systems through simulation. It supports Monte Carlo methods, A/B testing, and parameter sweeping. cadCad can model systems from agent-based modeling to system dynamic modeling. It can easily be integrated with other Python modules and data science workflows. But first, let’s briefly explain what these methods are:</p>
<p>“Monte Carlo simulations are used to model the probability of different outcomes in a process that cannot easily be predicted due to the intervention of random variables. It is a technique used to understand the impact of risk and uncertainty in prediction and forecasting models.” ‘What Is a Monte Carlo Simulation?’<sup>7</sup></p>
<p>“A/B Testing is a method to compare two (or more) variations of something and determine which one works better. In this method, users are randomly assigned to one of two variants. A statistical analysis is performed to determine which variation performs better for a defined business goal.”<sup>8</sup></p>
<p>“In modeling, parameter sweeps are an important method for fine-tuning parameter values, exploring parameter space, and calibrating simulations to data. A parameter sweep is an iterative process in which simulations are run repeatedly using different values of the parameter(s) of choice. This process enables the modeler to determine a parameter’s”best” value (or range of values), or even where in parameter space the model produces desirable (or non-desirable) behaviors.” ‘Parameter Sweeps and Model Iteration Idmtools Documentation’<sup>9</sup></p>
<p>Although it can be used to simulate any system that can be described as state variables that evolve over time according to a set of equations, cadCad has seen the most use in the Token Engineering process.</p>
<p>The first step in modeling using cadCad is the Visual System mapping we mentioned earlier.</p>
<p>Afterward, the next step is Mathematical specification using differential equations. For example, we will use the simple system of sheep from the cadCad introduction course:</p>
<p><img src="https://3327.io/documents/research/assets/ERFC-246/sheeps.png" width="600"></p>
<p>Here we set the initial differential equations for our model. It is self explanatory. Population growth depends on food sources.</p>
<p><em>Note: This is a simplified model used to for demonstration, Crypto Economy equations are much more complex</em></p>
<p>Afterwards, the Modelling and simulation process in general works like this:</p>
<p><img src="https://3327.io/documents/research/assets/ERFC-246/cadcad-flow.png" style="width:50.0%;height:50.0%"></p>
<p><em>Figure 7: cadCad processes</em></p>
<p>We will briefly explain the steps without going into code examples as we will cover plenty of code examples in future research papers:</p>
<ol type="1">
<li>First, the engineer defines all the state variables in the system and their initial values (they can be of any Python data type)</li>
<li>Afterwards, the variables that impact the behavior of the model.</li>
<li>Policy functions compute one or more signals to be passed to state update functions. They are used to describe the logic and behavior of a system component.</li>
<li>State update functions are then designed to define how the model changes over time.</li>
<li>Partial state update blocks are used for composing state update functions and policy functions in series or parallel.</li>
</ol>
<p>Simulation process steps:</p>
<ol type="1">
<li>In the configuration stage, engineer ties all the model compenents using “config_sim” and chooses how the simulation should run:
<ol type="1">
<li>The number of times it will run</li>
<li>The number of timesteps the simulation will run for</li>
<li>The parameters of the system</li>
</ol></li>
<li>Execution computes the simulation output</li>
<li>Output preparation is the process in which data is manipulated and analyzed in order to answer questions about the model.</li>
<li>Analysis is self explanatory - engineer evaluates the model performance and if there is a need, improves the model. Usually that is the case as the first model is almost always not the optimal one.</li>
</ol>
<p>As we can see cadCad covers the entire Token Engineering process with help from stock and flow diagrams and system mapping tools. We will cover this library and its functionalities in great detail in future research papers.</p>
</section>
<section id="tokenspice" class="level2">
<h2 class="anchored" data-anchor-id="tokenspice">TokenSPICE</h2>
<p>TokenSPICE is an EVM Agent-Based Token Simulator written in Python, which simulates tokenized ecosystems via an agent-based approach, with EVM “in the loop”.</p>
<p>Ethereum Virtual Machine (EVM) is a computation engine which acts like a decentralized computer that has millions of executable projects. It acts as the virtual machine which is the bedrock of Ethereum’s entire operating structure. ‘Ethereum Virtual Machine (EVM) | CoinMarketCap’<sup>10</sup></p>
<p>TokenSPICE has been mainly used in later stage analysis and for verifying and tuning the system designs.</p>
<p>Agent-based modeling focuses on the individual active components of a system. Agents in tokenSPICE can be DAOs, unique users, and other protocols, making it a versatile tool.</p>
<p>It can be used in Token Engineering flows to design, tune and verify tokenized ecosystems.</p>
<p>If the engineer wants to model on the smart contract code directly and skip the equations set up like in cadCad, then the tokenSPICE is the tool of choice.</p>
<p>It uses Brownie, which treats smart contracts as classes, making it easier to run simulations. It also requires less work upfront in contrast to cadCad. Write the contracts in Solidity, then simulate with tokenSPICE.</p>
<p>When you run the simulator, the run function in SimEngine.py is triggered and starts the run loop in it:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><span class="kw" style="color: #003B4F;">def</span> run(<span class="va" style="color: #111111;">self</span>):</span>
<span id="cb2-2">        <span class="co" style="color: #5E5E5E;">"""</span></span>
<span id="cb2-3"><span class="co" style="color: #5E5E5E;">        @description</span></span>
<span id="cb2-4"><span class="co" style="color: #5E5E5E;">          Runs the simulation!  This is the main work routine.</span></span>
<span id="cb2-5"></span>
<span id="cb2-6"><span class="co" style="color: #5E5E5E;">        @return</span></span>
<span id="cb2-7"><span class="co" style="color: #5E5E5E;">           &lt;&lt;none&gt;&gt; but it continually generates an output csv output_dir</span></span>
<span id="cb2-8"><span class="co" style="color: #5E5E5E;">        """</span></span>
<span id="cb2-9">        log.info(<span class="st" style="color: #20794D;">"Begin."</span>)</span>
<span id="cb2-10">        log.info(<span class="bu" style="color: null;">str</span>(<span class="va" style="color: #111111;">self</span>.state.ss) <span class="op" style="color: #5E5E5E;">+</span> <span class="st" style="color: #20794D;">"</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">"</span>)  <span class="co" style="color: #5E5E5E;"># pylint: disable=logging-not-lazy</span></span>
<span id="cb2-11"></span>
<span id="cb2-12">        <span class="cf" style="color: #003B4F;">while</span> <span class="va" style="color: #111111;">True</span>:  </span>
<span id="cb2-13">            <span class="va" style="color: #111111;">self</span>.takeStep()</span>
<span id="cb2-14">            <span class="cf" style="color: #003B4F;">if</span> <span class="va" style="color: #111111;">self</span>.doStop():</span>
<span id="cb2-15">                <span class="cf" style="color: #003B4F;">break</span></span>
<span id="cb2-16">            <span class="va" style="color: #111111;">self</span>.state.tick <span class="op" style="color: #5E5E5E;">+=</span> <span class="dv" style="color: #AD0000;">1</span> </span>
<span id="cb2-17">            chain.mine(blocks<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>, timedelta<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">self</span>.state.ss.time_step)</span>
<span id="cb2-18">        log.info(<span class="st" style="color: #20794D;">"Done"</span>)</span></code></pre></div>
<p>Every single time it loops, every single agent inside the state takes a step:</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"></span>
<span id="cb3-2"><span class="kw" style="color: #003B4F;">def</span> takeStep(<span class="va" style="color: #111111;">self</span>) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb3-3">        <span class="co" style="color: #5E5E5E;">"""Run one tick, updates self.state"""</span></span>
<span id="cb3-4">        log.debug(<span class="st" style="color: #20794D;">"============================================="</span>)</span>
<span id="cb3-5">        log.debug(<span class="st" style="color: #20794D;">"Tick=</span><span class="sc" style="color: #5E5E5E;">%d</span><span class="st" style="color: #20794D;">: begin"</span>, (<span class="va" style="color: #111111;">self</span>.state.tick))</span>
<span id="cb3-6"></span>
<span id="cb3-7">        <span class="cf" style="color: #003B4F;">if</span> (<span class="va" style="color: #111111;">self</span>.elapsedSeconds() <span class="op" style="color: #5E5E5E;">%</span> <span class="va" style="color: #111111;">self</span>.state.ss.log_interval) <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span>:</span>
<span id="cb3-8">            s, dataheader, datarow <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.createLogData()</span>
<span id="cb3-9">            log.info(<span class="st" style="color: #20794D;">""</span>.join(s))</span>
<span id="cb3-10">            <span class="va" style="color: #111111;">self</span>.logToCsv(dataheader, datarow)</span>
<span id="cb3-11"></span>
<span id="cb3-12">        <span class="co" style="color: #5E5E5E;"># main work</span></span>
<span id="cb3-13">        <span class="va" style="color: #111111;">self</span>.state.takeStep()</span>
<span id="cb3-14"></span>
<span id="cb3-15">        log.debug(<span class="st" style="color: #20794D;">"============================================="</span>)</span>
<span id="cb3-16">        log.debug(<span class="st" style="color: #20794D;">"Tick=</span><span class="sc" style="color: #5E5E5E;">%d</span><span class="st" style="color: #20794D;">: done"</span>, <span class="va" style="color: #111111;">self</span>.state.tick)</span></code></pre></div>
<p>The rest of the file is dedicated to logging the results into CSV format, and we will not examine it further.</p>
<p>Similarly, the simulation engine also takes a step when the Agents take a step in the simulation.</p>
<p>Simulation with tokenSPICE can be done using the following command in the terminal and the results can saved in CSV or a plot created in png:</p>
<pre><code>  tsp plot netlists/scheduler/netlist.py outdir_csv outdir_png</code></pre>
<p><em>Note: Netlists are just agents “wired-up”</em></p>
<p>Here we ran a vesting simulation in the Ocean protocol and this is the resulting plot:</p>
<p><img src="https://3327.io/documents/research/assets/ERFC-246/vesting.png" width="600"></p>
<p><em>Figure 8: Vesting simulation in tokenSPICE</em></p>
<p>You can run all kinds of netlists in order to get a “feel” of it, in the tokenSPICE <a href="https://github.com/tokenspice/tokenspice">official GitHub repo</a>.</p>
<p>In contrast to cadCad, which can be used for any type of system, tokenSPICE is focused on EVM systems and incentives. The main difference is that cadCad is mainly used in the early-stage design of systems.</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>Token Engineering as a field is still young, and the community around it is still tiny. However, the quality of tools available is exceptional. The tools range from general game design tools (Machinations) and general system design tools (cadCad) to specialized tools like tokenSPICE. The only missing piece of the puzzle are the Token Engineers, who will focus on mastering these tools to provide valuable insights into both designing and validating crypto-economic systems.</p>
<p>You can see the list of all possible tools for system modeling with tokens, and their strengths and weaknesses <a href="https://github.com/TokenEngineeringCommunity/summary-of-tools/blob/main/README.md">here</a>.</p>
<p>Considering the complex nature of systems in Web3, we have only discovered the tip of the iceberg and the picks to dig deeper and examine the economies of this vast ecosystem.</p>
</section>
<section id="bibliography" class="level1">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Bibliography</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-danaFrameworkBasicsMachinations" class="csl-entry">
Dana, ‘Framework Basics Machinations.io’, <em>Machinations.io</em> &lt;<a href="https://machinations.io/docs/framework-basics/" class="uri">https://machinations.io/docs/framework-basics/</a>&gt; [accessed 30 June 2022]
</div>
<div id="ref-EthereumVirtualMachine" class="csl-entry">
‘Ethereum Virtual Machine (EVM) | CoinMarketCap’, <em>CoinMarketCap Alexandria</em> &lt;<a href="https://coinmarketcap.com/alexandria/glossary/ethereum-virtual-machine-evm" class="uri">https://coinmarketcap.com/alexandria/glossary/ethereum-virtual-machine-evm</a>&gt; [accessed 17 July 2022]
</div>
<div id="ref-mcconaghyCanBlockchainsGo2020" class="csl-entry">
McConaghy, Trent, ‘Can Blockchains Go Rogue?’, <em>Medium</em>, 2020 &lt;<a href="https://blog.oceanprotocol.com/can-blockchains-go-rogue-5134300ce790" class="uri">https://blog.oceanprotocol.com/can-blockchains-go-rogue-5134300ce790</a>&gt; [accessed 29 June 2022]
</div>
<div id="ref-ParameterSweepsModel" class="csl-entry">
‘Parameter Sweeps and Model Iteration Idmtools Documentation’ &lt;<a href="https://institutefordiseasemodeling.github.io/idmtools/parameter-sweeps.html" class="uri">https://institutefordiseasemodeling.github.io/idmtools/parameter-sweeps.html</a>&gt; [accessed 1 July 2022]
</div>
<div id="ref-stephenyoTokenEngineeringProcess2019" class="csl-entry">
stephenyo, Author, ‘A Token Engineering Process’, <em>Syoung.org</em>, 2019 &lt;<a href="https://syounggallery.wordpress.com/2019/10/18/a-token-engineering-process/" class="uri">https://syounggallery.wordpress.com/2019/10/18/a-token-engineering-process/</a>&gt; [accessed 29 June 2022]
</div>
<div id="ref-voshmgirFoundationsCryptoeconomicSystems" class="csl-entry">
Voshmgir, Shermin, and Michael Zargham, ‘Foundations of Cryptoeconomic Systems’, 1.1, 18
</div>
<div id="ref-WhatCausalLoop" class="csl-entry">
‘What Is a Causal Loop Diagram and What Is It Good For? | Marketlinks’ &lt;<a href="https://www.marketlinks.org/resources/what-causal-loop-diagram-and-what-it-good" class="uri">https://www.marketlinks.org/resources/what-causal-loop-diagram-and-what-it-good</a>&gt; [accessed 30 June 2022]
</div>
<div id="ref-WhatMonteCarlo" class="csl-entry">
‘What Is a Monte Carlo Simulation?’, <em>Investopedia</em> &lt;<a href="https://www.investopedia.com/terms/m/montecarlosimulation.asp" class="uri">https://www.investopedia.com/terms/m/montecarlosimulation.asp</a>&gt; [accessed 1 July 2022]
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>‘Can Blockchains Go Rogue?’, <em>Medium</em>, 2020 &lt;&lt;https://blog.oceanprotocol.com/can-blockchains-go-rogue-5134300ce790&gt;&gt; [accessed 29 June 2022].↩︎</p></li>
<li id="fn2"><p>‘Foundations of Cryptoeconomic Systems’, 1.1, 18.↩︎</p></li>
<li id="fn3"><p>‘A Token Engineering Process’, <em>Syoung.org</em>, 2019 &lt;&lt;https://syounggallery.wordpress.com/2019/10/18/a-token-engineering-process/&gt;&gt; [accessed 29 June 2022].↩︎</p></li>
<li id="fn4"><p>&lt;[Https://www.marketlinks.org/resources/what-causal-loop-diagram-and-what-it-good](https://www.marketlinks.org/resources/what-causal-loop-diagram-and-what-it-good)&gt; [accessed 30 June 2022].↩︎</p></li>
<li id="fn5"></li>
<li id="fn6"><p>‘Framework Basics Machinations.io’, <em>Machinations.io</em> &lt;&lt;https://machinations.io/docs/framework-basics/&gt;&gt; [accessed 30 June 2022].↩︎</p></li>
<li id="fn7"><p><em>Investopedia</em> &lt;&lt;https://www.investopedia.com/terms/m/montecarlosimulation.asp&gt;&gt; [accessed 1 July 2022].↩︎</p></li>
<li id="fn8"><p><strong>devbot5sTesting2017?</strong>↩︎</p></li>
<li id="fn9"><p>&lt;[Https://institutefordiseasemodeling.github.io/idmtools/parameter-sweeps.html](https://institutefordiseasemodeling.github.io/idmtools/parameter-sweeps.html)&gt; [accessed 1 July 2022].↩︎</p></li>
<li id="fn10"><p><em>CoinMarketCap Alexandria</em> &lt;&lt;https://coinmarketcap.com/alexandria/glossary/ethereum-virtual-machine-evm&gt;&gt; [accessed 17 July 2022].↩︎</p></li>
</ol>
</section></div> ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-246.hugo.html</guid>
  <pubDate>Tue, 28 Jun 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>[ERFC - 315] Reaching Towards Realtime in Blockchain</title>
  <dc:creator>Milos Bojinovic</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-315.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p>The concept of <strong>Real-Time</strong> can be best explained as a set of guarantees that are given and that need to be met within a predetermined time period. Usually, though not necessarily, this is a short time period. In the case the guarantees are not met before the deadline has been reached, then the performance of the real-time system either degrades or the system has failed completely.</p>
<p>For a blockchain to achieve real-time operations, it has to have low latency and indirectly a high throughput, hopefully without sacrificing decentralization and security.</p>
<p>This is a problem of scaling a blockchain, and several approaches exist, each with its advantages and limitations. These approaches can be grouped into <strong>on-chain</strong> and <strong>off-chain</strong> scaling solutions, with the main difference being whether there exist a need for changing the blockchain’s protocol in some way.</p>
<p>The main focus of this research is put on the off-chain scaling in the Ethereum Ecosystem and how can a Decentralized Application (DApp) potentially achieve something that resembles real-time operations.</p>
<p>The research proposes a framework consisting of an off-chain and on-chain part where the on-chain part would be used to enforce rules that the off-chain code needs to honor.</p>
<p>The ideas proposed here would need to be expanded upon and thoroughly tested in real-world conditions to completely assess their practical significance.</p>
<p>Further research should also take into consideration on-chain scaling, namely ETH2.0, as well as an exciting concept of creating a network of private sovereign blockchains built specifically for the DApp’s needs.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<section id="ethereums-layer-1" class="level2">
<h2 class="anchored" data-anchor-id="ethereums-layer-1">Ethereum’s Layer 1</h2>
<p>Ethereum blockchain, as defined in,<sup>1</sup> can be viewed as a “transaction-based state machine” that groups transactions into blocks which are then sequentially executed in the order that was set by the block’s creator - miner.</p>
<p>Before being included inside a block, the transactions reside in the pending transaction pool. Miners have complete control over what transactions get included and in what order. Each transaction advances the chain’s state for which the miners are rewarded fees paid by the Externally-Owned-Account(EOA)* that initiated the transaction.</p>
<p>In essence, the more the EOA is willing to pay for the service of including their transaction, the more likely it is will be included in the next block. This creates the problem in the situation of blockchain’s network congestion - as the transactions are being created at a faster rate than they can be processed, fees drastically increase, and it becomes a competition between different EOAs, which leads to a bad user experience.</p>
<p>To ease the load put on the Ethereum Mainnet (Layer 1 - L1) chain and effectively perform scaling, multiple approaches exist: Sidechains and schemes commonly referred to as Layer 2 (L2) solutions. L2 solutions include State Channels, Plasma, and Rollups (Optimistic and Zero-Knowledge based).</p>
<p>* Ethereum account can be defined as a private-public keypair mapped to an address. EOA is a type of an Ethereum account where the private key is known and “externally” controlled, in contrast to smart contract accounts where the private key is not known, and only the address exists.</p>
</section>
<section id="off-chain-scaling-approaches" class="level2">
<h2 class="anchored" data-anchor-id="off-chain-scaling-approaches">Off-chain Scaling Approaches</h2>
<p>When considering approaches to Ethereum’s scaling problem, this paper considers only Ethereum Virtual Machine (EVM) compatible sidechains and optimistic rollups.</p>
<section id="sidechains" class="level3">
<h3 class="anchored" data-anchor-id="sidechains">Sidechains</h3>
<p>Sidechains are completely independent parallel blockchains to the Ethereum’s L1, with which they can communicate over two-way bridges. They introduce their own set of parameters and operate on different rules.</p>
<p>For example, <a href="https://polygon.technology/">Polygon</a>, a popular Ethereum sidechain, uses Proof-of-Stake for its consensus mechanism, with block times being around 2.3 seconds<sup>2</sup> (Ethereum’s average block time is between 12 and 14 seconds)<sup>3</sup></p>
</section>
<section id="optimistic-rollups" class="level3">
<h3 class="anchored" data-anchor-id="optimistic-rollups">Optimistic Rollups</h3>
<p>Unlike Sidechains, Optimistic Rollups have their security rooted in the L1 chain.</p>
<p>As Vitalik Buterin, the founder of Ethereum discusses in<sup>4</sup> :</p>
<blockquote class="blockquote">
<p>“Instead of putting all activity on the blockchain directly, users perform the bulk of their activity off-chain in a”layer 2” protocol. There is a smart contract on-chain, which only has two tasks: processing deposits and withdrawals and verifying proofs that everything happening off-chain is following the rules. There are multiple ways to do these proofs, but they all share the property that verifying the proofs on-chain is much cheaper than doing the original computation off-chain.”</p>
</blockquote>
<p>In Optimistic Rollups, after a state is proposed, there exists a period where it can be disputed, after which it cannot be longer challenged.</p>
<p>While anyone can propose a state, one of the optimistic rollups - <a href="https://developer.offchainlabs.com/docs/inside_arbitrum">Arbitrum One</a> chain has used a concept of a “sequencer”<sup>5</sup>:</p>
<blockquote class="blockquote">
<p>The sequencer is a specially designated full node, which is given limited power to control the ordering of transactions. This allows the sequencer to guarantee the results of user transactions immediately, without needing to wait for anything to happen on Ethereum. So no need to wait five minutes or so for block confirmations–and no need to even wait 15 seconds for Ethereum to make a block.</p>
</blockquote>
<p>The company behind Arbitrum has recently introduced another L2 concept chain - AnyTrust Chains<sup>6</sup>, which is operated by a “committee” of nodes signing the state that will later be put on-chain. If nodes go offline or refuse to cooperate, the chain reverts to a standard protocol.</p>
</section>
</section>
<section id="bridges-and-cross-chain-applications" class="level2">
<h2 class="anchored" data-anchor-id="bridges-and-cross-chain-applications">Bridges and Cross-chain Applications</h2>
<p>To enable cross-chain communication, there exist Bridges with the purpose of transferring assets and passing messages. The benefit of bridges is that users can move to a different chain if their needs require it. For example, when either transaction cost is too high or when there is more of a specific user activity going on the target chain - i.e., Non-Fungible Token (NFT) trading.</p>
<p>Bridges operate between two extremes - trusted (there is a centralized entity that is being <em>trusted</em>) and trustless (there is no need for the centralized entity).<sup>7</sup></p>
<p>The security of bridges, however, remains troublesome. As Buterin has pointed out in,<sup>8</sup> in the case of a 51% attack of the chain from which funds are being moved, attacker can broadcast a transaction that deposits some funds to the target chain and then revert it, as soon the assets are minted on the target chain. He states that:</p>
<blockquote class="blockquote">
<p>“… while I am optimistic about a multi-chain blockchain ecosystem (there really are a few separate communities with different values and it’s better for them to live separately than all fight over influence on the same thing), I am pessimistic about cross-chain applications.”</p>
</blockquote>
<section id="application-specific-blockchains" class="level3">
<h3 class="anchored" data-anchor-id="application-specific-blockchains">Application-specific Blockchains</h3>
<p>Instead of having all applications competing for the same resources, a DApp can run its own blockchain. There can exist inter-communication between those private and public chains through bridges.</p>
<p>Each chain operates with a unique set of rules and validators - making them sovereign but less decentralized.</p>
</section>
</section>
<section id="concept-of-time-in-blockchains" class="level2">
<h2 class="anchored" data-anchor-id="concept-of-time-in-blockchains">Concept of Time in Blockchains</h2>
<p>Blockchains operate in discrete time as the state is advanced only when a block is created and validated. It is worth noting that Ethereum’s Yellow Paper[2] states only that the current block’s timestamp should be strictly greater than its predecessor’s timestamp - not what’s the maximum difference between those two values.</p>
<p>This leads to blocks being produced at non-constant time intervals and the concept of time being distorted. When periods and deadlines are mentioned in this paper, it is meant in terms of block numbers.</p>
</section>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p>This paper tries to give a thought framework and a set of underlying principles that can be used to create a DApp that comes as close to real-time operations as possible.</p>
<p>It considers only EVM compatible chains when doing this and reasons how their properties can enable those operations.</p>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<p>The main ideas presented in this research are the separation of DApp’s functionality into parallel processes of different priorities while providing guarantees that a part of the process will be executed in a predefined period.</p>
<p>It breaks the DApp into its <strong>on-chain code</strong> (a set of smart contracts) and <strong>off-chain code</strong> (operates under rules imposed by the on-chain part).</p>
<section id="on-chain-code" class="level2">
<h2 class="anchored" data-anchor-id="on-chain-code">On-chain code</h2>
<section id="parallezization-of-processes" class="level3">
<h3 class="anchored" data-anchor-id="parallezization-of-processes">Parallezization of Processes</h3>
<p>Rather than separating DApp’s functionality into different contract methods with only one method being called per transaction, it is possible to have one method capable of executing different sequences of method calls and accomplishing more.</p>
<p>In the example shown below, there exist three separate processes(P0, P1, P2) that perform operations on the same set of data. Processes P0 and P1 are independent of each other and have no other dependencies (if EVM allowed concurrency, they could be executed in parallel). P2 is, however dependent on P0 and so before calling P2 we need to call P0.</p>
<pre class="solidity"><code>contract Example_0 {

    ...

    function execute (uint[] operation, uint[] data_0) public onlyAdmin returns (bool) {

        for (uint i = 0; i &lt; operation.length; ++i){

            if (operation[i] == 0){

                //P0 : calculate the sum of numbers in `data_0` and put in the `sum` storage variable

            } else if (operation[i] == 1){

                //P1 : store the entire `data_0` into the storage variable `buffer`

            } else if (operation[i] == 2){

                //P2 : if the `sum` even returns 'true'

            }
        }
        return false;
    }

    ...
}</code></pre>
<p>This setup allows us to create “programmable” sequences of operations and a higher degree of freedom. We can call the <code>execute</code> function with its <code>operation</code> argument set to [0, 2], [1], [0, 2, 1], [1, 0, 2] or [0, 1, 2]. We could also execute a single process multiple times by repeating a number corresponding to the process, though in the example above, that would not make much sense.</p>
</section>
<section id="persistence-across-transactions" class="level3">
<h3 class="anchored" data-anchor-id="persistence-across-transactions">Persistence across Transactions</h3>
<p>In the previous example, everything happens in the context of one single transaction, but it doesn’t have to. There can exist another process - P3 that would read from the <code>buffer</code> variable and perform a different operation on its data. Now the order of operations becomes even more important. Because P3 reads from the <code>buffer</code>, we could first call P1 that stores the <code>data_0</code> into the <code>buffer</code> and then P3 or first call P3 and after P1, which would exhibit a completely different behavior.</p>
</section>
<section id="prioritization-of-processes" class="level3">
<h3 class="anchored" data-anchor-id="prioritization-of-processes">Prioritization of Processes</h3>
<p>It is obvious that there are limitations to this approach - transaction size and the transaction cost. This is where prioritization comes in, as not all processes are created equal - some need to be executed more frequently in a shorter period of time while others are less important and can have higher latency. It is up to the DApp’s off-chain code to monitor, decide and optimize for the right moment when a process should be executed.</p>
</section>
<section id="providing-guarantees-committing-to-promises" class="level3">
<h3 class="anchored" data-anchor-id="providing-guarantees-committing-to-promises">Providing Guarantees: Committing to Promises</h3>
<p>Processes can depend upon each other; that is, they depend on the result(state) produced by previously executed processes. As there is so much that can fit into a single transaction, DApp doesn’t have to execute a process and produce a result right away - it can make a claim about that result and simultaneously commit to the promise that it will justify the claim later.</p>
</section>
<section id="honoring-commitments" class="level3">
<h3 class="anchored" data-anchor-id="honoring-commitments">Honoring Commitments</h3>
<p>Commitments made obviously need to be honored. Otherwise, there is no point. If the deadlines are not met, DApp should be penalized, and the users affected should be compensated.</p>
<p>However, there is no direct reason to halt the execution of the processes - they can operate on claims. The issue now becomes that they effectively act on promises - if it is found later on that the claim has not been honored, the processes and all of their results should be affected as well. An example of this dependency is shown in Figure 1.</p>
<center>
<p><img src="https://3327.io/documents/research/assets/ERFC-315/OperatingOnPromises.png" class="img-fluid"></p>
<p>Figure 1: Operating on Claims</p>
</center>
<p>For simplicity, states (S0, S1, S2, S3, S4) are just <code>uint</code> variables, while P0 and P1 are addition and multiplication operations, respectively. The yellow color indicates that a claim has been made for that variable, while green says that the claim has been honored. We see that claiming S0 affects S2 and S4.</p>
<p>It gets even more complicated when a process operates on and produces an update to the same variable. For instance, in Figure 1, if the S2 is fixed to always be equal to S0. The on-chain code would need to keep track of what is affected if the specific claim will not be honored.</p>
<p>How to effectively implement mechanisms that would take into account all of these concerns should be part of separate research.</p>
</section>
</section>
<section id="off-chain-code" class="level2">
<h2 class="anchored" data-anchor-id="off-chain-code">Off-chain code</h2>
<p>Off-chain code’s responsibility can be summed up to:</p>
<ul>
<li>monitor the state of the contract and all of the commitments that need to be honored</li>
<li>decide what to put inside the transaction by predicting when is the best time to execute a process</li>
</ul>
<section id="monitoring-the-on-chain-activity" class="level3">
<h3 class="anchored" data-anchor-id="monitoring-the-on-chain-activity">Monitoring the on-chain activity</h3>
<p>In the case where only the admin account can alter the contract’s state, off-chain code can maintain a separate record offline that will periodically be checked with the actual state read from the chain. If it is possible for users to interact directly with the contract, then the chain needs to be read more often - one approach would be to parse the blocks as soon as they are validated.</p>
</section>
<section id="optimization-of-action-sequences" class="level3">
<h3 class="anchored" data-anchor-id="optimization-of-action-sequences">Optimization of action sequences</h3>
<p>Deciding on how to structure a transaction is a more complex problem, and its main part resides in the scheduling of processes. When should a specific process be scheduled depends on what claims need to be honored and when, as well as the state of the network. If the demand for the network’s resources is high, the execution cost is high as well, so it is better to issue a transaction that will use a lot of resources when the demand becomes lower. However, there is no formal guarantee when a transaction will be mined; there would need to exist models that would try to predict and speculate how the demand will change over time and how much to incentivize the miners.</p>
<section id="bursts-of-transcatiions" class="level4">
<h4 class="anchored" data-anchor-id="bursts-of-transcatiions">Bursts of transcatiions</h4>
<p>Another important concept is that an EOA can create multiple transactions that can be included in the same block. The miner needs to honor only the order in which they are issued.<sup>9</sup> This can be used to enable “bursts” of transactions in order to catch up with the claims that are pending. If there are multiple accounts interacting with the contract, then the order is not guaranteed so there would need to exist some form of synchronization across transactions.</p>
</section>
</section>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>This research has defined a set of principles on how an individual DApp can be structured in order to more effectively distribute its functionality. The ideas proposed have not been tested in practice, so there exists a cloud of doubt about whether this approach is generalizable and sufficient for a large number of DApps.</p>
<p>The research has operated on the assumption that only the DApp’s admin account can alter the on-chain state of a contract, whether by aggregating** the users’ activity or by issuing commands that are made possible by on-chain code. There exist a problem of what happens if the DApp’s off-chain code goes offline, the users should not suffer for it, and so there needs to exist a mechanism that would enable the users to alter the contract’s state as well, which introduces more complexities in the DApp’s design.</p>
<p>The main proposed direction for further research is taking an existing real-world DApp and restructuring its code to enable “parallelization”. Also, as everything is dependent on the off-chain’s code correct scheduling of actions studies and simulations would need to be conducted based on a specific chain’s properties to see how much a chain can handle in terms of the block size, block time, transaction’s execution cost…</p>
<p>Another direction would be Ethereum’s on-chain scaling solution - ETH 2.0, as well as private chains and non-EVM chains and their approaches.</p>
<p>**By collecting signed messages from users that correspond to the action that the user wants to make. This, however, introduces the potential for censorship as well as manipulation when a message will be included in a transaction (both in terms of block numbers and in terms of ordering of messages).</p>
</section>
<section id="bibliography" class="level1">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Bibliography</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-IncompleteGuideRollups" class="csl-entry">
‘An Incomplete Guide to Rollups’ &lt;<a href="https://vitalik.ca/general/2021/01/05/rollup.html" class="uri">https://vitalik.ca/general/2021/01/05/rollup.html</a>&gt; [accessed 26 June 2022]
</div>
<div id="ref-Blocks" class="csl-entry">
‘Blocks’, <em>Ethereum.org</em> &lt;<a href="https://ethereum.org" class="uri">https://ethereum.org</a>&gt; [accessed 27 June 2022]
</div>
<div id="ref-EthereumMiningEthHub" class="csl-entry">
‘Ethereum Mining - EthHub’ &lt;<a href="https://docs.ethhub.io/using-ethereum/mining/" class="uri">https://docs.ethhub.io/using-ethereum/mining/</a>&gt; [accessed 21 June 2022]
</div>
<div id="ref-EthereumWhitepaper" class="csl-entry">
‘Ethereum Whitepaper’, <em>Ethereum.org</em> &lt;<a href="https://ethereum.org" class="uri">https://ethereum.org</a>&gt; [accessed 27 June 2022]
</div>
<div id="ref-ArbitrumOffchainLabs" class="csl-entry">
‘Inside Arbitrum <img src="https://latex.codecogs.com/png.latex?%5Ccdot"> Offchain Labs Dev Center’ &lt;<a href="https://developer.offchainlabs.com/" class="uri">https://developer.offchainlabs.com/</a>&gt; [accessed 27 June 2022]
</div>
<div id="ref-IntroductionBlockchainBridges" class="csl-entry">
‘Introduction to Blockchain Bridges’, <em>Ethereum.org</em> &lt;<a href="https://ethereum.org" class="uri">https://ethereum.org</a>&gt; [accessed 26 June 2022]
</div>
<div id="ref-labsIntroducingAnyTrustChains2022" class="csl-entry">
Labs, Offchain, ‘Introducing AnyTrust Chains: Cheaper, Faster L2 Chains with Minimal Trust Assumptions’, <em>Offchain Labs</em>, 2022 &lt;<a href="https://medium.com/offchainlabs/introducing-anytrust-chains-cheaper-faster-l2-chains-with-minimal-trust-assumptions-31def59eb8d7" class="uri">https://medium.com/offchainlabs/introducing-anytrust-chains-cheaper-faster-l2-chains-with-minimal-trust-assumptions-31def59eb8d7</a>&gt; [accessed 27 June 2022]
</div>
<div id="ref-polygonscan.comPolygonPoSChain" class="csl-entry">
polygonscan.com, ‘Polygon PoS Chain Average Block Time Chart | PolygonScan’, <em>Polygon (MATIC) Blockchain Explorer</em> &lt;<a href="http://polygonscan.com/chart/blocktime" class="uri">http://polygonscan.com/chart/blocktime</a>&gt; [accessed 27 June 2022]
</div>
<div id="ref-vbuterinFundamentalSecu2022" class="csl-entry">
vbuterin, ‘The Fundamental Secu…’, <em>R/Ethereum</em>, 2022 &lt;<a href="https://www.reddit.com/r/ethereum/comments/rwojtk/ama_we_are_the_efs_research_team_pt_7_07_january/hrngyk8/">www.reddit.com/r/ethereum/comments/rwojtk/ama_we_are_the_efs_research_team_pt_7_07_january/hrngyk8/</a>&gt; [accessed 26 June 2022]
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>‘Ethereum Whitepaper’, <em>Ethereum.org</em> &lt;&lt;https://ethereum.org&gt;&gt; [accessed 27 June 2022].↩︎</p></li>
<li id="fn2"><p>Polygonscan.com, ‘Polygon PoS Chain Average Block Time Chart | PolygonScan’, <em>Polygon (MATIC) Blockchain Explorer</em> &lt;&lt;http://polygonscan.com/chart/blocktime&gt;&gt; [accessed 27 June 2022].↩︎</p></li>
<li id="fn3"><p>‘Blocks’, <em>Ethereum.org</em> &lt;&lt;https://ethereum.org&gt;&gt; [accessed 27 June 2022].↩︎</p></li>
<li id="fn4"><p>‘An Incomplete Guide to Rollups’ &lt;&lt;https://vitalik.ca/general/2021/01/05/rollup.html&gt;&gt; [accessed 26 June 2022].↩︎</p></li>
<li id="fn5"><p>‘Inside Arbitrum <img src="https://latex.codecogs.com/png.latex?%5Ccdot"> Offchain Labs Dev Center’ &lt;&lt;https://developer.offchainlabs.com/&gt;&gt; [accessed 27 June 2022].↩︎</p></li>
<li id="fn6"><p>Offchain Labs, ‘Introducing AnyTrust Chains: Cheaper, Faster L2 Chains with Minimal Trust Assumptions’, <em>Offchain Labs</em>, 2022 &lt;&lt;https://medium.com/offchainlabs/introducing-anytrust-chains-cheaper-faster-l2-chains-with-minimal-trust-assumptions-31def59eb8d7&gt;&gt; [accessed 27 June 2022].↩︎</p></li>
<li id="fn7"><p>‘Introduction to Blockchain Bridges’, <em>Ethereum.org</em> &lt;&lt;https://ethereum.org&gt;&gt; [accessed 26 June 2022].↩︎</p></li>
<li id="fn8"><p>Vbuterin, ‘The Fundamental Secu…’, <em>R/Ethereum</em>, 2022 &lt;[www.reddit.com/r/ethereum/comments/rwojtk/ama_we_are_the_efs_research_team_pt_7_07_january/hrngyk8/](https://www.reddit.com/r/ethereum/comments/rwojtk/ama_we_are_the_efs_research_team_pt_7_07_january/hrngyk8/)&gt; [accessed 26 June 2022].↩︎</p></li>
<li id="fn9"><p>‘Ethereum Mining - EthHub’ &lt;&lt;https://docs.ethhub.io/using-ethereum/mining/&gt;&gt; [accessed 21 June 2022].↩︎</p></li>
</ol>
</section></div> ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-315.hugo.html</guid>
  <pubDate>Sun, 19 Jun 2022 00:00:00 GMT</pubDate>
  <media:content url="https://3327.io/documents/research/assets/ERFC-315/OperatingOnPromises.png" medium="image" type="image/png" height="55" width="144"/>
</item>
<item>
  <title>[ERFC - 248] Crosschain Identity</title>
  <dc:creator>Aleksandar Damjanovic</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-248.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p>When we look at the current Web2 user identity solutions, we can see that they are mostly linked to centralized corporate organizations. Although convenient for the end-user, this type of online identity is not owned by the user, and the issuers (Google, Facebook, Twitter, etc.) have complete control of them. In Web3, the focus is on decentralization; however, the problem of cross-chain interoperability of identities is a big one to overcome.</p>
<p>This paper examines the current state of cross-chain identity solutions and the technology behind them to understand how they operate and tackle the previously mentioned interoperability problem. Those solutions are:</p>
<ol type="1">
<li>Litentry - a decentralized cross-chain identity aggregator which enables linking user identities across multiple networks. Litentry collects, indexes, and distributes DIDs to blockchains in a decentralized way.</li>
<li>ORE - a cross-chain global identity registry where users have control over their own identity.</li>
<li>Accumulate (mainnet launch planned for September 2022) - an identity-based, delegated proof-of-stake blockchain solution.</li>
</ol>
<p>It also shortly covers Decentralized Identifiers (DIDs), Accumulate Digital Identifiers (ADIs), tests and analyzes the project’s solutions and current place in the Web3 market.</p>
<p>This paper does not cover Web3 identity solutions that are not cross-chain, as that is not the main focus of this research.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>In Web2, most users’ online identities are linked to centralized corporate organizations like Facebook, Twitter, or Google. The problem with this type of identity is that these organizations “own” your identity on the platform and the associated data. That means that the ease of use (single click logins, app interoperability, etc.) often comes with the price mentioned above. Corporate organizations can close and ban users’ accounts and sell their data which has been the case before. As they have all the data from the user, they can (technically) also generate credentials and log into any website using the user’s identity. ‘Thousands of Leaked Facebook Documents Show Mark Zuckerberg as “Master of Leverage” in Plan to Trade User Data’<sup>1</sup></p>
<p>Web3 is based on blockchain technology. Aside from use in financial applications, blockchain can be used in creating and managing Self-sovereign digital identities, like SSIs. SSI is a digital identity concept in which an individual or company has complete control over their account and personal data. ‘Self-Sovereign Identities’<sup>2</sup></p>
<p>The identity means nothing without claims from trusted sources (government ID credentials, student ID credentials, library card certificates). If many trusted parties assign claims to identity, thus implicitly confirming it, then the identity is valid. We use our ID number, issued by the government, anywhere, and every organization in the country will accept our identity number as it was issued by the trusted party confirming the identity. The validity of the identity is not in the keys, but the claims and the keys are there to verify that we indeed hold those claims.</p>
<p>Currently, when it comes to creating identity in Web3, we have various “approaches” to it:</p>
<ul>
<li>A user’s public key can be seen as a kind of identity on the blockchain. However, it is not very user-friendly, and it is limited in terms of cross-chain interoperability and in terms of representing a user. Users can own multiple addresses, thus having multiple “identities.”</li>
<li>In terms of creating an identity on the Ethereum blockchain, Ethereum Naming Service is the most used. ENS’s job is to map human-readable names like ‘3327.eth’ to machine-readable identifiers such as Ethereum addresses, other cryptocurrency addresses, content hashes, and metadata. ENS addresses can represent the user’s identity and be a kind of a user’s profile with its subdomains.</li>
<li>Various identity aggregators like Litentry, IDX, Accumulate, ORE network (this is debatable), etc.</li>
<li>SBTs and soul accounts are also proposed as a possible solution for an identity standard. However, they are currently a concept. They could evolve and become the standard someday.</li>
</ul>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p>This research will explore current solutions for creating a cross-chain Web3 identity (aggregators, protocols). After mapping the solutions, this research will propose the next steps in tackling this issue.</p>
<p>This paper will tackle this topic by reviewing various cross-chain solutions’ documentation and whitepapers and exploring their properties, implementation, and differences.</p>
<p>This paper will not be covering Web3 identity solutions that are not cross-chain.</p>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<p>Below we will discuss some of the current solutions that are trying to tackle cross-chain identity.</p>
<section id="litentry---identity-aggregator" class="level2">
<h2 class="anchored" data-anchor-id="litentry---identity-aggregator">Litentry - identity aggregator</h2>
<p>Litentry is a decentralized cross-chain identity aggregator which enables linking user identities across multiple networks. Litentry collects, indexes, and distributes DIDs to blockchains in a decentralized way.</p>
<p>Aggregation is the process of integrating a wide range of digital identities from multiple networks.</p>
<p>“Decentralized identifiers (DIDs) are a new type of identifier that enables verifiable, decentralized digital identity. A DID refers to any subject (e.g., a person, organization, thing, data model, abstract entity, etc.) as determined by the controller of the DID.” DIDs, by design, allow the controller of a DID to prove control over it without requiring permission from any other party. ‘Decentralized Identifiers (DIDs) V1.0’<sup>3</sup></p>
<p>Litentry’s main selling point is its decentralized identity and user activity data aggregation infrastructure. It is built on Substrate network.</p>
<p>Protocols could use identity aggregating service for collateralized lending, DeFi insurance rate, and DAO voting power calculations, preventing bots from getting airdrops and various other uses in dApps.</p>
<p>Main features of Litentry:</p>
<ol type="1">
<li>Identity management - The primary focus of this platform are identities. Litentry provides anonymous and independent identities from applications and services used by the user.</li>
<li>Identity Staking - As well as staking tokens and earning, users can “stake” their identity and get rewards.</li>
<li>Distributed storage of identity data.</li>
<li>Users do not need to create multiple accounts to use different platforms of services. They can use one identity to interact with various services.</li>
</ol>
<p>Using Litentry, blockchain projects can “offer” special services to users based on their identity’s quantified data.</p>
<p>“For example, if a new project knows that an account is a Polkadot validator, and it spends hundreds of DOTs on another Parachain for half a year, then the project could directly gift this specific user some token to start to play with, or send him/her an attractive offer of the new DeFi product, or accredit him to be a validated voter.” Litentry<sup>4</sup></p>
<p>It features an identity matching and identity staking mechanism, which are at the very core of the Litentry model. But what do they represent exactly?</p>
<p>Identity Matching is blind matchmaking where random anonymous identities are picked from the on-chain pool of identities, and the substrate off-chain worker processes candidate identity data. The network sends the matchwinners DID as a matching opportunity back to the matching buyer (for example, dApp that wants to do an airdrop). The buyer only has access to the matchwinner’s DID; thus match buyer pays the LIT token in exchange for a matching opportunity.</p>
<p>When it comes to identity staking, that is the process in which an identity owner sends the snapshot of their identity document and DID to the identities pool of blockchain and authorizes the read permissions to the validator node. The owner gets staking and matching rewards in the following blocks. The document is encrypted and stored on IPFS or on the on-chain key-value store. DID is stored on-chain.</p>
<p>Litentry’s use cases and platforms that cover these use cases:</p>
<ol type="1">
<li>TaskFi &amp; Airdrops Whitelisting - Not yet implemented (Drop3 Platform)</li>
</ol>
<p>Litentry identity verification system enables Web3 projects to identify target users and filter out bots. It also has a mechanism where users need to complete the task and then get rewarded after the task is complete.</p>
<ol start="2" type="1">
<li>Social interaction (My Crypto Profile)</li>
</ol>
<p>Using Litentry’s cross-chain capabilities, this platform enables users to generate proof of ownership of various accounts and create a unique identity graph that connects accounts and addresses from Ethereum, Binance, Polkadot, Kusama, Phala, Twitter, and Github into a <strong>unique</strong> Web3 identity. This identity can grant access to various dApps and Airdrops. ‘My Crypto Profile | 0x4d52f8d989796ffde311da9ad696258d5a7b3cc5’<sup>5</sup></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://3327.io/documents/research/assets/ERFC-248/MCP.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">MCP</figcaption><p></p>
</figure>
</div>
<p><em>Picture 1: My Crypto Profile Identity Graph</em></p>
<ol start="3" type="1">
<li>Identity Data Analytics (Web3Go)</li>
</ol>
<p>Web3 go is a multi-chain platform that uses Litentry’s DID aggregated identity data to analyze and provide insights into the activity of a particular cross-chain identity or identities.</p>
<ol start="4" type="1">
<li>Polkadot Name system</li>
</ol>
<p>Litentry currently acts as the main registrar entry for PNS (Polkadot Name System ). Public data is indexed into the domain name with the private name reserved in Litentry’s TEE side chain. A Trusted Execution Environment (TEE) is an environment for executing code; it guarantees code and data loaded inside to be protected with respect to confidentiality and integrity. ‘Polkadot Name System’<sup>6</sup></p>
<p>Litentry products technical overview:</p>
<ol type="1">
<li>Litentry Graph</li>
</ol>
<p>Litentry Graph serves clients with aggregated identity data from Substrate and EVM-based networks. Data is taken directly from the blockchain using APIs such as Polkadot API or using blockchain indexers.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://3327.io/documents/research/assets/ERFC-248/Graph.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Graph</figcaption><p></p>
</figure>
</div>
<p><em>Picture 2: Litentry Graph overview</em></p>
<p>Litentry Graph - An Express GraphQL server using schema stitching to aggregate a collection of remote schemas and subschemas.</p>
<p>Substrate Indexer - takes the data from the Substrate Archives and transforms it into a schema designed for easy querying. Postgres is used to store the data, and a GraphQL query node is used to serve the data to the Litentry graph as a remote schema. This indexer is hosted by Litentry.</p>
<p>Substrate Archive - Is a Postgres database with a real-time feed of raw events and extrinsic data directly from the blockchain. A GraphQL query node is used to serve the data to the Substrate Indexer.</p>
<p>Ethereum &amp; BSC Indedxers - Litentry uses The Graph.</p>
<p>Substrate Chain - The Substrate Chain component queries data directly from blockchain nodes via web sockets using the Polkadot API.</p>
<ol start="2" type="1">
<li>Drop 3</li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://3327.io/documents/research/assets/ERFC-248/Drop3.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Drop3</figcaption><p></p>
</figure>
</div>
<p><em>Picture 3: Drop3 Overview</em></p>
<p><strong>Pallets, Ethereum Verify Bot and Web3 go Analysis are not yet implemented</strong></p>
<p>Drop3 is still in the works. However, they have implemented some tasks into the product like getting verified as a human, connecting polkadot wallet etc.</p>
<ol start="3" type="1">
<li><p>Governance mobile App - We will not go into details of this product as mobile apps are not the topic of the research.</p></li>
<li><p>My Crypto Profile</p></li>
</ol>
<p>Identity Graph:</p>
<pre><code>{
  "version": "v0.1",
  "did": "did:mcp:0xd8ebc2be207451ff9eafb3ef7fada06d64d05059",
  "main": {
    "address": "0x8ad12345c3bc8598d2f602d63e927f5995dcf5d0",
    "chain": "ethereum"
  },
  "web2List": [
    {
      "cid": "bafybeid5fo6ig6ilobawudqwgsu7so5guaedgvkdwyo6k5hnvlqiqjlhaq",
      "account": "x3",
      "socialType": "github",
      "validator": {
        "name": "Litentry Technologies GmbH",
        "validatedAt": "1645810190",
        "signature": "0x0c4c08460e651c6d6949af21c5b290bed39ffcae6cfdb5ef374760758c9387f3643992be7d5b6f5373fb78540b116750471a9fbcc68e5e5ccb5330250158bfab1c"
      }
    }
  ],
  "web3List": [
    {
      "cid": "bafybeihj43osgpx3u5zo567lod25rzfxoqrbspb27v2akdwrgwugziddf4",
      "proofs": ["bafybeidcihuc74xxgatyag2q6iiv7tjwn6vjgc4dk6jravthcryrazzkru"],
      "address": "5DXZdKSFTEx5rE25dnxamebAoSsA4fqgGT9VPFiiouxP2xM1",
      "chain": "polkadot",
      "validator": {
        "name": "Litentry Technologies GmbH",
        "validatedAt": "1645810190",
        "signature": "0x0c4c08460e651c6d6949af21c5b290bed39ffcae6cfdb5ef374760758c9387f3643992be7d5b6f5373fb78540b116750471a9fbcc68e5e5ccb5330250158bfab1c"
      }
    },
    {
      "cid": "bafybeibic6syxpgnvyp5udyrhhuosm3thbslrfm4ivaauqxtus6vbjghsm",
      "proofs": ["bafybeibbsripq672skohuiy6ruztjr5hwclkwoswj6yilt5rkezgmn4f3u"],
      "address": "5GgmqtSXGuh2d3LxRiYo691bL4iTYQNjLCAYNakj4xfmLjnm",
      "chain": "polkadot",
      "validator": {
        "name": "Litentry Technologies GmbH",
        "validatedAt": "1645810356",
        "signature": "0x0c5eb79402646ab7390355404243d73c01cde9ccabd0c26cb1803599c44de8621f69c05848c0e254bdf5849b3ff69fd43b82f3e346cdac3175d052cedf107c3c1c"
      }
    }
  ],
  "createdAt": "1646836239",
  "updatedAt": "1646836239"
}</code></pre>
<p>“Each ID graph is extracted by ID pairs. An ID pair is made of two decentralized verifiable ownership claims. Each ID pair claims the joint ownership of two accounts, it can be a pairing of two web3 addresses, or a pairing of a web3 address and a web2 account. Everyone can verify and trust the ID pair. Each ID graph is represented in its unique DID. For ID graphs that have a common crypto address, one ID graph will be merged into the other ID graphs and keep only one MCP DID.” - Litentry ‘Identity Graph’<sup>7</sup></p>
<p>Token economy:</p>
<p>Suppose we look at the price of LIT token, which is $0.7227 at the time of writing. Litentry reached an all-time high of $14.79 on Feb 16, 2021. Currently, it’s down -95.11% since its record high.</p>
<p>From the market cap of just $26,979,670 we can see that Litentry hasn’t gained much attention or traction as a solution.</p>
</section>
<section id="ore-id---identity-registry" class="level2">
<h2 class="anchored" data-anchor-id="ore-id---identity-registry">ORE ID - identity registry</h2>
<p>Developed by Aikon, ORE is a cross-chain global identity registry where users have control over their own identity. This registry is stored on the ORE blockchain. Users can use ORE ID as a single sign-on to manage their wallets on multiple public blockchains. Single ORE ID account can be used as a wallet on multiple chains because ORE ID accounts hold public and private keypairs for ED 25519, SR25519, and SECP256K1 and SECP256R1 encryption curves.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://3327.io/documents/research/assets/ERFC-248/ore_acc.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Drop3</figcaption><p></p>
</figure>
</div>
<p><em>Picture 4: ORE ID account creation process</em></p>
<p>“Given how sensitive this data is, we use a Trustless Signing Service that allows a user to decrypt their keys and send a signed transaction to various blockchains using ChainJS library. Both of these modules are open source, so any developer can audit the code.” - <a href="https://ore.network/wp-content/uploads/2021/09/ORE-Whitepaper-2.0.pdf">ORE network’s whitepaper</a></p>
<p>ORE ID allows users to access various dApps with a one-click sign-up experience. Users can use social logins of their choosing. ORE ID creates blockchain accounts for the end-user when they sign up and encrypts and stores the user’s private key with their chosen PIN. ORE ID accounts are currently exportable to Scatter Wallet.</p>
<p>When developing an app that uses ORE ID accounts, developers need to register the app and the app logo in order to get their APP-ID and API-key. Documentation is well written and can be found <a href="https://github.com/TeamAikon/oreid">here</a>.</p>
<p>ORE ID operates differently from Litentry as it creates an account that works on multiple chains - it does not aggregate the existing addresses.</p>
<p>Token economy and future of ORE ID:</p>
<p>This project, although an interesting concept, with its market cap of only $ 319,175 doesn’t look like a solution for cross-chain identities and onboarding new users. The current price is $ 0.007984, while its all-time-high was $ 0.320. After testing the ORE ID, it seems that the project has been neglected.</p>
</section>
<section id="accumulate---mainnet-launch-planned-for-september-2022" class="level2">
<h2 class="anchored" data-anchor-id="accumulate---mainnet-launch-planned-for-september-2022">Accumulate - mainnet launch planned for September 2022</h2>
<p>Accumulate is an identity-based, delegated proof-of-stake blockchain solution. It plans on creating a universal communication and audit layer for individuals, entities, and blockchains to transact with each other using their version of identifiers that adhere to W3C standards: Accumulate Digital Identifiers (ADIs).</p>
<p>ADIs are human-readable addresses that users choose to represent their presence on the blockchain. Using ADIs accumulate can serve as a communication and audit layer between blockchains, enabling the transfer of tokens between different chains, no matter the consensus mechanism.</p>
<p>ADIs are made of a collection of independent sub-chains. They are managed by:</p>
<ol type="1">
<li>Token accounts - Issuing tokens and tracking deposits and withdrawals from a token account.</li>
<li>Data accounts - Tracking and organizing data.</li>
<li>Staking accounts - Staking ACME tokens to participate in consensus.</li>
<li>Scratch accounts - Accruing data that is needed to build consensus.</li>
</ol>
<p>Accumulate Innovations:</p>
<ol type="1">
<li>Identity - Accumulate is centered around ADIs where each ADI defines its own state that is independent of other ADIs. Each ADI has its own state and set of accounts and chains. They can be updated independently. They are distributed over a set of Tendermint networks.</li>
<li>Synthetic Transactions - Because each ADI has its state, transactions that are routed to an ADI must be processed independently of all other ADIs. Accumulate generates another transaction that performs settlements within an ADI. These transactions are called synthetic since the protocol generates them in response to the transactions initiated by the user.<br>
</li>
<li>Scratch Accounts - Accumulate provides scratch accounts, which reduce the cost of using the blockchain for consensus building. “Scratch accounts allow processes to provide cryptographic proof of validation and process without overburdening the blockchain” - Accumulate Whitepaper ‘Whitepaper - Accumulate’<sup>8</sup></li>
</ol>
<p>Integrations:</p>
<p>Accumulate protocol supports various smart contract roll-ups. This allows Accumulate to track the state and validity of contracts on third-party chains. Using Accumulate, organizations can process smart contracts across various layer one protocols (Solana, Ethereum, Tezus).</p>
<p>Accumulate also plans on integrating with Layer-0 protocols, for example, Cosmos and Polkadot. In that case, Accumulate can be utilized to manage the transferred asset under the identity (ADI) of a buyer and to continue tracking the assets across multiple chains.</p>
<p>Technical overview:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://3327.io/documents/research/assets/ERFC-248/Accumulate.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Accumulate overview</figcaption><p></p>
</figure>
</div>
<p><em>Picture 5: Accumulate system overview</em></p>
<p>In contrast to the traditional blockchain, where architecture is centered around blocks, Accumulate is centered around accounts. Each account is treated as an independent chain and managed as a growing Merkle tree, and blocks are treated as a synchronization point for all chains in the networks.</p>
<p>Inside the Directory Network and Block Validator Networks is the interconnected network of chains responsible for collecting signatures, communicating with each other, and anchoring roots to other blockchains.</p>
<p>These chains are:</p>
<ol type="1">
<li>Signature chain, which collects signatures for a period of 2 weeks</li>
<li>Main chain which records transactions in the origin account and accounts that are modified by the transactions</li>
<li>Synthetic Transaction chain, which is used to store cryptographic proof that a synthetic transaction was actually produced by a particular BVN.</li>
<li>Binary Patricia Trie, which collects hashes of the current state and history of accounts in BVN and DN.</li>
<li>Root Anchor Chain - collects an anchor once per block from every account and system chain updated during the block.</li>
<li>Intermediate Anchor Chain: Within the Directory Network, this chain collects anchors from the Root Anchor chain of every Block Validator Network once per block.</li>
</ol>
<p>As our topic is identity we will focus more on the account and identity architecture of Accumulate, which is actually at the very core of this protocol:</p>
<p>Accumulate supports these accounts:</p>
<ol type="1">
<li>Lite Token Account - Traditional address whose URL contains a public key hash and human-readable suffix denoting the token or a data type held by the account. When tokens are sent to this account, the account is created if it doesn’t exist. Users can create a key and have a trusted party send tokens to their URL.</li>
<li>Lite Data Account - It is used for collaboration with Factom protocol. Lite Data Accounts are similar to token accounts, but they are limited to writing data.</li>
<li>Accumulate Digital Identifier (ADI) - Primary unit of organization within Accumulate. ADIs can issue their tokens.</li>
<li>Key book and Key Page - Belongs to an ADI and is used for key management.</li>
<li>ADI Token and Data Accounts are explained at the beginning of the topic</li>
</ol>
<p>Identity architecture:</p>
<p>Users can participate in the network through ADIs and Lite Accounts. ADIs give users access to smart contracts, off-chain consensus building, and dynamic key management. Lite Token and Data Accounts are just a “lite” version of ADIs.</p>
<p>ADIs can only be created through the spending of Credits issued through the Accumulate protocol. Users can also use their ADI to sponsor the creation of other ADIs for themselves or others. These identities can govern token issuance, off-chain consensus building, and multisig signatures.</p>
<p>“ADI Data and Token Account URLs have the general format <code>acc://&lt;ADI&gt;/&lt;directory&gt;/&lt;account&gt;</code> where the prefix acc : // specifies the Accumulate blockchain, ADI specifies the toplevel identity in control of the URL, directory specifies a particular type of account, and account specifies data or tokens.” - Accumulate Whitepaper.</p>
<p>We will not venture deeper into the protocol architecture as it is reasonably complex and goes well beyond this research topic. The main takeaway is that it aims to create cross-chain transaction-compatible accounts using ADIs. The details of a way how this will work in practice are not covered in the whitepaper.</p>
<p>This project is still in development, which means the practical implementations of the concepts presented in the whitepaper are still under the big question mark sign.</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>We can see from the explored “solutions” that tackling cross-chain identity problems in Web3 is not an easy task. Many projects emerged but fell victim to their lousy architecture and the general public’s low interest. Different blockchains use different hash functions, making creating a standardized cross-chain identity hard. SBTs, a newly proposed solution by E. Glen Weyl, Puja Ohlhaver, and Vitalik Buterin aim to solve the problem of Web3 identities by creating a new standard. In their paper Decentralized Society: Finding Web3’s Soul, they propose a new solution: Soul Accounts and Soul Bound Tokens. However, there is no talk about Soul accounts being compatible with multiple chains. For more information, see ERFC-261, which we already covered in that paper. However, the concept of creating custom identity systems like the ones above mentioned is an exciting topic, and we think it should be looked into further, regardless of whether building a cross-chain identity or not.</p>
</section>
<section id="bibliography" class="level1">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Bibliography</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-DecentralizedIdentifiersDIDs" class="csl-entry">
‘Decentralized Identifiers (DIDs) V1.0’ &lt;<a href="https://www.w3.org/TR/did-core/" class="uri">https://www.w3.org/TR/did-core/</a>&gt; [accessed 15 June 2022]
</div>
<div id="ref-IdentityGraph" class="csl-entry">
‘Identity Graph’ &lt;<a href="https://docs.litentry.com/products/my-crypto-profile/product-features/identity-graph" class="uri">https://docs.litentry.com/products/my-crypto-profile/product-features/identity-graph</a>&gt; [accessed 15 June 2022]
</div>
<div id="ref-litentryIntroducingLitentry2020" class="csl-entry">
Litentry, ‘Introducing Litentry’, <em>Medium</em>, 2020 &lt;<a href="https://litentry.medium.com/introducing-litentry-d47b23d54281" class="uri">https://litentry.medium.com/introducing-litentry-d47b23d54281</a>&gt; [accessed 15 June 2022]
</div>
<div id="ref-MyCryptoProfile" class="csl-entry">
‘My Crypto Profile | 0x4d52f8d989796ffde311da9ad696258d5a7b3cc5’ &lt;<a href="https://mycryptoprofile.io/profile/0x4d52f8d989796ffde311da9ad696258d5a7b3cc5" class="uri">https://mycryptoprofile.io/profile/0x4d52f8d989796ffde311da9ad696258d5a7b3cc5</a>&gt; [accessed 15 June 2022]
</div>
<div id="ref-PolkadotNameSystem" class="csl-entry">
‘Polkadot Name System’ &lt;<a href="https://www.pns.link/" class="uri">https://www.pns.link/</a>&gt; [accessed 15 June 2022]
</div>
<div id="ref-SelfsovereignIdentities" class="csl-entry">
‘Self-Sovereign Identities’, <em>Bosch Global</em> &lt;<a href="https://www.bosch.com/stories/self-sovereign-identities/" class="uri">https://www.bosch.com/stories/self-sovereign-identities/</a>&gt; [accessed 14 June 2022]
</div>
<div id="ref-ThousandsLeakedFacebook" class="csl-entry">
‘Thousands of Leaked Facebook Documents Show Mark Zuckerberg as “Master of Leverage” in Plan to Trade User Data’, <em>NBC News</em> &lt;<a href="https://www.nbcnews.com/tech/social-media/mark-zuckerberg-leveraged-facebook-user-data-fight-rivals-help-friends-n994706" class="uri">https://www.nbcnews.com/tech/social-media/mark-zuckerberg-leveraged-facebook-user-data-fight-rivals-help-friends-n994706</a>&gt; [accessed 14 June 2022]
</div>
<div id="ref-WhitepaperAccumulate2022" class="csl-entry">
‘Whitepaper - Accumulate’, 2022 &lt;<a href="https://accumulatenetwork.io/whitepaper/" class="uri">https://accumulatenetwork.io/whitepaper/</a>&gt; [accessed 16 June 2022]
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p><em>NBC News</em> &lt;&lt;https://www.nbcnews.com/tech/social-media/mark-zuckerberg-leveraged-facebook-user-data-fight-rivals-help-friends-n994706&gt;&gt; [accessed 14 June 2022].↩︎</p></li>
<li id="fn2"><p><em>Bosch Global</em> &lt;&lt;https://www.bosch.com/stories/self-sovereign-identities/&gt;&gt; [accessed 14 June 2022].↩︎</p></li>
<li id="fn3"><p>&lt;[Https://www.w3.org/TR/did-core/](https://www.w3.org/TR/did-core/)&gt; [accessed 15 June 2022].↩︎</p></li>
<li id="fn4"><p>‘Introducing Litentry’, <em>Medium</em>, 2020 &lt;&lt;https://litentry.medium.com/introducing-litentry-d47b23d54281&gt;&gt; [accessed 15 June 2022].↩︎</p></li>
<li id="fn5"><p>&lt;[Https://mycryptoprofile.io/profile/0x4d52f8d989796ffde311da9ad696258d5a7b3cc5](https://mycryptoprofile.io/profile/0x4d52f8d989796ffde311da9ad696258d5a7b3cc5)&gt; [accessed 15 June 2022].↩︎</p></li>
<li id="fn6"><p>&lt;[Https://www.pns.link/](https://www.pns.link/)&gt; [accessed 15 June 2022].↩︎</p></li>
<li id="fn7"><p>&lt;[Https://docs.litentry.com/products/my-crypto-profile/product-features/identity-graph](https://docs.litentry.com/products/my-crypto-profile/product-features/identity-graph)&gt; [accessed 15 June 2022].↩︎</p></li>
<li id="fn8"><p>2022 &lt;&lt;https://accumulatenetwork.io/whitepaper/&gt;&gt; [accessed 16 June 2022].↩︎</p></li>
</ol>
</section></div> ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-248.hugo.html</guid>
  <pubDate>Tue, 14 Jun 2022 00:00:00 GMT</pubDate>
  <media:content url="https://3327.io/documents/research/assets/ERFC-248/MCP.png" medium="image" type="image/png" height="96" width="144"/>
</item>
<item>
  <title>[ERFC - 270] ZK NFT Mixer</title>
  <dc:creator>Aleksandar Veljković</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-270.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p>NFTs are growing in popularity, and so are the numbers of transactions for transferring the NFTs on the Blockchain. One of the main features of the Blockchain is privacy, but only in terms of pseudo-anonymity. The pseudo-anonymity implies that the user creating the transaction is hidden, as he is represented using an opaque, pseudo-random address. Still, the transactions between the addresses are transparent. By analyzing the transaction graph and external inputs, such as social network posts putting the address in a specific context, it is possible to deduce the address owner and reveal all his transactions. This research aims to analyze the possibility of creating a solution that can enable NFT transfers in an environment that supports complete anonymity but is still compatible with Ethereum. The proposed infrastructure represents a zero-knowledge mixer supporting shielded transfers of the NFTs on the side chain with the ability to withdraw NFTs back on the main chain.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Many existing solutions utilize zero-knowledge proofs to shield transactions or mix the coins and tokens. Those solutions include Zero cash, Tornado cash, Monero, and many more. The common thread connecting all of them is that they are meant for transferring currency. Although some providers (like Tornadocash [1]) announced, ZK solutions for transferring NFTs are not very popular. Unlike the currency, the NFTs are unique objects, and it is not easy nor practical to hide them in plain sight. It is possible to hide what is transferred, but it is easy to follow the trail if the thing that is transferred is unique.</p>
<p>NFTs are finding their way to the sidechains, as the Ethereum mainnet transactions often become too much overhead for minting or transferring NFTs [2]. ZK rollups like zkSync are also used for transferring and minting the NFTs [3], but the “ZK” part of the rollup doesn’t refer to privacy but compression of the transactions as a scalability solution. Bridges between sidechains and Ethereum allow NFT transfers between the chains [4], enabling cheap transactions on the side chain and final transfer back on the main chain. None of the general-purpose side chains provide shielded NFT transfers. A new solution promising shielded transfers for any assets is Namada [5, 6], Blockchain specifically built for asset privacy. With new updates of Nightfall, Polygon also announces featuring private NFT exchanges [7].</p>
<p>This research investigates the possibilities of using existing, widely adopted, general-purpose side chains to implement shielded NFT transfers. If the projects featuring shielded NFTs are scarce, a good question is if there is a market need for such a solution. The answer to this may not come from the current state of the market but the predictions of future trends. As the NFTs gain even more popularity and move from the hype-regulated market of novelties to more serious use cases, such as access control, certificate issuing, and similar, there is an indication that shielding NFTs of such documents will become a requirement. Such trends are also visible through the projects announcing future updates supporting this domain.</p>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p>The main goal of this research is to investigate the possibilities of implementing a zero-knowledge mixer for NFTs, using a side chain for shielding transfers resulting in a proposal of a software architecture and algorithms that would support such a system.</p>
<p>It is essential first to analyze the building blocks of similar solutions to be able to come up with a new one. A cross-chain movement of tokens is enabled using cross-chain bridges. The focus here would be on two-way decentralized bridges between two EVM chains. The two-way bridges consist of two smart contracts on each side. The role of smart contracts is locking tokens on one side and releasing or minting tokens on the other side. The contracts communicate by firing events on one side, and validator nodes that listen to those events trigger operations on the other.</p>
<p>There are two types of blockchains regarding the representation of the main currency on the chain - wallet-based and UTXO base. The wallet-based chains represent currency as a gross numerical value stored in the memory fields associated with specific accounts. When the amount <img src="https://latex.codecogs.com/png.latex?X"> is transferred from wallet A to wallet B, the values are updated so that wallet A has <img src="https://latex.codecogs.com/png.latex?X"> coins less and wallet B has <img src="https://latex.codecogs.com/png.latex?X"> coins more in the associated memory field. This logic is familiar to Ethereum users, as Ethereum is a wallet-based blockchain.</p>
<p>The chains based on UTXOs have a different philosophy. The UTXO acronym stands for “Unspent transaction (TX) output,” which may give a clue on the main structure used for representing the coins. Let’s use Bitcoin as a representative of a UTXO-based chain. Each transaction on Bitcoin requires an input amount of coins that should be transferred to the other address. The user might not see it, but the coins are not just numbers updated with each transaction, as the transactions on Bitcoin have a more strict input-output definition. There are no wallets as memory locations linked with the account, but the coins are represented as one or many UTXOs. Users own their UTXOs by having them linked with their public key and transfer them by signing the transactions using the private key associated with the UTXOs. When the user has a UTXO of five coins and wants to transfer three of them, the transaction uses a UTXO of five coins as input. The outputs of the transaction are two new UTXOs. The first one represents the transferred amount with the value three labeled with the recipient’s public key. The other is the remainder, or the unspent amount with the value two, tagged with the sender’s key. If the user has two UTXOs with two coins each and wants to transfer three coins, the user would use both UTXOs as transaction inputs. Again, the output would be two new UTXOs, one with the transferred amount for the recipient, and the other, the unspent part for the sender.</p>
<p>Systems that enable shielded transactions utilize UTXO representation for the shielded tokens even on chains that are not natively UTXO-based, as that representation is more suitable for the use case. In such systems, the UTXO values are hidden from the public and only visible to the recipient with a private key to decrypt it. The workload for computing transaction parameters is now on the sender’s side, as no other participant can see the UTXO value. The sender prepares the transaction’s inputs and outputs and generates a zero-knowledge proof that the transaction is generated correctly with proper values. The proof must confirm that the sender knows the non-encrypted UTXO value and the correct values of the resulting UTXOs after the transfer. Monero uses additional decoy values as fake UTXOs to spoof the actual token transfer and blur the overall chain of transfers [8]. Preventing double-spending is mainly done using nullifiers - values representing “coupons” for spending the UTXO. The UTXO is tied to a nullifier value, and transferring the UTXO requires the user to submit the nullifier linked with the UTXO, marking the UTXO as used. One nullifier can be used only once. When the piece of UTXO is spent, the remainder and the sent part are converted to new UTXOs with their respective nullifiers.</p>
<p>NFTs represent unique objects, so the methods used for hiding and splitting the token batches are not directly applicable to NFTs. Conversely, if the methods could be adapted to support NFTs, most well-tested algorithms and flows could be reused. Converting NFT to a UTXO-like object, called commitments, may be straightforward. The commitment may hide the token address and ID information, but the quantity value will always be one. Unfortunately, even if the quantity and token information are hidden, tracking the token in the network is easy. There is a 1-to-1 mapping between the input token and the resulting commitment. A solution to this problem may lay in decoys.</p>
<p><img src="https://3327.io/documents/research/assets/ERFC-270/decoy.jpeg"></p>
<p>One NFT can be converted to one correct commitment followed by <img src="https://latex.codecogs.com/png.latex?N-1"> false commitments constructed as decoys. This schema would fail when only the NFT commitment is transferred to the other user, revealing which of the <img src="https://latex.codecogs.com/png.latex?N"> commitments was the NFT. To mitigate this problem, each transfer transaction of the NFT commitment should also include transferring <img src="https://latex.codecogs.com/png.latex?K"> additional decoys to different addresses. When all participants use decoys with their transfers, the transfer graph is quickly blurred, and finding the actual NFT commitment needle in a haystack of decoys becomes difficult. One downside of this approach is a quicker filling of the commitment Merkle tree, but it can be mitigated using a bigger tree. The other is the cost increase. Under the assumption that the decoying mechanism provides reasonable privacy and anonymity, the protocol can reuse the previous building blocks to complete the system.</p>
<section id="depositing-nfts-from-ethereum-to-the-side-chain" class="level2">
<h2 class="anchored" data-anchor-id="depositing-nfts-from-ethereum-to-the-side-chain">Depositing NFTs from Ethereum to the side chain</h2>
<p>User deposits NFTs on the Ethereum smart contract by sending a transaction allowing the smart contract to take over the NFT. On the side chain, <img src="https://latex.codecogs.com/png.latex?N"> commitments are minted and added to a Merkle tree. The smart contract can’t say which commitment resembles the NFT, so the commitment values need to be constructed in a specific way by the user and submitted to Ethereum smart contract. The NFT commitment should be a hash of NFT ID, NFT address, owner’s ephemeral public key, and some secret value. Other, <img src="https://latex.codecogs.com/png.latex?N-1">, commitments should be hashes of a string value NULL, the owner’s ephemeral public key, and some other secret value. The user must provide ZK proof that exactly one commitment is the NFT commitment while all other <img src="https://latex.codecogs.com/png.latex?N-1"> values are decoys. Each commitment is tied to a nullifier, generated as a hash of the commitment ID, a Merkle path of the commitment inside the Merkle tree, and the same secret value used for the specific commitment. The secrets should be different for each commitment-nullifier pair. By doing this setup, the public still doesn’t know which commitment is the NFT, but anyone can verify that one of the commitments indeed is the NFT, while others are blanks.</p>
</section>
<section id="transfering-nfts-on-the-sidechain" class="level2">
<h2 class="anchored" data-anchor-id="transfering-nfts-on-the-sidechain">Transfering NFTs on the sidechain</h2>
<p>Users on the side chain are identified using their new ephemeral keys, meaning the keys should be changed frequently. The keys are the private key, public key, and encryption key. The public key is a private key hash, while the encryption key is “the real” public key, in the sense of public-key cryptography, derived from the private key. Transferring NFTs is similar to tornado cash logic with the addition of decoys. For each NFT transfer, the user also transfers <img src="https://latex.codecogs.com/png.latex?N-1"> other decoys to <img src="https://latex.codecogs.com/png.latex?N-1"> different addresses. Received decoys from other users can (and should) be used in further transfers of NFTs, thus enabling further obfuscation of the trading paths. Each transfer on the sidechain is a shielded transfer, meaning that it is not performed as a regular token transfer but as a protocol backed by zero-knowledge proofs. Before explaining the protocol, let us first see how the commitment is constructed. The commitment contains two values, the commitment value, defined during deposit, and a secret value used as a salt while generating the first value. Both values are stacked in a byte array and encrypted using the owner’s public key. When the user wants to transfer the commitment, a new commitment and decoys are sent to the sidechain. ZK proof is also sent on the chain, proving that all the computations were correct. The sender proves that the new commitment is derived from the proper input commitments and nullifiers, and the output commitments are generated in the way that only one output commitment contains the NFT. The new commitment is encrypted using the recipient’s public key, so only the recipient can decrypt it and use it later. The recipient listens to the sidechain events to see if any new commitment can be decrypted using his private key and notes down all the commitments that pass the test.</p>
</section>
<section id="withdrawing-nfts-from-the-side-chain-to-ethereum" class="level2">
<h2 class="anchored" data-anchor-id="withdrawing-nfts-from-the-side-chain-to-ethereum">Withdrawing NFTs from the side chain to Ethereum</h2>
<p>The user who initiates withdrawal must prove ownership of the commitment representing the NFT by providing ZK proof. The user proves the knowledge of the secret preimage used for generating the initial commitment. When the proof is verified and valid, the commitment is nullified. The smart contract on the Ethereum transfers the locked NFT to the Ethereum address provided within the withdrawal request.</p>
</section>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<p>The system’s building blocks are presented in the previous chapter, and it is time to put them all together. The system architecture consists of two smart contracts, one on Ethereum and the other on the EVM side chain, and a validator network that can support the bridge between the chains.</p>
<p>The commitment format is a slightly modified UTXO Tornado Cash implementation used for TORN tokens, which benefits the protocol’s safety, as it is not an entirely new, untested concept. The strength of the protocol lies in indistinguishable commitments that are simultaneously transferred to multiple addresses. An external viewer cannot discern which of the commitments hide the NFT, as with each transfer step, new <img src="https://latex.codecogs.com/png.latex?N-1"> commitments are generated or reused and transferred to obfuscate the token trail further. The novelty introduced by the protocol lies in the initial issuing of commitments for NFT as hashes, backed by the zero-knowledge proofs, which guarantee that strictly one copy of the token is cloned on the sidechain while the other copies are decoys. The proposed name for the protocol is “The thimblerig protocol,” as it closely resembles a street con artist who tries to hide a ball by shuffling it many times under multiple, same-looking cups.</p>
<p>The downside of the protocol is the volume of commitments generated for transferring decoys and their respective nullifiers, which are stored locally in wallets. A proof of concept implementation is needed to estimate better the protocol cost, efficiency, and practical usability.</p>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>The presented protocol represents a combination of the existing protocols for shielded transfers and token mixing, adapted for NFT transfers. Generic in nature, it can be used between any two EVM chains. The next steps should include selecting the practical use cases that require the shielded NFT token transfers and evaluating the usability of the presented protocol against the selected use cases. Further research may also require a proof of concept implementation between two designated EVM chains.</p>
</section>
<section id="bibliography" class="level1">
<h1>Bibliography</h1>

<p>[1] https://www.coindesk.com/tech/2021/12/15/ethereum-mixer-tornado-cash-launches-major-upgrade-as-v3-approaches/</p>
<p>[2] https://www.one37pm.com/nft/alt-chain-nfts-palm-sidechain-loom-network-xdai</p>
<p>[3] https://zknft.xyz</p>
<p>[4] https://bridge.mintnft.today/</p>
<p>[5] https://namada.net/</p>
<p>[6] https://medium.com/anomanetwork/introducing-namada-shielded-transfers-with-any-assets-dce2e579384c</p>
<p>[7] https://blog.polygon.technology/introducing-polygon-nightfall-mainnet-decentralized-private-transactions-for-enterprise/</p>
<p>[8] https://www.coindesk.com/layer2/privacyweek/2022/01/25/monero-the-privacy-coin-explained/</p>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs">

</div></section></div> ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-270.hugo.html</guid>
  <pubDate>Sun, 05 Jun 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Approaches to Testing Of Smart Contracts</title>
  <dc:creator>Milos Bojinovic</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-259.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p><strong>Smart Contracts</strong> are applications built on blockchain that, once deployed, cannot be altered or updated. With that in mind, their testing is crucial, even more so than in traditional software development.</p>
<p>Several different techniques exist in the testing of Smart Contracts, and it is up to the developers to choose when a technique should be used with the goal of creating tests that will perform sufficient validation. This is a non-standardized, individualistic approach as there is no established methodology for doing this, and the developers’ skill plays an essential part in it.</p>
<p>This research focuses on testing techniques that are most widely used and showcases them in order to give a sense of what kind of testing is possible and where it makes sense.</p>
<p>In testing, there is always the question of whether the collection of tests (test suite) covers all of the cases - “Who will guard the guards themselves?”*.</p>
<p>To answer this question, to a certain degree, the paper elaborates on evaluation tools that indicate whether or not more tests should be written or if there’s a case that is overlooked.</p>
<p>As the techniques and tools mature and increase in complexity, we may see the introduction of standardized methodologies that provide a thinking framework on how code should be written and/or tested, as well as a separation of roles between developers and testers.</p>
<p>*Quis custodiet ipsos custodes? - a Latin phrase found in the work of the Roman poet Juvenal (Satire VI, lines 347–348)</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Testing involves thinking about how code sections should behave in the wanted (ideal) case, but also what consequences might occur if some unintended actions are performed by unaware or even malevolent actors.</p>
<p>The logical question occurs of “what needs to get tested … and how ?”. This is an extremely hard question, and the answer to it lies in the considerations that the developers consciously/unconsciously make. It is important that they keep up to date with the latest techniques, now more than ever, as the past experiences of others can help in establishing best practices and be used in solving similar or completely new problems.</p>
<p>Sanity checks can be performed by using evaluation tools that help with casting light on areas that were previously overlooked. Still, to add another layer of confidence, a set of completely new, trusted eyes should separately go through the code and try to find bugs and/or exploits in it. This is referred to as a Smart Contract audit and is the last step before the deployment to mainnet.</p>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p>The focus of this research is on the testing and evaluation techniques that are currently being used in the area of Smart Contract development in the Ethereum Virtual Machine (EVM) ecosystem without going down the rabbit hole of what the best practices are.</p>
<p>The methodology consists of describing a technique and then giving an appropriate example that shows when it is adequate to use it. Frameworks are purposefully not mentioned, as it is more important to first understand the key concepts of what is being done rather than the unique and specific details of how something is done.</p>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<p>As to not give too abstract and vague descriptions, an example of a smart contract is given on which the testing can be performed and through which a better understanding can be created.</p>
<section id="contract-example" class="level2">
<h2 class="anchored" data-anchor-id="contract-example">Contract example</h2>
<p>The example contract <code>DummyToken</code> can wrap/unwrap Ether through <code>deposit</code> and <code>withdraw</code> functions and transfer the tokens between two addresses using a function of the same name - <code>transfer</code>. During the execution of those functions, a corresponding event is emitted.</p>
<p>The implementation details are purposefully hidden with the intention of starting the thinking process of how those functions should behave both when called in intended and non-intended ways.</p>
<pre class="solidity"><code>/**
 * @dev Implementation of the Dummy Token.
 */
contract DummyToken {

    /**
     * @dev Emitted when tokens are moved from one account (`from`) to
     * another (`to`) of the `value` amount.
     */
    event Transfer(address indexed from, address indexed to, uint value);

    /**
     * @dev Emitted when a new Deposit is made
     */
    event Deposit(address indexed to, uint value);

    /**
     * @dev Emitted when new Withdrawal is made
     */
    event Withdrawal(address indexed to, uint value);

    ...

    /**
     * @dev Mints `value` tokens to `msg.sender` that corresponds to `msg.value` .
     *
     * Returns a boolean value indicating whether the operation succeeded.
     *
     * Emits a {Deposit} event.
     */
    function deposit () public payable returns (bool) {...}

    /**
     * @dev Burns `value` tokens if the `msg.sender` balance can cover it.
     *
     * Returns a boolean value indicating whether the operation succeeded.
     *
     * Emits a {Withdraw} event.
     */
    function withdraw (uint value) public returns (bool) {...}

    /**
     * @dev Moves `value` tokens from the caller's account to `to`.
     *
     * Returns a boolean value indicating whether the operation succeeded.
     *
     * Emits a {Transfer} event.
     */
    function transfer (address to, uint value) public returns (bool) {...}

    /**
     * @dev Returns the number of tokens owned by `account`.
     */
    function balanceOf(address account) public view returns (uint) {...}

    /**
     * @dev Returns the total amount of tokens in existence.
     */
    function totalSupply() public view returns (uint) {...}

}</code></pre>
<section id="specification-of-the-transfer-function" class="level3">
<h3 class="anchored" data-anchor-id="specification-of-the-transfer-function">Specification of the <code>transfer</code> function</h3>
<p>To understand the forms of testing that can be performed, let us write a specification on what one of the functions needs to accomplish, namely the <code>transfer</code> function.</p>
<section id="high-level-specification-of-the-transfer-function" class="level4">
<h4 class="anchored" data-anchor-id="high-level-specification-of-the-transfer-function">High level specification of the <code>transfer</code> function</h4>
<p>This function transfers the amount of tokens (<code>value</code>) from the <code>msg.sender</code>‘s balance to the <code>to</code> address’ balance.</p>
</section>
<section id="low-level-specification-of-the-transfer-function" class="level4">
<h4 class="anchored" data-anchor-id="low-level-specification-of-the-transfer-function">Low level specification of the <code>transfer</code> function</h4>
<ul>
<li>After successful transfer, the balance of <code>to</code> address is incremented by the <code>value</code> amount and the <code>msg.sender</code>’s balance is decremented by it.</li>
<li>If the <code>msg.sender</code>’s balance is smaller than the <code>value</code>, the transaction should revert with the <code>"Transfer amount exceeds balance"</code> message.</li>
<li>If the transfer is successful, the function returns <code>true</code> - otherwise, it returns <code>false</code></li>
<li>If the transfer is successful, the <code>Transfer</code> event should be emitted with the corresponding fields:
<ul>
<li><code>from</code> : <code>msg.sender</code></li>
<li><code>to</code> : value of the <code>to</code> argument</li>
<li><code>value</code> : value of the <code>value</code> argument</li>
</ul></li>
</ul>
</section>
</section>
</section>
<section id="forms-of-testing" class="level2">
<h2 class="anchored" data-anchor-id="forms-of-testing">Forms of testing</h2>
<section id="unit-testing" class="level3">
<h3 class="anchored" data-anchor-id="unit-testing">Unit Testing</h3>
<p>Unit Testing relies on keeping the tests separate from each other and as simple as possible, with each unit test being responsible for testing a single module(“unit”).</p>
<p>These tests follow a common pattern referred to as <strong>Arrange-Act-Assert(AAA)</strong>. First, the “arrangments” are made to put the system in the desired state, then the “act” is performed (function call most often) that leads the system to the next state, after which that state is “asserted” for correctness.</p>
<p>In an individual unit test, most often, only one assertion is made, which increases the number of tests. This, however, has the benefits of having a clear indication of why a test has failed and increasing the code readability.</p>
<p>When thinking about unit testing the <code>DummyToken</code> contract, we will take only the <code>transfer</code> function as an example. Following is an incomplete list of test scenarios for this functionality that should serve as a starting point.</p>
<section id="test-scenarios" class="level4">
<h4 class="anchored" data-anchor-id="test-scenarios">Test Scenarios:</h4>
<p>To form a part of a test suite, let us divide the test scenarios into two sections (<strong>generalized</strong> and <strong>edge cases</strong>) and write some examples of tests for each of them.</p>
<ul>
<li><p><strong>Generalized:</strong></p>
<ul>
<li>Valid* Transfer <code>amount</code>** of <code>DummyToken</code> from <code>address0</code> to <code>address1</code> where <code>address0</code> != <code>address1</code>
<ul>
<li>Tests:
<ul>
<li><code>address0</code>’s balance is decremented by the <code>amount</code></li>
<li><code>address1</code>’s balance is incremented by the <code>amount</code></li>
<li>balances of other adresses has not changed</li>
<li><code>Transfer</code> event was emitted with the corresponding fields</li>
</ul></li>
</ul></li>
<li>Invalid* Transfer <code>amount</code> of <code>DummyToken</code> from <code>address0</code> to <code>address1</code> where <code>address0</code> != <code>address1</code>
<ul>
<li>Tests:
<ul>
<li>transaction was reverted with the right message (“Transfer amount exceeds balance”)</li>
</ul></li>
</ul></li>
<li>…</li>
</ul></li>
<li><p><strong>Edge Cases:</strong></p>
<ul>
<li>Valid/Invalid Transfer <code>amount</code> of <code>DummyToken</code> from <code>address0</code> to <code>address1</code> where <code>address0</code> == <code>address1</code></li>
<li>Valid Transfer <code>0/1</code> of <code>DummyToken</code> from <code>address0</code> to <code>address1</code> where <code>address0</code> != <code>address1</code></li>
<li>Valid Transfer <code>0/1</code> of <code>DummyToken</code> from <code>address0</code> to <code>address1</code> where <code>address0</code> == <code>address1</code></li>
<li>…</li>
</ul></li>
</ul>
<p>*Term “Valid/Invalid” refers to the fact of whether this transfer should be possible (due to balance amounts).</p>
<p>**<code>amount</code> can be any <code>uint</code> (including the value being greater than the total supply)</p>
<p>We can notice that for the first scenario of the generalized section, four tests need to be written, with each of them being a unit test that checks a specific thing (i.e., the sender’s balance has been decremented by the right amount).</p>
<p>It is important to note that a “Property-based Testing” technique was used in the above list, which is a form of an automated process called “fuzzing” that is used to find bugs by feeding randomized data into the system. This technique focuses on the “properties” of the code that should always hold. The tests are not concerned with the actual values of <code>amount</code>, <code>address0</code>, and <code>address1</code>, which can be anything in the allowed range of possibilities. Rather, they aim to say whether the properties around the balances hold in the test scenario - i.e., if an account transfers some tokens to another account, only those two balances should be affected.</p>
</section>
</section>
<section id="integration-testing" class="level3">
<h3 class="anchored" data-anchor-id="integration-testing">Integration Testing</h3>
<p>In the context of Smart Contract testing, integration tests validate interactions between different components of a single contract or across multiple different contracts and are more complex when compared to unit tests.</p>
<p>One form of integration testing is <strong>Stateful testing</strong>, an advanced method of property-based testing, where a single test is defined by:</p>
<ul>
<li>an <strong>initial state</strong> that can, after deployment, be kept as it is or be created by some fixed sequence of <strong>actions</strong></li>
<li><strong>actions</strong> - transactions that lead to a transition of state</li>
<li><strong>invariants</strong> which are properties that should always hold true</li>
</ul>
<p>Starting from the <strong>initial state</strong>, a randomized sequence of <strong>actions</strong> is carried out, where after each action, all of the <strong>invariants</strong> are tested.</p>
<p>For example, when writing a “stateful” test for the <code>DummyToken</code> contract :</p>
<ul>
<li><strong>initial state</strong> can be created such that each test account calls a <code>deposit</code> function with a random amount of Ether provided</li>
<li><strong>actions</strong> can be kept basic (<code>deposit</code> , <code>transfer</code> and <code>withdraw</code>) or more complex (nested - i.e.&nbsp;one action can be [<code>deposit</code>, <code>withdraw</code>, <code>withdraw</code>,…])</li>
<li>one of the <strong>invariants</strong> can be that sum of account balances of the <code>DummyToken</code> must always be equal to the Ether amount that the contract holds</li>
</ul>
<p>Besides being more complex, integration tests require more resources and execution time.</p>
</section>
<section id="static-code-analysis" class="level3">
<h3 class="anchored" data-anchor-id="static-code-analysis">Static (code) analysis</h3>
<p>Both of the above-mentioned forms of testing are considered a type of “dynamic code analysis” that searches for bugs during the execution of the program, and they are the main topic of this research.</p>
<p>It is worth mentioning its counterpart - <strong>Static code analysis</strong> or just <strong>Static analysis</strong>, which is a debugging method that examines the source code before a program is run. This is done by analyzing the code against a set of detection rules that include: timestamp dependency, integer underflow/overflow, re-entrancy issues, use of tx.origin instead of msg.sender, … It remains up to the developer to implement or reject the recommendations of these rules.</p>
</section>
<section id="general-considerations" class="level3">
<h3 class="anchored" data-anchor-id="general-considerations">General Considerations</h3>
<p>Smart Contracts operate in an extremely hostile environment, and this should always be taken into account. During development and testing, the most valuable guiding principle is that everything that can go wrong will eventually go wrong, especially if someone stands to benefit from it.</p>
<p>A set of principles can be adopted to make the functionality of a contract and its complexity more manageable as to reduce the probability of bugs or exploits happening. Some of those include that:</p>
<ul>
<li>code should be modularized and kept simple (KISS and DRY principles*** should be followed)</li>
<li>clarity should be preferred over performance (if possible)</li>
<li>latest versions of battle-tested tools and frameworks should be used</li>
<li>the blockchain characteristics should be considered</li>
<li>the latest security developments should always be incorporated</li>
<li>deployment and testing should be done on Testnet before moving to Mainnet</li>
</ul>
<p>*** KISS (Keep It Simple, Stupid) and DRY (Don’t Repeat Yourself) are software programming principles where KISS states that the most simple solutions often work the best, while DRY follows the reasoning that same/similar code sections should not be replicated across the code base.</p>
</section>
</section>
<section id="evaluation" class="level2">
<h2 class="anchored" data-anchor-id="evaluation">Evaluation</h2>
<p>The purpose of tests is to verify the correctness of the implementation, which poses the question of whether or not the test suite is sufficient for the implementation requirements. To address this and to have a sanity check for a developer’s thought process, evaluation tools have been created.</p>
<section id="code-coverage" class="level3">
<h3 class="anchored" data-anchor-id="code-coverage">Code Coverage</h3>
<p>The term <strong>code coverage</strong> refers to the set of evaluation metrics that are used to determine how much of the program has been tested by the test suite - how many functions have been called, how many statements have been executed, etc.</p>
<p>For example, in the code below, to reach a 100% coverage for the function <code>fcn</code>, at least one of the tests would need to call with parameters that pass all of the three <code>if</code> statements (i.e.&nbsp;<code>fcn(32, 300, 500)</code>).</p>
<pre class="solidity"><code>function fcn (uint a, uint b, uint c) {

    if(a &lt; 100) {
        if(b &gt; 200) {
            if(c &gt; 300 &amp;&amp; c &lt; 600) {
                ...
            }
        }
    }
}</code></pre>
<p>While a high coverage doesn’t generally equal good tests, low coverage helps in identifying gaps in the test suite that can be filled by adding new, carefully designed tests.</p>
<section id="coverage-guided-fuzzing" class="level4">
<h4 class="anchored" data-anchor-id="coverage-guided-fuzzing">Coverage-guided Fuzzing</h4>
<p>During testing, feeding purely randomized values is often wasteful and time-consuming. In the example above, parameter <code>a</code> is of type <code>uint</code>, which means it can hold any value in the range [0, 2**64-1], but the condition <code>a &lt; 100</code> will hold true only for a small portion of time.</p>
<p>Coverage-guided Fuzzing takes into account code coverage information for each random value it tries, and if that value executes a new code, it is put in the set of promising values. For example, if <code>a = 32</code> has been generated, fuzzer will keep note of it, as it opens the door to new code - it can then keep <code>a</code> fixed and randomize parameters <code>b</code> and <code>c</code>, thus reducing the search space.</p>
</section>
</section>
<section id="mutation-testing-mutation-analysis" class="level3">
<h3 class="anchored" data-anchor-id="mutation-testing-mutation-analysis">Mutation Testing (Mutation analysis)</h3>
<p>Mutation testing is a technique used to evaluate the effectiveness of a test suite by introducing minor modifications, called “mutations”, in the code, thus producing “mutants”.</p>
<p>These modifications are performed using a fixed set of mutation operators like operand replacement, expression modification, statement modification, etc.</p>
<p>Listed below is an example of an <strong>original</strong> code as well as one potential <strong>mutant</strong> that can be generated from it.</p>
<p><strong>Original Code</strong></p>
<pre class="solidity"><code>function fcn (uint a, uint b) returns (bool) {

    if(a &gt; b){

        return true;
    }

    return false;
}</code></pre>
<p><strong>Mutant #1</strong> - produced by using an expression modification operator (replaced <code>&gt;</code> with <code>&lt;</code>)</p>
<pre class="solidity"><code>function fcn (uint a, uint b) returns (bool) {

    if(a &lt; b){

        return true;
    }

    return false;
}</code></pre>
<p>These mutants are then tested, and, ideally, all of them would need to get caught (killed) by at least one of the tests. The percentage of killed mutants is referred to as the <strong>mutation score</strong>.</p>
<p>These techniques can give insight into what are the tests missing and where are the blind spots as well as what tests are rarely killing mutants - both of which is valuable when improving the test suite.</p>
<p>If a mutant cannot be compiled (i.e., mutation produced a syntax error), it is called <strong>stillborn</strong> and is not taken into consideration. Sometimes, mutants can have the same behavior as the original code, in which case, they are referred to as <strong>equivalent mutants</strong>. These mutants will not get killed by the test suite and will lower the mutation score. Detecting and taking them out of consideration is not an easy task and is the biggest obstacle to the widespread application of mutation testing.</p>
</section>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>This research concludes that the space of testing techniques is vast and evolving. As the complexity of challenges that the developers are faced with is rapidly increasing, staying up to date is a task by itself.</p>
<p>With time, we will probably see more and more specialized roles and the separation of responsibilities as it was done in traditional software. For this to happen, some standards should be formed that would enable effective communication between team members, namely clear requirement specification documents.</p>
<p>While posing a risk of the field becoming too rigid, rather than each individual/team having a different approach, we may also see the evolution of techniques and frameworks leading up to complete standardized methodologies.</p>
<p>Some possible roads for future research on this topic should include tools that are used when creating a well-documented functional specification for the project and digging deeper into the evaluation methods, specifically mutation testing, which is an active area of research.</p>


</section>

 ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-259.hugo.html</guid>
  <pubDate>Sat, 04 Jun 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>SBT - Soulbound Tokens</title>
  <dc:creator>Aleksandar Damjanovic</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-261.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p>This paper explores the SBTs (Soulbound Tokens) as a concept, their potential use cases, and the difficulties of implementing this solution. It also covers concepts of social and community recovery and briefly covers designated-verifier proofs and verifiable delay functions as they are potential enablers of this solution.</p>
<p>SBTs as a concept have major potential, although they face major obstacles like legacy systems, privacy and cold start issues. Nevertheless there is a positive sentiment towards this solution.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>The online identity of users plays an essential role in Web2. It allows users to have an online reputation, a unique identifier, and access to products and services that would otherwise not be available to them.</p>
<p>In the Web3 ecosystem, there is a persistent problem of proving the identity and personhood of a user without going through various KYC processes. There have been multiple attempts to aggregate identities in a decentralized way, and solutions like Litentry, Open Rights Exchange and IDX have emerged as solutions to this problem. However, there is no standard for creating unique Web3 user identities. These identities, in theory, could broaden the use-cases and the complexity of the ecosystem.</p>
<p>In 2021 and the beginning of 2022, NFTs (Non-fungible tokens) were the “hot topic”. Some of those NFTs reached a sale price of over $90.000.000.<sup>1</sup> At the core of these tokens is their transferability between addresses (parties), be it transfers or sales. Alas, we will not cover NFTs in great detail as there are more papers and research on that topic.</p>
<p>In this paper, we explore the newly proposed primitive: SBTs (Soulbound Tokens), which trade in transferability to satisfy other potential use cases that could not be satisfied with transferable NFTs. The “soulbound” in the name of SBTs takes inspiration from the famous game World of Warcraft, where some items, once acquired, are bound to the player and cannot be traded or transferred.</p>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p>The goal is to understand the need for this type of tokens, the necessity of using them for various use-cases in Web3, and the utility they could provide.</p>
<p>This will be done by exploring the <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4105763">“Decentralized Society: Finding Web3’s Soul”</a> paper written by E. Glen Weyl, Puja Ohlhaver, and Vitalik Buterin and how non-transferable SBTs could transform the Web3 space(lending, governance, reputation, etc.). Current sentiment towards this new primitive will also be explored (social media, blog posts, papers, etc.).</p>
<p>This research can be used as a short overview of the paper mentioned above and an overview of the current sentiment on SBTs.</p>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<section id="some-of-the-current-problems-in-web3" class="level2">
<h2 class="anchored" data-anchor-id="some-of-the-current-problems-in-web3">Some of the current problems in Web3</h2>
<p>If we look at the Web2 as it is now, the online identities of various users are a major part of various processes. Users can even use their identity on other platforms to easily register to others with a click or two. For example, a Google account In the future, unique identity linked to a user (in this case a “Soul”) could be a solution that would bring onboard more people to Web3, unlock new potential uses-cases, and potentially create a standardized reputation system. Currently Web3 is dependent on various Web2 structures regarding representing social identity. Examples:</p>
<ol type="1">
<li>NFT platforms rely on centralized platforms for a proof of scarcity and initial provenance.</li>
<li>DAOs. If DAOS want to prevent Sybil attacks, they usually rely on social media profiles for proof of personhood.</li>
<li>Web3 participants rely on centralized custodial wallets. Wallets that offer decentralized key management are not user-friendly.</li>
<li>Generally, it’s hard to establish reputation systems and manage blacklisting as anyone can create another address and access your protocol, for example</li>
<li>Lack of native web3 identity. This makes undercollateralized lending virtually impossible.</li>
<li>Governance vulnerability to financial attacks.</li>
</ol>
<p>These problems could, in theory, as the paper mentioned earlier says, be solved by introducing SBTs in Web3.</p>
</section>
<section id="what-are-souls-exactly" class="level2">
<h2 class="anchored" data-anchor-id="what-are-souls-exactly">What are souls exactly?</h2>
<p><strong>Souls are accounts or wallets that hold publicly visible, non-transferable tokens. Those tokens could pottentially also be revocable by the issuer.</strong><sup>2</sup></p>
<p>The tokens that the Soul account or wallet owns should be SBTs. Soul could, in theory, hold various types of tokens, but that possibility isn’t explored in the paper. SBTs could be used to represent affiliations, credentials, memberships, etc. but more on that in the following paragraphs. The true power of these tokens lies if there was a possibility for SBTs to be issued and verified by other Soul accounts that are counterparties in the relationship. These counterparty Souls could be individuals, companies, or institutions.</p>
<p>Another essential property of Soul accounts or wallets is the abundance of a requirement for a soul to be linked to a legal name or a need to ensure that there is one soul account per human. Soul accounts or wallets could also be possibly transferred across humans.</p>
<p>Souls can also be a type of reputation signal of the user to the ecosystem. Depending on the SBTs that the soul account has, the user could have a positive or negative reputation. A positive reputation could give the user various benefits regarding products and services, and a negative one could prevent users from accessing them. This property can also pose a problem protocols could “redline” (discriminate) owners of some SBTs and prevent them from using their product.</p>
</section>
<section id="possible-use-cases-of-sbts" class="level2">
<h2 class="anchored" data-anchor-id="possible-use-cases-of-sbts">Possible use cases of SBTs</h2>
<section id="sbts-and-lending" class="level3">
<h3 class="anchored" data-anchor-id="sbts-and-lending">SBTs and Lending</h3>
<p>In traditional finance, reputation is a significant factor in uncollateralized lending. This system often relies on centralized credit scores of borrowers to gauge creditworthiness. However, this has flaws like not providing lending services if there is insufficient data on the borrower and discrimination.</p>
<p>In Web3, users must overcollateralize in the token of their choice to receive a loan. This is where the SBTs could, in theory, provide a solution.</p>
<p><strong>“Implementation and adoption of SBTs have a potential to unlock a censorship-resistant, bottom-up alternative to top-down commercial and”social” credit systems.”</strong> - E. Glen Weyl, Puja Ohlhaver, Vitalik Buterin</p>
<p>In the case of lending, SBTs could represent education credentials, work history, and rental contracts, which could signal “creditworthiness”.</p>
<p>The loans themselves could be represented by the SBTs, which could be burnable by the institution that has given the loan. After the burning of the token, an institution could send another SBT to the borrower. This time it would be a proof of timely repayment SBT. This token could serve as a “signal” to other lenders that this borrower returns his/hers loans on time, which would impact the borrower’s “credit score” and provide the borrower with better loan conditions. Non-transferability prevents transferring or hiding outstanding loans. A rich ecosystem of SBTs ensures that borrowers who try to escape their loans (creating a new soul) will have insufficient SBTs to stake their reputation.</p>
<section id="community-lending-market" class="level4">
<h4 class="anchored" data-anchor-id="community-lending-market">Community lending market</h4>
<p><strong>“SBTs would offer a substrate for community lending practices similar to those pioneered by Muhammad Yunus and the Grameen Bank, where members of a social network agree to support one another’s liabilities. Because a Soul’s constellation of SBTs represents memberships across social groups, participants could easily discover other Souls who would be valuable co-participants in a group lending project.Whereas commercial lending is a”lend-it-and-forget-it” until repayment model, community lending might take a “lend-it-and-help-it” approach—combining working capital with human capital with greater rates of return.”</strong> - E. Glen Weyl, Puja Ohlhaver, Vitalik Buterin</p>
</section>
<section id="what-are-the-first-steps" class="level4">
<h4 class="anchored" data-anchor-id="what-are-the-first-steps">What are the first steps?</h4>
<p>There are a couple of “requirements” for this type of lending to be true:</p>
<ul>
<li>Soul accounts/wallets would carry SBTs they are comfortable sharing publicly. This could be an excellent first step for the adoption of social/intra-community lending in Web3.</li>
<li>Social relationships and credentials would play a significant role in this type of lending.</li>
</ul>
</section>
</section>
<section id="sbts-and-nfts" class="level3">
<h3 class="anchored" data-anchor-id="sbts-and-nfts">SBTs and NFTs</h3>
<p>In terms of NFTs , Souls could play a major role in terms of artist’s reputation. When issuing NFTs artist could issue them from their Soul.</p>
<p>“The more SBTs the artist’s Soul carries, the easier it would be for buyers to identify the Soul as belonging to that artist, and thereby also confirm the NFT’s legitimacy. Artists could go a step further to issue a linked SBT stored in their Soul that attests to the NFT’s membership to a”collection” and vouches for whatever scarcity limits the artist wishes to set. Souls would thus create a verifable, on-chain way to stake and build reputation on the provenance and scarcity of an object.” - E. Glen Weyl, Puja Ohlhaver, Vitalik Buterin</p>
<p>The application of SBTs in this market extends beyond art. Some examples of potential use cases:</p>
<ul>
<li>various services</li>
<li>rentals/property</li>
<li>authentication</li>
<li>social provenance</li>
<li>retail</li>
<li>gaming</li>
<li>and many more, SBTs unlock the use cases where NFTs cannot be applicable</li>
</ul>
</section>
<section id="soul-accounts-in-airdrops-and-daos" class="level3">
<h3 class="anchored" data-anchor-id="soul-accounts-in-airdrops-and-daos">Soul Accounts in Airdrops and DAOs</h3>
<p>Soulbound Tokens could also enable communities to be convened at the intersection of souls and to form a DAO, for example. Drops of SBTs or “Souldrops” can be given based on SBTs and other tokens within a Soul (soul account/wallet). Some examples:</p>
<ul>
<li>conference attendees</li>
<li>certified programmers</li>
<li>early members</li>
<li>etc</li>
</ul>
<p>“Souldrops could also introduce novel incentives to encourage community engagement. Dropped SBTs could be engineered to be soulbound for a period but eventually”vest” into transferable tokens over time. Or the reverse could be true. Transferable tokens held for some period could unlock the right to SBTs that confer further governance rights over a protocol. SBTs open a rich possibility space to experiment with mechanisms that maximize community engagement and other goals, like decentralization” - E. Glen Weyl, Puja Ohlhaver, Vitalik Buterin</p>
<p>In DAOS, SBTs could be used to mitigate Sybil attacks in various ways:</p>
<ul>
<li>computing over a Soul’s constellation of SBTs to differentiate between unique Souls and probable bots and denying any voting power to a Soul that appears to be a Sybil.</li>
<li>conferring more voting power to Souls with more reputable SBTs — like work or educational credentials, licenses, or certifications.</li>
<li>issuing specialized “proof-of-personhood” SBTs could help other DAOs bootstrap Sybil resistance.</li>
<li>checking for correlations between SBTs held by Souls who support a particular vote and applying a lower vote weight to highly correlated voters.</li>
</ul>
<p>Souls and SBTs could also be used to estimate the decentralization degree in the governance of DAOs and protocols.</p>
</section>
<section id="property" class="level3">
<h3 class="anchored" data-anchor-id="property">Property</h3>
<p>So far, NFTs could not effectively be applied to property rights, considering their ease of transfer. Using SBTs, owners could set different rights and limitations for the same property (vehicles, real estate, events, etc.).</p>
</section>
</section>
<section id="recovery-of-soul-accountswallets" class="level2">
<h2 class="anchored" data-anchor-id="recovery-of-soul-accountswallets">Recovery of Soul Accounts/Wallets</h2>
<p>Soul accounts would probably be recoverable by using Social Recovery.</p>
<section id="social-recovery" class="level3">
<h3 class="anchored" data-anchor-id="social-recovery">Social recovery</h3>
<p>A social recovery system/wallet works as follows:</p>
<ul>
<li>There is a single “signing key” that can be used to approve transactions</li>
<li>There is a set of at least 3 (or a much higher number) of “guardians”, of which a majority can cooperate to change the signing key of the account. The signing key can add or remove guardians, though only after a delay.</li>
</ul>
<p>A social recovery wallet can be used as a regular wallet. In case of losing a key, the user can reach out to their guardians and ask them to sign a particular transaction to change the signing pubkey registered in the wallet contract to a new one.</p>
<p>Guardians can be:</p>
<ul>
<li>other devices</li>
<li>friends and family members</li>
<li>institutions (they can verify your identity by phone number, e-mail, etc.)<sup>3</sup></li>
</ul>
</section>
<section id="sbt-community-recovery" class="level3">
<h3 class="anchored" data-anchor-id="sbt-community-recovery">SBT community recovery</h3>
<p>In this proposed solution, Soul recovery is tied to the Soul’s memberships across communities.</p>
<p>“In a community recovery model, recovering a Soul’s private keys would require a member from a qualified majority of a (random subset of) Soul’s communities to consent.” - E. Glen Weyl, Puja Ohlhaver, Vitalik Buterin.</p>
<p>This recovery implies secure, off-chain communication channels where authentication can occur.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://3327.io/documents/research/assets/ERFC-261/Soc_rec_vs_sbt.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">SBT rec</figcaption><p></p>
</figure>
</div>
<p><em>Picture 1: Social recovery vs SBT community recovery</em></p>
<p><strong>By embedding security in sociality , a Soul can always regenerate their keys through community recovery, which deters Soul theft (or sale): because a Seller would need to prove selling the recovery relationships, any attempt to sell a Soul lacks credibility.</strong> - E. Glen Weyl, Puja Ohlhaver, Vitalik Buterin.</p>
<p>This recovery solution is just a proposition and requires more experimentation.</p>
</section>
</section>
<section id="implementation-and-adoption-challenges" class="level2">
<h2 class="anchored" data-anchor-id="implementation-and-adoption-challenges">Implementation and adoption challenges</h2>
<section id="privacy" class="level3">
<h3 class="anchored" data-anchor-id="privacy">Privacy</h3>
<p>One of the biggest challenges in the adoption of SBTs is privacy. Too many public SBTs that a soul possesses can reveal too much information about a soul.</p>
<p>Blockchain systems are public by default, and every transaction and relationship recorded on-chain is available for everyone in the world to see. One possible solution is to have separate souls for professional and private life. These souls can easily be linked if there are no serious privacy solutions.</p>
<p>Another solution is to have SBTs that could store data off-chain, leaving only the hash of the data on-chain.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://3327.io/documents/research/assets/ERFC-261/off_chain_data.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Privacy with SBTs</figcaption><p></p>
</figure>
</div>
<p><em>Picture 2: A way to keep some of the SBTs private</em></p>
<p>The choice of how to store data is left to the person. Possible solutions are:</p>
<ul>
<li>their own devices</li>
<li>a trusted cloud service</li>
<li>IPFS or other decentralized networks</li>
</ul>
<p>Zero-knowledge proofs are another possible solution that could help kickstart the adoption of SBTs. They also can allow people to prove arbitrary statements without revealing any more information beyond the statement itself. They can be computed over SBTs to prove characteristics about a Soul. Privacy could be extended further by introducing multi-party computation techniques like <a href="https://www.esat.kuleuven.be/cosic/blog/introduction-to-garbled-circuit/">garbled circuits</a>.</p>
<p>Other possible solutions for privacy problems include designated-verifier proofs and verifiable delay functions.</p>
<p>For example: If user A wants to prove some property about its SBTs to user B, they can make a zero-knowledge proof of the statement “I hold SBTs that have the property Z.” User B can then be sure as he didn’t make the proof. But what about passing somebody else’s proof? Users can mitigate this by using <a href="https://eprint.iacr.org/2018/601.pdf">verifiable delay functions</a>. Using verifiable delay functions, user A can make and present a proof that can only be made with required SBTs at the moment, but anyone else will be able to make five minutes from now.</p>
</section>
<section id="bribing-the-owners-of-the-sbts" class="level3">
<h3 class="anchored" data-anchor-id="bribing-the-owners-of-the-sbts">Bribing the owners of the SBTs</h3>
<p>Owners of the SBTs could be bribed by various parties in order to influence their voting or to exploit their other SBTs.</p>
<p>In the research paper, writers mention these ways of exploits mitigations:</p>
<ol type="1">
<li>“The ecosystem of SBTs could bootstrap of”thick” community channels , where SBTs signal authentic off-chain community membership with strong social bonds and repeat interactions. This would make it easier for communities to alter and revoke SBTs of impersonators and bots. Such thick channels—which we often and in churches, workplaces, schools, meet-up groups, and organizations in civil society—would provide a more sybil-resistant social substrate to police gaming (e.g., through bots, bribes, impersonation) in more “thin” social channels.</li>
<li>Nested communities could require SBTs to force context on potential collusion vectors “just below” them . For example, if a state were holding a funding round or vote, the state might require every participating citizen to also hold an SBT of a defined county and municipality.</li>
<li>The openness and cryptographic provability of the SBT ecosystem could itself be used to actively detect collusive patterns and penalize inauthentic behavior —perhaps discounting the voting power of collusive Souls, or obliging Souls to accept SBTs representing negative attestations.</li>
<li>ZK technology (eg. MACI ) could cryptographically prevent some attestations made by a Soul from being provable.</li>
<li>Encouraging of whistleblowers</li>
<li>Mechanisms from peer-prediction theory</li>
<li>Correlation scores that focus on correlations where there is a large incentive to be honest if a group of Souls share a common interest.” - E. Glen Weyl, Puja Ohlhaver, Vitalik Buterin. ‘Decentralized Society: Finding Web3’s Soul by E. Glen Weyl, Puja Ohlhaver, Vitalik Buterin :: SSRN’<sup>4</sup></li>
</ol>
</section>
<section id="legacy-systems" class="level3">
<h3 class="anchored" data-anchor-id="legacy-systems">Legacy systems</h3>
<p>Current identity systems tend to concentrate power on the issuer of identity proofs. If we look at the government IDs, for example, the user doesn’t own their identity. Government can track users’ movement (passports), revoke licenses (driving licenses), and put an “expiration date” on your ID card. In Web3 idendity is often handled by identity protocols like: Litentry, ORE network and IDX. When it comes to identity, SBTs and their DeSoc property could, in theory, replace the existing legacy system. However, changes in ID systems usually take a very long time.</p>
</section>
<section id="cold-start-challenge" class="level3">
<h3 class="anchored" data-anchor-id="cold-start-challenge">Cold start challenge</h3>
<p>The research paper asks a question: <strong>What comes first SBTs or social recovery?</strong></p>
<p>When it comes to SBTs currently revokable tokens could be created and minted to wallets. They are referred to as “Proto SBTs”, allthough they are not as practical as SBTs proposed they could be a step in the right direction.</p>
<p>Community recovery wallets like <a href="https://www.argent.xyz/">Argent</a> and <a href="https://loopring.io/#/">Loopring</a> also show that social recovery wallets can work in practice.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://3327.io/documents/research/assets/ERFC-261/Social_recovery.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">soc rec wallets</figcaption><p></p>
</figure>
</div>
<p><em>Picture 3: Social recovery wallets explained</em></p>
<p>“Norms can also shepherd Souls into existence. As we rethink tokens and wallets, we can also reframe how we think about certain classes of NFTs and tokens that are intended to signal membership. In particular, we can introduce a norm of not transferring NFTs and POAPs issued by reputable institutions that reflect attendance to a conference, work experience, or education credentials. Such transfers of membership tokens—if traded for value—could diminish the reputation of a wallet and perhaps discourage issuers from further issuing membership or POAP tokens to that wallet.” - E. Glen Weyl, Puja Ohlhaver, Vitalik Buterin</p>
</section>
</section>
<section id="sentiment" class="level2">
<h2 class="anchored" data-anchor-id="sentiment">Sentiment</h2>
<p>When the paper came out on May 11th 2022, it didn’t gain mainstream attention initially. Around 20th of May the paper and the ideas in it caught the attention of media outside Web3 space with magazines like <a href="https://fortune.com/2022/05/26/what-are-soulbound-tokens-web3-buterin/">Fortune</a> covering the ideas presented.</p>
<p><a href="https://twitter.com/iamjasonlevin/status/1527316024659353601?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1527316024659353601%7Ctwgr%5E%7Ctwcon%5Es1_&amp;ref_url=https%3A%2F%2Fnftnow.com%2Fguides%2Fsoulbound-tokens-sbts-meet-the-tokens-that-may-change-your-life%2F">In an interview</a> held by Jason Levin with E. Glen Weyl , the author predicted that that SBTs will be available for early uses by the end of 2022 and that the 2024 up cycle will focus on SBTs.</p>
<p>Overall response to the paper was very positive all across the board and many potential use cases are discussed.</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>As presented above, Souls and SBTs and their potential implementation have many obstacles in front of them. Problems like privacy, bribing users, and cold-start challenges are not the small ones to get a grip on. Souls and community recovery system would also require efficient and secure off-chain communication channels.</p>
<p>When it comes to privacy, zero-knowledge proofs are a great possible solution to this problem. Other problems presented will be hard to solve.</p>
<p>Regarding Web3 and its mass adoption and its principles, SBTs (Soulbound tokens) seem like the next logical step. There are various potential use-cases for them, and if the initial hurdles presented in this research and the research paper of the authors are to be overcome, it is more than likely that SBTs will start a “new chapter” in Web3 and onboard new users.</p>
<p>If the potential use-cases are satisfied, SBTs have the potential to change society as we know it. All beginnings are rough, right?</p>
</section>
<section id="bibliography" class="level1">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Bibliography</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-DecentralizedSocietyFinding" class="csl-entry">
‘Decentralized Society: Finding Web3’s Soul by E. Glen Weyl, Puja Ohlhaver, Vitalik Buterin :: SSRN’ &lt;<a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4105763" class="uri">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4105763</a>&gt; [accessed 14 June 2022]
</div>
<div id="ref-WhyWeNeed" class="csl-entry">
‘Why We Need Wide Adoption of Social Recovery Wallets’ &lt;<a href="https://vitalik.ca/general/2021/01/11/recovery.html" class="uri">https://vitalik.ca/general/2021/01/11/recovery.html</a>&gt; [accessed 1 June 2022]
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p><strong>MostExpensiveNFTs?</strong>↩︎</p></li>
<li id="fn2"><p><strong>weylDecentralizedSocietyFinding2022?</strong>↩︎</p></li>
<li id="fn3"><p>‘Why We Need Wide Adoption of Social Recovery Wallets’ &lt;&lt;https://vitalik.ca/general/2021/01/11/recovery.html&gt;&gt; [accessed 1 June 2022].↩︎</p></li>
<li id="fn4"><p>&lt;[Https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4105763](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4105763)&gt; [accessed 14 June 2022].↩︎</p></li>
</ol>
</section></div> ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-261.hugo.html</guid>
  <pubDate>Tue, 31 May 2022 00:00:00 GMT</pubDate>
  <media:content url="https://3327.io/documents/research/assets/ERFC-261/Social_recovery.png" medium="image" type="image/png" height="87" width="144"/>
</item>
<item>
  <title>Royalty Contract Standardization - RCS</title>
  <dc:creator>Aleksandar Damjanovic</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-171.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p>This research examines the possibility of hardcoding the royalty logic for the NFT royalty payments. It also explores how are royalties for NFT creators/artists taken care of by two largest NFT marketplaces OpenSea and LooksRare. It examines the EIP-2981 which aims to solve the royalty implementation problem. Small experiment is conducted with a goal to modify the transfer function from the ERC-721 standard.</p>
<p>After explorative research and a short experiment we have come to these conclusions:</p>
<ol type="1">
<li>The Marketplaces prefer handling the royalties themselves and only for the trades on their platform</li>
<li>ERC-2981 contains the optional royalty implementation logic. It’s on the platforms to decide whether they will utilize this standard.</li>
<li>Hardcoding royalties without making “a mess” of the NFT smart-contract is currently way too complex and would require altering the ERC-721 heavily.</li>
</ol>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Current markketplaces and NFTs have fragmented royalty payment implementations. This leaves the nft artist/creator with the issue of unpredictable royalty payments for his art. Each marketplace has different solutions for this problem. EIP-2981 has basic royalty implementation. Which doesn’t enforce actual payments. Royalty Contract Standardization (RCS) could in theory be done by modifying the transfer functions to enable the transfer of royalties to the creator during trading of the NFT via transaction splitting.</p>
<p><strong>This research is the aftermath of a brainstorming session and has some brave assumptions initially, which is why this short research is conducted to further validate those assumptions.</strong></p>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p>The goal of this research is to explore how royalties are taken care of currently and the way EIP-2981 works and the possibility of further improvement.</p>
<p>This will done by doing an explorative research of current royalty implementations on OpenSea and LooksRare as they are the biggest players.</p>
<p>Another examination will be done, maimly of the EIP-2981 standard to explore the solution it proposes.</p>
<p>Afterwards we will examine the possibility of hardcoding royalty in the NFT contract itself.</p>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<section id="opensea" class="level2">
<h2 class="anchored" data-anchor-id="opensea">OpenSea</h2>
<p>OpenSea offers royalties for Artists and Creator which are usually around 10%. They are also applied to secondary sales and the proceeds after fees go to the seller of the NFT.</p>
<p>Users can check the royalty fees with 3 methods:</p>
<ol type="1">
<li>Attempting to buy an NFT which will then open up a checkout window where the royalty amount is listed under the name of the NFT.</li>
<li>Installing the Flava Chrome extension which shows the royalty next to the NFT without needing to open the checkout menu.</li>
<li>Using the NFT analytics tools - There are numerous NFT analytics tools that include creator royalties in their stats.<sup>1</sup></li>
</ol>
<p>As we can see royalties are very important part of NFT space and they are of great importance for both traders and creators.</p>
<section id="how-do-creators-earn-their-royaties" class="level3">
<h3 class="anchored" data-anchor-id="how-do-creators-earn-their-royaties">How do creators earn their royaties</h3>
<p>On OpenSea proceeds from the primary sales of the NFT are immediately forwarded to the creators address. Royalties are usually held by OpenSea for 2-4 weeks before paid out to the creator, this includes <strong>both primary sales and secondary sales</strong>.</p>
<p>Royalties are not automatically set on OpenSea and the creator of the collection must set the royalty percentage and the payout address on the collection level.</p>
</section>
<section id="opensea-royalty-on-other-marketplaces" class="level3">
<h3 class="anchored" data-anchor-id="opensea-royalty-on-other-marketplaces">OpenSea royalty on other marketplaces</h3>
<p>OpenSea royalties are enforced on many other platforms. This is a result of various legal agreements between platforms.</p>
<p>If we are talking about ERC-721 and ERC-1155 standard tokens there is no royalty support on token or smart contract level. That is why previosly mentioned legal agreements are needed to enforce royalty payments.<sup>2</sup></p>
</section>
</section>
<section id="looksrare" class="level2">
<h2 class="anchored" data-anchor-id="looksrare">LooksRare</h2>
<p>LooksRare is a decentralized NFT marketplace which rewards traders, token stakers, creators and collectors for participating on the platform.</p>
<p>It was launched in January 22 with an aim to dethrone Opensea from it’s spot as a leader in the NFT market.</p>
<p>As a community-first platform all the revenue generated is distributed to the stakers of LOOKS token.</p>
<section id="token" class="level3">
<h3 class="anchored" data-anchor-id="token">Token</h3>
<p>LOOKS is the native token that powers the LooksRare marketplace, its price is $0.5908 at the time of this writing. It is used for staking and various rewards.</p>
</section>
<section id="royalties" class="level3">
<h3 class="anchored" data-anchor-id="royalties">Royalties</h3>
<p>Whenever the NFT is traded on LooksRare there are 2 types of fee the seller is charged:</p>
<ul>
<li>Platform fee (2%)</li>
<li>Creator royalties</li>
</ul>
<p>“Creator royalties are fees that are decided by the collection creator. Collection owners can specify a percentage of royalties they wish to recieve on their collection management page.”</p>
<p>Royalties are on-chain. Whenever a sale is made through the platform the royalties are paid in the same transaction as the sale and the creators instantly recieve their royalty. This is one of the ways LooksRare is different from OpenSea.</p>
<p>LooksRare also supports EIP-2981 royalty standard which takes precedent over any royalties specified directly on LooksRare.</p>
</section>
</section>
<section id="eip-2981" class="level2">
<h2 class="anchored" data-anchor-id="eip-2981">EIP-2981</h2>
<p>This standard provides a way to retrieve royalty payment information for NFTs with a goal to enable universal support for royalty payments across all NFT marketplaces and ecosystem participants.</p>
<p>This standard enables all marketplaces to retrieve royalty payment information for a given NFT. This enables accurate royalty payments regardless of which marketplace the NFT is sold or re-sold at.</p>
<p>This standard only provides a mechanism to fetch the royalty amount and recipients. The actual funds transfer is something the marketplace needs to do.</p>
<p>“Royalty amounts are always a percentage of the sale price. If a marketplace chooses not to implement this EIP, then no funds will be paid for secondary sales.”</p>
<p><strong>That is one of the reasons hardcoding royalties idea was proposed.</strong></p>
<p>EIP-2981 can also be integrated with other contracts to return royalty payment information. <strong>ERC-2981</strong> is a royalty standard for many asset types.</p>
<p>It is recomended to read the full specification of the proposal in order to better understand the issue at hand and the way it is handled in the <a href="https://eips.ethereum.org/EIPS/eip-2981">EIP-2981</a>.</p>
<p>In the proposal the writers have come to these conclusions:</p>
<ul>
<li><p>“It is impossible to know which NFT transfers are the result of sales, and which are merely wallets moving or consolidating their NFTs. Therefore, we cannot force every transfer function, such as transferFrom() in ERC-721, to involve a royalty payment as not every transfer is a sale that would require such payment.”</p></li>
<li><p>“It is impossible to fully know and efficiently implement all possible types of royalty payments logic. With that said, it is on the royalty payment receiver to implement all additional complexity and logic for fee splitting, multiple receivers, taxes, accounting, etc. in their own receiving contract or off-chain processes. Attempting to do this as part of this standard, it would dramatically increase the implementation complexity, increase gas costs, and could not possibly cover every potential use-case.”</p></li>
<li><p>“This EIP mandates a percentage-based royalty fee model. It is likely that the most common case of percentage calculation will be where the royaltyAmount is always calculated from the _salePrice using a fixed percent i.e.&nbsp;if the royalty fee is 10%, then a 10% royalty fee must apply whether _salePrice is 10, 10000 or 1234567890.”</p></li>
<li><p>“This EIP does not specify a currency or token used for sales and royalty payments. The same percentage-based royalty fee must be paid regardless of what currency, or token was used in the sale, paid in the same currency or token. This applies to sales in any location including on-chain sales, over-the-counter (OTC) sales, and off-chain sales using fiat currency such as at auction houses. As royalty payments are voluntary, entities that respect this EIP must pay no matter where the sale occurred - a sale outside of the blockchain is still a sale.”</p></li>
</ul>
<p>They also plan on taking on the mechanism for paying and notifying the recepient in the future EIPs.<sup>3</sup></p>
<section id="our-experiment" class="level3">
<h3 class="anchored" data-anchor-id="our-experiment">Our experiment</h3>
<p>After trying to implement hardcoding the royalties the same issue with the transfer function occured.</p>
<pre class="solidity"><code>
// SPDX-License-Identifier: MIT
pragma solidity ^0.8.13;

import "@openzeppelin/contracts@4.5.0/token/ERC721/ERC721.sol";
import "@openzeppelin/contracts@4.5.0/token/ERC721/extensions/ERC721Enumerable.sol";
import "@openzeppelin/contracts@4.5.0/access/Ownable.sol";
import "@openzeppelin/contracts@4.5.0/utils/Counters.sol";
import "@openzeppelin/contracts@4.5.0/interfaces/IERC2981.sol";

contract InstantRoyaltyToken is ERC721, ERC721Enumerable, Ownable, IERC2981 {
    using Counters for Counters.Counter;

    Counters.Counter private _tokenIdCounter;

    address royaltyAddress;
    uint256 royalty = 10_000;

    constructor(address _royaltyAddress ) ERC721("InstantRoyaltyToken", "IRT") {
            royaltyAddress = _royaltyAddress;
    }

    function safeMint(address to) public onlyOwner {
        uint256 tokenId = _tokenIdCounter.current();
        _tokenIdCounter.increment();
        _safeMint(to, tokenId);
    }

    // The following functions are overrides required by Solidity.

    function _beforeTokenTransfer(address from, address to, uint256 tokenId)
        internal
        override(ERC721, ERC721Enumerable)
    {
        super._beforeTokenTransfer(from, to, tokenId);
    }

    function supportsInterface(bytes4 interfaceId)
        public
        view
        override(ERC721, ERC721Enumerable, IERC165)
        returns (bool)
    {
        return interfaceId == type(IERC2981).interfaceId || super.supportsInterface(interfaceId);
    }

    function royaltyInfo(uint256 tokenId, uint256 salePrice) public view override returns(address receiver, uint256 royaltyAmount) {
        return (royaltyAddress, royalty);
    }
    /* 

        * The function below from ERC721 is the main issue. Making this a
        * payable function would add unecessary complexity to the standard
        * and would make the function payable, thus requiring payment 
        * even when sales are not ocurring.

    */
    function transferFrom(
        address from,
        address to,
        uint256 tokenId
    ) public virtual override(ERC721,IERC721) {
            require(_isApprovedOrOwner(_msgSender(), tokenId), "ERC721: transfer caller is not owner nor approved");
            //royaltyInfo and pay royalty for transfer part would go here
            //implementing this would make the function payable
            _transfer(from, to, tokenId);
    }

}</code></pre>
</section>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>After researching how the royalties are taken care of so far by the leading NFT marketplaces we have come to these conclusions:</p>
<ol type="1">
<li>The Marketplaces prefer handling the royalties themselves and only for the trades on their platform</li>
<li>ERC-2981 contains the optional royalty implementation logic. It’s on the platforms to decide whether they will utilize this standard.</li>
<li>Hardcoding royalties without making a mess of the NFT smart-contract is currently way to complex and would require altering the ERC-721 heavily.</li>
</ol>
<p>The above reasons are the reason for not going further with this initiative, however this gave us a better insight of how the NFT marketplaces operate in terms of royalties and how are the new standards for NFTs proposed, and what are the limitations.</p>
<p><em>Special thanks to Stevan Bogosavljevic for his opinions on this research and expertize in NFT royalties. Thank you for showing the fallacies in the logic of this research proposal</em></p>
</section>
<section id="appendices" class="level1">
<h1>Appendices</h1>
</section>
<section id="bibliography" class="level1">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Bibliography</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-10SettingFees" class="csl-entry">
‘10. Setting Fees on Secondary Sales’, <em>OpenSea Developer Documentation</em> &lt;<a href="https://docs.opensea.io/docs/10-setting-fees-on-secondary-sales" class="uri">https://docs.opensea.io/docs/10-setting-fees-on-secondary-sales</a>&gt; [accessed 18 May 2022]
</div>
<div id="ref-NFTAnalyticsTools2022" class="csl-entry">
‘8 NFT Analytics Tools to Boost Your Profits Tokenized’, 2022 &lt;<a href="https://tokenizedhq.com/nft-analytics/" class="uri">https://tokenizedhq.com/nft-analytics/</a>&gt; [accessed 18 May 2022]
</div>
<div id="ref-EIP2981NFTRoyalty" class="csl-entry">
‘EIP-2981: NFT Royalty Standard’, <em>Ethereum Improvement Proposals</em> &lt;<a href="https://eips.ethereum.org/EIPS/eip-2981" class="uri">https://eips.ethereum.org/EIPS/eip-2981</a>&gt; [accessed 18 May 2022]
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>‘8 NFT Analytics Tools to Boost Your Profits Tokenized’, 2022 &lt;&lt;https://tokenizedhq.com/nft-analytics/&gt;&gt; [accessed 18 May 2022].↩︎</p></li>
<li id="fn2"><p>‘10. Setting Fees on Secondary Sales’, <em>OpenSea Developer Documentation</em> &lt;&lt;https://docs.opensea.io/docs/10-setting-fees-on-secondary-sales&gt;&gt; [accessed 18 May 2022].↩︎</p></li>
<li id="fn3"><p>‘EIP-2981: NFT Royalty Standard’, <em>Ethereum Improvement Proposals</em> &lt;&lt;https://eips.ethereum.org/EIPS/eip-2981&gt;&gt; [accessed 18 May 2022].↩︎</p></li>
</ol>
</section></div> ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-171.hugo.html</guid>
  <pubDate>Thu, 12 May 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Data Analytics in Blockchain</title>
  <dc:creator>Milos Bojinovic</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-146.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p><strong>Data Analytics</strong> is the science of analyzing raw data related to a specific problem and extracting all of the necessary information in order to make conclusions about as well as derive approaches for solving it.</p>
<p>In the context of <strong>Blockchain</strong>, Data Analytics revolves around the process of collecting and parsing of raw transaction data thus transforming it into usable and actionable data. Parsing of those transactions requires knowledge about the chain specifics as well as internal workings of Smart Contract that that are of interest which is an extremely time consuming process - all of the data on the Blockchain, while it may be public and unchangable, is unstructured.</p>
<p>Blockchain data, however, holds all of the chain’s history since its inception, making it possible to see past interactions between addresses and/or Smart Contracts. This data can then be segmented to include only a wanted subset for which the analysis will be performed. With this aggregated information it is then possible to gain insight in the past trends for a set of Non-Fungible-Tokens(NFTs) and Decentralized Finance(DeFi) related applications as well as general Crypto related trends and potentially predict future ones.</p>
<p>Data Analytics platforms in the Blockchain space are gaining users as the whole crypto ecosystem evolves and is becoming harder to navigate. With substantial recent investments in this area,<sup>1</sup><sup>2</sup> it is clear that the investors are showing interest in what these platforms can do and the potential they have in shaping the future of Blockchain.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>This research focuses on the type of information that can be extracted from the blockchain, elaborates on where that information can be used and signals the utility that lies in it - especially in the NFT and DeFi related applications that dominate the crypto ecosystem.</p>
<p>Out of the scope of the research falls the aquiring/storing/organizing/displaying of the raw data which are extremely hard and complex processes that also open questions about the decentralization of those processes and the integrity of the collected data.</p>
<p>Instead, it casts a light on the current state of the Data Analytics / Blockchain intersection, top platforms that operate in it and the tools that they provide. These platforms/tools are then categorized based on area where they are used and their use cases briefly explained.</p>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p>Data Analytics platforms/tools enable users to make sense of this rapidly changing space and so the importance of this explorative research lies in the fact that they are relatively new with a huge potential and as such must be investigated further.</p>
<p><strong>The goal</strong> of this research is to:</p>
<ul>
<li>explore, explain and categorise Data Analytics platforms and their tools</li>
</ul>
<p><strong>The methodology</strong> of the research includes:</p>
<ul>
<li><p>taking into account only platforms that support Ethereum Virtual Machine (EVM) compatible chains</p></li>
<li><p>discussing where a platform/tool can be used</p></li>
<li><p>categorizing a platform/tool as one of the following:</p>
<ul>
<li><strong>General Purpose</strong> - contains both of the other categories as well as some additional functionality</li>
<li><strong>NFT specific</strong> - focuses on providing information about a collection/NFT or the NFT market in general</li>
<li><strong>DeFi specific</strong> - focuses on the extracting metrics for specific DeFi projects and DeFi market in general</li>
</ul></li>
</ul>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<p>With those three categories explained above, platforms can be investigated and then grouped. Regarding the distribution of categories that will be elaborated on it is evident that most platforms/tools are not general purpose ones. They require a lot of time to develop and so there is an emerging trend of developing specizalised ones that are easier to develop and target a single niche.</p>
<p>In the following text categories are listed in order, with each category being divided into “Tools” and “Platforms” sections. In the “Tools” section, each entry describes a specific functionality and the “Platforms” section focuses on illustrative platforms that have those functionalities (among others) incorporated into them.</p>
<p>Platforms/tools from the same/different categories are not mutually exclusive and can be combined.</p>
<section id="general-purpose" class="level2">
<h2 class="anchored" data-anchor-id="general-purpose">General Purpose</h2>
<section id="tools" class="level3">
<h3 class="anchored" data-anchor-id="tools">Tools</h3>
<p>Tools in this category query information about the complete transaction activity of a specific address (both Externally-Owned-Accounts (EOA) and Smart Contracts) and groups the extracted information into human readable metrics.</p>
<section id="contract-interactions" class="level4">
<h4 class="anchored" data-anchor-id="contract-interactions">Contract interactions</h4>
<p>For any choosen contract it is possible to extract general information about the:</p>
<ul>
<li>transaction count</li>
<li>unique addresses</li>
<li>token inflow/outflow</li>
</ul>
<p>for a specific timeframe. These values can then be organized and monitored over a larger time periods to provide information about the latest trends and changes in the number of users, who these users are, etc.</p>
<p>They can also be used to detect contracts that were recently deployed that are gaining popularity as to investigate the project with which those contracts are associated with.</p>
<p>More valuable information would be tied to how the contract is being used - what methods are being called, their sequence, etc. To extract meaningfull data, as it was discussed above, there would need to exist a parser with a specific domain knowledge.</p>
</section>
<section id="address-profiler" class="level4">
<h4 class="anchored" data-anchor-id="address-profiler">Address Profiler</h4>
<p>For any user address of interest, it is possible to extract the information about the :</p>
<ul>
<li>portfolio (all of the assets that the address holds)</li>
<li>estimated portfolio value (sum of values of NFT* and ERC20 holdings)</li>
<li>recent token trades (both ERC20 and NFTs)</li>
<li>addresses that the user has interacted with</li>
</ul>
<p>All of these values can also be monitored since the beginning of the chain’s history and addresses can be grouped together to provide some form of live feed for those that are most interesting either to the user or to the platform itself.</p>
<p>*Estimated value of an NFT is platform specific (i.e.&nbsp;see<sup>3</sup>)</p>
</section>
<section id="alerts" class="level4">
<h4 class="anchored" data-anchor-id="alerts">Alerts</h4>
<p>Alerts are delivered to the user, via a communication channel of choice (Telegram, Text Message, Discord, …), when a certain customly defined condition is met - some address buys an NFT, collection’s floor price has increased/decreased by some margin, …</p>
</section>
</section>
<section id="platforms" class="level3">
<h3 class="anchored" data-anchor-id="platforms">Platforms</h3>
<p>Two of the top plaftforms in this category are <a href="https://nansen.ai">Nansen</a> and <a href="dune.xyz">Dune Analytics</a> which can be used to gather and analyze similar information but take two drastically different approaches - user oriented and business oriented, respectively.</p>
<section id="nansen.ai" class="level4">
<h4 class="anchored" data-anchor-id="nansen.ai">Nansen.ai</h4>
<p>This paid platform doesn’t require or demand from user to have technical knowledge and it provides detailed non-customizable dashboards for General purpose, NFT and DeFi specific tools. Almost all of the tools (from the three categories) listed in this paper, in one form or another, are supported by Nansen making it the most comprehensive and beginner friendly platform.</p>
<p>An interesting additional feature that Nansen provides is labeling of some addresses as being “Smart Money” (addresses that were early adopters and/or have made smart decisions in the NFT and/or DeFi space)*. There exist specific dashboards/sections where it is shown what the “Smart Money” is doing - what are they minting/buying/selling, with whom they are interacting, etc. This information can be used by the user to decide what they think is a good strategy for them when investing and can be combined with custom alerts when a certain condition is met.</p>
<p>*See<sup>4</sup> for more details on the labeling of these addresses.</p>
</section>
<section id="duneanalytics.com" class="level4">
<h4 class="anchored" data-anchor-id="duneanalytics.com">DuneAnalytics.com</h4>
<p>Dune Analytics translates raw on-chain transaction data into SQL databases such that the information can be requested using SQL queries. Custom vizualizations (charts, graphs, …) and dashboards can be created from those queries which can then be embedded into other websites.</p>
<p>Additional benefit of the platform is that there exists an active community of members who can create dashboards for which both the visualizations and the SQL queries are publicly avaliable. This enables them to build upon on another’s work, making a powerfull snowball effect.</p>
<p>There exist, however, two drawbacks to the platform:</p>
<ol type="1">
<li>only the platfrom itself can perfom the parsing of smart contracts (users can request a contract to be parsed)</li>
<li>doesn’t provide an API (though paid users can export results as a CSV file)</li>
</ol>
</section>
</section>
</section>
<section id="nft-specific" class="level2">
<h2 class="anchored" data-anchor-id="nft-specific">NFT specific</h2>
<section id="tools-1" class="level3">
<h3 class="anchored" data-anchor-id="tools-1">Tools</h3>
<section id="market-overviewtrends" class="level4">
<h4 class="anchored" data-anchor-id="market-overviewtrends">Market Overview/Trends</h4>
<p>Contains information about the whole NFT market and specific marketplaces, such as:</p>
<ul>
<li>number of distinct users (minters/buyers/sellers)</li>
<li>trading volume</li>
<li>average price of all NFTs sold</li>
<li>floor price (taking into account all NFTs listed)</li>
<li>trending collections</li>
</ul>
<p>These values are then used to analyze the percentage share of a marketplace compared to the whole market which is useful to determine the top marketplaces and capture the moment when there is a drastic shift in the leaderboard.</p>
<p>The tool also helps in discovering new trending NFT collections and on which marketplace is the most of the trading activity for that collection happening thus answering the question where to go to when considering to invest in it.</p>
</section>
<section id="collection-breakdown" class="level4">
<h4 class="anchored" data-anchor-id="collection-breakdown">Collection Breakdown</h4>
<p>Contains information tied to a specific collection and involves:</p>
<ul>
<li>basic information (number of distinct holders, average price, volume, price range, number of trades…)</li>
<li>balance changes (how many NFTs were bought/sold/minted by an address)</li>
<li>rarity stats - what traits are the rarest and thus more valuable</li>
<li>recent mints/trades</li>
<li>similar collections</li>
</ul>
<p>This data can be used to determine whether the majority of NFTs from the collection are held by few addresses which is a bad position for other holders as those addresses can quickly unload the NFTs, selling them at lower prices and so driving the floor price for the entire collection down.</p>
<p>It can also be used to assess the confidence of NFT holders in the collection by seeing if long term holders are suddenly started selling or if the collection is gaining momentum (for example, a lot of trades by different addresses in a short period of time).</p>
<p>All of this can be used by the users to develop unique NFT trading strategies, making this tool extremely informative.</p>
</section>
<section id="nft-breakdown" class="level4">
<h4 class="anchored" data-anchor-id="nft-breakdown">NFT Breakdown</h4>
<p>This tool focuses on a specific NFT from a collection and displays</p>
<ul>
<li>history of trades - changes in ownership and price</li>
<li>similar NFTs (based on traits)</li>
</ul>
<p>One of the obvious use case is tracking the price movement of that NFT but another one is tracking at the same time the price movement of similar NFTs and buying those that seem undervalued (ofter reffered as “sniping”).</p>
</section>
</section>
<section id="platforms-1" class="level3">
<h3 class="anchored" data-anchor-id="platforms-1">Platforms</h3>
<p>All of the previously listed tools are supported by Nansen but there are specialized alternatives that perform limited subset of those functionalities in a same/slightly different way. Some of the popular ones are <a href="https://icy.tools">icy.tools</a>, <a href="https://moby.gg">moby.gg</a> and <a href="https://nftnerds.ai">NFTNerds.ai</a>.</p>
</section>
</section>
<section id="defi-specific" class="level2">
<h2 class="anchored" data-anchor-id="defi-specific">DeFi specific</h2>
<section id="tools-2" class="level3">
<h3 class="anchored" data-anchor-id="tools-2">Tools</h3>
<section id="total-value-locked-tvl-tracker" class="level4">
<h4 class="anchored" data-anchor-id="total-value-locked-tvl-tracker">Total Value Locked (TVL) Tracker</h4>
<p>TVL s the overall value of crypto assets deposited in a specific DeFi protocol – or in DeFi protocols generally. It is often analyzed to determine the oportunities across chains and protocols. When analyzed over longer periods of time it can help in discovering new project trends.</p>
</section>
<section id="recent-activity-tracker" class="level4">
<h4 class="anchored" data-anchor-id="recent-activity-tracker">Recent Activity Tracker</h4>
<p>This tool gathers in real time the latest transactions that happened on Decentralized Exchanges (DEXs), Lending/borrowing and Derivatives platforms. Using it, it is possible to detect and take into account large funds movement by an address that is of interest.</p>
</section>
<section id="stakinglendingliquidity-metrics" class="level4">
<h4 class="anchored" data-anchor-id="stakinglendingliquidity-metrics">Staking/Lending/Liquidity Metrics</h4>
<p>These metrics revolve around the number of lenders/borrowers/stakers of a DeFi platform, their current and past balances (including deposits/withdrawals/liquidations) as well as the distribution of token holders.</p>
</section>
</section>
<section id="platforms-2" class="level3">
<h3 class="anchored" data-anchor-id="platforms-2">Platforms</h3>
<p>Dune Analytics is very useful in this area as the most useful information is DeFi platform specific and needs to be analyzed in a different way. For general, comparable information there are <a href="https://www.defipulse.com/">DeFi Pulse</a> and <a href="https://defillama.com/">DeFi Llama</a>.</p>
</section>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>Using Data Analytics platforms, it is possible to track and analyze the performance of a portfolio for any address and to learn from their past experiences. They are also useful in determining the differences between the most sucessfull and least successful addresses as well as what they have in common. These groups of addresses can then be monitored for future transactions and can alert an user when they happen. Users can then assess the new information and act accordingly.</p>
<p>The bottleneck of this process lies in the human factor that does information assessing manually and so a lot of time is spent on it. Improvements can be made by automating the decision process that leads to the action. Since it would be dealing with real funds, a machine could suggest a potential sequence of actions and the user would still need to aprove it by signing the corresponding transactions.</p>
<p>For example, in NFT trading, a bot could monitor all trades in realtime and detect an increase/decrease in the popularity of a collection which would signal it to buy/sell an NFT or a set of NFTs and suggest the price of it - at what price to list an NFT or what offer to make.</p>
<p>This, and other use cases from specific niches would need to be studied further, as part of a separate research. There exists a question on the utility of those tools, however, their functionalities are in a large measure dependant on the Data Analytics and so their whole processing pipeline would need to be carefully designed.</p>
</section>
<section id="bibliography" class="level1">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Bibliography</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-finsmesDuneAnalyticsRaises2022" class="csl-entry">
FinSMEs, ‘Dune Analytics Raises $69.42M in Series B Funding’, <em>FinSMEs</em>, 2022 &lt;<a href="https://www.finsmes.com/2022/02/dune-analytics-raises-69-42m-in-series-b-funding.html" class="uri">https://www.finsmes.com/2022/02/dune-analytics-raises-69-42m-in-series-b-funding.html</a>&gt; [accessed 8 May 2022]
</div>
<div id="ref-NansenWalletLabels" class="csl-entry">
‘Nansen Wallet Labels &amp; Emojis: What Do They Mean?’ &lt;<a href="https://www.nansen.ai/guides/wallet-labels-emojis-what-do-they-mean" class="uri">https://www.nansen.ai/guides/wallet-labels-emojis-what-do-they-mean</a>&gt; [accessed 9 May 2022]
</div>
<div id="ref-UtilizingNansenInvesting" class="csl-entry">
‘Utilizing Nansen: Investing in NFTs’ &lt;<a href="https://www.nansen.ai/research/utilizing-nansen-investing-in-nfts" class="uri">https://www.nansen.ai/research/utilizing-nansen-investing-in-nfts</a>&gt; [accessed 9 May 2022]
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p><strong>NansenRaises7?</strong>↩︎</p></li>
<li id="fn2"><p>FinSMEs, ‘Dune Analytics Raises $69.42M in Series B Funding’, <em>FinSMEs</em>, 2022 &lt;&lt;https://www.finsmes.com/2022/02/dune-analytics-raises-69-42m-in-series-b-funding.html&gt;&gt; [accessed 8 May 2022].↩︎</p></li>
<li id="fn3"><p>‘Utilizing Nansen: Investing in NFTs’ &lt;&lt;https://www.nansen.ai/research/utilizing-nansen-investing-in-nfts&gt;&gt; [accessed 9 May 2022].↩︎</p></li>
<li id="fn4"><p>‘Nansen Wallet Labels &amp; Emojis: What Do They Mean?’ &lt;&lt;https://www.nansen.ai/guides/wallet-labels-emojis-what-do-they-mean&gt;&gt; [accessed 9 May 2022].↩︎</p></li>
</ol>
</section></div> ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-146.hugo.html</guid>
  <pubDate>Sat, 07 May 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Developing with Ape</title>
  <dc:creator>Aleksandar Damjanovic</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-172.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p>This research examines Ape The Ethereum Development Framework For Python Developers. It examines its plugin system and ease of use. As a conclusion Web3 Tech Radar location is suggested.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Ape is a new tool for creating and exploring on Ethereum and other blockchains. This framework is written in python with a goal of onboarding more python developers to Web3 thus providing much needed inclusivity in the space.</p>
<p>Their goal is to make development smoother with their modular approach. Ape is centered around their open-source plugins written in python; some of them are:</p>
<ol type="1">
<li>Ape-hardhat - Hardhat network provider for Ape</li>
<li>Ape-infura - Infura provider plugins for Ethereum-based networks</li>
<li>Ape-solidity - Support for Solidity smart contracts</li>
<li>Ape-ledger - Ledger Nano S and X plugin for Ape</li>
<li>Ape-alchemy - Alchemy Provider plugins for Ethereum-based networks</li>
</ol>
<p><em>There are over 20 plugins Ape offers. Considering the open-source nature of the project a lot of new plugins are on the way.</em></p>
<p>Current version of Ape is <strong>v0.2.1</strong> and some of the new interesting features offered are:</p>
<ol type="1">
<li>Polygon, Binance Smart Chain, and Fantom support. Developers can build multi-chain applications with ape’s network switching feature.</li>
<li>Impersonated account. This let’s the developers test their project and interact with the contract on a fork network pretending to be any account. If you want to impersonate Vitalik, Ape makes that possible.</li>
</ol>
<p>They are also working on Ape Project Templates which should increase productivity and enhance developers’ experience when using this framework. Some of the templates Ape is currently developing are:</p>
<ol type="1">
<li>NFT template</li>
<li>Token template</li>
<li>Various other templates for airdrops,minting</li>
<li>Templates for different ERC standards</li>
</ol>
<p>Ape is also set out to be the “first professional-grade smart contract development framework to support multi-chain application development, including non-EVM chains like StarkWare” .[^1]</p>
<p>Another sign that Ape is growing is that a Yearn.Finance repo has <a href="https://github.com/yearn/veYFI/pull/98?utm_campaign=Updates%20from%20ApeWorX&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">officially migrated</a> over from Brownie to Ape.</p>
<p>As previosly mentioned, this is a new framework and we are expecting more adoption and improvements in the coming months, especially as more developers “take it for a spin”.</p>
<p>Another interesting thing is that there is a possibility of developers switching to Ape from Brownie framework, as Brownie updates <a href="https://github.com/eth-brownie/brownie/issues/1515">have slowed down</a>.</p>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p>The goal of this research paper is to explore this new player in the smart contract frameworks market, this is an opportunity to explore a new framework that is python oriented.</p>
<p>This will be done by writing a simple smart contract, deployment script for rinkeby and a couple tests for said contract and examining the documentation and tutorials present. That way we can research the ease of use for both beginners and experienced developers, and see what is the approach to development process this open-source framework is taking.</p>
<p>As a result Web3 Tech Radar location for this framework will be suggested.</p>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<p><strong>Beginner friendly?</strong></p>
<p>After initial testing of this framework and considering the state of the documentation at this stage I would recommend this framework to experienced python developers venturing into Web3. Documentation is well written, still in the works and continuosly updated with contributions from the community around this framework. Apeworx Team and Apeworx community is currently working on workshops to get developers up to speed and tutorials are in the works.</p>
<p>Currently there is little materials for newcomers. Considering this is a new open-source project this is understandable. However, for absolute beginners, going through the Brownie framework first is recomended at this stage of Ape’s development. The reason for that is abundance of tutorials, workshops and well written documentation. After Brownie, switch to Ape and its plugin system is smooth.</p>
<p><strong>Performance:</strong></p>
<p>Ape framework performs well. Smart contract was developed and deployed to Rinkeby test network using a python script without any problems. Verification of the contract on Etherscan via a python script is not yet possible but is in the works in the Etherscan plugin.</p>
<p>Testing works well both locally and when using network forks, which makes exhaustive testing possible. Currently Ape doesn’t include built-in smart contract fuzz-testing tool.</p>
<p>Currently the speed of the framework is satisfactory and more improvements are on the way.</p>
<p><strong>Plugins:</strong></p>
<p>Open-source modular plugins are definitely the highlight of this framework. It allows developers to easily install and remove the functionality they need in their development process and I could see this being a way to onboard new developers from the python world and a way to incentivize developers to develop their own plugins. Some of the interesting Ape plugins are:</p>
<p><strong>ape-tokens</strong> is an interesting plugin which allows developers to get token contracts without putting in the addresses themselves.</p>
<p>Example:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">from</span> ape_tokens <span class="im" style="color: #00769E;">import</span> tokens</span>
<span id="cb1-2"></span>
<span id="cb1-3">link <span class="op" style="color: #5E5E5E;">=</span> tokens[<span class="st" style="color: #20794D;">"LINK"</span>]</span>
<span id="cb1-4"></span>
<span id="cb1-5"><span class="bu" style="color: null;">print</span>(link.address)</span></code></pre></div>
<p>This will print out the eth adress of the LINK token. “link” can now be used in various python scripts, be it testing or development.</p>
<p><strong>ape-ledger</strong> is a plugin for Ape Framework which integrates with Ledger devices to load and create accounts, sign messages, and sign transactions.</p>
<p>Requirements</p>
<ul>
<li>have the Ledger USB device connected</li>
<li>have the Ledger USB device unlocked (by entering the passcode)</li>
<li>have the Ethereum app open.</li>
</ul>
<p>Ledger accounts have the following capabilities in ape:</p>
<ul>
<li>Can sign transactions</li>
<li>Can sign messages using the default EIP-191 specification</li>
<li>Can sign messages using the EIP-712 specification</li>
</ul>
<p><strong>ape-trezor</strong> is a plugin for Ape Framework which integrates Trezorlib ethereum.py to load and create accounts, sign messages, and sign transactions.</p>
<p>You can load the account like any other account in Ape console and then use it to sign transactions like this:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1">ape trezor sign<span class="op" style="color: #5E5E5E;">-</span>message [YOUR TREZOR ALIAS] <span class="st" style="color: #20794D;">"hello world"</span></span>
<span id="cb2-2">ape trezor verify <span class="st" style="color: #20794D;">"hello world</span></span></code></pre></div>
<p>The output of verify should be the same address as the account $account_name.</p>
<p><strong>Ape Polygon Ecosystem Plugin</strong> - Ecosystem Plugin for Polygon support in Ape</p>
<p><strong>Ape Fantom Ecosystem Plugin - Ecosystem Plugin for Fantom support in Ape</strong></p>
<p><strong>ape-addressbook</strong> is plugin that allows tracking addresses and contracts in projects and globally. This is an interesting way to improve developers user experience and is currently in development.</p>
<p><em>…And many more.</em></p>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p><strong>Tech Radar Proposal:</strong></p>
<p>Recommended location is the Assess ring at this stage. The reason for that is the shere novelty of this framework. However the development team is great, community is growing and we are seeing new projects emerging using Ape. This framework is with its simplicity aiming to become the industry standard in Ethereum development for python developers and is on a great way to do so.</p>
</section>
<section id="bibliography" class="level1">




</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Bibliography</h2><div id="refs">

</div></section></div> ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-172.hugo.html</guid>
  <pubDate>Sat, 30 Apr 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>OWT - Omni Web Token</title>
  <dc:creator>Aleksandar Veljković</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-147.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p>JSON Web Tokens, or JWT, are the format of JSON encoded data structures for authorizing clients on the Web. Some JWT payloads have a specific standardized structure, defined by the protocol, such as OAuth(2) tokens. Others, however, are designed specifically for particular apps.</p>
<p>Authorization on the Blockchain is done mainly through explicitly whitelisting addresses that are allowed to perform specific actions. Whitelisting introduces high costs when the number of whitelisted addresses is large. A good example is ICO whitelisting, where hundreds or even thousands of participants need to get whitelisted.</p>
<p>This research aims to find an efficient, more cost-effective solution for authorizing users on the Blockchain using a system of authorization tokens issued and received off-chain, without the Blockchain transaction fees, and which will be valid on-chain and off-chain. In addition, the token structure should be transferrable off-chain as a JWT token, compatible with the OAuth2 standard, and reusable in both Web 2.0 and Web 3.0 worlds.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Ethereum Blockhain gas prices are following the price of Ether, resulting in higher transaction fees. The cost of 1 ETH on January 1st, 2019, was $140.82 [1]. On the same day in 2022, the price for 1 ETH was $3,769.70 [2]. That means that the same transaction from 2019 became just three years later became more than 30 times more expensive.</p>
<p>Executing transactions on Blockchain, in general, doesn’t require any specific authorization. The transactions are signed using the private key and paid using ETH from the signer’s wallet. However, some transactions, such are token purchases during ICOs, require explicit approval by the smart contract owner. The approval on the Blockchain is done by whitelisting wallet addresses that are allowed to perform specific actions, submitting the list of the whitelisted wallets, and storing them on the Blockchain. The price of each transaction for storing whitelisted wallets linearly grows by the number of the wallets.</p>
<p>In a more concrete example, storing one 20 byte address on Blockchain, having ETH at the January 1st, 2022 price, costs approximately 20000 GAS or around $5.6, having an average gas price of 74 Gwei. With those prices, storing a hundred whitelisted addresses would cost about $565, with base transaction cost included. It is challenging for technology to expand with such high prices for such basic requirements.</p>
<p>Before introducing the solution this research is proposing, it is essential first to briefly introduce some basic concepts regarding the existing methods for authorization on the Web.</p>
<section id="oauth-standard" class="level2">
<h2 class="anchored" data-anchor-id="oauth-standard">OAuth standard</h2>
<p>Open Authorization, or OAuth for short, is an authorization standard followed by many APIs worldwide. The standard specifies the protocol between client and authorization server and data transferred in protocol messages. There are two versions of OAuth standard, 1 and 2.</p>
<p>OAuth standard doesn’t specify the transfer method for sending messages, but one widely adopted standard is using JWT tokens as the authorization data container.</p>
</section>
<section id="jwt-tokens" class="level2">
<h2 class="anchored" data-anchor-id="jwt-tokens">JWT Tokens</h2>
<p>In 2015, Michael Jones, John Bradley and Nat Sakimura introduced JSON Web Tokens (JWT) through RFC-7519 as a compact structure for representing claims transferred between two parties [3]. Since then, JWTs have been used for client authentication on the Web. Initially, the authentication was performed between APIs but quickly found use in client authentication following the growth of client-heavy applications.</p>
<p>JWT has a general structure, made of a header, body, and signature segments. The header segment includes the token type and a label of the algorithm used for creating signatures.</p>
<p>Example JWT header</p>
<pre><code>{
    "type": "JWT",
    "alg": "ES256"
}</code></pre>
<p>The body segment is a container segment used for storing protocol-specific information. OAuth 2.0 standard, introduced with RFC-6749 [4], specifies several fields required for authorization that are members of the body of a JWT token. Some of those fields are:</p>
<ul>
<li><code>aud</code> (Audience) - Identifier of the user to whom the client will present the token for executing an action</li>
<li><code>exp</code> (Expiration) - Token expiration timestamp</li>
<li><code>iss</code> (Issuer) - Identifier of the token issuer, authorization service provider</li>
<li><code>scope</code> (Action scope) - List of actions for which the token owner would be authorized to perform</li>
<li><code>sub</code> (Subject) - Identifier of the token owner</li>
<li><code>iat</code> (Issued at) - Isusing timestamp</li>
</ul>
<p>Example JWT Body</p>
<pre><code>{
  "sub": "user1",
  "name": "John Doe",
  "iat": 1516239022,
  "aud": "server1",
  "scope": ["data.fetching"]
}</code></pre>
<p>Field <code>name</code> in the JWT body example represents a custom, application-specific data field.</p>
<p>The signature part of the JWT token contains the hash or signature of the token provided by the token issuer.</p>
<p>The three token parts are put together into one base64 encoded string (without trailint <code>=</code> symbols), having the tree parts separated by the dot <code>.</code> symbol.</p>
<p>Example of a complete JWT string</p>
<pre><code>eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ.SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5c</code></pre>
</section>
<section id="general-authorization-protocol" class="level2">
<h2 class="anchored" data-anchor-id="general-authorization-protocol">General Authorization Protocol</h2>
<p>A general protocol for client authorization on the Web using JWT tokens consists of two steps: - Requesting token from the authorization server for executing some action - Presenting the authorization token received from the authorization server to the server which would perform the requested action</p>
</section>
<section id="existing-approaches" class="level2">
<h2 class="anchored" data-anchor-id="existing-approaches">Existing Approaches</h2>
<p>There are some existing approaches for combining the Blockchain and OAuth tokens. In one such research [5], the authors used NFTs as authorization tokens generated on-chain that would be verifiable using the OAuth 2.0 protocol. That approach is inverse to this research: it doesn’t reduce costs but puts authorization tokens on the chain.</p>
</section>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p>The main goal of this research was to find a way to make authorization on the Web cheaper than the existing whitelisting method with the general idea to build a solution analogous to the current, proven methods for authorization on the Web. The key motivation for using tokens as an authorization method is an authorization protocol that shifts significant transaction fees from one authorization entity to many clients that pay only a small additional fee on top of the price they pay for executing the authorized action.</p>
<p>Reducing the price paid by the authorization entity by 100% can be achieved by issuing authorization tokens off-chain. This protocol specification introduces challenges regarding the design of the token, as the token should include all the information that the authorization entity would provide with the Blockchain transaction in the first place.</p>
<p>Reducing the costs of additional fees that clients would now pay for the authorization requires the overhead authorization data submitted on the Blockchain to be as small as possible. This requirement poses the main challenge for token design. Additionally, the Blockchain should not explicitly store authorization data, except as transaction arguments.</p>
<p>Combining these requirements, a perfect authorization schema represents a two-step protocol where the client first acquires the authorization token from the authorization server, off-chain. Second, the client submits the data required for performing the action to the Blockchain with a minor (ideally none) overhead the smart contract would use to confirm the client’s authorization.</p>
<section id="chain-token-ct-representation" class="level2">
<h2 class="anchored" data-anchor-id="chain-token-ct-representation">Chain token (CT) representation</h2>
<p>The essential requirements for the token that would be used on the chain are: - Efficient verifiability; token should be efficiently verifiable on the chain - Authenticity; the probability of token forgery should be negligible - Succinctness; token should be small in byte size - Non-transferability; token should be used only by the user who received the token</p>
<p>As an example throughout this research, we will use the money checkout allowance problem, where a client needs to be authorized to payout a certain amount of money from the account of the authorizing entity. An existing approach for solving this problem is calling the approval method on the smart contract or whitelisting clients and explicitly approving the total allowed amount for each client. Method signature without a token argument would look like this:</p>
<pre><code>payout(address account, address receiver, uint256 amount)</code></pre>
<p>A naive approach for constructing a token that would follow JWT logic would be providing all the values bound by the token. In our example, the values that are required for money checkout from the account are: - account owner identifier; 20 bytes address value - authorized client identifier; 20 bytes address value - allowed amount; 32 bytes value</p>
<p>Next, the apparent problem is a forgery. Everyone can create a token with listed values and submit it on the Blockchain. The solution for this problem is to provide a signature made by the authorization entity, which confirms the provided values. Ethereum signatures contain three segments, v, r, and s, 65 bytes long. All summed up to 137 bytes of memory. Even if this doesn’t look like a significant sum, the main issue is that the token size asymptotically grows by <img src="https://latex.codecogs.com/png.latex?O(n)">, linearly with the number of arguments n.&nbsp;In other words, it would become costly, or even unusable, for methods with more arguments. It is not very efficient, but it is a start.</p>
<section id="token-size-optimization" class="level3">
<h3 class="anchored" data-anchor-id="token-size-optimization">Token size optimization</h3>
<p>The problem with the naive approach is linear growth with the number of arguments. Solving this problem requires looking closely at the method that is being called. The method <code>payout</code> already contains the token values as a method argument, and it would be redundant to provide them again in the token. The same pattern is visible with different use-cases. This observation suggests that we can avoid providing the values within the token but use only a hash of the approved values and check if the hash of the provided input values matches the token hash. Using the hashing method clears the linear growth of the token as the size of the keccak256 hash is fixed to 32 bytes in length, achieving a constant <img src="https://latex.codecogs.com/png.latex?O(1)"> size of the token. The hash can also cover other values that could be hard-coded into the smart contract without a token size increase, which will become an essential feature in later sections.</p>
</section>
<section id="signature-size-optimization" class="level3">
<h3 class="anchored" data-anchor-id="signature-size-optimization">Signature size optimization</h3>
<p>The Ethereum signature size is fixed to 65 bytes. That means that it passes the size of 2 memory words (32 bytes in size) and requires three blocks of memory. The solution for this problem comes with EIP-2098 [6], which proposes a simple technique for compact signature representation, reducing its size by 1 byte and allowing it to fit into two memory blocks.</p>
<p>The total token size is now fixed to 32 bytes of token hash plus another 64 bytes of signature data totaling 96 bytes or three blocks of memory.</p>
</section>
<section id="mapping-oauth2.0-parameters" class="level3">
<h3 class="anchored" data-anchor-id="mapping-oauth2.0-parameters">Mapping OAuth2.0 parameters</h3>
<p>Now that we have a token structure, we need to figure out how to standardize token parameters to comply with the OAuth2.0 standard.</p>
<p>The audience parameter refers to the smart contract containing the payout method. It doesn’t need to be provided explicitly as a method argument as it is already encoded in the smart contract.</p>
<p>The token issuer can be deduced from the signature and doesn’t need to be explicitly provided.</p>
<p>The subject parameter is provided both as the input argument of the <code>payout</code> method. It doesn’t have to be provided explicitly. It should not be provided even as the argument, as it is already given as the message sender value.</p>
<p>The scope parameter describes the action that should be executed. It should not be explicitly provided as it should be hardcoded in the method.</p>
<p>The token expiration time is a tricky one. It doesn’t naturally belong to method arguments, so it should be provided explicitly. To prevent the token size increase, we can do a simple modification of the token hash. The value of the timestamp can be stored in 8 bytes. A straightforward solution is to provide another method argument with an 8-byte value. A more elegant solution is to transform the keccak256 value into “pseudo-keccak224” (SHA224 [7] value, with unchanged initialization value) by truncating the hash size to its 224 bytes prefix and appending 8 bytes extension with expiration timestamp as the last 8 bytes of the token hash. This transformation returns us to the previously proposed token size without extra arguments.</p>
<p>As we can see, all the crucial parameters of the OAuth2.0 protocol can be successfully mapped to the Blockchain transactions and the chain token.</p>
</section>
</section>
<section id="token-reusability" class="level2">
<h2 class="anchored" data-anchor-id="token-reusability">Token reusability</h2>
<p>Some authorization tokens are reusable many times until the expiration date. However, some use-cases require that the tokens may be used only once. An example of such a use case is exactly the example we have used so far. Once the payout method has been executed, the user should not be able to perform double-payout transactions. This problem can be solved the same way as in Web 2.0 - by introducing a payment identifier. The payment identifier should be included as an extra method argument and included in the token hash. This solution also solves the issue of the lost token, as the token can be reissued with the same payment identifier and used for the same payment only once. Specific use cases may require the existence of only one token. In that case, the token (and method arguments) may include <code>jti</code> parameter or JWT token ID as a token identifier or use the token hash as an identifier. The smart contract should implement mechanisms for preventing double payments and a potential blacklisting of tokens.</p>
</section>
<section id="action-scope-schemas" class="level2">
<h2 class="anchored" data-anchor-id="action-scope-schemas">Action scope schemas</h2>
<p>OAuth2.0 proposes a parameter that includes the action scope or label of the action for which the client can use the token. Action scopes are not specified as they can be represented using any string value. The problem here is the cost of using string data types in smart contracts. This research proposes restriction for action type values to numerical data types of 4 bytes. This restriction allows <img src="https://latex.codecogs.com/png.latex?2%5E32"> possible scope values that could represent many use cases.</p>
<p>A library of token schemas can help developers properly format their tokens based on scope number schemas. Furthermore, enumeration of action types can introduce standardization for tokens where a smart contract may require, for example, “scope 42” tokens for executing a method. We present the first two token scopes that would be used in the following use-cases:</p>
<section id="scope-1-generic-identity" class="level3">
<h3 class="anchored" data-anchor-id="scope-1-generic-identity">Scope 1: Generic Identity</h3>
<p>Generic identity scope should be used for verification of the client’s identity. The verification is based on the client’s wallet address and unique identifier in the issuer’s database. The hash for “scope 1” tokens be made by hashing the following array of values in their respective order: - <code>address iss</code>; token issuer <code>address aud</code>; smart contract address or 0 address for general identification - <code>address sub</code>; client’s wallet address - <code>uint4 scope</code>; action scope with value <code>1</code> for generic identification - <code>bytes32 uuid</code>; unique identifier of the client in the issuer’s - <code>uint8 exp</code>; token expiration timestamp in UNIX timestamp format database ### Scope 2: Allowance Allowance tokens, used for crypto cheques, should have hashes made by hashing the following array of values in their respective order: - <code>address iss</code>; token issuer - <code>address aud</code>; smart contract address - <code>address sub</code>; money receiver - <code>uint4 scope</code>; action scope with value <code>2</code> for allowance - <code>bytes32 paymentId</code>; payment identifier (NOTE: token hash may be used as payment ID but it can introduce new problems) - <code>uint256 amount</code>; amount to transfer - <code>uint8 exp</code>; token expiration timestamp in UNIX timestamp format</p>
<p>The reader may notice that in both cases, there are two logical groups of parameters: - general parameters; <code>iss</code>, <code>aud</code>, sub<code>,</code>scope<code>and</code>exp<code>- application-specific parameters;</code>userId<code>,</code>paymentId<code>,</code>amount`</p>
<p>The general parameters are the same for all tokens, and application-specific parameters are different for each scope.</p>
</section>
</section>
<section id="from-chain-token-ct-to-omni-web-token-owt" class="level2">
<h2 class="anchored" data-anchor-id="from-chain-token-ct-to-omni-web-token-owt">From Chain Token (CT) to Omni Web Token (OWT)</h2>
<p>Now that we have the complete definition of the chain token, we can go one more step and make it usable and transferrable in the Web 2.0 world. We can do this by packing chain token data as part of theJWT token, following the OAuth 2.0 schema.</p>
<section id="owt-body" class="level3">
<h3 class="anchored" data-anchor-id="owt-body">OWT Body</h3>
<p>The token scopes define OAuth 2.0 parameters, so the only remaining thing is appropriately packing the chain token into the JWT body and creating a proper JWT signature. The verifier needs to know the CT hash value and the parameters used in the construction of the token.</p>
<p>The proposed OWT body schema is:</p>
<pre><code>{
    aud: &lt;smart contract address&gt;,
    iss: &lt;issuer's wallet address&gt;,
    scope: &lt;readable name of the scope&gt;,
    exp: &lt;token expiration timestamp&gt;
    chain_token: {
        token_hash: &lt;CT hash with expiration timestamp&gt;,
    r: &lt;signature r value&gt;,
    sv: &lt;compact representation of s and v signature values&gt;
        params: [&lt;
                ordered list of token parameters
                in form of:
                 {
                    param: &lt;parameter name&gt;,
                    value: &lt;parameter value&gt;,
                    type: &lt;parameter data type&gt;,
                 }
            &gt;]
    }
}</code></pre>
</section>
<section id="owt-signature" class="level3">
<h3 class="anchored" data-anchor-id="owt-signature">OWT Signature</h3>
<p>The JWT standard allows using the Ethereum secp256k1 signatures by providing the <code>EC256</code> algorithm type value in the token header. The signature of the OWT token is created using the issuer’s private key. To verify the signature, the verifier needs access to the issuer’s public key, which should be available from the issuer’s <code>/.well-known/jwks.json</code> route of the authorization API.</p>
</section>
</section>
<section id="owt-issuing" class="level2">
<h2 class="anchored" data-anchor-id="owt-issuing">OWT Issuing</h2>
<p>The OAuth 2.0 protocol allows using <code>client id</code> and <code>client secret</code> parameters when requesting the authorization tokens. OWT requests can be made using wallet address as client’s identity and signature of the clients wallet address as the <code>client secret</code> parameter</p>
</section>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<p>To test our hypothesis and estimate the costs of working with OWTs, a simple NodeJS library for generating and verifying OWTs was implemented together with testing REST API for issuing OWTs following the OAuth 2.0 protocol. An example smart contract for testing the usability of the chain token was also implemented.</p>
<p>The smart contract used for testing included four methods: - <code>whitelist(address client, uint256 amount)</code> method for whitelisting the user for a given amount of money - <code>payoutOld(uint256 amount)</code> method for performing payout in the old fashioned way by checking the whitelisted amount - <code>payoutNew(address sender, uint256 amount, bytes32 paymentId, bytes32[3] calldata token)</code> method for performing payout using the chain token following “scope 2” schema - <code>payoutNewShort(address sender, uint256 amount, bytes32[3] calldata token)</code> method for performing payout using the chain token but without payment identifier, having token hash as a payment identifier - <code>verifyIdentity(address issuer, bytes32 userId, bytes32[3] calldata token)</code> method for simple verification of the client’s identity following “scope 1” schema</p>
<section id="allowance-use-case" class="level2">
<h2 class="anchored" data-anchor-id="allowance-use-case">Allowance Use Case</h2>
<p>The allowance use case tested the token issuing protocol for payout allowances, evaluated the costs of performing payouts using the token, and compared the results with the basic whitelisting protocol.</p>
<section id="test-setup" class="level3">
<h3 class="anchored" data-anchor-id="test-setup">Test setup</h3>
<p>Authorization entity submitted allowance amount for the client using the <code>whitelist</code> smart contract method. The cost of the whitelisting transaction was 44,484 gas.</p>
</section>
<section id="test-1-payout-by-whitelisting" class="level3">
<h3 class="anchored" data-anchor-id="test-1-payout-by-whitelisting">Test 1: Payout by Whitelisting</h3>
<p>The client executed the <code>payoutOld</code> method of the smart contract with a propper allowance amount. The cost of the payout transaction was 22,389 + T gas.</p>
</section>
<section id="test-2-payout-with-token" class="level3">
<h3 class="anchored" data-anchor-id="test-2-payout-with-token">Test 2: Payout with Token</h3>
<p>The client requested an OWT from the authorization server using OAuth 2.0 request schema. The authorization server verified the client’s credentials and issued a “scope 2” token to the client with a specified allowance amount. The client verified the OWT data and extracted the chain token and its parameters from the OWT. After the OWT verification step, the client submitted them to the smart contract using the <code>payoutNew</code> method. The payout was successful, and the execution cost was 59,935 + T gas.</p>
</section>
<section id="test-3-payout-with-token-using-token-hash-as-payment-identifier" class="level3">
<h3 class="anchored" data-anchor-id="test-3-payout-with-token-using-token-hash-as-payment-identifier">Test 3: Payout with Token using Token Hash as Payment Identifier</h3>
<p>The protocol for issuing and verifying the OWT was done the same way as in the previous test. The only difference was that the token did not follow the “scope 2” schema but left out the payment identifier. The client performed a payout using the <code>payoutNewShort</code> method. Again, the payout was successful, and the execution cost was 59,189 + T gas.</p>
</section>
<section id="cost-analysis" class="level3">
<h3 class="anchored" data-anchor-id="cost-analysis">Cost Analysis</h3>
The test results show that the cost of the payout protocol using whitelisting was 44,484 gas for the issuer and 22,389 gas for the client, resulting in 66,873 gas for the entire protocol. Test 2 showed that using the token has reduced the issuer’s costs to 0, but the client’s cost was increased to 59,935 gas which is 37,546 gas more than in test 1. Interestingly, the overhead cost for the client is lower than the costs of the issuer’s whitelisting, which indicates that using the token reduces the issuer’s fees, compared to whitelisting, even if the issuer compensates the overhead client’s costs by increasing the allowance amount. Test 3 showed that using token hash as payment identifier reduces the costs for extra 746 gas. However, this introduces problems with token reissuing. The exact token needs to be reissued every time the original one gets lost, requiring the expiration timestamp to be the same as the original one for the hashes to match and thus have the same payment identifier. This situation can cause the issuer to be unable to reissue the token as its timestamp has already expired. The results of the cost analysis are presented in Table 1. <br><br>

<table>
<tbody><tr>
<th>
Method
</th>
<th>
Issuer’s costs (gas)
</th>
<th>
Client’s costs (gas)
</th>
<th>
Total protocol costs (gas)
</th>
</tr>
<tr>
<th>
Whitelisting
</th>
<th>
44,484
</th>
<th>
22,389
</th>
<th>
66,873
</th>
</tr>
<tr>
<th>
OWT allowance
</th>
<th>
0
</th>
<th>
59,935
</th>
<th>
59,935
</th>
</tr>
<tr>
<th>
Short OWT allowance
</th>
<th>
0
</th>
<th>
59,189
</th>
<th>
59,189
</th>
</tr>

</tbody></table>
<center>
Table 1. Cost anlysis of the allowance use case methods
</center>
<p><br><br></p>
</section>
</section>
<section id="generic-identity-use-case" class="level2">
<h2 class="anchored" data-anchor-id="generic-identity-use-case">Generic Identity Use Case</h2>
<p>The generic identity use case tested the issuing and verification of the “scope 1” tokens and assessed the costs of using identification tokens on the chain.</p>
<p>The client acquired OWT from the authorization server and submitted the token with the received user id from the issuer’s database. The client submitted the token to the <code>verifyIdentity</code> method of the smart contract and successfully verified the identity token. The cost of the verification was 36,816 gas, which suggests that the verification proces cost was 15,817 gas, leaving out the base transaction cost.</p>
<section id="use-case-analysis" class="level3">
<h3 class="anchored" data-anchor-id="use-case-analysis">Use case analysis</h3>
<p>The test showed that the costs for verifying the identity tokens are low and open a new path for the identity representations valid on multiple chains. Additional use cases may specify scope schemas for more specific identity tokens and introduce low-cost decentralized identities to a multi-chain environment.</p>
</section>
</section>
<section id="general-purpose-token-verification-service-gptvs" class="level2">
<h2 class="anchored" data-anchor-id="general-purpose-token-verification-service-gptvs">General Purpose Token Verification Service (GPTVS)</h2>
<p>The entire verification protocol can be summed up into a token verification smart contract that can be deployed and used by multiple users to verify the authorization tokens for their smart contracts. Blacklisting can be introduced for tokens or clients. This service should allow listing approved issuers and smart contract addresses from which the requests may come. Also, the service can be monetized by requiring a certain amount of Ethers or ERC-20 tokens to be submitted monthly by the users to the verification smart contract, or the service will become unavailable for the requests coming from the user’s smart contracts.</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>The test results show that the OWTs and the chain tokens can cover a variety of use cases while introducing standardization in token construction, issuing, and verification. Operating with OWTs reduces costs for the services requiring whitelisting while enabling new multi-chain use cases thanks to a succinct yet general token structure and easy verification. The following steps would include defining more token schemas covering miscellaneous use cases and implementing the General Purpose Token Verification Service.</p>
</section>
<section id="appendices" class="level1">
<h1>Appendices</h1>
<section id="appendix-1-chain-token-verification-smart-contract" class="level2">
<h2 class="anchored" data-anchor-id="appendix-1-chain-token-verification-smart-contract">Appendix 1: Chain token verification smart contract</h2>
<pre class="solidity"><code>// SPDX-License-Identifier: GPL-3.0
pragma solidity &gt;=0.7.0 &lt;0.9.0;

contract VerifierContract {
        mapping(address =&gt; uint256) whitelisted;
        mapping(bytes32 =&gt; bool ) usedPaymentIds;
        bytes prefix = "\x19Ethereum Signed Message:\n32";
        uint32 genericIdentityScope = 1;
        uint32 payoutScope = 2;

        function checkSignature(bytes32[3] calldata token, address signer) public returns (bool) {
                // Decode r, s, v values
                bytes32 hash = token[0];
                bytes32 sv = token[2];
                bytes32 r = token[1];
                bytes32 s = sv &amp; bytes32((uint((1 &lt;&lt; 255) - 1)));
                uint8 v = uint8(uint(sv &gt;&gt; 255) + 27);

                // Create signature hash
                bytes32 prefixedProof = keccak256(abi.encodePacked(prefix, hash));

                // Verify signer
                address recovered = ecrecover(prefixedProof, v, r, s);
                return recovered == signer;
        }
        
        function whitelist(address client, uint256 amount) public {
                whitelisted[client] = amount;
        }

        function payoutOld(uint256 amount) public {
                require(amount &lt;= (whitelisted[msg.sender]));
                whitelisted[msg.sender] -= amount;
        }

        function payoutNew(address sender, uint256 amount, bytes32 paymentId, bytes32[3] calldata token) public{
                // Check if token has already been used
                require(usedPaymentIds[paymentId] == false);

                // Check token expiration
                uint32 exp = uint32(uint256(token[0]));
                require(exp &gt; block.timestamp, "Token expired");

                // Check token signature
                require(this.checkSignature(token, sender) == true, "Invalid signature");

                // Check token values
                bytes32 prefixedProof = keccak256(abi.encodePacked(sender, address(this), msg.sender, payoutScope, exp, paymentId, amount));
                require (bytes32((uint256(prefixedProof &gt;&gt; 32 &lt;&lt; 32) | uint256(exp))) == token[0]);

                usedPaymentIds[paymentId] = true;
        }

        function payoutNewShort(address sender, uint256 amount, bytes32[3] calldata token) public{
                // Check if token has already been used
                require(usedPaymentIds[token[0]] == false);

                // Check token expiration
                uint32 exp = uint32(uint256(token[0]));
                require(exp &gt; block.timestamp);

                // Check token signature
                require(this.checkSignature(token, sender) == true);

                // Check token values
                bytes32 prefixedProof = keccak256(abi.encodePacked(sender, address(this), msg.sender, payoutScope, exp, amount));
                require (bytes32((uint256(prefixedProof &gt;&gt; 32 &lt;&lt; 32) | uint256(exp))) == token[0]);

                usedPaymentIds[token[0]] = true;
        }

        function verifyIdentity(address issuer, bytes32 userId, bytes32[3] calldata token) public {
                // Check token expiration
                uint32 exp = uint32(uint256(token[0]));
                require(exp &gt; block.timestamp);

                // Check token signature
                require(this.checkSignature(token, issuer) == true);

                // Check token values
                bytes32 prefixedProof = keccak256(abi.encodePacked(issuer, address(this), msg.sender, genericIdentityScope, exp, userId));
                require (bytes32((uint256(prefixedProof &gt;&gt; 32 &lt;&lt; 32) | uint256(exp))) == token[0]);
        }
}</code></pre>
</section>
</section>
<section id="bibliography" class="level1">
<h1>Bibliography</h1>

<ol type="1">
<li><p>Coinmarketcap, Historical snapshot from 2019/01/01, https://coinmarketcap.com/historical/20190101/</p></li>
<li><p>Coinmarketcap, Historical snapshot from 2022/01/01, https://coinmarketcap.com/historical/20220101/</p></li>
<li><p>M. Jones, J. Bradley, N. Sakimura, RFC-7519: JSON Web Token (JWT), https://datatracker.ietf.org/doc/html/rfc7519</p></li>
<li><p>D. Hardt, Ed., RFC-6749: The OAuth 2.0 Authorization Framework, https://datatracker.ietf.org/doc/html/rfc6749</p></li>
<li><p>N. Fotiou, I. Pittaras, V. A. Siris, S. Voulgaris, G. C. Polyzosar, OAuth 2.0 authorization using blockchain-based tokens, arXiv:2001.10461v1, 28 Jan 2020, https://arxiv.org/pdf/2001.10461.pdf</p></li>
<li><p>R Moore, N Johnson, EIP-2098: Compact Signature Representation, https://eips.ethereum.org/EIPS/eip-2098</p></li>
<li><p>R. Housley, RFC-3874: A 224-bit One-way Hash Function: SHA-224, https://datatracker.ietf.org/doc/html/rfc3874</p></li>
</ol>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs">

</div></section></div> ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-147.hugo.html</guid>
  <pubDate>Wed, 06 Apr 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Blacklisting Platform based on untransferable NFTs</title>
  <dc:creator>Aleksandar Damjanovic</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-154.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p>The main topic of this research is exploring the possibility and the need to create the “Authority” protocol that would handle blacklisting based on community voting and assessment. This protocol would mint the untransferable NFT to the blacklisted address. Creating this solutions (both the platform and the NFT) would not be challenging but the need for these solutions is questionable to the author. This paper explored the current blacklist cases and the possibility of creating the said NFTs. The Tether case is in the main focus since the solutions are similar and simple. The main takeaway is that creating this solution is not necessary per se, but the issue is open for discussion.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>When it comes to Web3, security breaches, hacks and malicious behaviour are a big issue. That is why some protocols resort to blacklisting the addressses they deem malicious. Blacklisting is essentially putting the addresses that have engaged in unethical or unacceptable activities on a list which in turn would limit their usage of said protocols.<sup>1</sup></p>
<p>Initial idea for this research is to explore the possibility of creating a platform that would blacklist addresses and send them an untransferable NFT. This platform would take it upon itself to take care of blacklisting for other protocols and users. The cases would be reported and voted on i.e Nexus Mutual model (for more info on their voting model check ERFC-91). When it comes to problems that this solution would solve the main problem is taking care of blacklisting for other protocols, this in turn makes our solution (even with voting) a point of centralization but more on that in later paragraphs.</p>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p>The goal of this research is to explore how was blacklisting taken care of so far and to explore the possibility and need of creating a protocol that would do this with utilizing untransferable NFTs. Untransferable NFTs have been a topic of interest in the field for a while, otherwise there is no explicit point of including them except for “flagging” the addresses for the world to see.</p>
<p>This will be done by examining the source code of protocols that have done blacklisting in the past. After the examination we will draw some conclusions.</p>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<section id="blacklisting" class="level2">
<h2 class="anchored" data-anchor-id="blacklisting">Blacklisting</h2>
<p>As we pointed above we did a deep-dive into contracts that utilize blacklisting. In the beginning of the research we have searched for contracts that previously used blacklisting and we have come across the Tether case as it is the biggest one. There are various contracts that use the blacklist contracts but it is the exact same approach. When it comes to individual sites and addresses MetaMask already blocks sites that are known to steal funds.<sup>2</sup></p>
<p>Stablecoin issuer Tether froze the ethereum <a href="https://etherscan.io/tx/0x60891b856cdae4fd0878d45d2768e640be2dc2a50876d20138797a09877a7cd6#eventlog">address</a> holding over $715,000 worth of USDT. This address is the address of hackers who stole $3 million on the Multichain bridge. This means that they cannot move the funds.</p>
<ul>
<li>The question here is how did Tether manage to do that?</li>
</ul>
<p>They managed that by importing the Blacklist contract in their main contract. We will try to explain the contract in the code-box comments below:</p>
<pre><code>contract BlackList is Ownable, BasicToken {

    // Getters to allow the same blacklist to be used also by other contracts.(including upgraded Tether) 
    function getBlackListStatus(address _maker) external constant returns (bool) {
        return isBlackListed[_maker];
    }

    // Returns the owner of the contract address.
    function getOwner() external constant returns (address) {
        return owner;
    }

    // Puts the blacklisted addresses in the mapping for checking and later use.
    mapping (address =&gt; bool) public isBlackListed;

    // Self explanatory, adds the address to the isBlacklisted mapping. Only owner of the contract can call the function
    function addBlackList (address _evilUser) public onlyOwner {
        isBlackListed[_evilUser] = true;
        AddedBlackList(_evilUser);
    }

    // Removes the address from the blacklist and "unfreezes the assets". Only owner of the contract can call the function.
    function removeBlackList (address _clearedUser) public onlyOwner {
        isBlackListed[_clearedUser] = false;
        RemovedBlackList(_clearedUser);
    }

    // Destroys the funds of the blacklisted address and reduces the total suply by the same amount. Only owner of the contract can call this function.
    function destroyBlackFunds (address _blackListedUser) public onlyOwner {
        require(isBlackListed[_blackListedUser]);
        uint dirtyFunds = balanceOf(_blackListedUser);
        balances[_blackListedUser] = 0;
        _totalSupply -= dirtyFunds;
        DestroyedBlackFunds(_blackListedUser, dirtyFunds);
    }
    // Simple events for transaction logs.
    event DestroyedBlackFunds(address _blackListedUser, uint _balance);

    event AddedBlackList(address _user);

    event RemovedBlackList(address _user);

}</code></pre>
<p>Then they simply put the require statement in all their main contract functions(except for the ones with the “Only Owner modifier”) for example:</p>
<pre><code>// Require statement above makes sure the blacklisted address can't access the function.
function transferFrom(address _from, address _to, uint _value) public whenNotPaused {
        require(!isBlackListed[_from]);
        if (deprecated) {
            return UpgradedStandardToken(upgradedAddress).transferFromByLegacy(msg.sender, _from, _to, _value);
        } else {
            return super.transferFrom(_from, _to, _value);
        }
    }</code></pre>
<p>This approach to blacklisting gives the Tether the absolute control in what addresses it blacklists and for how long.</p>
<p>As we can see in the getBlacklistStatus the other contracts can use the same Blacklist to limit their usage as Tether thus leaning on their decision making.</p>
<p>In theory a blacklist protocol can be created where the voting what address to blacklist could be done by the community. The said addresses would be stored in the contract and those addresses could be whitelisted by voting again. Then, other contracts could lean on the “list” and block the addresses from using their functions. This would also make our solution the major point of centralization and considering how easy it is to set up blacklisting individually this proposes a question is the such solution needed?</p>
<p>Implementing a separate blacklist functions is not challenging and any contract can include them and have the complete control in what addresses it freezes and for how long.</p>
</section>
<section id="untransferable-nfts" class="level2">
<h2 class="anchored" data-anchor-id="untransferable-nfts">Untransferable NFTs</h2>
<p>Untrasferable NFTs have been a topic of interest for a while in Web3 and there are various use cases that have been explored. Such as:</p>
<ul>
<li>identity</li>
<li>badges</li>
<li>achievements, etc</li>
</ul>
<p>Vitalik Buterin in his blog post showed his interest in “soulbound NFTs”. If we want these NFTs to be truly soulbound (untrasferable) we would need to block transferability thus limiting them to only one address. When it comes to badges and achievements there are already POAPs. POAP has made the decision not to block transferability of POAPs themselves since the owners might want to change addresses and migrate assets for various reasons. There are various cases where they have been sold or even given out for free and after that sold for the highest bidder.<sup>3</sup></p>
<p>When it comes to creating a “soulbound NFT” we think that it is possible and that it can be done by modifying the transfer function from the ERC-721 standard.</p>
<p>The main issue here is utilizing them in the Blacklisting sense, the mint function from the ERC-721 interface can be included in the addBlacklist() function which would mint the said token to the said address. But so far we haven’t come to the use-case except for “flagging” the addresses for the world to see, so it seems unnecessary at the moment.</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>When exploring blacklisting we have come to conclusion that it is already implemented in some contracts and that creating a protocol that marks the “malicious” addresses is possible. The untransferable NFTs are possible to create also. The main question here is are those solutions needed? Creating a protocol that others can lean on can be useful but it would also be a major point of centralization and a lot of effort for a feature that simple. Not to mention including untransferable NFTs in the process which at this stage of the research seem unnecessary. What if the address is removed from the blacklist for various reasons does the NFT stay?</p>
</section>
<section id="bibliography" class="level1">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Bibliography</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Soulbound" class="csl-entry">
‘Soulbound’ &lt;<a href="https://vitalik.ca/general/2022/01/26/soulbound.html" class="uri">https://vitalik.ca/general/2022/01/26/soulbound.html</a>&gt; [accessed 12 April 2022]
</div>
<div id="ref-WhatBlacklist" class="csl-entry">
‘What Is a Blacklist?’, <em>Investopedia</em> &lt;<a href="https://www.investopedia.com/terms/b/blacklist.asp" class="uri">https://www.investopedia.com/terms/b/blacklist.asp</a>&gt; [accessed 12 April 2022]
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>‘What Is a Blacklist?’, <em>Investopedia</em> &lt;&lt;https://www.investopedia.com/terms/b/blacklist.asp&gt;&gt; [accessed 12 April 2022].↩︎</p></li>
<li id="fn2"><p><strong>metamaskmetamaskMetaMaskAutomaticallyBlocks2018?</strong>↩︎</p></li>
<li id="fn3"><p>‘Soulbound’ &lt;&lt;https://vitalik.ca/general/2022/01/26/soulbound.html&gt;&gt; [accessed 12 April 2022].↩︎</p></li>
</ol>
</section></div> ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-154.hugo.html</guid>
  <pubDate>Thu, 31 Mar 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>NFT that is bound by time</title>
  <dc:creator>Marija Mijailovic</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-101.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p>NFTs have a unique ID and belong to a single wallet. Two standards define what an NFT is and should do: ERC721 and ERC1155, aiming to distinguish each token to be unique. The development of NFT is still in the early stage, and this research shows how NFTs can change their properties. We go through some existing solutions where some events fundamentally affect the NFT, changing its state, properties, or value. We give an overview of those solutions with a desire to cover how they work under the hood and notice potential problems. In the end, are presented possible use cases that open a new door into the NFT word.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>NFTs (Non-Fungible Tokens) reached incredible popularity in 2021 Ryan Browne<sup>1</sup>. Most of created NFTs are static. We collect it, and we hope its market value will increase. In the case of <em>static</em> NFT, it’s characteristic that its properties and data are immutable and recorded on the blockchain, so such NFTs can’t be changed. Otherwise, there are <em>dynamic</em> NFT for which it’s characteristic that properties and data are mutable, often through oracles that trigger events off-chain system or by interaction with on-chain components, for example, smart contracts other NFTs.</p>
<blockquote class="blockquote">
<p>“Dynamic NFTs are the logical next step for the NFT space, allowing unique items to evolve, and sometimes decay. This replicates the ephemeral nature of the real world and potentially gives exceptional value to a collected item because of its current state. NFTs transitioning from being ‘only’ static to being dynamic can be thought of as progressing from 2D to 3D, it enables an immense possibility of use cases.” — Adrien Berthou, Head of Crypto-Native Comms at DoinGud</p>
</blockquote>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p>The goals of this research:</p>
<ul>
<li>Introduce with dynamic NFT</li>
<li>Search for project that make evolvable NFTs</li>
<li>Research how they work, find some leak</li>
<li>Suggest improvements</li>
</ul>
<p>Methodology for accomplishing those goals:</p>
<ul>
<li>Getting under the hood of open source solutions</li>
<li>Testing existing approach</li>
<li>Solidity</li>
</ul>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<p>First of all, let’s briefly review some existing projects:</p>
<ul>
<li><a href="https://ether.cards/">EtherCards</a>
<ul>
<li>EtherCards is a dynamic NFT platform that allows anyone to give a base set of traits and requirements and launch their NFT collection so that the EtherCards team can create unique NFTs. Traits can be discounts, special access rights, connections to real-world events, airdrops, upgrades, and other benefits. The ability to have traits allows the creator to maximize the value of their art. Ether Cards is an integrated ecosystem composed of two major parts. Those are the platform and the Ether Cards (an advanced membership NFT card). Anybody can use the EtherCards platform, but the owner of the EtherCards card has certain privileges. Under the hood, EtherCards integrate Chainlink VRF to provide verifiable randomness on-chain. Chainlink allows developers to read data from any external API and blockchain network and perform off-chain computation. That will enable NFTs to be connected to the external world to trigger real-world events, in a word, to be dynamic.</li>
<li>EtherCards have supported and worked with <a href="https://blog.ether.cards/lamelo-ball-nft/">LaMelo Ball</a>, <a href="https://nfttyson.com/">Mike Tyson</a>, <a href="https://blog.ether.cards/steve-aoki-partners-with-ether-cards-to-produce-new-animated-nft-collection-dominion-x/">Steve Aoki</a> and <a href="https://blog.ether.cards/artist-profile-dirty-robot/">DirtyRobot</a>. In the above collections, all NFTs metadata are stored <code>https://client-metadata.ether.cards</code> on the central server. Within that metadata is a link that points to NFTs image on IPFS. So, inside the smart contract, we store points to metadata JSON URIs to all variants of one NFT. Later, inside <code>tokenURI</code> function with the support of Chainlink return dynamically created URI of NFT, only one variant.</li>
</ul></li>
<li><a href="https://www.loopheads.info/">Loopheads</a>
<ul>
<li>Loopheads is a Loopring ‘Loopring - <span class="nocase">zkRollup Layer2</span> for Trading and Payment’<sup>2</sup> <em>Moody Brains</em> NFT collection, minted on Looprings Layer 2. There are 25 variants for one Loophead avatar(5 different backgrounds and 5 different brain sizes), which one will be displayed depending on the LRC token price using Uniswap Oracles.</li>
<li>All NFT metadata are stored on decentralized storage - IPFS, within that metadata, is a link that sends to NFT’s image on IPFS. So, inside the smart contract, we store points to metadata JSON URIs to all of the Loophead’s variations. When a Loophead NFT is accessed because Loopheads use ERC1155 standard, the Loophead NFT runs the <code>uri</code> function, the start point of dynamic calculation, to show the loophead avatar. The calculation is done with the support of Uniswwap V3 Oracles. That changes parts of the metadata link based on LRC price and returns only one variant.</li>
</ul></li>
<li><a href="https://docs.uniswap.org/protocol/reference/periphery/libraries/NFTDescriptor">Uniswap LP NFT</a>
<ul>
<li>On Uniswap V3 liquidity provider(LP) position is represented as NFT. This NFT shows information about liquidity position. Based on the pool and your parameters selected on the liquidity providing interface. The unique NFT will be minted, representing your position in that specific pool. As the owner of this NFT, you can modify or save the position. The best part of this project is that NFT is SVG generated entirely on-chain. Because of that, it is secure as an image not rely on any other service that is not on the blockchain, and it affects the price of that NFT.</li>
<li>All liquidity parameters for NFT are stored on-chain. Interesting is that SVG generation is done inside a pure function, and it returns base64 encoded metadata from the view function.</li>
<li>When a Uniswap V3 LP NFT is accessed because it uses the ERC721 standard, it runs the <code>tokenURI</code> function, which is the start point that generates SVG from liquidity parameters and returns base64 encoded metadata.</li>
</ul></li>
<li><a href="https://www.aavegotchi.com/">Aavegotchi</a>
<ul>
<li>Aavegotchi is a crypto collectible game. It was developed to provide users with a new blockchain-based game powered by dynamic NFTs. Aavegotchi information such as Aavegotchi name, traits, and SVG files themselves are saved as contract calldata because it is less gas cost than store in contract storage. The fundamental element of Aavegotchi’s game is randomness. Because of that, they use Chainlink VRF. The main idea behind the game is that the more you love your Aavegotchi character, the more rewards it will give you.</li>
<li>To store SVG, we pass one or more SVG images as a string, along with the information of SVG category type(aavegotchi, collaterals, eyeShapes, wearables) and size of passed SVG images. So inside <code>tokenURI</code> we have all NFTs prepared to return only one determined based on real-life events.</li>
</ul></li>
</ul>
<p>You can quickly determine where your NFT is by calling the <code>tokenURI</code> or <code>uri</code> function on the contract, which returns a URI that points to metadata that shows where NFT lives. Above project for NFT storage use:</p>
<ul>
<li>Centralized server</li>
<li>Decentralized storage (IPFS, Filecoin, Arweave)</li>
<li>On-chain storage</li>
</ul>
<p>The problem with the central server is that the possibility for manipulation is vast. The server owner can change the JSON scheme of your NFT whenever he wants.</p>
<p>The problem with IPFS is that there is no defined way of data replication. It just happens depending on the relevance of the content. In addition, the IPFS node can become offline. The problem is that if the relevance of our data is minor, the bigger is chance to lose data. To resolve the issue, Filecoin and Arweave come into play. Filecoin is a solution where we pay some price to store data for a set time. The problem is that we are limited by time, so our data are not stored permanently. Arweave is a solution that incentivizes the nodes to hold data permanently by paying only one fee in the Arweave token and keeping data forever. The most significant leak here is that it all comes down to having one storage layer that is separate from the blockchain and from the NFT itself on which it is located.</p>
<p>When it comes to on-chain storage, the SVG is scalable because it does not rely on pixels to display the image. SVG is used for vector graphics where we can describe shapes and lines mathematically. But, if we want to present a more complex image in this format, we get a massive SVG file, which will lead to a considerable gas cost. Additionally, the worth of mention is <a href="https://eips.ethereum.org/EIPS/eip-2569">EIP-2569</a>.</p>
<ul>
<li>EIP-2569 is an Ethereum improvement proposal to allow a smart contract to save and retrieve an SVG image. Based on that, the two methods contract must have: <code>getTokenImageSvg(uint256) view returns (string memory)</code> and <code>setTokenImageSvg(uint256 tokenId, string memory imagesvg) internal</code>. As we can see, the potential flaw of function <code>setTokenImageSvg</code> as input parameter accepts SVG image string, which can lead to a considerable gas cost in case of complex SVG.</li>
</ul>
<p>There is no obstacle to the realization of any project that would require the evolution of NFT. Everything needed is that our contract overrides the <code>tokenURI</code> or <code>uri</code> function from ERC721 or ERC1155. Therefore, the precondition is that we have prepared all parameters variants for the dynamic generation of potential variants. The project specification itself decides which variants to return within it.</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span id="cb1-1">  <span class="kw" style="color: #003B4F;">function</span> <span class="fu" style="color: #4758AB;">tokenURI</span>(uint256 tokenId) <span class="kw" style="color: #003B4F;">public</span> view <span class="fu" style="color: #4758AB;">override</span>(ERC721) <span class="fu" style="color: #4758AB;">returns</span> (string memory) {</span>
<span id="cb1-2">    <span class="pp" style="color: #AD0000;">require</span>(<span class="fu" style="color: #4758AB;">_exists</span>(tokenId))<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb1-3">    <span class="cf" style="color: #003B4F;">return</span> <span class="fu" style="color: #4758AB;">generateDynamicNFT</span>(tokenId)<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb1-4">  }</span></code></pre></div>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span id="cb2-1">  <span class="kw" style="color: #003B4F;">function</span> <span class="fu" style="color: #4758AB;">uri</span>(uint256 tokenId) <span class="kw" style="color: #003B4F;">public</span> view <span class="fu" style="color: #4758AB;">override</span>(ERC1155) <span class="fu" style="color: #4758AB;">returns</span> (string memory) {</span>
<span id="cb2-2">    <span class="pp" style="color: #AD0000;">require</span>(<span class="fu" style="color: #4758AB;">_exists</span>(tokenId))<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb2-3">    <span class="cf" style="color: #003B4F;">return</span> <span class="fu" style="color: #4758AB;">generateDynamicNFT</span>(tokenId)<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb2-4">  }</span></code></pre></div>
<p>Inside <code>generateDynamicNFT</code>, the user defines how and under what conditions NFT to generate, usually using oracles.</p>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>This research has shown that it is possible to change the data and properties of NFTs, and the next evaluation in NFT is moving from static NFTs to dynamic NFTs. With dynamic NTFs, some use cases could be:</p>
<ul>
<li>An NFT ticket that could retain a value after the event is finished can turn as a discount for a related event or, as some bonus, gifts.</li>
<li>Sports NFT cards can evolve, such as updating their player’s stats or having a limited edition of sports event cards if the player got a super score in a match.</li>
<li>Sport NFT cards that receive bonuses or losses based on wins/losses.</li>
<li>Artist NFT cards that change on a daily/monthly based.</li>
<li>NFTs affected by social media/real-life events.</li>
<li>NFTs that affect the real world, where a user can receive a physical item in exchange for NFT.</li>
<li>Kata NFTs were on the users’ progress the Kata NFT will change.</li>
<li>Geometric shape that change as price change</li>
</ul>
<p>The only related problem is about on-chain storage assets. Most NFTs do not store their assets directly on the blockchain because the cost of keeping them on-chain is expensive, as every action and every byte of information we hold on the blockchain has a fee. In addition, the Ethereum blockchain is designed to keep a record of transactions and not to serve as a data warehouse. Second, on-chain geometrical arts can quickly present, but for the more complex SVG files, it is possible to use <em>the bottom-top</em> approach. The idea is to have one zero-based image as a base and then add traits dynamically to the base image. Where will store only characteristics on-chain, and the NFT image is created dynamically. On-chain storage reduces external dependence, increasing reliability, durability, ownership, and decentralization. Keeping assets on-chain has excellent value. Users can rely on the same guarantees of immutability they use to secure property ownership, and the value of such art is more significant. When the asset is being followed on the Ethereum, we also want that asset to be placed on the Ethereum somehow.</p>
</section>
<section id="bibliography" class="level1">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Bibliography</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-browneTradingNFTsSpiked2022" class="csl-entry">
Browne, Ryan, ‘Trading in NFTs Spiked 21,000% to More Than $17 Billion in 2021, Report Says’, <em>CNBC</em>, 2022 &lt;<a href="https://www.cnbc.com/2022/03/10/trading-in-nfts-spiked-21000percent-to-top-17-billion-in-2021-report.html" class="uri">https://www.cnbc.com/2022/03/10/trading-in-nfts-spiked-21000percent-to-top-17-billion-in-2021-report.html</a>&gt; [accessed 24 March 2022]
</div>
<div id="ref-LoopringZkRollupLayer2" class="csl-entry">
‘Loopring - <span class="nocase">zkRollup Layer2</span> for Trading and Payment’, <em>Loopring</em> &lt;<a href="https://loopring.org/#/" class="uri">https://loopring.org/#/</a>&gt; [accessed 24 March 2022]
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>‘Trading in NFTs Spiked 21,000% to More Than $17 Billion in 2021, Report Says’, <em>CNBC</em>, 2022 &lt;&lt;https://www.cnbc.com/2022/03/10/trading-in-nfts-spiked-21000percent-to-top-17-billion-in-2021-report.html&gt;&gt; [accessed 24 March 2022].↩︎</p></li>
<li id="fn2"><p><em>Loopring</em> &lt;&lt;https://loopring.org/#/&gt;&gt; [accessed 24 March 2022].↩︎</p></li>
</ol>
</section></div> ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-101.hugo.html</guid>
  <pubDate>Mon, 14 Mar 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Detect NFT Wash Trading</title>
  <dc:creator>Milos Bojinovic</dc:creator>
  <link>https://3327.io/documents/research/posts/ERFC-90.hugo.html</link>
  <description><![CDATA[ 




<section id="executive-summary" class="level1">
<h1>Executive Summary</h1>
<p>With the monthly trading volume of the <strong>Non-Fungible Token (NFT)</strong> marketplace <a href="https://opensea.io">OpenSea</a> reaching 5 billion dollars in January 2022<sup>1</sup> it is clear that NFTs are gaining popularity and with that grows the importance of having a transparent trading activity.</p>
<p><strong>Wash trading</strong> is a form of market manipulation where a single entity or a group of colluding entities buy and sell the same asset with the goal of feeding the marketplace misleading information<sup>2</sup>. There are at least two possible benefits to wash trading, the first being that a single asset can be wash traded multiple times, continually increasing the price, thus making the asset appear more sought after than it actually is. This chain of wash trades is broken when an unsuspecting victim buys the asset. The second potential benefit is that the trading can be incentivized by the platform, with rewards being tied to the volume traded. Trading rewards can, at least for a limited time period, be higher than the fees, which makes this process worthwhile.</p>
<p>In the case of NFTs, wash trading is additionally enabled by the associated user anonymity. One single entity can control a large number of addresses without a way of reliably determining who is behind them. Those addresses, however, need to be somehow funded to make them usable, which leads to a money trail that can be followed to detect connections between them and to flag suspicious NFT trades.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Currently, only <a href="https://nansen.ai">Nansen</a>, a blockchain analytics platform that requires a paid subscription, offers a feature called “Wash Trading Filter” where users can see the metrics (volume, average price, etc.) for an NFT collection with and without the filter but cannot browse through the individual NFTs. Another drawback is that Nansen doesn’t disclose how the filter works, and so the question of why some trades were flagged remains.</p>
<p>Data on the blockchain is public, but it is hard to extract specific pieces of information from it. Detecting if a particular NFT was wash traded would require collecting every single trade that was made on all of the marketplaces and checking if the addresses involved in it are connected in some way. This data would need to be safely stored and effectively parsed to enable answering if any arbitrarily chosen NFT has been wash traded. The detection algorithm should also provide adequate reasoning on why a specific trade has been flagged. Developing and publicly disclosing the inner workings of such an algorithm would add more transparency to NFT trading, but it would inevitably lead to the creation of more intricate patterns that would not get caught if the algorithm is not regularly updated.</p>
</section>
<section id="goals-methodology" class="level1">
<h1>Goals &amp; Methodology</h1>
<p><strong>The goals</strong> of this research are to :</p>
<ul>
<li>define what transaction patterns classify as a wash trade</li>
<li>develop ways of extracting the necessary information needed for the detection:
<ul>
<li>trades on two of the largest NFT marketplaces (OpenSea and <a href="https://looksrare.org/">LooksRare</a>)</li>
<li>Ether transfers for each of the accounts involved in the trade</li>
</ul></li>
<li>serve as a starting point for the creation of detection algorithms</li>
</ul>
<p><strong>Methodology</strong> for accomplishing those goals consists of</p>
<ul>
<li>taking into account only Ethereum’s on-chain transactions when discussing ways a wash trade can be made</li>
<li>using <a href="https://docs.etherscan.io/">Etherscan</a> and <a href="https://docs.alchemy.com/alchemy/">Alchemy</a> APIs to enable the data collection process</li>
<li>using Python programming language for the implementation part</li>
</ul>
</section>
<section id="results-discussion" class="level1">
<h1>Results &amp; Discussion</h1>
<section id="wash-trading-patterns" class="level3">
<h3 class="anchored" data-anchor-id="wash-trading-patterns">Wash Trading Patterns</h3>
<p>The explanation for the diagrams used in this paper is the following:</p>
<ul>
<li>White circles with a letter inside them are addresses that are considered</li>
<li>Address can be connected with multiple lines</li>
<li>The line that has the <strong>NFT</strong> written on it signals that those two addresses were involved in an NFT trade</li>
<li>The line containing a number <strong>n</strong> on it signals that exists an Ether transfer trail between those addresses through <strong>n</strong> intermediaries
<ul>
<li>if <strong>n</strong> = 0 that is a direct transfer</li>
<li>if <strong>n</strong> = 1 there is a transfer trail involving one intermediary address</li>
</ul></li>
<li>Lines with an arrow care about the direction of a transfer and point to the new owner’s address</li>
<li>Lines without an arrow do not care about the direction</li>
</ul>
<p>Shown on <em>Figure 1</em> there are two “meta-patterns” that this paper considers.</p>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://3327.io/documents/research/assets/ERFC-90/images/meta-patterns.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">meta-patterns</figcaption><p></p>
</figure>
</div>
<p><em>Figure 1 - Considered Meta-patterns</em></p>
</center>
<p>Meta-patterns can be expanded into specific patterns that care about the direction of those transfers (<em>Figure 2</em>). While some patterns may be more suspicious than others, all of them can be used for the purpose of wash trading. For example <em>pattern 2.2</em> can mean that after making a wash trade and selling the NFT to someone else, addresses <strong>A</strong> and <strong>B</strong> send all of their funds to address <strong>C</strong>.</p>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://3327.io/documents/research/assets/ERFC-90/images/expanded-patterns.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">expanded-patterns</figcaption><p></p>
</figure>
</div>
<p><em>Figure 2 - Expanded patterns</em></p>
</center>
<p>The reason that all of these patterns do not take the time order of transfers into account is that it doesn’t matter - they need to detect only the connections between addresses.</p>
</section>
<section id="collecting-and-parsing-of-data" class="level2">
<h2 class="anchored" data-anchor-id="collecting-and-parsing-of-data">Collecting and Parsing of Data</h2>
<p>This research takes into account only trades of NFTs that follow the ERC721 standard. The same principles can be applied to the trades involving the ERC1155 standard, with the only difference being the collection and parsing of trades.</p>
<p>When an NFT trade is executed, the ERC721 compliant contracts emit a <strong>Transfer event</strong> that contains three fields: previous owner, new owner, and the token id. Using the combination of Etherscan and Alchemy APIs, it is possible to get all the events that were emitted by the transaction and to extract the needed event based on its topic along with all of its fields.</p>
<p>Not every Transfer event corresponds to a trade, so there needs to be an extra processing step that will eliminate all transfers that were not made through a marketplace. To do this, one needs to go through all of the marketplace’s contract’s transactions and select only those that have the right <strong>methodID</strong>.</p>
<p>After the seller’s (previous owner’s) and buyer’s (new owner’s) addresses are known, the last step is collecting and parsing of all of their transactions searching for Ether transfers and all the addresses they have interacted with - in this paper referred to as “associates”.</p>
</section>
<section id="wash-trading-detectors" class="level2">
<h2 class="anchored" data-anchor-id="wash-trading-detectors">Wash Trading Detectors</h2>
<p>Having a set of all of the buyer’s and seller’s associates enables the creation of <strong>Wash Trading Detectors (WTD)</strong>. This paper proposes and implements two basic algorithms:</p>
<ul>
<li><strong>WTD0</strong> that detects a direct transfer by checking if the seller’s address belongs to the set of buyer’s associates</li>
<li><strong>WTD1*</strong> that detects a set of common associates that are Externally Owned Accounts (EOAs)</li>
</ul>
<p>*WTD1 is incomplete because the detected common associate can be a Centralized Exchange’s (CEX) address which would give a false positive. The only way to make the WTD1 fully functional is to manually keep a list of all the addresses that should be ignored.</p>
</section>
<section id="implementation" class="level2">
<h2 class="anchored" data-anchor-id="implementation">Implementation</h2>
<p>Using the proposed ways of getting the data and reasoning on it, it is possible to extract suspicious wash trading patterns, flag those trades, and perform an analysis of the results. The code shown bellow is capable of getting the count of detected wash trades performed through a marketplace in a given block range :</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> utils</span>
<span id="cb1-2"></span>
<span id="cb1-3"><span class="kw" style="color: #003B4F;">def</span> run(contract, methodIds, start_block, end_block):</span>
<span id="cb1-4">    <span class="co" style="color: #5E5E5E;">'''Detects potential Wash trades for a marketplace's contract'''</span></span>
<span id="cb1-5"></span>
<span id="cb1-6">    transactions <span class="op" style="color: #5E5E5E;">=</span> utils.get_all_transactions(</span>
<span id="cb1-7">        contract,</span>
<span id="cb1-8">        start_block,</span>
<span id="cb1-9">        end_block</span>
<span id="cb1-10">    )</span>
<span id="cb1-11"></span>
<span id="cb1-12">    wtd0_count, wtd1_count, total <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb1-13"></span>
<span id="cb1-14">    <span class="cf" style="color: #003B4F;">for</span>  tx <span class="kw" style="color: #003B4F;">in</span> transactions:</span>
<span id="cb1-15"></span>
<span id="cb1-16">        <span class="cf" style="color: #003B4F;">if</span> tx[<span class="st" style="color: #20794D;">'input'</span>][:<span class="dv" style="color: #AD0000;">10</span>] <span class="kw" style="color: #003B4F;">in</span> methodIds:</span>
<span id="cb1-17"></span>
<span id="cb1-18">            status, logs <span class="op" style="color: #5E5E5E;">=</span> utils.get_logs(tx[<span class="st" style="color: #20794D;">'hash'</span>])</span>
<span id="cb1-19"></span>
<span id="cb1-20">            <span class="cf" style="color: #003B4F;">if</span> status <span class="op" style="color: #5E5E5E;">!=</span> <span class="dv" style="color: #AD0000;">1</span>: <span class="co" style="color: #5E5E5E;"># Reverted transaction</span></span>
<span id="cb1-21">                <span class="cf" style="color: #003B4F;">continue</span></span>
<span id="cb1-22"></span>
<span id="cb1-23">            nft_contract, token_id, A, B <span class="op" style="color: #5E5E5E;">=</span> utils.parse_logs(logs)</span>
<span id="cb1-24"></span>
<span id="cb1-25">            <span class="cf" style="color: #003B4F;">if</span> A <span class="op" style="color: #5E5E5E;">==</span> <span class="va" style="color: #111111;">None</span> <span class="kw" style="color: #003B4F;">or</span> B <span class="op" style="color: #5E5E5E;">==</span> <span class="va" style="color: #111111;">None</span>: <span class="co" style="color: #5E5E5E;"># not a standard ERC721</span></span>
<span id="cb1-26">                <span class="cf" style="color: #003B4F;">continue</span></span>
<span id="cb1-27"></span>
<span id="cb1-28">            associates_A <span class="op" style="color: #5E5E5E;">=</span> utils.get_associates(A)</span>
<span id="cb1-29">            associates_B <span class="op" style="color: #5E5E5E;">=</span> utils.get_associates(B)</span>
<span id="cb1-30"></span>
<span id="cb1-31">            wtd0_count <span class="op" style="color: #5E5E5E;">+=</span> <span class="bu" style="color: null;">int</span>(</span>
<span id="cb1-32">                utils.wtd0(A, B, associates_A, associates_B)</span>
<span id="cb1-33">            )</span>
<span id="cb1-34">            wtd1_count <span class="op" style="color: #5E5E5E;">+=</span> <span class="bu" style="color: null;">int</span>(</span>
<span id="cb1-35">                <span class="bu" style="color: null;">len</span>(utils.wtd1(A, B, associates_A, associates_B)) <span class="op" style="color: #5E5E5E;">&gt;</span> <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb1-36">            )</span>
<span id="cb1-37"></span>
<span id="cb1-38">            total <span class="op" style="color: #5E5E5E;">+=</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb1-39"></span>
<span id="cb1-40">    <span class="cf" style="color: #003B4F;">return</span> (wtd0_count, wtd1_count, total)</span></code></pre></div>
<p>The <code>run</code> function consists of getting all transaction data for a marketplace’s contract starting from the <code>start_block</code> up to the <code>end_block</code> and considering only those that are in the provided list of <code>methodIds</code>. These transactions are then parsed, and values are extracted that will be passed to the <code>utils.wtd0</code> and <code>utils.wtd1</code> functions which will perform detection.</p>
<p>For the full implementation of all of the used helper methods from <code>utils</code> module see Appendix A.</p>
<section id="example" class="level3">
<h3 class="anchored" data-anchor-id="example">Example</h3>
<p>For example, let us take the <a href="https://etherscan.io/address/0x7Be8076f4EA4A4AD08075C2508e481d6C946D12b">OpenSea’s Wyvern V1 contract</a> and pass three different block ranges. The <code>['0xab834bab']</code> argument corresponds to the <code>methodID</code> of the contract’s method that gets called when there is a trade.</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1">WYVERN_V1 <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'0x7Be8076f4EA4A4AD08075C2508e481d6C946D12b'</span></span>
<span id="cb2-2"></span>
<span id="cb2-3">ranges <span class="op" style="color: #5E5E5E;">=</span> [</span>
<span id="cb2-4">    [<span class="dv" style="color: #AD0000;">6652089</span>, <span class="dv" style="color: #AD0000;">6652239</span>],</span>
<span id="cb2-5">    [<span class="dv" style="color: #AD0000;">7486211</span>, <span class="dv" style="color: #AD0000;">7486311</span>],</span>
<span id="cb2-6">    [<span class="dv" style="color: #AD0000;">7704798</span>, <span class="dv" style="color: #AD0000;">7704898</span>],</span>
<span id="cb2-7">]</span>
<span id="cb2-8"></span>
<span id="cb2-9"><span class="cf" style="color: #003B4F;">for</span> start_block, end_block <span class="kw" style="color: #003B4F;">in</span> ranges:</span>
<span id="cb2-10"></span>
<span id="cb2-11">    <span class="bu" style="color: null;">print</span>(run(WYVERN_V1, [<span class="st" style="color: #20794D;">'0xab834bab'</span>], start_block, end_block))</span></code></pre></div>
<p>From the total of <strong>23</strong> trades that were made during the provided ranges :</p>
<ul>
<li>WTD0 flags <strong>8</strong> trades</li>
<li>WTD1 flags <strong>11**</strong> trades</li>
</ul>
<p>**WTD1 returns a list of associate addresses; these lists were manually checked through Etherscan to see if they belong to a CEX. The list of ignored addresses is available in Appendix B.</p>
</section>
<section id="implications" class="level3">
<h3 class="anchored" data-anchor-id="implications">Implications</h3>
<p>The sample size of <strong>23</strong> is too small to discuss how the reported numbers relate to all of the NFT trades since the marketplace’s contract deployment. The code itself can, however, serve as a starting point for the development of a service capable of extracting the data from all of the NFT marketplaces since their creation. In that data lies the key to answering not only what trades are a wash trade but also who performed them, how many times was an address linked to a wash trade, whether one NFT has been wash traded multiple times, etc. Such a service would need to effectively manage its resources such as the collection of data and the computation needed in the detection - in the example above, set of associates is always computed from scratch (there is no storing of the result and checking if those values have already been computed). The full specification for the development of this service is out of the scope of this paper and should be a topic of a separate research.</p>
<section id="complex-patterns" class="level4">
<h4 class="anchored" data-anchor-id="complex-patterns">Complex Patterns</h4>
<p>Due to current non-negligible transaction fees on Ethereum and the fact that not many people are deeply looking into each trade, it is unlikely that there are complex patterns present in NFT wash trading. As the fees get lower and as the adoption grows, it’s almost certain that they will emerge. On the <em>Figure 3</em> is shown one pattern that could be used in the process of wash trading.</p>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://3327.io/documents/research/assets/ERFC-90/images/complex-pattern.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">complex-pattern</figcaption><p></p>
</figure>
</div>
<p><em>Figure 3 - Complex pattern</em></p>
</center>
<p>There are two NFT wash trades present (marked by the black and blue colored arrows). The sequence of transfers is the following:</p>
<ol type="1">
<li><strong>A</strong> finances <strong>B</strong> and <strong>C</strong> through 3 and 2 intermediaries, respectively</li>
<li><strong>B</strong> finances <strong>D</strong> through 3 intermediaries</li>
<li><strong>D</strong> buys an NFT from some non-associated address</li>
<li><strong>D</strong> sells the NFT to <strong>C</strong></li>
<li><strong>D</strong> sends the funds to <strong>B</strong> through the same 3 intermediaries that were used before</li>
<li><strong>B</strong> finances <strong>E</strong> through 2 intermediaries</li>
<li><strong>E</strong> buys the NFT from <strong>C</strong></li>
</ol>
<p>After the last step, <strong>E</strong> can sell the NFT to an unsuspecting victim. It is important to note that addresses used do not have to be discarded after each wash trade - i.e.&nbsp;<strong>B</strong> can be used just for routing of the funds. Furthermore, a malevolent entity can inflate the prices of not just a single NFT but for a complete collection, making it look like the collection is very popular, which attracts victims.</p>
</section>
</section>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>This research shows that it is possible to flag a specific trade as being a wash trade. The proposed algorithms can serve as a starting point in this process. To flag a specific NFT as being wash traded there would need to exist a list of all the trades of that NFT. This could be done via a service that would enable the users to browse the history of trades of any NFT on every marketplace and see all of the connections between the addresses that once owned it. If the service is built and popularized while keeping its inner workings public, the malevolent parties would try to evade detection which would lead to the need to constantly improve the algorithm.</p>
</section>
<section id="appendices" class="level1">
<h1>Appendices</h1>
<section id="appendix-a" class="level2">
<h2 class="anchored" data-anchor-id="appendix-a">Appendix A</h2>
<p>Implementation of the <code>utils</code> module.</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;">import</span> time, json, requests</span>
<span id="cb3-2"><span class="im" style="color: #00769E;">from</span> web3 <span class="im" style="color: #00769E;">import</span> Web3</span>
<span id="cb3-3"></span>
<span id="cb3-4">config <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb3-5">    <span class="st" style="color: #20794D;">"alchemy-url"</span> : <span class="st" style="color: #20794D;">""</span>,</span>
<span id="cb3-6">    <span class="st" style="color: #20794D;">"etherscan-api-key"</span>: <span class="st" style="color: #20794D;">""</span>,</span>
<span id="cb3-7">}</span>
<span id="cb3-8"></span>
<span id="cb3-9">web3 <span class="op" style="color: #5E5E5E;">=</span> Web3(Web3.HTTPProvider(config[<span class="st" style="color: #20794D;">'alchemy-url'</span>]))</span>
<span id="cb3-10"></span>
<span id="cb3-11"><span class="kw" style="color: #003B4F;">def</span> get_all_transactions(address, start_block <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span>, end_block <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">19999999</span>):</span>
<span id="cb3-12">    <span class="co" style="color: #5E5E5E;">'''Gets all transactions using Etherscan API for the provided address'''</span></span>
<span id="cb3-13">    transactions <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb3-14"></span>
<span id="cb3-15">    <span class="cf" style="color: #003B4F;">while</span> <span class="va" style="color: #111111;">True</span>:</span>
<span id="cb3-16">        time.sleep(<span class="dv" style="color: #AD0000;">5</span>)</span>
<span id="cb3-17">        result <span class="op" style="color: #5E5E5E;">=</span> requests.get(</span>
<span id="cb3-18">            <span class="st" style="color: #20794D;">'https://api.etherscan.io/api?module=account&amp;action=txlist'</span> <span class="op" style="color: #5E5E5E;">+</span></span>
<span id="cb3-19">            <span class="ss" style="color: #20794D;">f'&amp;address=</span><span class="sc" style="color: #5E5E5E;">{</span>address<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span> <span class="op" style="color: #5E5E5E;">+</span></span>
<span id="cb3-20">            <span class="ss" style="color: #20794D;">f'&amp;startblock=</span><span class="sc" style="color: #5E5E5E;">{</span>start_block<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span> <span class="op" style="color: #5E5E5E;">+</span></span>
<span id="cb3-21">            <span class="ss" style="color: #20794D;">f'&amp;endblock=</span><span class="sc" style="color: #5E5E5E;">{</span>end_block<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span> <span class="op" style="color: #5E5E5E;">+</span></span>
<span id="cb3-22">            <span class="ss" style="color: #20794D;">f'&amp;offset=</span><span class="sc" style="color: #5E5E5E;">{</span><span class="dv" style="color: #AD0000;">1_000</span><span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span> <span class="op" style="color: #5E5E5E;">+</span></span>
<span id="cb3-23">            <span class="ss" style="color: #20794D;">f'&amp;sort=</span><span class="sc" style="color: #5E5E5E;">{</span><span class="st" style="color: #20794D;">"asc"</span><span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span> <span class="op" style="color: #5E5E5E;">+</span></span>
<span id="cb3-24">            <span class="ss" style="color: #20794D;">f'apikey=</span><span class="sc" style="color: #5E5E5E;">{</span>config[<span class="st" style="color: #20794D;">"etherscan-api-key"</span>]<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span></span>
<span id="cb3-25">        ).json()[<span class="st" style="color: #20794D;">'result'</span>]</span>
<span id="cb3-26"></span>
<span id="cb3-27">        transactions <span class="op" style="color: #5E5E5E;">+=</span> result</span>
<span id="cb3-28"></span>
<span id="cb3-29">        <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">len</span>(result) <span class="op" style="color: #5E5E5E;">&lt;</span> <span class="dv" style="color: #AD0000;">1_000</span>:</span>
<span id="cb3-30">            <span class="cf" style="color: #003B4F;">break</span></span>
<span id="cb3-31"></span>
<span id="cb3-32">        start_block <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">int</span>(result[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>][<span class="st" style="color: #20794D;">"blockNumber"</span>]) <span class="op" style="color: #5E5E5E;">+</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb3-33"></span>
<span id="cb3-34"></span>
<span id="cb3-35">    <span class="cf" style="color: #003B4F;">return</span> transactions</span>
<span id="cb3-36"></span>
<span id="cb3-37"><span class="kw" style="color: #003B4F;">def</span> is_EOA(address):</span>
<span id="cb3-38">    <span class="co" style="color: #5E5E5E;">'''Returns true if the address belongs to an Externally Owned Account'''</span></span>
<span id="cb3-39"></span>
<span id="cb3-40">    <span class="cf" style="color: #003B4F;">try</span>:</span>
<span id="cb3-41">        _address <span class="op" style="color: #5E5E5E;">=</span> Web3.toChecksumAddress(address)</span>
<span id="cb3-42">        <span class="cf" style="color: #003B4F;">return</span> web3.eth.getCode(_address) <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">b""</span></span>
<span id="cb3-43">    <span class="cf" style="color: #003B4F;">except</span>:</span>
<span id="cb3-44">        <span class="cf" style="color: #003B4F;">return</span> <span class="va" style="color: #111111;">False</span></span>
<span id="cb3-45"></span>
<span id="cb3-46"><span class="kw" style="color: #003B4F;">def</span> get_associates(address):</span>
<span id="cb3-47">    <span class="co" style="color: #5E5E5E;">'''Returns a set of all account with which the provided addresses interacted with'''</span></span>
<span id="cb3-48"></span>
<span id="cb3-49">    transactions <span class="op" style="color: #5E5E5E;">=</span> get_all_transactions(address)</span>
<span id="cb3-50"></span>
<span id="cb3-51">    associates <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">set</span>()</span>
<span id="cb3-52">    <span class="cf" style="color: #003B4F;">for</span> tx <span class="kw" style="color: #003B4F;">in</span> transactions:</span>
<span id="cb3-53">        <span class="cf" style="color: #003B4F;">if</span> tx[<span class="st" style="color: #20794D;">'from'</span>] <span class="op" style="color: #5E5E5E;">!=</span> address:</span>
<span id="cb3-54">            associates.update([tx[<span class="st" style="color: #20794D;">'from'</span>]])</span>
<span id="cb3-55">        <span class="cf" style="color: #003B4F;">if</span> tx[<span class="st" style="color: #20794D;">'to'</span>] <span class="op" style="color: #5E5E5E;">!=</span> address:</span>
<span id="cb3-56">            associates.update([tx[<span class="st" style="color: #20794D;">'to'</span>]])</span>
<span id="cb3-57"></span>
<span id="cb3-58">    <span class="cf" style="color: #003B4F;">return</span> associates</span>
<span id="cb3-59"></span>
<span id="cb3-60"><span class="kw" style="color: #003B4F;">def</span> get_logs(tx_hash):</span>
<span id="cb3-61">    <span class="co" style="color: #5E5E5E;">'''Gets the logs from the transaction receipt of the tx_hash'''</span></span>
<span id="cb3-62"></span>
<span id="cb3-63">    tx_receipt <span class="op" style="color: #5E5E5E;">=</span> web3.eth.get_transaction_receipt(tx_hash)</span>
<span id="cb3-64"></span>
<span id="cb3-65">    <span class="cf" style="color: #003B4F;">return</span> tx_receipt[<span class="st" style="color: #20794D;">'status'</span>], tx_receipt[<span class="st" style="color: #20794D;">'logs'</span>]</span>
<span id="cb3-66"></span>
<span id="cb3-67"><span class="kw" style="color: #003B4F;">def</span> parse_logs(logs):</span>
<span id="cb3-68">    <span class="co" style="color: #5E5E5E;">'''Returns the NFT contract's address, token id and addresses involved in the trade'''</span></span>
<span id="cb3-69"></span>
<span id="cb3-70">    TRANSFER_TOPIC <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef"</span></span>
<span id="cb3-71">    WRAPPED_ETH <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"0xC02aaA39b223FE8D0A0e5C4F27eAD9083C756Cc2"</span></span>
<span id="cb3-72"></span>
<span id="cb3-73">    nft_contracts, token_ids, _from, _to <span class="op" style="color: #5E5E5E;">=</span> [], [], <span class="va" style="color: #111111;">None</span>, <span class="va" style="color: #111111;">None</span></span>
<span id="cb3-74"></span>
<span id="cb3-75">    <span class="cf" style="color: #003B4F;">for</span> ev <span class="kw" style="color: #003B4F;">in</span> logs:</span>
<span id="cb3-76"></span>
<span id="cb3-77">        <span class="cf" style="color: #003B4F;">if</span> TRANSFER_TOPIC <span class="op" style="color: #5E5E5E;">==</span> ev[<span class="st" style="color: #20794D;">"topics"</span>][<span class="dv" style="color: #AD0000;">0</span>].<span class="bu" style="color: null;">hex</span>() <span class="kw" style="color: #003B4F;">and</span> ev[<span class="st" style="color: #20794D;">"address"</span>] <span class="op" style="color: #5E5E5E;">!=</span> WRAPPED_ETH:</span>
<span id="cb3-78"></span>
<span id="cb3-79">            nft_contracts.append(ev[<span class="st" style="color: #20794D;">"address"</span>])</span>
<span id="cb3-80"></span>
<span id="cb3-81">            bytecode <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">""</span>.join([x.<span class="bu" style="color: null;">hex</span>() <span class="cf" style="color: #003B4F;">for</span> x <span class="kw" style="color: #003B4F;">in</span> ev[<span class="st" style="color: #20794D;">"topics"</span>]]) <span class="op" style="color: #5E5E5E;">+</span> <span class="st" style="color: #20794D;">""</span>.join(ev[<span class="st" style="color: #20794D;">"data"</span>])</span>
<span id="cb3-82">            _from <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"0x"</span> <span class="op" style="color: #5E5E5E;">+</span> bytecode[<span class="dv" style="color: #AD0000;">66</span> : <span class="dv" style="color: #AD0000;">66</span> <span class="op" style="color: #5E5E5E;">*</span> <span class="dv" style="color: #AD0000;">2</span>][<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">40</span>:]</span>
<span id="cb3-83">            _to <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"0x"</span> <span class="op" style="color: #5E5E5E;">+</span> bytecode[<span class="dv" style="color: #AD0000;">66</span> <span class="op" style="color: #5E5E5E;">*</span> <span class="dv" style="color: #AD0000;">2</span> : <span class="dv" style="color: #AD0000;">66</span> <span class="op" style="color: #5E5E5E;">*</span> <span class="dv" style="color: #AD0000;">3</span>][<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">40</span>:]</span>
<span id="cb3-84">            token_ids.append(<span class="bu" style="color: null;">int</span>(bytecode[<span class="dv" style="color: #AD0000;">66</span> <span class="op" style="color: #5E5E5E;">*</span> <span class="dv" style="color: #AD0000;">3</span> : <span class="dv" style="color: #AD0000;">66</span> <span class="op" style="color: #5E5E5E;">*</span> <span class="dv" style="color: #AD0000;">4</span>][<span class="dv" style="color: #AD0000;">2</span>:<span class="dv" style="color: #AD0000;">66</span>], base<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">16</span>))</span>
<span id="cb3-85"></span>
<span id="cb3-86">    <span class="cf" style="color: #003B4F;">return</span> nft_contracts, token_ids, _from, _to</span>
<span id="cb3-87"></span>
<span id="cb3-88"></span>
<span id="cb3-89"><span class="kw" style="color: #003B4F;">def</span> wtd0(A, B, associates_A, associates_B):</span>
<span id="cb3-90">    <span class="co" style="color: #5E5E5E;">'''WTD0 implementation'''</span></span>
<span id="cb3-91"></span>
<span id="cb3-92">    <span class="cf" style="color: #003B4F;">return</span> (A <span class="kw" style="color: #003B4F;">in</span> associates_B) <span class="kw" style="color: #003B4F;">or</span> (B <span class="kw" style="color: #003B4F;">in</span> associates_A)</span>
<span id="cb3-93"></span>
<span id="cb3-94"><span class="kw" style="color: #003B4F;">def</span> wtd1(A, B, associates_A, associates_B):</span>
<span id="cb3-95">    <span class="co" style="color: #5E5E5E;">'''WTD1 implementation'''</span></span>
<span id="cb3-96"></span>
<span id="cb3-97">    EOA_associates <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb3-98"></span>
<span id="cb3-99">    common_associates <span class="op" style="color: #5E5E5E;">=</span> associates_A.intersection(associates_B)</span>
<span id="cb3-100">    <span class="cf" style="color: #003B4F;">for</span> ca <span class="kw" style="color: #003B4F;">in</span> common_associates:</span>
<span id="cb3-101">        <span class="cf" style="color: #003B4F;">if</span> is_EOA(ca):</span>
<span id="cb3-102">            EOA_associates.append(ca)</span>
<span id="cb3-103"></span>
<span id="cb3-104">    <span class="cf" style="color: #003B4F;">return</span> EOA_associates</span></code></pre></div>
</section>
<section id="appendix-b" class="level2">
<h2 class="anchored" data-anchor-id="appendix-b">Appendix B</h2>
<p>Following is the list of all the addresses that were ignored by WTD1 due to the fact that they belong to CEXs</p>
<center>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Address</th>
<th style="text-align: center;">CEX</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">0x564286362092d8e7936f0549571a803b203aaced</td>
<td style="text-align: center;">Binance3</td>
</tr>
<tr class="even">
<td style="text-align: center;">0x59a5208b32e627891c389ebafc644145224006e8</td>
<td style="text-align: center;">HitBTC2</td>
</tr>
<tr class="odd">
<td style="text-align: center;">0x56eddb7aa87536c09ccc2793473599fd21a8b17f</td>
<td style="text-align: center;">Binance17</td>
</tr>
<tr class="even">
<td style="text-align: center;">0xeb2629a2734e272bcc07bda959863f316f4bd4cf</td>
<td style="text-align: center;">Coinbase6</td>
</tr>
<tr class="odd">
<td style="text-align: center;">0xd551234ae421e3bcba99a0da6d736074f22192ff</td>
<td style="text-align: center;">Binance2</td>
</tr>
<tr class="even">
<td style="text-align: center;">0xb5d85cbf7cb3ee0d56b3bb207d5fc4b82f43f511</td>
<td style="text-align: center;">Coinbase5</td>
</tr>
<tr class="odd">
<td style="text-align: center;">0x0681d8db095565fe8a346fa0277bffde9c0edbbf</td>
<td style="text-align: center;">Binance4</td>
</tr>
<tr class="even">
<td style="text-align: center;">0x3f5ce5fbfe3e9af3971dd833d26ba9b5c936f0be</td>
<td style="text-align: center;">Binance</td>
</tr>
</tbody>
</table>
</center>
</section>
</section>
<section id="bibliography" class="level1">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Bibliography</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-haywardOpenSeaHitsRecord2022" class="csl-entry">
Hayward, Decrypt / Andrew, ‘OpenSea Hits Record $5b in Monthly Sales as Ethereum NFT Market Swells’, <em>Decrypt</em>, 2022 &lt;<a href="https://decrypt.co/91748/opensea-record-5b-ethereum-nft-market-swells" class="uri">https://decrypt.co/91748/opensea-record-5b-ethereum-nft-market-swells</a>&gt; [accessed 13 March 2022]
</div>
<div id="ref-WashTradingDefinition" class="csl-entry">
‘Wash Trading Definition’, <em>Investopedia</em> &lt;<a href="https://www.investopedia.com/terms/w/washtrading.asp" class="uri">https://www.investopedia.com/terms/w/washtrading.asp</a>&gt; [accessed 21 March 2022]
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Decrypt / Andrew Hayward, ‘OpenSea Hits Record $5b in Monthly Sales as Ethereum NFT Market Swells’, <em>Decrypt</em>, 2022 &lt;&lt;https://decrypt.co/91748/opensea-record-5b-ethereum-nft-market-swells&gt;&gt; [accessed 13 March 2022].↩︎</p></li>
<li id="fn2"><p>‘Wash Trading Definition’, <em>Investopedia</em> &lt;&lt;https://www.investopedia.com/terms/w/washtrading.asp&gt;&gt; [accessed 21 March 2022].↩︎</p></li>
</ol>
</section></div> ]]></description>
  <guid>https://3327.io/documents/research/posts/ERFC-90.hugo.html</guid>
  <pubDate>Sat, 12 Mar 2022 00:00:00 GMT</pubDate>
  <media:content url="https://3327.io/documents/research/assets/ERFC-90/images/meta-patterns.png" medium="image" type="image/png" height="35" width="144"/>
</item>
</channel>
</rss>
